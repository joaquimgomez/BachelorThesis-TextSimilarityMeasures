
























































A Vision of Bringing Immersive Visualization to Scientific Workflows


A Vision of Bringing Immersive
Visualization to Scientific Workflows

Xiyao Wang
Inria
France
xiyao.wang23@gmail.com

Lonni Besançon
Linköping University
Sweden
lonni.besancon@gmail.com

Florimond Guéniat
Birmingham City University
UK
florimond.gueniat@bcu.ac.uk

Mickaël Sereno
Inria
France
mickael.sereno@inria.fr

Mehdi Ammi
University of Paris 8
France
ammi@ai.univ-paris8.fr

Tobias Isenberg
Inria
France
tobias.isenberg@inria.fr

ABSTRACT
The process of data exploration is becoming an essential part of today’s scientific workflows. A large
number of immersive visualization environments are being explored to help researchers and experts
to better understand the data and to offer intuitive interaction. Despite these benefits, shown by prior
research, it is still uncommon to find them being applied to realistic scientific workflows. We argue
that immersive visualization techniques will not be adopted until they can be easily integrated in the
workflow of domain experts, and that specific efforts should be made to help the integration of novel
and immersive visualization techniques with classically used software.

KEYWORDS
Immersive Analytics; Visualization; Interaction; Applications;

INTRODUCTION
In many practical application domains for visualization, the size of the used datasets grows tremen-
dously. For example in high-energy physics, even after eliminating noisy and useless data, a typical

CHI-IA 2019, May 2019, Glasgow, UK
© 2019 Association for Computing Machinery.
This is the author’s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of
Record was published in Proceedings of CHI 2019 Workshop on Immersive Analytics (CHI-IA 2019), https://doi.org/10.475/123_4.

https://doi.org/10.475/123_4


A Vision of Bringing Immersive Visualization to Scientific Workflows CHI-IA 2019, May 2019, Glasgow, UK

collision experiment generates more than 10, 000 new particle trajectories, each of them composed of
dozens of points and each with spatial position and energy information. The physicists then analyze
this massive data to find out strange outliers, with trajectories that are hard to explain by current
physic theories. As another example, in fluid mechanics, researchers in academia and industry inves-
tigate multiple fields, for instance, velocity, pressure, concentration or temperature (to understand,
e. g., combustion, understanding global warming, weather forecasting, flood risks). Multiple fields for
time-dependent data are usually a few gigabytes large and can easily grow up to the terabyte range.

Flow data example:
Even with only 128 points per direction
of space, the final grid will have, in 3D,
1283 = 2097152 nodes. Outputs of simula-
tions are multiple, making one snapshot
3 to 10+ times larger than the grid. Fluid
mechanics is unsteady, it means that, com-
monly, thousands of snapshots are saved.
As a consequence, saved data are, for the
present illustration, larger than 6GiB. Also,
if the number of points per direction is sim-
ply doubled, then the size of the data is
multiplied by a factor of 8.

For research and engineering purposes, the exploration and analysis of data are thus becoming piv-
otal processes. In recent years and decades, various innovative interactive visualization environments,
for example, the Responsive Workbench [12], occluded virtual reality (VR) glasses, and CAVE virtual
environment [6], appeal to offer a better feeling of being visually immersed inside the data compared
to traditional 2D screens. With such environments, it has been widely recognized in the literature
that visualization enlightens users’ understanding of and facilitate the interaction with the large and
complex data. Many prior work argued that scientific data exploration tasks could take benefits of
them (e. g., [2, 3]). However, in reality, they are rarely applied to scientific workflows.
In contrast to such purely VR visualization environments, previous literature (e. g., [1, 10, 11])

described a vision that desktops will not be totally replaced by such innovative visualization envi-
ronments but rather be combined with others to make use of each environments and their inherent
benefits. Here we further discuss this vision with a focus on scientific workflows. First we discuss
the usage and benefits of immersive visualization for complex data exploration. Then, through our
communication with researchers and a short analysis of related work, we expose why they are still
not adopted by researchers. We emphasize the need to focus our effort in the visualization and
HCI community towards combining and integrating immersive technologies with classical desktop
workstations and software to benefit from Hybrid Virtual Environments (HVEs) for visualization
purposes. Finally, we conclude our near-future research agenda highlighting several challenges for
the interaction design in such hybrid environments.

IMMERSIVE VISUALIZATION FOR SCIENTIFIC DATA EXPLORATION
Using immersive environments for data exploration has been envisioned for a long time. Bryson
[3], for example, explained that 3D VR environments and scientific visualization naturally match,
not only because of the spatial proprieties of scientific data, but also the potential of real-world
interactions leveraged by this combination. Early evaluation (e. g., [18]) concluded that visualization
in stereoscopic view usually facilitates the understanding of complex line cluster and network graphs.
Many recent work also confirms the advantages of immersive visualizations. For instance, Prabhat et al.
[16] compared the performance of biological volume data exploration tasks in three environments.
The environment with the highest immersion yielded the best results for both users’ preference and



A Vision of Bringing Immersive Visualization to Scientific Workflows CHI-IA 2019, May 2019, Glasgow, UK

performance of understanding spatial relationship. Usher et al. [20] explored the use VR environments
and 3D interaction techniques for experts to trace neural circuits in brain, finding this system effective
and less frustrating compared to traditional tools. They argued that scientists are able to understand
large and complex cases better with such setting. Hurter et al. [8] designed FiberClay, a system that
visualizes massive 3D airplane trajectories through occluded VR glasses. They mention that thanks to
their system, domain experts were able to discover new interesting patterns in the data, therefore
concluding that such immersive systems have benefits for the data sense-making process. A recent
survey [7, 15] also summarized many possible advantages brought by immersive analytics, including
the possibilities of offering situated/embodied data exploration, spatial immersion, and collaboration.
Based on the literature, it therefore seems that immersive visualization systems combined with 3D
spatial input has benefits for data exploration and understanding.

LIMITATIONS OF IMMERSIVE ENVIRONMENTS FOR SCIENTIFIC WORKFLOWS
Despite the benefits offered by different immersive environments, and despite the fact that such
environments are gaining popularity in many different areas (for example, augmented reality (AR)
and VR systems have been already much used in education, art and tourism), it is hard to find
them practically applied and integrated into real scientific and engineering workflows. Indeed, some
inherent technical problems of the environments themselves, for instance possible occlusion, remain.
However, based on the feedback and observations from domain experts, we believe that the adoption
of immersive visualization environments are not only hold back by these fundamental reasons.
Consequently, in this section, we quickly survey findings from the literature that highlight the
limited rate of adoption of immersive technologies, before reporting the limitations of such immersive
environments from experts’ observations.

Limitations from the literature
One reason is that scientific work usually requires dense real-time computations [10]. Small and
portable device cannot proper handle it, while large environment (like wall-sized screen and CAVE)
has complicated setup and usually requires additional technique supports which limits their usage
in laboratories. The need of constant calibration and maintenance is also a major drawback in such
workflows. Apart from that, although many studies pointed out that visual analysis helps researchers
and engineers to understand their data, scientific workflows are not limited to spatial aspects only.
Abstract data such as statistical results play a pivotal role and the analysis of such data usually
requires traditional plots such as histograms, charts, etc. Showing these elements simply as a billboard
placed into stereoscopic 3D view is not necessarily always advantageous, and turning the plots into a
3D representation is often argued to be inefficient (e. g., [17]). Also, 3D spatial input sometimes fails to
meet the interaction requirements of certain scientific tasks, which usually demand a high accuracy.



A Vision of Bringing Immersive Visualization to Scientific Workflows CHI-IA 2019, May 2019, Glasgow, UK

A recent study [2] reported that domain experts mentioned that the traditional scripts-based input
is still necessary for accurate and advanced analysis, and would rather combine the studied new
interactive approach with traditional mouse and keyboard input.

Field observations

Figure 1: Display of particle trajectories
generated by photon collision.

Through our observation and discussion with researchers working in fluid mechanics and high-energy
physics, we work toward understanding people’s resistance of applying novel immersive visualization
environments to their workflows in practice. In particular, we work with experts in high-energy
physics and our observations in this domain are similar to what Besançon et al. [2] reported about
fluid dynamics. The desktop-based visualization software Vitual Point1 used by Atlas team in CERN

1https://atlas-vp1.web.cern.ch/atlas-vp1/
home/

provides beautiful images of collision events, yet for the experts there are still a number of challenges.
For instance, it is difficult to distinguish different events and the numerous trajectories; traces and
trajectories are overlaid on each others (e. g., Figure 1). Although the physicists agree that stereoscopic
output with intuitive and fluid input is inspiring to understand the global event, they expressed the
need to find a way to support script writing-loading in such environments as well due to the fact that
scientists do not explore the data in a random way. Many predefined views, settings, and interaction
(like filtering on different parameters) are specifically designed by and for the scientists to carry out an
analysis. Writing scripts with keyboards is still the easiest way to quickly adjust all these parameters
with high precision.

Figure 2: 2D-divergence field from experi-
mental data (flow past a cavity).

Furthermore, one of the authors, a fluid dynamics researcher, also reports from his observations
that several crucial needs are not fulfilled by the state-of-the-art visualization toolkits and new
interactive systems. For instance, having access simultaneously to global and local metrics, and being
able to compare the results within the visualization space is a fundamental task in fluid dynamics
research. For instance, a common procedure is to verify the ergodicity of the flow: is the turbulence
homogeneous at all scales, or do some parts of the data have a more specific behavior? The task is
not only to discover it, but to quantify it. A second illustration is the investigation of the divergence
field (e. g., Figure 2). It allows researchers, from experimental 2D snapshots, to understand some of
the 3D properties of the system. From the simulation perspective, it also allows the researchers to
verify if the simulation is accurate. In most scenarios, the flow rate crossing a plane of reference, say
from the left to the right, has to be equal to the flow rate crossing the plane from the right to the left
(if not, accumulation would occur, which leads to an explosion). The amount of fluids crossing the
plane is hence, globally, zero. Note that it is not necessary the case locally, and understanding these
behaviors are critical to understand the physics.
These examples illustrate that user-defined metrics are pivotal to understand the physics. The

needs are not only expending the predefined settings and views, but to propose ways to interact
and derive quantities from the use of the immersive environments. Based on these considerations,

https://atlas-vp1.web.cern.ch/atlas-vp1/home/
https://atlas-vp1.web.cern.ch/atlas-vp1/home/


A Vision of Bringing Immersive Visualization to Scientific Workflows CHI-IA 2019, May 2019, Glasgow, UK

our vision of bringing immersion to scientific workflows, is consistent with that of Isenberg [10], is
that desktop should not disappear, but would rather be combined with immersive environments to
augment its limited 2D output, thus help to better explore and understand complex dataset [1].

HYBRID 2D/3D VISUALIZATION ENVIRONMENTS (HVES)
Our observations indicate that a hybrid 2D/3D visualization environments could be highly appreciated
for scientific workflows. In fact, the study of such HVEs to explore and to understand data is not
a brand new topic. Bryson [3] made a point that “Non-immersive interactive visualization systems
implemented for the conventional desktop and mouse are effective for moderately complex problems.
Virtual reality displays aid in the unambiguous display of these structures by providing a rich set of spatial
and depth cues.” It has been pointed out that immersion is not only offered by the data visualized in
3D, but also by the direct and intuitive interaction [4, 13]. This is largely supported in HVEs: using an
additional tactile surface in stereoscopic visualization environments adds both various input (such as
touch an tangible input) and output (a 2D space for information display and possible haptic feedback).
In this submission, we focus more on the visualization aspect, discussing the benefits brought by
using both 2D and 3D visualization. For such environments, one common design is to visualize a
“god-like” global view on the 2D screen [9, 19] while users discover detailed information through
immersive stereoscopic views. Thus users are able to discover data in details without losing the
control/observation of the general context. Another method lets users perceive a global view of the
data in 3D, and a slice or a small set of the data in 2D (for example, the interactive WIM [5]). Such
approaches are common in scientific data exploration as a large portion of the scientific data (like
flow fields or medical data) is volumetric. Exploring such dataset requires, in particular, visualization
of slices, which is particularly suited for a 2D surface. A similar example is the one from Mandalika
et al. [14] who designed a hybrid interface combing a zSpace VR system with a traditional desktop
interface for radiology data exploration. In this paper, an interesting finding is that while students do
faster in hybrid environments with stylus input, experts still perform the best in 2D using mouse in
term of speed. This finding confirmed our hypothesis that desktop working environments should not
be totally replaced for scientific workflows.

VISION AND RESEARCH AGENDA
Taking inspirations from previous work, we envision that a HVE that can be practically applied in
today’s scientific workflows. It should be composed with at least a PC (with mouse, keyboard, and
a screen—this could be a laptop as well) and an immersive output device. While general research
questions about data visualizaton with novel/immersive environments are summarized in the literature
(e. g., [4, 5, 7, 15]), in the remainder we describe our near future research agenda by reporting several
challenges that focus on bridging immersive visualizations with current scientific workflows.



A Vision of Bringing Immersive Visualization to Scientific Workflows CHI-IA 2019, May 2019, Glasgow, UK

Based on our experience with different immersive output environments, we believe that the use
of non-occluded AR headsets2 is currently a good solution to provide a common data exploration2For example, Microsoft’s HoloLens.
environment. Such AR headsets immerse users by projecting the data in a stereoscopic view. Compared
with large immersive environments like responsive workbench and CAVE, AR glasses do not require
complex setup and maintenance. Compared with occluding VR headsets, users are not separated from
the real word, thus they have more freedom to perform tasks on the desktop, we consequently do not
need to replicate existing tools completely in the virtual realm, and people can continue to interact
with real-world objects (e. g., paper/pen, blackboard). We consider this last point as a major advantage
as we observed researchers needing to take traditional notes in their current scientific workflows.
The use of AR as a further output in addition to a PC thus provides an extension of the 2D screen
with larger space. For domain experts to be able to perform their data analysis, it is thus important to
clarify which elements can be visualized immersively, and which ones are better used on traditional
screens. A challenge is thus how to make the visual transitions between different devices [10]. For
example, a data exploration and analysis system should provide support to its users to decide what to
show on each view as well as how to move a view from desktop to the AR view or in the opposite
direction. In addition, existing AR headsets have intrinsic and unchangeable camera parameters and
the data display should thus be well adjusted to match these specs. For example, while researchers in
both particle physics and fluid dynamics often rely on orthographic projections of their 3D datasets,
such views would be equivalent to a flat image in AR. Nonetheless, the projection parameters of
AR headsets are equivalent to our normal vision, so that the disadvantages often associated with
perspective projection of 3D data may not be as severe as for a general perspective projection. Further
investigation is thus needed to understand how to best match the different views between the screen
and the AR space.33For example, the view angle of Microsoft

HoloLens is fixed to 18 degrees. In such limited
view field, it is hard to visualize the dataset in
3D without proper adjustment of the model.

Second, our vision is not to create a novel environment and to replace current tools. Domains
experts are familiar with the data analysis on desktops, the second challenge is thus to design the
interaction technique compatible with scientific workflows. We thus need to design ways to interact
with popular scientific software (e. g., Python, Paraview, and proprietary software such as MatLab,
Virtual Point). While it is easy for experts to interact with them using keyboard and mouse, we need to
investigate how to adopt the input to the AR space. More recent forms of input (e. g., tactile/tangible,
voice, gestures) are often considered to be intuitive and natural. Yet, the question of whether they are
suitable for generic or specific tasks in the context of existing scientific workflows is still open and
requires investigation. This research does not only need to address the problems of mapping 2D input
to 3D output but also how to create forms of control that is perceived by the intended users as fluid
for both desktop and “hologram” representations.
A third challenge lies in the design of dedicated interaction techniques to support such hybrid

environments—techniques that make specific use of both views and that seamlessly extend the



A Vision of Bringing Immersive Visualization to Scientific Workflows CHI-IA 2019, May 2019, Glasgow, UK

existing interaction metaphors that the experts are used to on their PC-based tools. We first need
to determine which practical tasks require either the traditional or the AR views only, and design
appropriate controls (likely captured by the PC) for the AR setting. We also need to support tasks
that use both parts of the system and that that allow researchers to easily transition between them.

A forth challenge lies in collaborative scenarios scientists face on a daily basis. The sharing, discus-
sion, and exploration of datasets together must be investigated, in terms of communication channels,
interaction techniques, and efficiency both in co-located and distributed setups.

Finally, there are a number of practical challenges to consider. One of them is that we need interfaces
to high-performance computing that is likely not done on the workstation that is used for interaction
but on a remote server. Another one is the extension and further development of existing APIs such that
existing tools can be extended to include AR components. Without answers such practical questions
the adoption of new interaction designs will ultimately remain slow.

CONCLUSION
We described our vision of a practical way to bring immersive visualization environments to scientific
workflows. We believe that traditional desktop workstations are still highly required to support the
complex data processing and analysis tasks. At the same time, AR glasses could be used to augment
the traditional screen to improve complex data understanding. By focusing on how to merge the
two environments and handle their interaction through an extensive programming effort, we believe
that we could improve the adoption rate of techniques and systems developed by the visualzation
communities into domain experts’ workflow.

REFERENCES
[1] Lonni Besançon. 2017. An Interaction Continuum for 3D Dataset Visualization. Thesis. Université Paris-Saclay. https:

//tel.archives-ouvertes.fr/tel-01684210
[2] Lonni Besançon, Paul Issartel, Mehdi Ammi, and Tobias Isenberg. 2017. Hybrid Tactile/Tangible Interaction for 3D Data

Exploration. IEEE Transactions on Visualization and Computer Graphics 23, 1 (Jan. 2017), 881–890. https://doi.org/10.1109/
TVCG.2016.2599217

[3] Steve Bryson. 1996. Virtual Reality in Scientific Visualization. Communications of the ACM 39, 5 (May 1996), 62–71.
https://doi.org/10.1145/229459.229467

[4] Tom Chandler, Maxime Cordeil, Tobias Czauderna, Tim Dwyer, Jaroslaw Glowacki, Cagatay Goncu, Matthias Klapper-
stueck, Karsten Klein, Kim Marriott, Falk Schreiber, and Elliott Wilson. 2015. Immersive analytics. In Proc. BDVA. IEEE
Computer Society, Los Alamitos. https://doi.org/10.1109/BDVA.2015.7314296

[5] Dane Coffey, Nicholas Malbraaten, Trung Le, Iman Borazjani, Fotis Sotiropoulos, Arthur G. Erdman, and Daniel F. Keefe.
2012. Interactive Slice WIM: Navigating and Interrogating Volume Data Sets Using a Multisurface, Multitouch VR
Interface. IEEE Transactions on Visualization and Computer Graphics 18, 10 (Oct. 2012), 1614–1626. https://doi.org/10.
1109/TVCG.2011.283

https://tel.archives-ouvertes.fr/tel-01684210
https://tel.archives-ouvertes.fr/tel-01684210
https://doi.org/10.1109/TVCG.2016.2599217
https://doi.org/10.1109/TVCG.2016.2599217
https://doi.org/10.1145/229459.229467
https://doi.org/10.1109/BDVA.2015.7314296
https://doi.org/10.1109/TVCG.2011.283
https://doi.org/10.1109/TVCG.2011.283


A Vision of Bringing Immersive Visualization to Scientific Workflows CHI-IA 2019, May 2019, Glasgow, UK

[6] Carolina Cruz-Neira, Daniel J. Sandin, Thomas A. DeFanti, Robert V. Kenyon, and John C. Hart. 1992. The CAVE:
Audio Visual Experience Automatic Virtual Environment. Communications of the ACM 35, 6 (June 1992), 64–72. https:
//doi.org/10.1145/129888.129892

[7] Tim Dwyer, Kim Marriott, Tobias Isenberg, Karsten Klein, Nathalie Riche, Falk Schreiber, Wolfgang Stuerzlinger, and Bruce
Thomas. 2018. Immersive Analytics: An Introduction. See [15], Chapter 1, 1–23. https://doi.org/10.1007/978-3-030-01388-2_1

[8] Christophe Hurter, Nathalie Riche, Steven Drucker, Maxime Cordeil, Richard Alligier, and Romain Vuillemot. 2019.
FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights. IEEE Transactions on Visualization and
Computer Graphics 25, 1 (Jan 2019), 704–714. https://doi.org/10.1109/TVCG.2018.2865191

[9] Hikaru Ibayashi, Yuta Sugiura, Daisuke Sakamoto, Natsuki Miyata, Mitsunori Tada, Takashi Okuma, Takeshi Kurata,
Masaaki Mochimaru, and Takeo Igarashi. 2015. Dollhouse VR: A Multi-view, Multi-user Collaborative Design Workspace
with VR Technology. In SIGGRAPH Asia Emerging Technologies. ACM, New York, Article 8, 2 pages. https://doi.org/10.
1145/2818466.2818480

[10] Tobias Isenberg. 2014. An Interaction Continuum for Visualization. In Proc. VIS Workshop “Death of the Desktop: Envisioning
Visualization without Desktop Computing”.

[11] Daniel F. Keefe. 2010. Integrating Visualization and Interaction Research to Improve Scientific Workflows. IEEE Computer
Graphics and Applications 30, 2 (March 2010), 8–13. https://doi.org/10.1109/MCG.2010.30

[12] Wolfgang Krueger and Bernd Froehlich. 1994. The Responsive Workbench. IEEE Comput.er Graphics and Applications 14, 3
(May 1994), 12–15. https://doi.org/10.1109/38.279036

[13] David López, Lora Oehlberg, Candemir Doger, and Tobias Isenberg. 2016. Towards an Understanding of Mobile Touch
Navigation in a Stereoscopic Viewing Environment for 3D Data Exploration. IEEE Transactions on Visualization and
Computer Graphics 22, 5 (May 2016), 1616–1629. https://doi.org/10.1109/TVCG.2015.2440233

[14] Veera Bhadra Harish Mandalika, Alexander I. Chernoglazov, Mark Billinghurst, Christoph Bartneck, Michael A. Hurrell,
Niels de Ruiter, Anthony P. H. Butler, and Philip H. Butler. 2018. A Hybrid 2D/3D User Interface for Radiological Diagnosis.
Journal of Digital Imaging 31, 1 (Feb. 2018), 56–73. https://doi.org/10.1007/s10278-017-0002-6

[15] Kim Marriott, Falk Schreiber, Tim Dwyer, Karsten Klein, Nathalie Henry Riche, Takayuki Itoh, Wolfgang Stuerzlinger, and
Bruce H. Thomas. 2018. Immersive Analytics. Springer, Berlin/Heidelberg. https://doi.org/10.1007/978-3-030-01388-2

[16] Prabhat, Andrew Forsberg, Michael Katzourin, Kristi Wharton, and Mel Slater. 2008. A Comparative Study of Desktop,
Fishtank, and Cave Systems for the Exploration of Volume Rendered Confocal Data Sets. IEEE Transactions on Visualization
and Computer Graphics 14, 3 (May 2008), 551–563. https://doi.org/10.1109/TVCG.2007.70433

[17] Michael Sedlmair, Tamara Munzner, and Melanie Tory. 2013. Empirical Guidance on Scatterplot and Dimension Reduction
Technique Choices. IEEE Transactions on Visualization and Computer Graphics 19, 12 (Dec 2013), 2634–2643. https:
//doi.org/10.1109/TVCG.2013.153

[18] Randy L. Sollenberger and Paul Milgram. 1993. Effects of Stereoscopic and Rotational Displays in a Three-Dimensional
Path- Tracing Task. Human Factors 35, 3 (Sept. 1993), 483–499. https://doi.org/10.1177/001872089303500306

[19] Erik Sundén, Ingemar Lundgren, and Anders Ynnerman. 2017. Hybrid Virtual Reality Touch Table – An Immersive
Collaborative Platform for Public Explanatory Use of Cultural Objects and Sites. In Proc. EG Workshop on Graphics and
Cultural Heritage. Eurographics Assoc., Goslar, Germany, 109–113. https://doi.org/10.2312/gch.20171300

[20] Usher Will, Klacansky Pavol, Federer Frederick, Bremer Peer-Timo, Knoll Aaron, Yarch Jeff, Angelucci Alessandra, and
Pascucci Valerio. 2018. A Virtual Reality Visualization Tool for Neuron Tracing. IEEE Transactions on Visualization and
Computer Graphics 24, 1 (Jan 2018), 994–1003. https://doi.org/10.1109/TVCG.2017.2744079

https://doi.org/10.1145/129888.129892
https://doi.org/10.1145/129888.129892
https://doi.org/10.1007/978-3-030-01388-2_1
https://doi.org/10.1109/TVCG.2018.2865191
https://doi.org/10.1145/2818466.2818480
https://doi.org/10.1145/2818466.2818480
https://doi.org/10.1109/MCG.2010.30
https://doi.org/10.1109/38.279036
https://doi.org/10.1109/TVCG.2015.2440233
https://doi.org/10.1007/s10278-017-0002-6
https://doi.org/10.1007/978-3-030-01388-2
https://doi.org/10.1109/TVCG.2007.70433
https://doi.org/10.1109/TVCG.2013.153
https://doi.org/10.1109/TVCG.2013.153
https://doi.org/10.1177/001872089303500306
https://doi.org/10.2312/gch.20171300
https://doi.org/10.1109/TVCG.2017.2744079

	Abstract
	Introduction
	Immersive visualization for scientific data exploration
	Limitations of immersive environments for scientific workflows
	Limitations from the literature
	Field observations

	Hybrid 2D/3D visualization environments (HVEs)
	Vision and research agenda
	Conclusion
	References

