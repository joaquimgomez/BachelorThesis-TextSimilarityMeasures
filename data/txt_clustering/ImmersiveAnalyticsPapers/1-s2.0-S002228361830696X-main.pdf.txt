





























































































Molecular Visualization on the Holodeck


Perspec�ve
Molecular Visua

Thomas D. Goddard1, Alan A. Brilliant 1,
4 1
☆ This article is part of th
Gaël McGill, Seán O'Do

0022-2836/© 2018 The
(http://creativecommons.org
lization on the Holodeck☆
Thomas L. Skillman2, Steven Vergenz3,
James Tyrwhitt-Drake , Elaine C. Meng and Thomas E. Ferrin1

1 - Department of Pharmaceutical Chemistry, University of California, San Francisco, CA 94158, USA
2 - Benaroya Research Institute, Seattle, WA 98101, USA
3 - AltspaceVR, Redwood City, CA 94063, USA
4 - Bioinformatics and Computational Biosciences Branch, NIH National Institute of Allergy and Infectious Disease, Rockville,
MD 20852, USA

Correspondence to Thomas D. Goddard: 600 16th St, San Francisco, CA 94158, USA. Thomas.Goddard@ucsf.edu
https://doi.org/10.1016/j.jmb.2018.06.040
Edited by Charles Reilly
Abstract

Can virtual reality be useful for visualizing and analyzing molecular structures and three-dimensional (3D)
microscopy? Uses we are exploring include studies of drug binding to proteins and the effects of mutations,
building accurate atomic models in electron microscopy and x-ray density maps, understanding how immune
system cells move using 3D light microscopy, and teaching schoolchildren about biomolecules that are the
machinery of life. Virtual reality (VR) offers immersive display with awide field of view and head tracking for better
perception of molecular architectures and uses 6-degree-of-freedom hand controllers for simple manipulation of
3D data. Conventional computer displays with trackpad, mouse and keyboard excel at two-dimensional tasks
such as writing and studying research literature, uses for which VR technology is at present far inferior. Adding
VR to the conventional computing environment could improve 3D capabilities if new user-interface problems can
be solved.We have developed three VR applications: ChimeraX for analyzingmolecular structures and electron
and light microscopy data, AltPDB for collaborative discussions around atomic models, and Molecular Zoo for
teaching young students characteristics of biomolecules. Investigations over three decades have produced an
extensive literature evaluating the potential of VR in research and education. Consumer VR headsets are now
affordable to researchers and educators, allowing direct tests of whether the technology is valuable in these
areas. We survey here advantages and disadvantages of VR for molecular biology in the context of affordable
and dramatically more powerful VR and graphics hardware than has been available in the past.
e special issue on "Biovisualization" edited by Donald E Ingber, Janet H Iwasa, Jodie Jenkinson,
noghue, Charles Reilly, Alain Viel.
© 2018 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/).
Introduction

A plethora of virtual, augmented, and mixed reality
display devices intended for video game entertain-
ment and virtual experiences are now available.
They have a display strapped to the user's face
providing images to the two eyes from two slightly
different viewpoints to allow natural depth percep-
tion. They track the view direction and position in
Author. Published by Elsevier Ltd. Th
/licenses/by/4.0/).
space and use this to update the display so that the
user appears to occupy a computer-generated
three-dimensional (3D) hologram-like environment.
Augmented and mixed reality devices use a see-
through display superimposing the computer-
generated scene on the actual physical surround-
ings, while virtual reality (VR) devices do not show
the surroundings. Some devices include controllers
held in each hand, with position and orientation
is is an open access article under the CC BY license
J Mol Biol (2018) 430, 3982–3996

Thomas.Goddard@ucsf.edu
https://doi.org/Thomas D.Goddard1NThomas.Goddard@ucsf.eduAlan A.Brilliant1Thomas L.Skillman2StevenVergenz3JamesTyrwhitt-Drake4Elaine C.Meng1Thomas E.Ferrin11Department of Pharmaceutical Chemistry, University of California, San Francisco, CA 94158, USADepartment of Pharmaceutical ChemistryUniversity of CaliforniaSan FranciscoCA94158USA2Benaroya Research Institute, Seattle, WA 98101, USABenaroya Research InstituteSeattleWA98101USA3AltspaceVR, Redwood City, CA 94063, USAAltspaceVRRedwood CityCA94063USA4Bioinformatics and Computational Biosciences Branch, NIH National Institute of Allergy and Infectious Disease, Rockville, MD�20852, USABioinformatics and Computational Biosciences BranchNIH National Institute of Allergy and Infectious DiseaseRockvilleMD20852USANCorresponding author. 600 16th St, San Francisco, CA 94158, USA.600 16th StSan FranciscoCA94158USA
https://doi.org/


3983Perspective: Molecular Visualization on the Holodeck
tracked and shown in the scene. The controllers
allow interaction with virtual objects using buttons,
trackpads, and thumb sticks, and can vibrate for
basic touch feedback. Many devices include stereo
audio for spatially localized sounds and micro-
phones. The combination of a visual 3D environ-
ment, use of hands, touch, and sound produces an
immersive multi-modal experience that has more
resemblance to the real world than to conventional
computer screens, trackpads, mice, and keyboards.
Immersive visualization of molecular and cellular

structure has been employed for education, commu-
nicating results, and research data analysis. Exam-
ples include a virtual tour through a breast cancer cell
based on serial block-face electron microscopy [1], a
tour through the bloodstream and into a cell nucleus
called The Body VR (http://thebodyvr.com), a learning
tool to build organic molecules called NanoOne from
Nanome (http://nanome.ai), web tools such as Auto-
desk Molecule Viewer [2] and RealityConvert [3] that
create VR scenes with protein structures, a collabo-
rative VR environment Arthea developed by Gwydion
(https://gwydion.co) for viewing protein structures,
and an augmented reality molecular analysis tool
ChemPreview [4]. Molecular Rift [5] and 3D-Lab [6]
facilitate drug design using VR. Most of these
applications are based on a video game engine
Unity3D (https://unity3d.com) which does not have
built-in support for molecules. An open source library,
UnityMol [7], allows molecular display in Unity3D. A
wide variety of VR displays, 6-degree-of-freedom
input devices, and haptics devices are supported by
the VMD molecular visualization package [8]. Older
immersive computer systems called CAVEs (CAVE
Automatic Virtual Environment [9, 10]) project images
on walls and the floor of a room and use 3D glasses
and custom-built head and hand tracking devices;
these have beenused for exploring drug binding using
molecular dynamics [11, 12], comparing related
molecular structures [13], interactive protein–protein
docking [14], examining NMR ensembles and con-
straints [15], quantum mechanical and classical
molecular dynamics studies with Caffeine [16],
building and modeling nanotubes [17], and teaching
drug receptor interactions [18]. ConfocalVR for
visualization of confocal microscope image stacks is
described in a companion article in this issue [19].
Ultimately, all of these systems can trace their lineage
to groundbreakingwork by IvanSutherland in 1965 on
what he called the “Ultimate Display” [20].
We have developed three new VR applications:

ChimeraX VR for research data analysis and visuali-
zation, AltPDB for group discussions of molecular
structures, and Molecular Zoo for teaching young
students about familiar biomolecules. These applica-
tions focus on time-varying 3D data and multi-person
interactions, two areas where immersive environments
have substantial advantages over traditional computer
displays. Two-dimensional (2D) computer screens can
effectively convey the depth of molecular models by
usingmultiple cues. Rotating themodels gives a strong
sense of depth (the “kinetic depth effect”), and
occlusion of far atoms by near ones, dimming distant
atoms, and shadows all work to improve 3D perception
on a 2D screen. Time-varying 3D models can be
thought of as four-dimensional data, and such motions
are difficult to clearly perceive on a 2D screen. Virtual
environments with stereo depth perception excel at
conveying this type of data. We illustrate this with
energy minimization and bond rotations to study
mutations in proteins and also with 3D lightmicroscopy
time series using ChimeraX VR. Our educational
application Molecular Zoo presents familiar and simple
molecules suchaswater, aspirin, a saturated fatty acid,
and ATP as dynamic, fully flexible ball-and-stick
models that can collide and have bonds broken and
formed in qualitatively realistic ways. Our interpersonal
communication application AltPDB currently does not
support dynamics but offers the ability to have
collaborating researchers meet and discuss via live
audio molecular function using room-scale virtual
molecular structures, or have teachers and students
meet to discuss molecular mechanisms. Each
participant can move and point at the structures,
which canbe scaled topermit the viewers (for example)
to stand within a deeply buried drug binding site inside
a protein.
There is a largedifference in capabilities between the

various virtual, augmented, and mixed reality devices
currently available. We developed our applications
specifically for VR headsets with tracked hand
controllers that are driven by laptop and desktop
computers. We use HTC Vive, Oculus Rift, and
Samsung Odyssey headsets which are tethered to a
computer having a high-performance graphics adapter
by a 3-m cable providing video, sound, tracking data,
and power. In contrast, headsets that are driven by a
smartphone such as Google Cardboard, GearVR, or
Merge 360 are not currently suitable for our applica-
tions for several reasons: inadequate graphics perfor-
mance, no hand controllers, and rotational but not
positional tracking. The hand controller and positional
tracking limitations are solved by standalone VR
headsets such as Oculus Go, Vive Focus, and Mirage
Solo which do not require a separate computer, but
inadequate graphics speed for interacting with molec-
ular data remains a severe limitation of these devices
for complex interactive scenes. Augmented and mixed
reality devices such as Microsoft Hololens and Meta 2
are much less mature technologies currently offering
only developer kit hardware. Theyhavea limited field of
view (30–50 degrees), and unlike other application
domains, there are few advantages to superimposing
molecular data with human-scale physical surround-
ings. In the future, augmented reality devices may be a
good choice for multi-person immersive environments
allowing participants to see each other. In summary,
consumer computer-driven VR headsets are currently

http://thebodyvr.com
http://nanome.ai
https://gwydion.co
https://unity3d.com


Table 1. Some advantages and disadvantages of
visualization with current consumer VR headsets

Advantages of VR visualization
1. Wide field of view (100 degrees)
2. Direct stereoscopic depth perception
3. Viewpoints inside molecules; no need for clip planes
4. Ease in changing viewpoint by moving head
5. Ease in moving, rotating, and manipulating models with

6-degree-of-freedom hand controllers
6. Built-in microphone and headphones for collaboration

Disadvantages of VR visualization
1. Hard to use keyboard and mouse
2. Low resolution, ~6× fewer pixels per angular degree
3. Hard to use common software like a web browser at the

same time
4. Large data sets can slow visual update rates potentially

inducing nausea.
5. Tethered by cord to computer
6. Cumbersome equipment feels like putting on scuba gear.
7. Not for children, restricts education applications

3984 Perspective: Molecular Visualization on the Holodeck
the only device type we feel are useful for the
interactive visualizations described in this paper.
Some of the advantages and disadvantages of

visualization with VR headsets are summarized in
Table 1.
Results

The ChimeraX visualization program [21] displays
molecular structures and 3D microscopy data and
has approximately 100 diverse analysis capabilities.
In 2014, we began adding the capability to display
and manipulate these data using high-end VR
headsets (https://www.rbvi.ucsf.edu/Outreach/
Dissemination/OculusRift.pdf). In this section, we
compare how a task is carried out using VR versus a
conventional desktop interface, highlighting the
strengths and weaknesses.

Replacing a residue

Our example task will be changing an amino acid,
rotating a bond, running interactive molecular
dynamics to repack nearby residues, and looking
for changes in hydrogen bonds in a beta-amyloid
fibril (PDB 2LNQ). A single amino acid mutation,
aspartic acid to asparagine at residue position 23 of
this beta-amyloid peptide, is associated with early-
onset neurodegeneration [22]. The mutation allows
formation of anti-parallel beta-sheet fibrils (Fig. 1).
We start with a fibril structure deduced by solid-state
NMR and revert the mutation to look into why the
wild-type peptide does not appear to form anti-
parallel beta-sheets.
Performing these actions takes a few minutes

using either conventional or VR interfaces and
entails essentially the same steps and achieves
the same results. The structure is opened and the
mutated residue is colored with commands, toolbar

buttons are used to
Fig. 1. Beta-amyloid fibril con-
sisting of stacked anti-parallel beta
strands. A single amino acid mu-
tation favors anti-parallel fibril
formation. The mutation can be
manually reversed in VR and
energy-minimized to explore how
residue repacking may disrupt the
fibril.

https://www.rbvi.ucsf.edu/Outreach/Dissemination/OculusRift.pdf
https://www.rbvi.ucsf.edu/Outreach/Dissemination/OculusRift.pdf


3985Perspective: Molecular Visualization on the Holodeck
display the structure in stick style and show ribbons,
and mouse modes allow swapping amino acids,
rotating bonds, and running molecular dynamics. In
VR, the same toolbar buttons and mouse modes are
activated using the desktop user-interface window
that appears floating in the VR scene (Fig. 2), with
mouse clicks and drags replaced by hand controller
clicks and motions. Although the steps are the same,
the experience is substantially different, with the VR
method having advantages and disadvantages we
now elaborate.
The first steps of opening and coloring involve

typing commands and are done prior to starting the
VR which is also done with a command (vr on). This
skirts the difficult problem that typing while wearing
the VR headset is too cumbersome to be practical.
The headset completely blocks the view of a
physical keyboard, and the hands are holding
controllers. Poking at a virtual keyboard floating in
the VR scene is feasible but tedious. The reason
these initial steps use typed commands is because
they have parameters, the PDB code 2LNQ to be
opened and the sequence number of the mutated
residue. While there is no drawback of typing initial
commands, analysis tasks during a VR session will
frequently involve entering parameters such as
numbers and names of data sets. A possible solution
Fig. 2. ChimeraX user interface. Mouse modes, toolbar butto
this floating panel in the VR scene. A 3D optical microscopy
interface elements specific to this type of data in the lower rig
is to use speech recognition to enter commands
while wearing the VR headset, and we describe our
tests of speech input below. VR headsets have built-
in microphones so no extra hardware is needed.
The steps of changing display style to sticks and

ribbon can be done with toolbar buttons since no
parameters are needed. In VR, a button press on
either hand controller shows the ChimeraX desktop
window floating in the VR scene; it can be dragged to
any position and is initially a meter wide. (When
immersed in VR space you perceive distance in true
physical dimensions, so one tends to describe scenes
in real units such as meters.) The hand controllers are
depicted as cones in the scene for accurate pointing,
and clicks on any desktop user-interface control act
like equivalent mouse clicks. This VR user interface is
a poor experience compared to the conventional
desktop window for several reasons. Extra effort is
required to position a 3D input device on a floating 2D
panel compared to using a trackpad or mouse,
pointing accuracy is lower, and the panel can be
inconveniently out of reach or view when moving or
rotating the head to obtain different vantage points.
The resolution of current VR displays is also much
inferior to conventional displays, making text in the
user interface panel hard to read. Each eye in a VR
device uses a screen with about half the number of
ns, and other controls can be used with hand controllers on
time series of a crawling neutrophil is shown along with

ht.



3986 Perspective: Molecular Visualization on the Holodeck
pixels (1080 by 1200) of desktop screens (1920
by 1080) and covers 3 times the field of view
(100 degrees versus 30 degrees) giving a factor of
6 reduction in pixels per angular degree. Increasing
this resolution is the active focus of VR technology
development companies, as can be seen by the
recently announced HTC Vive Pro (1440 × 1600).
Although embedding the conventional desktop user
interface panel in VR is unsatisfactory in the above
respects, it has the significant advantage that users
familiar with the complex desktop interface need not
learn a completely newVR interface. Conventional 2D
user interfaces have proven effective for providing a
wide range of functionality in the molecular VR
package ImmersivePDB [23].
The next step in our task is to obtain a clear view of

the mutated residue. In VR, either the head can be
moved (e.g., while seated in a rolling chair or
walking) or either hand can grab the structure (with
a button held down) and rotate and move it smoothly
matching the hand motion. Bringing the two hands
together or apart scales the structure. A typical
viewpoint would have the mutated residue half a
meter in size and one meter away with orientation
chosen to avoid intervening atoms blocking the view.
This process is simple and feels natural compared to
the equivalent operations without VR.
The process for obtaining a useful 3D view with a

conventional 2D user interface is difficult to describe,
with several factors contributing to the complexity of
the task. Because a mouse has only two degrees
of freedom, ChimeraX uses two mouse buttons
for translation and rotation. Rotation and translation
each have three independent axes, so other tech-
niques enable rotation and translation perpendicular
to the screen: z-rotation is implied by initiating the
mouse pointer near the edge of the window [24], and
z-translation is done by holding down the control key
while moving the mouse. Scaling is done with the
third mouse button or scroll wheel. Laptop com-
puters with a trackpad require emulating three
mouse buttons by holding additional keyboard keys
(e.g., alt, option, command).
The desirable view will also differ substantially on a

conventional display. Because the field of view ismuch
narrower, typically 30 degrees versus 100 degrees in
VR, it is undesirable to move in close to the residue of
interest because the surrounding residues will then
be out of view. But if the viewpoint is not close, then
other atoms are likely to block the view, a problem
solved by use of clipping planes to hide nearby atoms,
controlledwith yet anothermousemode.Our example
system is a fortuitous case where the residue of
interest is on the surface and clipping is not needed.
An alternative to clipping is to artificially increase the
graphics field of view to allow a close vantage point,
but the high degree of distortion from a wide-angle
perspective projection on a flat screen makes it hard
to perceive spatial relationships and is rarely useful.
Researchers becomeadept at the baroque process of
using a 2D interface for 3Dvisualization, although only
a minority discover the advanced techniques such
as how to perform rotations and translations perpen-
dicular to the screen. While automated methods
can find unoccluded viewpoints in molecular struc-
tures [25], natural head and hand motions in VR allow
the researcher to orient the view to the salient
structure features. Aside from the difficulty in
achieving useful structure views, the vantage
achieved in VR gives a dramatically clearer
perception of spatial relationships due to the close-
up view where stereoscopic depth perception is most
effective. It may also be faster to find ideal views; one
study [26] found that objects can be located twice as
fast controlling a camera by headmotion than by hand
motion.
The next steps in our example are to compute and

display hydrogen bonds as dashed lines, swap
amino acid 23, replacing asparagine with aspartic
acid, rotate bonds of the new amino acid if needed
to avoid clashes with neighbor residues, and run
molecular dynamics to equilibrate the new residue
and its neighbors. These actions are all performed
with the mouse or hand controllers. Hydrogen bonds
are displayed by clicking a toolbar button. The swap
amino acid mode is enabled by pressing a button on
the mouse modes panel; then, a click and drag on
the target residue flips through the 20 standard
amino acids, replacing the atoms and displaying the
new residue three-letter code as a label, with button
release choosing the new amino acid.
Currently, a replaced residue is added in a single

orientation by alignment of a template to the
backbone. ChimeraX's predecessor program, UCSF
Chimera, can choose an appropriate rotamer from a
library to reduce clashes and optimize hydrogen
bonds, but that capability is not yet available in
ChimeraX. Sowe instead can resolve serious clashes
with the bond rotation mouse mode, which rotates
atomsononeside of a bond by a click andmousedrag
or hand controller twist on the bond. In VR, observing
suitable bond rotations is easier than on a 2D screen
because the clashes are perceived directly in stereo.
Equally important is the ability to move the head to get
different viewpoints while simultaneously performing
the rotation with one hand. Subconscious head
motions with head-tracked displays lead to more
accurate perception of moving objects [27]. Alterna-
tively, onehand canmove the structurewhile the other
hand rotates the bond. On a conventional screen with
a mouse, the user instead must switch between
rotating the bond and rotating the molecule with
different mouse buttons to see the degree of clashes.
Finally, a mouse or VR mode that runs molecular

dynamics on any clicked residue and its contacting
neighbor residues is used to repack the residues into a
lower energy state. Insight into residue motions is
much clearer in VR due to the close-up direct 3D



3987Perspective: Molecular Visualization on the Holodeck
perception. The dynamics is calculated using
OpenMM [28], which requires hydrogen atoms that
can be added with a ChimeraX command, and
currently uses force field parameterization limited to
standard amino acids. We typically use 1–3 s of
dynamics to achieve energy minimization with some
sampling, long enough to remove steric clashes but
not sufficient to significantly rearrange residues.
The operations to perform the residue replace-

ment are nearly identical with and without VR. In VR,
the same user interface icons that are clicked with
a mouse when using a conventional display are
instead clicked with either of the VR hand controllers.
For assigning VR modes, any of the three buttons on
either hand controller can be clicked on the user-
interface icons to assign that button to the desired
operation. This allows up to six different operations
using the two hand controllers. With one button
assigned to rotate and move structures there are five
additional operations that can be assigned to buttons
for immediate use. Using a three-button mouse with
scroll-wheel for zooming, typically only one button is
reassigned over and over to new operations
because the others are needed for rotation, transla-
tion and zooming.
In summary, the benefits of using VR in this residue

mutation example are improved perception of the
spatial arrangement of residues in combination with
easier access to many hand controller operations. A
recurring aspect in the VR uses that we find most
compelling is structure dynamics. When parts of a
molecule or cell are moving, understanding this four-
dimensional data (space and time variation) on a
conventional 2D screen is challenging. The direct
stereo depth perception of VR combined with the
ability to move one's head to alter the viewpoint while
hands are controlling the structure dynamics provides
a clear view of the dynamics not possible with a
conventional 2D display.

Refining atomic models in density maps

A second example where VR may have substan-
tial advantages is refining and correcting atomic
models in X-ray or electron cryo-microscopy density
maps. Early VR efforts fit whole molecules in 20-Å
resolution maps [29] and used exhaustive search
fitting [30], but a more demanding task is building into
atomic resolution data. Initial atomic models are
“built” into density with automated software such as
Phenix [31], which can correctly build more than 90%
of most structures. Subsequently, interactive refine-
ment is used, where a researcher fixes remaining
problems such as incorrect residue positions or
register shifts of strands and helices, and may
incorporate additional residues. Maps of large
systems at lower resolutions (~3 Å) from cryoEM
can require extensive interactive refinement be-
cause more errors are present. The ChimeraX tool
ISOLDE [32], developed by Tristan Croll, enables
corrections and makes use of interactive molecular
dynamics to maintain correct bonded geometry,
minimize clashes, and move atoms into density. It
also computes and displays 3D indicators for poor
backbone geometry and bond angles. Interactive
refinement requires excellent perception of the fit of
atomic models in density map meshes combined
with tugging residues to corrected positions, which
we believe would benefit from a VR user interface.
The complexity of the task when done with conven-
tional displays is seen in an ISOLDE tutorial video
(https://www.youtube.com/watch?v=limaUsNAVL8).
ChimeraX has a mouse and VR mode that allows

tugging atoms while running molecular dynamics,
but parallel computation of the graphics and dynam-
ics is not yet implemented despite being needed to
avoid flickering in VR, as discussed further below.
Additional current capabilities assist visually inspect-
ing the fit of residues in density maps. Map contour
level can be changed using a hand controller mode
dragging up and down. Maps can be cropped to
regions of interest with another mode in which a map
outline box is shown and faces of the box can be
dragged. The main purpose of cropping is to reduce
the scene complexity so it can render sufficiently fast
for VR. Another mode allows clip planes to be moved
and rotated, although clipping is usually not neces-
sary because VR allows close-up views with no
obstructing density between the viewer and region of
interest. Manual fitting by rigidly moving and rotating
component atomic models into density is supported
by another hand controller mode, and positions can
be optimized to maximize correlation between
atomic models and maps. To identify residues, yet
another mode allows clicking atoms to display a
floating residue name and number.
We have found that the conventional mesh

surface display of density maps used in refinement
does not display well in VR. The limited VR display
resolution results in pixelated (stair-stepped) mesh
lines where the steps drift up and down the lines with
even small head motions, creating an overwhelming
shimmering appearance. Common recommenda-
tions in VR video game development call for
minimizing use of lines due to these distracting
low-resolution artifacts. We find that transparent
solid surfaces perform well for atomic model and
map comparison. This is initially surprising because
such surfaces are not used with 2D displays
because of poor perception of depth, but stereo-
scopic VR remedies that weakness.

Tracking features in 3D light microscopy

A third ChimeraX VR use is in tracking features in
3D light microscopy time series of live cells. An
example is lightsheet microscopy of neutrophils
crawling through collagen filaments [33] imaged

https://www.youtube.com/watch?v=limaUsNAVL8


Fig. 3. Measuring and tracking features in 3D lightsheet microscopy. Measurement of deflection of a collagen filament
over a 5-s interval as a crawling neutrophil passes it (left). Manually marked path of motion of a T-cell protrusion over a 15-s
interval (right).

3988 Perspective: Molecular Visualization on the Holodeck
once per second for 3 min, with and without motility-
affecting drugs. To examine whether the cells propel
themselves by pushing or pulling on filaments, we
can measure displacements of collagen in contact
with cells (Fig. 3). This is well suited to VR as it
benefits from an immersive view from within the
collagen filament network. A VRmode allows placing
markers on the filaments, while a secondmode allows
switching time points by dragging. Dragging up or
down advances or regresses one time step for each
5 cm of hand motion. Quickly going back and forth
through 20 frames allows moving filaments to be
identified and marked. Markers placed on the same
filament can be connected and distances shown on
the connections using VR modes. Markers can be
placed on a surface or on maximum density along a
ray extending from the hand controller. Each marker
can be moved to improve placement accuracy,
resized, or deleted, all by direct action with hand
controller buttons.
Another 3D lightsheet microscopy example in-

volves tracking dozens of T-cell surface protrusions
used to interrogate antigen-presenting cells [34].
Again, VR is well suited to the task by combining
stereo perception and hand-controlled time series
playback to manually track paths of individual
protrusions, determine their lifetimes, and assess
localization of fluorescently labeled T-cell receptors
seen in a second channel (Fig. 3). The protrusions
move large distances between time points, making
automated tracking challenging. Both the neutrophil
and T-cell examples would best be done with
automated tracking to provide reproducible mea-
surements. Similar to the refinement of atomic
models, it is likely that automated tracking will need
interactive correction to remove spurious results.
Handling large data

A critical requirement of VR displays is that
graphics be rendered at the full 90 frames per
second used by current devices. The headset
displays we use are 1080 by 1200 pixels for each
eye, but warping of the images to correct for optics
distortions in the device involves rendering 1344 by
1600 pixels, a size comparable to rendering on
conventional desktop displays. Two eye images are
rendered for each frame. The rendering speed
requirement is thus approximately 180 eye images
per second. If this rendering rate is notmaintained, the
display flickers and the objects do not remain at fixed
positions in space as the view direction changes, but
instead jitter. Slow rendering causes motion sickness
with symptoms of nausea persisting as long as 24 h
[35]. This poses a serious and unfamiliar problem for
software developers: applications can make users
sick. The rapid performance improvements of
Graphics Processing Units (GPUs) is one of the key
technology developments that have enabled VR to
move fromwhat Fred Brooks, Jr. described in 1999 as
“barely working” [36] to the successful consumer-level
systems of today; we anticipate continued GPU
improvements in the future.
Conventional 2D computer displays typically re-

fresh at a rate of 60 frames per second, but large
science data sets that render at only 10 frames per
second are common, and that frame update rate
does not greatly interfere with visualization or
analysis. VR requires nearly 20 times that rendering
rate because the user's head position can be
constantly changing and it is imperative that the
view tracks this head motion in order to avoid
inducing nausea. The only way to achieve those



3989Perspective: Molecular Visualization on the Holodeck
speeds for large data sets with today's GPUs is to
reduce the level of detail shown. In this respect, VR
is more limited than traditional 2D visualization in the
level of detail that can be shown with large data sets.
As an example, we take an Escherichia coli

ribosome structure of 280,000 atoms with a bound
antibiotic (PDB 4V7S) and a 130 Mbyte X-ray density
map (grid size 253 × 363 × 372) used to determine
this structure at 3.3-Å resolution (Fig. 4). We simplify
the depiction by displaying the ribosomal RNA as
ribbons with rungs for each base; proteins are shown
with all-atom spheres, the antibiotic is shown in ball-
and-stick and the density map is displayed only within
a range of 10 Angstroms from the antibiotic. Those
settings allow full-speed rendering in VR with a high-
end Nvidia GTX 1080 graphics card. The atom
spheres appear somewhat faceted due to automatic
level-of-detail control which represents each sphere
with only 90 triangles. The limited map range and
ribbon style choices took some exploration to find
settings that allow adequate VR rendering speed, and
for many data sets, the process of finding suitable
settings can be challenging.
Fig. 4. Antibiotic telithromycin (purple) bound at the cata
methylation site on ribosomal RNA shown in yellow and X-ray
viewing in a VR headset. Level-of-detail tuning allows comp
second.
In the case of neutrophils crawling through collagen
filaments, the 3D image data were reduced by a factor
of 2 along x and y axes (original grid size 256 ×
512 × 151, 110 time steps, 32-bit floating point
numbers) for VR to allow playing the time series
while maintaining full frame update rate. The subsam-
pling is done with a command to use every other grid
point along the x and y axes on the fly so it does not
require preprocessing, although preprocessing to
produce a reduced file size makes the data load into
memory faster. This reductionwasnecessary because
the full-resolution data of 20 Gbytes did not fit in the
graphics card memory, which is necessary for
maintaining the fast rendering rate. (Most current
high-performance graphics cards have 8 Gbytes of
memory, although this continues to increase.)
Finding suitable display styles and settings to obtain

the rendering speed needed for VR is burdensome
and few researchers will have the detailed under-
standing of how to adjust interrelated graphics
parameters to allow maximum detail to be shown.
For example, a standard ChimeraX lighting method
called ambient occlusion casts shadows from 64
lytic center of E. coli ribosome with antibiotic resistance
density shown as a transparent surface, as rendered for

lex scenes such as this to be rendered at 90 frames per



3990 Perspective: Molecular Visualization on the Holodeck
different directions and even small models cannot
render fast enough for VR with this setting. ChimeraX
automatically turns off ambient occlusion in VRmode.
More sophisticated automated level-of-detail control
will be needed to allow researchers to routinely use
VR for large data sets.

Handling slow calculations

A second performance issue critical for successful
use of VR is that many calculations require longer
than a single graphics frame update (1/90th second)
to compute. In order for the graphics to render at full
speed, it must not wait for these calculations to
complete. Examples of such calculations are hydro-
gen bond determination, molecular dynamics, add-
ing hydrogen atoms to existing structures, molecular
surface calculation, electrostatic potential calcula-
tion, computing new density map contour surfaces,
optimizing rigid fits of atomic models into density
maps, and dozens more. Currently, ChimeraX
performs the calculations and graphics rendering
sequentially, and each calculation causes a pause in
the VR rendering. Calculations that take a half a
second or more cause the headset to gray out and
show a busy icon. While these pauses have a good
visual payoff for the wait, the effective use of VR
requires a more sophisticated software design
where the graphics renders in parallel to all other
calculations. With this capability, all objects in the VR
scene continue to render at full speed, and the
objects themselves are only updated to reflect the
results of a calculation when it completes.

Speech recognition

Typed commands are common inChimeraX usage.
They are needed when specifying parameters, such
as a residue number that cannot be easily chosen
from a menu because the range of possible values is
large. Other examples are fetching a known database
entry by specifying its accession code, specifying a
distance range for displaying atoms or density maps
within a zone around a ligand, and typing a filename
for saving a modified model. One approach is to type
commands on a virtual keyboard floating in the VR
scene by pressing each key with a hand controller.
This is a general mechanism provided by the
SteamVR (http://store.steampowered.com) environ-
ment but it is slow and tedious.
A potentiallymoreeffective solution is to use speech

recognition, for example, saying “color chainA residue
23 yellow” to perform the coloring operation discussed
in the example above. Using the Windows Speech
Recognition toolkit, one of us (J.T.D.) developed a
set of about 50 speech input macros for performing
tasks within ChimeraX, and demonstrated their use
in a video (https://www.youtube.com/watch?v=
NHiOpNInEjM). The spoken commands are not the
literal typed-text commands required by ChimeraX.
For instance, the coloring command needed is color /
A:23 yellow so themacrosperforma translation, in this
case changing the words “chain” and “residue” to the
corresponding syntax characters used by ChimeraX.
Although the video shows perfect speech recognition,
errors are common. Our experience suggests that an
essential element of speech recognition in VR will be
the display of words as the speech engine recognizes
them, with the ability to fix mistakes, for instance, by
saying “back up” or “start over.” Speech input error
rates could also be reduced by restricting to a limited
vocabulary using open-source speech recognition
toolkits such as Mozilla DeepSpeech (https://github.
com/mozilla/DeepSpeech), Kaldi (http://kaldi-asr.org,
http://publications.idiap.ch/index.php/publications/
show/2265), or CMUSphinx (https://cmusphinx.
github.io).
Beyond the cases of entering parameters, speech

recognition could reduce tedious interactions with
the VR user interface panel. Simple commands like
“show hydrogen bonds” or changing a hand control-
ler mode, for example, “swap amino acid” with the
desired hand controller button held could reduce
interactions with the 2D user interface. VR headsets
include built-in microphones intended for high-
quality speech input, so no additional hardware is
needed, and ChimeraX has the ability to create
command aliases, so adding new voice commands
should be straightforward.

Multi-person VR

ChimeraX has basic capabilities for two or more
people to join the same VR session. Each participant
is shown with cones for hands and a postage stamp
head (with image optionally specified by the user)
that track the hand and head motions (Fig. 5). Any
participant can move or scale the models and point
at features of interest as part of collaborative
discussions. A session is started by one participant
who loads data and initiates the meeting by invoking
the ChimeraX command “meeting start” while others
connect to the host's machine with command
“meeting b hostname N,” automatically receiving a
copy of the scene from the host. Participants can be
in the same room or at remote locations. This
capability currently has many limitations, some of
which are described below.
The SteamVR toolkit that ChimeraX uses to

communicate with VR headsets requires a separate
computer (or virtual machine) running each head-
set. Any changes one participant makes to the VR
scene must be communicated to the others over a
network connection. Currently, the only changes
propagated to other participants are moving, rotating
and scaling the displayed structures. Some addi-
tional synchronization is simple to add, such as for
colors, display styles, and atom coordinates, while

http://store.steampowered.com
https://www.youtube.com/watch?v=NHiOpNInEjM
https://www.youtube.com/watch?v=NHiOpNInEjM
https://github.com/mozilla/DeepSpeech
https://github.com/mozilla/DeepSpeech
http://kaldi-asr.org
http://publications.idiap.ch/index.php/publications/show/2265
http://publications.idiap.ch/index.php/publications/show/2265
https://cmusphinx.github.io
https://cmusphinx.github.io


Fig. 5. ChimeraX VRmeeting command shows each party as a postage-stamp head with customizable image and cone
hands for pointing (left). AltPDB allows VR participants to discuss Protein Data Bank structures with custom human
avatars, control molecule styles, and browse web pages within a popup pane (right).

3991Perspective: Molecular Visualization on the Holodeck
other changes such as swapping an amino acid
(creating new atoms), or loading new data sets will
likely require an approach that is slower to update, in
which the new full ChimeraX session is sent to all
participants. Large data sets such as 3D microscopy
may take minutes or more to transfer because of
their size.
While it is possible for participants to connect from

remote sites, most academic institution firewalls
block incoming network connections except for a
select few and require administrative requests to
have network ports opened up. A more usable
design would have all participants connect to a hub
machine set up to accept connections. To allow this to
scale to hundreds of sessions running simultaneously
by different groups of researchers, ChimeraX could
start a cloud-based server on demand using a
commercial service such as Amazon Web Services
that accepts the connections and forwards changes to
all participants. This would require accounts and
payment for commercial services and is a complex
undertaking. A further burden of remote connections
in our existing implementation is that a third-party
voice chat service is required.
We have developed another approach to allow

multi-person molecular visualization called AltPDB
using a social VR site called AltspaceVR. The
technical complexity of initiating multi-person VR
sessions, maintaining synchronized views of data,
audio connections, and customizable avatars for each
participant is provided by AltSpaceVR (https://altvr.
com/). Two of us (T.L.S. and S.V.) have added
molecular display capabilities to this environment:
ball-and-stick, ribbon, hydrogen bond, and surface
depictions. Ribbon, surface, and hydrogen bond
depictions are computed by ChimeraX and passed
to theAltspaceVR client asGLTF format (https://www.
khronos.org/gltf/) geometric models. A user interface
panel allows selecting entries from the Protein Data
Bank by either typing an accession code or choosing
one of several example structures from a list.
Structures can be moved, rotated, and scaled. The
overall feel is richer with the meeting taking place in a
room with web browser and other controls available
(Fig. 6), contrasting with ChimeraX VR where only the
structures in empty space are shown.
AltPDB is a powerful tool for research and education

in which an expert explains the details of molecular
structures to collaborators or students. We have used
it in presentations with up to 15 participants, explain-
ing human T-cell receptor interactions with antigen-
presenting cells. The ability to talk and listen, to pass
human-sized molecular structures around, to point at
key features like an Ebola virus antigen, and explore
inside molecules is by far the most effective method
we have seen to share biology research with both
scientists and a lay audience.
While many of the multi-person VR difficulties are

solved in AltPDB, the interaction is not directly with
ChimeraX, which limits the analysis capabilities.
Additional interfaces could allow participants to
invoke any ChimeraX calculation or change in
display, which would then run ChimeraX on a server
and return a new scene (ChimeraX has an option for
running on a server without a graphics display
attached). Hand manipulation of the structure
beyond moving and scaling will not allow real-time
feedback using this relatively slow server-calculation
approach. For example, rotating a bond would
instead need new code added to AltPDB. Another
current limitation is that the AltspaceVR platform only
provides flat lighting. We adjust coloring of ribbons to
include shadow effects to compensate for this.

Molecular Zoo: learning to love chemistry

We have developed a VR application called
Molecular Zoo intended to allow young students to

https://altvr.com
https://altvr.com
https://www.khronos.org/gltf
https://www.khronos.org/gltf


Fig. 6. Molecular Zoo educational application depicts fully flexible models in a large space. A tractor beam (blue)
activated with hand controllers brings out-of-reach molecules to the VR user's hand.

3992 Perspective: Molecular Visualization on the Holodeck
handle biomolecules they have heard of such as
water, carbon dioxide, aspirin, caffeine, a saturated
fatty acid, sulfuric acid, DNA, ATP, and methane. The
aim is to familiarize students who have little or no
knowledge of chemistry with the molecular world.
Molecules and chemistry as presented in textbooks
are abstract, and we hope that a concrete experience
of fully flexible molecules, breaking their bonds, and
assembling new molecules as if they were human-
sized objects can contribute substantially to encour-
aging more students to become scientists. Previous
work has shown that high school students had
improved understanding of water phase transitions
when using an interactive stereoscopic molecular
viewing system [37]. A review of 53 articles on
educational virtual environments [38] found almost
all report positive learning outcomes, suggesting that
VR has potential value in education.
The Molecular Zoo application starts with 100

molecules of many types flying in random directions,
with sizes ranging from 30 cm for water to a few
meters for a long fatty acid, shown in ball-and-stick
style with standard coloring by element type (oxygen
red, nitrogen blue, carbon black, hydrogen white,
phosphorous orange, …) (Fig. 6). The molecules
vibrate, flex, and collide with each other in qualita-
tively realistic ways, the dynamics simulated as
springs and masses, with torsions and rotating joints
implemented using the Nvidia PhysX engine (https://
en.wikipedia.org/wiki/PhysX). While this does not
provide physically accurate molecular mechanics,
the purpose is to capture the qualitative level of
flexibility of small molecules and is visually highly
engaging. Grabbing and shaking a molecule causes
bonds to break. Breaking bonds make a snapping
sound, and fragments fly off with stub half-bonds
able to form new compounds either when combined
by hand or through collisions.
The virtual space is a 10-m cube so that almost all

of the molecules are flying out of easy reach. Virtual
hands and arms allow interacting with the molecules
using a variety of tools. The most basic is a tractor
beam that produces a blue ribbon-like laser beam
that pulls a molecule to your hand. Grasped
molecules are identified in the headphones, for
instance, announcing “aspirin,” encouraging students
to grab all the molecules to hear their names. In our
experience showing this to hundreds of students,
for example, at a local video game expo, many did
not recognize even the simplest molecules, water,
and carbon dioxide, and such commonplace notions
as the colors representing different elements were
not obvious to them.
A basic aspect of the game is breaking molecules

apart, and two hand tools allow launching hydrogen
and oxygen atoms at other molecules. The oxygen
atoms can break molecules, and both hydrogen and
oxygen can bind to molecular fragments when
valence electrons are available. Molecules can
also be grabbed, held in two hands, and pulled
apart. Likewise, creating molecules is a central
activity. We found that it takes considerable resolve

https://en.wikipedia.org/wiki/PhysX
https://en.wikipedia.org/wiki/PhysX


3993Perspective: Molecular Visualization on the Holodeck
to break apart existing molecules to produce
ingredients for new molecules, so we added atoms
of carbon, nitrogen, oxygen and hydrogen that
sprout from the virtual arms and can be plucked off
for an unlimited supply of at-hand atoms.
An important principle of our design was to favor

user engagement over physical correctness, so the
environment contains a rich, diverse, and inconsis-
tent set of items and behaviors including the planet
Earth (2 m in diameter and very massive, such that
throwing it causes significant molecular damage on
collisions), a user has four arms and hands (natural
size), hydrogens are launched from a heme group
held in the hand, oxygens are launched from an ATP
synthetase complex (scaled down in size), a green
cube floats as a remnant from the game's early
beginnings, an astronomy view of the universe is in
the distance in all directions, and a floor is at your
feet. Launching atoms, tractor beaming, and making
and creating bonds have distinctive sound effects,
and hitting Earth causes it to scream.
A common question from educators and other

adults who have tried Molecular Zoo is “What are
students expected to learn?”We have not attempted
to incorporate specific lessons, as we feel that our
goal of producing future scientists will be better
served by a playful rather than pedantic experience.
But we believe that much intuition about molecules
and chemistry is conveyed, from the frequency of
element types in biomolecules, the number of bonds
each element can form, and the degree of flexibility
of molecules. We consider this only an initial version
of the application and plan to add other ingredients
that will enhance student intuition about the molec-
ular world. Some examples are as follows: add water
in ice, liquid, and gas forms where the user heats
with a flame to add energy and qualitatively realistic
hydrogen-bonding orientations are favored; add
duplex DNA that can be pulled apart and zipped
back together—again using qualitative hydrogen-
bonding forces imposed by weak springs; and allow
the user to ignite natural gas (primarily methane) to
observe the combustion cascade through dozens of
intermediates ending in water, carbon dioxide, and
other compounds. We would like to provide a box of
clinical drugs to familiarize students with the typical
chemical characteristics needed to reach targets in
cells. All of our current molecules are fetched from
the PubChem database [39], and we would like to
add speech input that permits saying the name of a
molecule and making it magically appear via a
search and fetch from PubChem.
Molecular Zoo uses the Unity game engine

(https://unity3d.com) which offers built-in support
for spheres, cylinders, custom shapes, spring-and-
mass physics, and VR headsets. It enables rapid
software development where we only need to im-
plement molecules and molecular interaction behav-
iors. Our current scenes include about 1000 atoms
and scenes with more objects or denser packing
resulting in more collisions per second will require
optimizations to achieve the high-speed needed for
VR graphics. This has shaped development toward
smaller simulations that demonstrate the beauty of
a few unique molecules and how the player can
interact with them.
A troublesome aspect of this application is that the

ideal audience is younger than the minimum recom-
mended age for using VR of 13 years. These current
recommended minimum ages from the headset
manufacturers are based on uncertainty about ad-
verse effects on the developing visual systems of
younger children. The use of VR could increase the
prevalence of myopia, which rose dramatically in the
past four decades due to increased use of electronic
displays [40]. Also, a recent study of VR use in twenty
8- to 12-year-olds showed some adverse effects
[41]. Nonetheless, efforts to include VR headsets in
K-12 education are in early stages [42]. We believe
that many children over the age of 12 years can
benefit from Molecular Zoo, but the issue of how to
minimize exposure to younger children needs careful
consideration.
Discussion

The applications we describe have been demon-
strated to hundreds of researchers, often visualizing
their own data. In several cases, they have claimed
to observe features in their data they had not seen
before. For example, the Matt Jacobson and Neil
Shah labs at UCSF recently investigated mutations
of the kinase KIT. They noticed, using ChimeraX VR,
networks of hydrogen bonds and hydrophobic
interactions leading to conformational changes that
are not directly linked to the mutated residues, but
impair two binding sites, leading to drug resistance
[43]. Anecdotal evidence is not sufficient to establish
the value of VR for molecular research; however,
and a conclusive evaluation will require wider use in
research. Such wider use is now feasible given the
low cost of consumer VR headsets.
Our experience suggests that the ability to

perceive spatial relations especially in time-varying
3D molecular and cellular data is greatly enhanced
using VR compared to conventional displays. A
recent study suggests that users can perform
interactive molecular manipulations with time-
varying structures more efficiently with VR than
with conventional displays [44]. We describe the VR
advantages as immersive visualization that includes
the wide field of view, close-in vantage points,
stereoscopic depth perception, 6-degree-of-
freedom head and hand tracking with plentiful button
inputs, and audio headphones andmicrophone. The
combination of features rather than any single
capability is the unique strength of the technology.

https://unity3d.com


3994 Perspective: Molecular Visualization on the Holodeck
While the novel combination of VR characteristics of
immersive and multi-modal interaction on paper
seem like small advances over prior 3D technolo-
gies, the user experience of VR headsets is
qualitatively dramatically different and difficult to
appreciate except by experiencing it.
The drawbacks of the VR headsets are numerous.

The powerful devices we have used are bulky, heavy
(typically 500 g), and tethered by a cable to a
computer; require an expensive high-end graphics
card, have marginal resolution; interact poorly with
2D user interfaces; and completely block the user's
view of the real world. Achieving the fast rendering
required for VR of large time-varying scientific data
sets has long been an obstacle (e.g., in computa-
tional fluid dynamics [45]) with solutions that are
complex to implement. Future improvements in
hardware and software can ameliorate these disad-
vantages to some extent.
The VR applications we have described are all at a

proof-of-concept or demonstration stage with signif-
icant technical limitations and ease-of-use problems.
The development of these tools has revealed many
hurdles that will need to be overcome to make
production-quality VR analysis tools for molecular
and cellular structure researchers and for education.
The problems for research analysis applications
include input of parameters that would normally be
typed, level-of-detail control for large data sets, and
parallel processing for slow computations. These are
challenging technical issues that will take months to
years to adequately solve, but the potential solutions
are well understood and likely to be successful.
Conventional mouse, trackpad, keyboard, and flat
screen interfaces are clearly superior for essential
2D aspects of structure research such as web
browsing, reading literature, and analyzing graphical
data. Successful VR applications will need to
minimize interleaving of 2D tasks which are difficult
in current low-resolution headsets. Whether the
advantages of VR analysis will outweigh the poorer
interplay between 2D and 3D tasks will only be
determined by reducing technical limitations and
gauging adoption of VR in labs for routine research
use.
Our efforts on multi-person VR reveal difficult

technical challenges. Currently, few researchers
have VR headsets, so the chance of collaborating
researchers having the needed equipment is small,
and thus, the potential audience for multi-person VR
may be more limited than single-person applications.
This suggests that near-term effort should focus
more on single-person applications.
Educational applications such as Molecular Zoo

avoid most of the technical difficulties encountered
with research analysis: typed input, excessively large
data sets, and slow computations. They have perhaps
the greatest potential for making production-quality
VR applications in the near term.
The poor resolution and more cumbersome inter-
actions to perform 2D tasks (e.g., web browsing) in an
immersive environment suggests that VR headsets
should be used as an accessory to conventional
screen, trackpad, mouse and keyboard, rather than
trying to replace those interfaces. Future advances in
see-through augmented reality headsets may allow
easy simultaneous use of VR data display and
traditional keyboard input. For analysis-intensive
work done by researchers in ChimeraX, we can
envision an alternative immersive environment com-
bining 2D and 3D tasks using the older stereoscopic
technologies of liquid-crystal or polarized glasses
combined with currently available ultrawide 4 K or 5 K
resolution screens for a wide field of view, with added
head tracking, and a tracked 6-degree-of-freedom
hand controller. This setup would offer lightweight
glasses, providing an augmented reality where both
2D user interfaces and 3D graphics can be mixed,
and incorporates most of the advantages of current
VR technology. While such a design is attractive for
scientific data analysis, it seems less effective
for entertainment applications than current VR ap-
proaches that allow 360-degree immersion. The
success of any immersive technology will likely be
controlled by mass-market entertainment and other
consumer applications rather than the relatively small
scientific data analysis and visualization market, so it
will be necessary to focus effort developing science
analysis on devices that are commercially the most
successful.
Methods and Materials

ChimeraX is a program for the visualization and
analysis of biomolecular structures, especially pro-
teins and nucleic acids, integrative hybrid models of
large molecular complexes, multiple sequence
alignments, and 3D electron and light microscopy
image data. It is free for academic use; runs on
Windows, Mac, and Linux operating systems; and
can be obtained from https://www.rbvi.ucsf.edu/
chimerax/. Detailed instructions for mutating a
residue in VR are available at https://www.cgl.ucsf.
edu/chimera/data/vr-scorpion-june2018/vrscorpion.
html. The use of a VR headset is enabled with the
ChimeraX command vr on, collaborative VR ses-
sions with the command meeting, and 3D micros-
copy time-series viewing with command vseries.
Hand-controller interaction modes are 3D versions
of mouse modes associated with the mousemode
command. Each of these commands is extensively
documented on the ChimeraX web site. All Python
source code is included with the ChimeraX distribu-
tion. Features described here are part of version 0.6
and earlier daily builds and are continually being
refined. ChimeraX VR requires the SteamVR run-
time system to access connected headsets available

https://www.rbvi.ucsf.edu/chimerax
https://www.rbvi.ucsf.edu/chimerax
https://www.cgl.ucsf.edu/chimera/data/vr-scorpion-june2018/vrscorpion.html
https://www.cgl.ucsf.edu/chimera/data/vr-scorpion-june2018/vrscorpion.html
https://www.cgl.ucsf.edu/chimera/data/vr-scorpion-june2018/vrscorpion.html


3995Perspective: Molecular Visualization on the Holodeck
with a free Steam account (https://steamcommunity.
com). We have only tested ChimeraX VR on the
Windows 10 operating system.
The AltPDB collaborative viewing environment

allows display of any models from the Protein Data
Bank on Windows or Mac operating systems and can
be used through a free AltspaceVR account (https://
account.altvr.com/spaces/altpdb) with source code
available at Github (https://github.com/AltPDB). From
the AltspaceVR web site, select the “Molecule Viewer
Activity” to enter a protein VR viewing room.
The Molecular Zoo application and source code

can be obtained from GitHub (https://github.com/
alanbrilliant/MolecularZoo). It is written in the C#
programming language and uses the Unity3D video
game engine. Molecular Zoo releases for the
Windows 10 operating system are available and
version 7 is described in this article. For Mac and
Linux operating systems, the Unity project can be
run with a free copy of the Unity3D development
environment (https://unity3d.com). We have only
tested Molecular Zoo on Windows 10.
Acknowledgments

We thank Lillian Fritz-Laylin and Dyche Mullins for
neutrophil light microscopy data, En Cai for T-cell
receptor light microscopy data, and Tristan Croll for
help with OpenMM molecular dynamics and the
ISOLDE ChimeraX plugin. Support for this work was
provided by theUCSFSchool of Pharmacy, 2018Mary
Anne Koda-Kimble Seed Award for Innovation, and
National Institutes of Health grant P41-GM103311.

Received 31 March 2018;
Received in revised form 15 June 2018;

Accepted 22 June 2018
Available online 28 June 2018

Keywords:
virtual reality;

ChimeraX;
Molecular Zoo;

AltPDB;
microscopy

Abbreviations used:
3D, three-dimensional; VR, Virtual reality; GPUs,

Graphics Processing Units.
References
[1] A.P.R. Johnston, J. Rae, N. Ariotti, B. Bailey, A. Lilja, R.
Webb, et al., Journey to the centre of the cell: virtual reality
immersion into scientific data, Traffic (Copenhagen, Den-
mark) 19 (2018) 105–110.

[2] A.R. Balo, M. Wang, O.P. Ernst, Accessible virtual reality of
biomolecular structural models using the Autodesk Molecule
Viewer, Nat. Methods 14 (2017) 1122–1123.

[3] A. Borrel, D. Fourches, RealityConvert: a tool for preparing
3D models of biochemical structures for augmented and
virtual reality, Bioinformatics (Oxford, England) 33 (2017)
3816–3818.

[4] M. Zheng, M.P. Waller, ChemPreview: an augmented reality-
based molecular interface, J. Mol. Graph. Model. 73 (2017)
18–23.

[5] M. Norrby, C. Grebner, J. Eriksson, J. Bostrom, Molecular rift:
virtual reality for drug designers, J. Chem. Inf. Model. 55
(2015) 2475–2484.

[6] C. Grebner, M. Norrby, J. Enstrom, I. Nilsson, A. Hogner, J.
Henriksson, et al., 3D-Lab: a collaborative web-based platform
for molecular modeling, Future Med. Chem. 8 (2016)
1739–1752.

[7] Z. Lv, A. Tek, F. Da Silva, C. Empereur-Mot, M. Chavent, M.
Baaden, Game on, science—how video game technology
may help biologists tackle visualization challenges, PLoS
One 8 (2013), e57990.

[8] J.E. Stone, A. Kohlmeyer, K.L. Vandivort, K. Schulten,
Immersive molecular visualization and interactive modeling
with commodity hardware, International Symposium on
Visual Computing, Springer 2010, pp. 382–393.

[9] C. Cruz-Neira, D.J. Sandin, T.A. Defanti, R.V. Kenyon, J.C.
Hart, The CAVE: audio visual experience automatic virtual
environment, Commun. ACM 35 (1992) 64–72.

[10] A. Febretti, A. Nishimoto, T. Thigpen, J. Talandis, L. Long, J.
Pirtle, et al., CAVE2: a hybrid reality environment for
immersive simulation and information analysis, The Engi-
neering Reality of Virtual Reality 2013: International Society
for Optics and Photonics 2013, p. 864903.

[11] Z. Ai, T. Fröhlich, Molecular dynamics simulation in virtual
environments. Computer graphics forum: Wiley online,
Library (1998) 267–273.

[12] A. Anderson, Z. Weng, VRDD: applying virtual reality
visualization to protein docking and design, J. Mol. Graph.
Model. 17 (1999) 180–186.

[13] E. Moritz, J. Meyer, Interactive 3D protein structure visuali-
zation using virtual reality, Bioinformatics andBioengineering,
2004 BIBE 2004 Proceedings Fourth IEEE Symposium on,
IEEE 2004, pp. 503–507.

[14] N. Férey, J. Nelson, C. Martin, L. Picinali, G. Bouyer, A.
Tek, et al., Multisensory VR interaction for protein-
docking in the CoRSAIRe project, Virtual Reality 13
(2009) 273.

[15] J.N. Block, D.J. Zielinski, V.B. Chen, I.W. Davis, E.C. Vinson,
R. Brady, et al., KinImmerse: macromolecular VR for NMR
ensembles, Source Code Biol. Med. 4 (2009) 3.

[16] A. Salvadori, G. Del Frate, M. Pagliai, G. Mancini, V. Barone,
Immersive virtual reality in computational chemistry: applications
to the analysis of QM and MM data, Int. J. Quantum Chem. 116
(2016) 1731–1746.

[17] B.N. Doblack, T. Allis, L.P. Davila, Novel 3D/VR interactive
environment for MD simulations, visualization and analysis,
J. Vis. Exp. 94 (2014) https://doi.org/10.3791/51384 (Dec 18,
PMID: 25549300).

[18] A. Richardson, L. Bracegirdle, S.I. McLachlan, S.R.
Chapman, Use of a three-dimensional virtual environment
to teach drug–receptor interactions, Am. J. Pharm. Educ. 77
(2013) 11.

https://steamcommunity.com
https://steamcommunity.com
https://account.altvr.com/spaces/altpdb
https://account.altvr.com/spaces/altpdb
https://github.com/AltPDB
https://github.com/alanbrilliant/MolecularZoo
https://github.com/alanbrilliant/MolecularZoo
https://unity3d.com
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0005
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0005
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0005
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0005
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0010
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0010
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0010
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0015
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0015
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0015
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0015
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0020
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0020
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0020
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0025
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0025
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0025
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0030
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0030
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0030
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0030
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0035
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0035
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0035
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0035
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0040
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0040
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0040
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0040
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0045
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0045
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0045
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0050
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0050
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0050
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0050
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0050
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0055
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0055
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0055
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0060
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0060
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0060
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0065
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0065
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0065
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0065
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0070
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0070
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0070
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0070
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0075
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0075
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0075
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0080
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0080
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0080
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0080
https://doi.org/10.3791/51384
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0090
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0090
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0090
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0090


3996 Perspective: Molecular Visualization on the Holodeck
[19] C. Stefani, A. Lacy-Hulbert, T. Skillman, ConfocalVR: Immer-
sive visualization applied to confocal microscopy, J. Mol. Biol.
(2018).

[20] I.E. Sutherland, The ultimate display. Multimedia: from
Wagner to, Virtual Reality (1965) 506–508.

[21] T.D. Goddard, C.C. Huang, E.C. Meng, E.F. Pettersen, G.S.
Couch, J.H. Morris, et al., UCSF ChimeraX: meeting modern
challenges in visualization and analysis, Protein Sci. Publ.
Protein Soc. 27 (2018) 14–25.

[22] W. Qiang, W.M. Yau, Y. Luo, M.P. Mattson, R. Tycko,
Antiparallel beta-sheet architecture in Iowa-mutant beta-
amyloid fibrils, Proc. Natl. Acad. Sci. U. S. A. 109 (2012)
4443–4448.

[23] J.P. Schulze, H.S. Kim, P.Weber, A. Prudhomme, R.E. Bohn,
M. Seracini, et al., Advanced applications of virtual reality, in:
M.V. Zelkowitz (Ed.), Advances in Computers, Academic
Press 2011, pp. 217–260.

[24] M. Chen, S.J. Mountford, A. Sellen, A study in interactive 3-D
rotation using 2-D control devices, ACM SIGGRAPH
Comput. Graph. 22 (1988) 121–129.

[25] M. Trellet, N. Ferey, M. Baaden, P. Bourdot, Content and task
based navigation for structural biology in 3D environments.
Virtual and augmented reality for molecular science
(VARMS@ IEEEVR), 2015 IEEE 1st international Workshop
on, IEEE 2015, pp. 31–36.

[26] R. Pausch, M.A. Shackelford, D. Proffitt, A user study
comparing head-mounted and stationary displays. Virtual
reality, 1993 Proceedings, IEEE 1993 Symposium on
Research Frontiers in IEEE 1993, pp. 41–45.

[27] J.M. Fulvio, B. Rokers, Use of cues in virtual reality depends
on visual feedback, Sci. Rep. 7 (2017), 16009.

[28] P. Eastman, J. Swails, J.D. Chodera, R.T. McGibbon, Y.
Zhao, K.A. Beauchamp, et al., OpenMM 7: rapid develop-
ment of high performance algorithms for molecular dynamics,
PLoS Comput. Biol. 13 (2017), e1005659.

[29] W. Wriggers, S. Birmanns, Using situs for flexible and rigid-
body fitting of multiresolution single-molecule data, J. Struct.
Biol. 133 (2001) 193–202.

[30] J. Heyd, S. Birmanns, Immersive structural biology: a new
approach to hybrid modeling of macromolecular assemblies,
Virtual Reality 13 (2009) 245–255.

[31] P.D. Adams, P.V. Afonine, G. Bunkoczi, V.B. Chen, I.W.
Davis, N. Echols, et al., PHENIX: a comprehensive Python-
based system for macromolecular structure solution, Acta
Crystallogr. D Biol. Crystallogr. 66 (2010) 213–221.
[32] T.I. Croll, ISOLDE: a physically realistic environment for
model building into low-resolution electron-density maps,
Acta Crystallogr. Sect. D 74 (2018) 519–530.

[33] L.K. Fritz-Laylin, M. Riel-Mehan, B.C. Chen, S.J. Lord, T.D.
Goddard, T.E. Ferrin, et al., Actin-based protrusions of
migrating neutrophils are intrinsically lamellar and facilitate
direction changes, elife 6 (2017).

[34] E. Cai, K. Marchuk, P. Beemiller, C. Beppler, M.G.
Rubashkin, V.M. Weaver, et al., Visualizing dynamic
microvillar search and stabilization during ligand detection
by T cells, Science (New York, N.Y.) 356 (2017).

[35] E.M. Kolasinski, Simulator Sickness in Virtual Environments,
Army research Inst for the Behavioral and Social Sciences,
Alexandria, VA, 1995.

[36] F.P. Brooks, What's real about virtual reality? IEEE Comput.
Graph. Appl. 19 (1999) 16–27.

[37] J. Trindade, C. Fiolhais, L. Almeida, Science learning in
virtual environments: a descriptive study, Br. J. Educ.
Technol. 33 (2002) 471–488.

[38] T.A. Mikropoulos, A. Natsis, Educational virtual environ-
ments: a ten-year review of empirical research (1999–2009),
Comput. Educ. 56 (2011) 769–780.

[39] S. Kim, P.A. Thiessen, E.E. Bolton, J. Chen, G. Fu, A.
Gindulyte, et al., PubChem substance and compound
databases, Nucleic Acids Res. 44 (2016) D1202–D1213.

[40] S. Vitale, R.D. Sperduto, F.L. Ferris III, Increased prevalence
of myopia in the United States between 1971–1972 and
1999–2004, Arch. Ophthalmol. (Chicago, Ill: 1960) 127
(2009) 1632–1639.

[41] D. Yamada-Rice, F. Mushtaq, A. Woodgate, D. Bosmans, A.
Douthwaite, I. Douthwaite, et al., Children and Virtual Reality:
Emerging Possibilities and Challenges, 2017.

[42] B. Herold, M. Molnar, Virtual Reality for Learning Raises
High Hopes and Serious Concerns, Education Week, 2018
37.

[43] D. Matthews, Virtual-reality applications give science a new
dimension, Nature 557 (2018) 127–128.

[44] M.O. Connor, H.M. Deeks, E. Dawn, O. Metatla, A. Roudaut,
M. Sutton, et al., Sampling molecular conformations and
dynamics in a multi-user virtual reality framework, arXiv
preprint arXiv:180102884, 2018.

[45] S. Bryson, Virtual reality in scientific visualization, Commun.
ACM 39 (1996) 62–71.

http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0095
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0095
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0095
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0100
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0100
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0105
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0105
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0105
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0105
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0110
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0110
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0110
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0110
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0115
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0115
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0115
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0115
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0120
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0120
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0120
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0125
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0125
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0125
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0125
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0125
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0130
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0130
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0130
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0130
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0135
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0135
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0140
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0140
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0140
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0140
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0145
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0145
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0145
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0150
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0150
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0150
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0155
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0155
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0155
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0155
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0160
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0160
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0160
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0165
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0165
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0165
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0165
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0170
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0170
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0170
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0170
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0175
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0175
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0175
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0180
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0180
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0185
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0185
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0185
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0190
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0190
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0190
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0195
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0195
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0195
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0200
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0200
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0200
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0200
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0205
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0205
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0205
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0210
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0210
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0210
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0215
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0215
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0220
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0220
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0220
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0220
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0225
http://refhub.elsevier.com/S0022-2836(18)30696-X/rf0225

	Molecular Visualization on the�Holodeck
	Introduction
	Results
	Replacing a residue
	Refining atomic models in density maps
	Tracking features in 3D light microscopy
	Handling large data
	Handling slow calculations
	Speech recognition
	Multi-person VR
	Molecular Zoo: learning to love chemistry

	Discussion
	Methods and Materials
	Acknowledgments
	References


