







































untitled


Mobile Volume Rendering: Past,
Present and Future
Jos�e M. Noguera and J. Roberto Jim�enez

Abstract—Volume rendering has been a relevant topic in scientific visualization for the last decades. However, the exploration of

reasonably big volume datasets requires considerable computing power, which has limited this field to the desktop scenario. But the

recent advances in mobile graphics hardware have motivated the research community to overcome these restrictions and to bring

volume graphics to these ubiquitous handheld platforms. This survey presents the past and present work on mobile volume rendering,

and is meant to serve as an overview and introduction to the field. It proposes a classification of the current efforts and covers aspects

such as advantages and issues of the mobile platforms, rendering strategies, performance and user interfaces. The paper ends by

highlighting promising research directions to motivate the development of new and interesting mobile volume solutions.

Index Terms—Mobile computing, computer graphics, volume rendering, medical imaging, data compression, cloud computing

Ç

1 INTRODUCTION

VOLUME rendering is a classic computer graphics disci-pline focused on rendering 3D scalar data [1]. It is
essential to a number of applications in several domains
that require visualization of three dimensional data sets
such as engineering, medicine, etc.

Volume rendering is a computationally expensive task
that has traditionally been confined to desktop computers
and powerful workstations. However, the recent advent of
mobile devices equipped with low energy Graphics
Processing Units (GPUs) [2] has allowed a progressive
adaptation of volume rendering techniques to these new
ubiquitous platforms.

The first efforts towards achieving real-time volume
visualization on mobile platforms date back to the year 2005
[3], [4], approximately. This pioneering work opened up a
new research line that has evolved constantly since then.
With the development of both hardware and techniques,
the quality and complexity of these solutions have dramati-
cally increased, phasing out the generally accepted assump-
tion that volume graphics require expensive, cumbersome
workstations. As the technology matured, it also began to
be progressively applied to diverse areas outside of the
purely academic world, especially medicine.

However, the problem of interactively visualizing a volu-
metric model on a handheld device is still far from being
solved. The battery-dependant nature of these devices
severely constrains their hardware in comparison to their
desktop counterparts. Given these huge differences, we can-
not expect that a mere transporting of existing desktop
techniques to the mobile scenario would lead to useable

volume-based applications on mobile devices [5]. Therefore,
further development is still required in order to improve the
state-of-the-art techniques in a number of different techno-
logical areas [6].

The goal of this state-of-the-art paper is to collect and
classify all the research carried out in the area of mobile vol-
ume rendering, in order to provide a clear vision of its past,
present and future. We hope that the following analysis of a
wide range of studies will give the reader a solid starting
point for getting involved in this relatively new field.

This paper is organized as follows: Section 2 presents the
opportunities for bringing volume rendering techniques
to the mobile environment. Difficulties are analyzed in
Section 3. Then existing efforts are discussed and analyzed
in Section 4. Section 5 specifically addresses user-interaction
issues. A research agenda is proposed in Section 6. Finally,
Section 7 concludes the paper.

2 VOLUME RENDERING IN A UBIQUITOUS
SCENARIO. ADVANTAGES AND OPPORTUNITIES

The increasingly widespread diffusion of graphics-enabled
mobile devices is one of the most relevant technological rev-
olutions of recent decades. Tablets have also been an
unprecedented success, clearly surpassing more veteran
platforms such as laptops in market penetration and sales
rates [7]. This success is due to the fact that mobile technolo-
gies offer unique features not present on classical desktop
platforms, such as ubiquity, intuitive interfaces, easy trans-
portation and everywhere/everytime access to web services
[8]. In addition, graphics capabilities and display technolo-
gies of the mobile platforms have dramatically improved in
a brief period of time. Today’s smartphones and tablets fea-
ture low energy GPUs that enable them to offer 3D graphics
that were inconceivable just a few years ago [9], with even
higher resolution than most desktop monitors.

This new context has favoured the apparition of mobile
volume rendering as a new research area with a wide
range of new potentially interesting applications, e.g.,

� The authors are with the “Graphics and Geomatics Group of Ja�en” (GGGJ),
University of Ja�en, Campus Las Lagunillas s/n, Building A3. 23071, Ja�en,
Spain. E-mail: {jnoguera, rjimenez}@ujaen.es.

Manuscript received 26 Mar. 2014; revised 25 Feb. 2015; accepted 23 Apr.
2015. Date of publication 20 May 2015; date of current version 2 Jan. 2016.
Recommended for acceptance by R. Machiraju.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identifier below.
Digital Object Identifier no. 10.1109/TVCG.2015.2430343

1164 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016

1077-2626� 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.



diverse scientific visualization apps. Remarkably, the
most extensive use of mobile volume rendering has taken
place within the medical field. This stems from the fact
that the idea of viewing medical imaging outside the radi-
ology reading room had already been attracting the inter-
est of the scientific community for years [10]. Indeed,
several authors [11], [12] have also directly identified the
availability of 3D medical radiological images on mobile
devices as one of the main challenges in the field of medi-
cal imaging distribution.

3 ISSUES AND CHALLENGES

Despite the considerable progress of mobile volume render-
ing, the current solutions are still far behind their desktop
counterparts in term of visual quality, interactiveness and
volume complexity. In addition, the mobile scenario poses
some issues that require the development of specific solu-
tions in a number of technological areas.

Now we look at various issues and open challenges
related to the implementation of volume rendering techni-
ques on mobile devices.

3.1 Hardware Limitations

Table 1 shows a comparison of the evolution over time of
several representative mobile and desktop GPUs. The
table lists the release date, the fill rate and the graphics
API supported by each GPU. For illustrative purposes,
we have selected the fill rate (millions of pixels per sec-
ond) as the most relevant value to compare the graphics
power of the different GPUs because volume rendering
applications use little geometry and depend mostly on
fragment processing [6]. Note that the fill rate numbers of
this table are peak values provided mostly by the manu-
facturers under ideal conditions.

Looking at Table 1, we see that the mobile GPUs avail-
able during the first days of mobile volume rendering
greatly resemble those of the early desktop scenario, when
the availability of dedicated graphics hardware was not as
common as it is today. For example, the Dell Axim PDA
used in some pioneer studies [13], [14] had a graphics
power similar to the first commercial GPUs available on
desktop computers back in the 90’s.

From that point, mobile GPUs have spectacularly
incremented their graphics power in less than a decade
(2005-2013). In spite of this dramatic increment, the fill
rate of 4,800 MPixel/s achieved by a modern mobile
GPU (PowerVR G6430) is far below the 42,700 MPixel/s
provided by a contemporary desktop GPU (GeForce
GTX Titan Black). In fact, Table 1 shows that over time
the computing power of the mobile GPUs appears to
stay approximately a decade behind their desktop coun-
terparts [15].

Furthermore, it should be taken into account that current
mobile displays feature resolutions that even surpass the
Full HD standard of most desktop monitors. For example,
the iPad Air 2 retina screen has a resolution of 2,048� 1,536
pixels. Obviously, these high resolution screens are very
demanding in terms of fill rate, which complicates the
development of interactive volume rendering apps. And
last but not least, mobile constraints also extend to the mem-
ory size and bandwidth, which might also cause problems
with storing large volumes of data.

Another interesting aspect in the evolution of the mobile
GPUs is the development of the associated graphics API.
Until OpenGL ES 2.0, developers did not have access to
fully programmable shaders. As a result, in the literature
we can find an important number of mobile volume render-
ing proposals that do not require any programmable GPU.
In addition, until the very recent advent of OpenGL ES 3.0
[16], 3D textures had not been natively supported by most
of the mobile GPUs.

The main reason for this gap between mobile and desk-
top GPUs stems from the fact that, by definition, mobile
devices must be small and powered by batteries. As a result,
overheating and resource poverty are two major limiting
factors that condition the development of mobile hardware.
As an illustrative example, the PowerVR MBX Lite included
in the iPhone 3G consumes as little as 60 mW, whereas a
typical high-end home desktop GPU requires no less than
150-300 W.

Because of these limitations, advanced algorithms which
perform well on current desktop platforms are still far from
being integrated into the constrained environments pro-
vided by mobile platforms [5].

3.2 Network Dependency

In traditional desktop scenarios we can safely assume that
the volume data is stored locally or at the most, available
through a reliable wired network. However these
assumptions do not extend to the mobile scenario, given
its wireless nature and memory limitations. As a result,
mobile volume rendering solutions usually depend on
costly cellular networks in order to access the required
volume data from remote servers. This poses several
additional problems that should be addressed, e.g., lack
of reliability and poor bandwidth/latency, all of which
can lead to loss of performance. Recent advances in cellu-
lar technologies such as 4G can reduce these problems to
some extent, but unfortunately we should keep in mind
that large parts of the world are, in the best cases, limited
to slow 2G networks. Local area wireless networks can
offer a fast and reliable alternative, at the cost of reducing
the mobility of these devices.

TABLE 1
Comparison of Some Representative Mobile and Desktop GPUs

Model Year Fill rate
MPixel/s

OpenGL

Intel 2700G (Dell Axim x51v) 2005 84 ES 1.0
PowerVR MBX Lite (iPhone3G) 2008 100 ES 1.1
Tegra2 (Galaxy Tab 10.1) 2011 1,200 ES 2.0
PowerVR SGX543MP2 (iPad2) 2011 2,000 ES 2.0
PowerVR SGX554MP4 (iPad4) 2012 4,000 ES 2.0
PowerVR G6430 (iPad Air) 2013 4,800 ES 3.1

Voodoo 1996 50 Glide
Riva TNT 1998 180 1.0
GeForce 256 1999 480 1.2
GeForce FX 5900 Ultra 2003 1,800 1.5
GeForce 8800 GTX 2006 13,800 2.1
GeForce GTX 285 2009 20,736 2.1
GeForce GTX 680 2012 32,192 4.2
GeForce GTX Titan Black 2014 42,700 4.4

NOGUERA AND JIM�ENEZ: MOBILE VOLUME RENDERING: PAST, PRESENT AND FUTURE 1165



3.3 Usability Concerns

The limitations of mobile devices extend to their input/out-
put modalities. Handheld devices include a small physical
screen size and input interfaces that greatly diverge from
those available on most desktop platforms (e.g., multi-touch
screens, accelerometers, and the lack of a physical key-
board). Therefore, mobile volume apps require specifically
crafted user interfaces in order to achieve a fluent and user-
engaging 3D exploration of volumetric data.

4 EXISTING PROPOSALS

Volume rendering on mobile devices is still a relatively
immature field, and therefore there exist several technical
issues that should be resolved before a fluent visualization
of large models can be achieved. Consequently, most of the
reported literature up to date has focused on computer
graphics aspects such as efficient rendering strategies, com-
pression and network transmission, memory issues, perfor-
mance assessment, etc.

We propose a multi-faceted scheme for classifying the
existing published literature on mobile volume work with
respect to several aspects: the responsibility of carrying out
the rendering tasks (Section 4.1), the selected strategy of ren-
dering (Section 4.2), the strategy used for handling the vol-
ume data (Section 4.3), and the application of the solution
(Section 4.4).

Fig. 2 presents screenshots of representative mobile vol-
ume rendering approaches. Table 2 provides an overview
of the surveyed mobile volume rendering proposals. This
table characterizes the papers with respect to their release
date, the rendering technique used, the strategy used for
managing the volume data, whether or not a programmable
GPU is required on the mobile device, the mobile device
used and the unique features provided.

4.1 Strategies for Distributing the Rendering Tasks

Existing mobile volume rendering papers can be
approached on the basis of the place where the actual ren-
dering takes place. As detailed in the following subsections,
there are four main strategies [33], [34] (see Fig. 1): thin
client (Section 4.1.1), balanced distribution of tasks
(Section 4.1.2), fat client and local rendering (Section 4.1.3).

4.1.1 Thin Client

The papers classified under the thin client category over-
come the innate limitations of mobile devices by moving the

entire rendering task to a dedicated remote rendering server
accessible via a wireless network [35]. This server is in
charge of storing, rendering and streaming to the client the
resulting images/video of the volumetric model. Therefore,
the workload on the client is relatively light and indepen-
dent of the size of the volume data.

Thin client was the natural choice when mobile GPUs
were still uncommon and thus providing volume visualiza-
tions using only local resources was still inconceivable.
Most papers published before 2008 were based on this
approach, see Table 2. But nowadays, the important devel-
opment of mobile devices graphics capabilities shown in
Table 1 has moved most of the research interest towards
local/fat solutions that do not rely on external rendering
servers. Nevertheless, thin client techniques are still an
active research field as they propose an effective solution in
scenarios where visual realism prevails over interactivity
[36], when economic limitations preclude the use of high-
end mobile devices [19], where the volume data cannot be
distributed due to confidentiality/security reasons, or
where the volume data size/complexity exceeds the mobile
device’s capacity.

Table 3 shows the performance details of most thin client
approaches reported in Table 2. From left to right, Table 3
lists the mobile device model used in the evaluation, the
rendering server configuration, the network bandwidth
required, the video codec used to encode the images sent to
the client, the number of frames per second (FPS) achieved
at the client side, the device’s screen resolution, and finally
the voxel resolution of the volumetric model. Note that
some papers provide multiple performance evaluations
using different parameters. In those cases, the general crite-
ria we followed was to reflect in the table the configuration
that achieved the best visual quality level.

Below we review the thin client approaches proposed in
the literature, remarking on the differences among them.

Lamberti and Sanna presented [3] a milestone cluster-
based remote rendering framework that was later expanded
by the same authors [17] (see Fig. 2b). The core of the frame-
work is a high-performance parallel rendering server that
implements a standard GPU-based volume renderer. The
mobile client sends the user input to the server and in turn
receives back the rendered scene as an MPEG video stream.

Several other studies have also proposed similar client/
server architectures for providing interactive medical visu-
alisation on mobile devices via WIFI. Gutenko et al. [32] pre-
sented a framework that replaced the MPEG codec used by
Lamberti and Sanna [17] for a more modern H.264 video
stream. In addition, many proposals [13], [19], [29], [36] do
not employ any video codec, but instead encode the images
generated by the server as individual still images. In this
line, Hachaj [29] and Jeong and Kaufman [13] differed in
the algorithms used to compress such still images: Hachaj
employed a lossless image compression scheme in order to
avoid unwanted noise, whereas Jeong preferred the lossy
JPEG format in order to increase interactivity during virtual
colonoscopies, see Fig. 2c. Siemens syngo WebViewer [36],
[37], on the other hand, is a web-based commercial applica-
tion intended for use in large hospitals that offers the user
the option to choose between lossless and loss-inducing
JPEG compression.

Fig. 1. The four strategies for distributing the rendering tasks. Each box
encircles the steps carried out by the mobile client for the associated
strategy. The remaining steps are performed by the remote server.

1166 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016



TABLE 2
Main Features of Mobile Volume Rendering Publications

Reference Release
date

Task
distribution
(Section 4.1)

Rendering
technique
(Section 4.2)

Volume
management
(Section 4.3)

GPU Device
tested

Unique
features

Lamberti and
Sanna [3]

2005 Thin 3D-textured slic-
ing (in the server)

3D Texture HP iPaq H5500 Uses a Chromium cluster as
rendering server.

Zhou et al. [4] 2006 Thin/balanced Independent of
the technique

n/a ‘ Nokia N90 General framework for
remote rendering. Focuses
on compression and network
transmission.

Jeong and
Kaufman [13]

2007 Thin Ray-casting
(in the server)

3D texture ‘ Dell Axim X50v Interactive virtual
colonoscopies.

Lamberti and
Sanna [17]

2007 Thin 3D-textured
slicing
(in the server)

3D texture ‘ HP iPaq H5500 Expands their previous
proposal [3].

Moser and
Weiskopf [18]

2008 Local 2D-textured
slicing

Stack of 2D
textures

‘ Dell Axim X50v First volume renderer fully
implemented on a mobile
device.

Park et al. [14] 2008 Thin/fat Ray-casting (in the
server). 2D ren-
dering using a
cutting plane in
any arbitrary axis
(in the client)

n/a HP iPaq Hx4700 Collaborative sessions.

Meir and
Rubinsky [19]

2009 Thin n/a n/a ‘ HTC G1 Framework for acquisition and
visualization of 3D ultrasound
scans in developing countries.

Congote et al. [20] 2011 Fat Ray-casting Flat 2D texture @@@@ Samsung
Galaxy S

Implemented in WebGL.

Tapna [21] 2011 Local 2D-textured
slicing

Flat 2D texture @@@@ Nokia N900 Studies several subsampling
methods for simplifying vol-
umes.

Campoalegre
et al. [22]

2012 Balanced Ray-casting Block-based
volume

@@@@ HTC Desire Z Proposes a client-server
transfer function-aware
compression scheme based
on wavelets.

ImageVis3D [23] 2012 Local/thin 2D-textured
slicing

Stack of 2D
textures

‘ iOS General purpose volume
viewer. Available in AppStore.

Movania and
Feng [24]

2012 Fat Ray-casting Flat 2D texture @@@@ Samsung
Galaxy S II

Implemented in WebGL. Single
pass ray-casting that expands
Congote et al. [20].

Noguera et al. [25] 2012 Local 3D-textured
slicing

Flat 2D texture @@@@ iPad2 Proposes a 3D-textured slicing
approach that does not require
a recalculating of the proxy
geometry.

Noguera et al. [26] 2012 Local/fat Ray-casting Flat 2D texture @@@@ iPad2 Proposes a scheme to maximize
the usage of the GPU’s textures
to render larger volumes. Can
be implemented in WebGL.

Noon [27] 2012 Local 2D-textured
slicing

Stack of 2D
textures

‘ iPad2 Discusses several tricks to
improve the rendering speed.
Provides detailed implementa-
tion details.

Balsa and
V�azquez [6]

2012 Local Ray-casting, 2D
& 3D-textured
slicing

3D textures, stack
of 2D textures

@@@@ HTC Desire Z Compares the performance of
different volume rendering
techniques.

Butson et al. [28] 2013 Local 2D-textured
slicing

Stack of 2D
textures

‘ iOS Based on ImageVis3D [23]
Combines volumes and geome-
try. Implements a deep brain
stimulation simulator.

Hachaj [29] 2013 Thin 3D-textured
slicing (in the
server)

3D Texture ‘ Samsumg Galaxy
Tab 2

Uses lossless compressions
algorithms to transmit reliable
images to the mobile client.

Noguera et al. [30] 2013 Local Ray-casting Flat 2D texture @@@@ iOS M-learning tool for teaching
physical therapy in
laboratories.

Movania et al. [31] 2014 Fat Ray-casting,
3D-textured
slicing

Flat 2D texture @@@@ Samsung
Galaxy S II

Implemented in WebGL. Com-
pares their previous work [24]
with a 3D-textured slicing
method.

Gutenko et al. [32] 2014 Thin Ray-casting
(in the server)

n/a ‘ IBM Thinkpad
X41

Encodes the video into an
H.264 stream.

NOGUERA AND JIM�ENEZ: MOBILE VOLUME RENDERING: PAST, PRESENT AND FUTURE 1167



The work of Park et al. [14] followed similar goals to
the previous proposals, but added some innovative ele-
ments. For example, their solution allows local visualiza-
tions to a minor degree. That is, the server provides
clients with downsampled subvolumes that can be visual-
ized locally using a 2D slicing plane. This low quality ver-
sion allows the user to examine the model interactively.
Once an interesting view is defined, a high quality 3D
visualization can be downloaded from a remote rendering
server. The system proposed by Park et al. [14] also
allows collaborative sessions, as users can share views
with other colleagues.

In terms of performance, Table 3 shows that the number
of FPS varies significantly between different proposals,
ranging from 30 FPS [32] to less than a frame per second
[14], [19]. One of the reasons for this difference resides in
the use of distinct technological resources. That is, the recent
proposal of Gutenko et al. [32] benefits from a more modern
hardware and video codec, whereas Park et al. [14] and
Meir and Rubinsky [19] do not even use the GPU on the
server side, which considerably slows down the rendering.
Another important reason resides in the fact that not all sol-
utions seek the same goals. Most notably, while most pro-
posals aim at achieving an interactive visualization of the
volume dataset, Meir and Rubinsky [19] focused instead on
obtaining an off-line batch processing of medical imaging
for medical diagnosis purposes.

Additionally, in sight of Table 3 we can observe that
these techniques, although very akin to commodity mobile
devices, typically have to deal with a number of issues:

Network issues. Issues such as latency, congestion, etc.
can reduce interactivity. Note that all performance evalu-
ations reported in Table 3 were carried out using a wire-
less LAN instead of a wide-area cellular network, which
was to be expected on a mobile device. This is due to the
high data traffic of remote rendering applications. For
instance, UMTS (commonly referred to as 3G) provides a
384 kbit/s downlink and a latency of roughly one second.
By comparing these values to the bandwidth required by
the proposals of Table 3, we find that neither Lamberti
and Sanna [17] nor Gutenko et al. [32] can be deployed
under such a restricted network. Even HSDPA (3.5G),
which provides 14,000 kbit/s downlink under optimal
conditions [19], could be insufficient for achieving an

actual interactive response in the case of Gutenko et al.
[32], which requires up to 12,288 kbit/s.

Scalability. The number of concurrent devices is limited
as the server can be a potential bottleneck. For this reason,
several solutions described in Table 3 employ a complex,
multi-node cluster of PCs on the server side. This require-
ment complicates the development and practical usage of
thin client approaches.

Loss of quality. In order to reduce the traffic, the image
quality is usually compromised by applying lossy compres-
sion algorithms which could be a problem for certain medi-
cal applications [38]. Another usual trade-off consists of
reducing the resolution of the image streamed to the client,
e.g., Hachaj [29] uses a 5122 image resolution instead of the
1;024� 600 supported by the Galaxy Tab.

4.1.2 Balanced

The articles that fall into the balanced category aim at dis-
tributing the rendering task between the server and the cli-
ent. In this way the graphics capabilities of modern mobile
devices can be used to improve the overall performance of
the system. However, the distribution of the workload is
not a trivial task. The techniques described below follow
different approaches to achieve this aim.

Zhou et al. [4] presented a client-oblivious framework
where the mobile devices can vary from low to high GPU
capacities (see Fig. 2a). The data model is independent of
the rendering approach that the client is able to deal with:
point-based rendering, surface-based rendering or volume
rendering. From the same transmitted data the client is
capable of reconstructing points, isosurfaces or volumes
with minimum extra redundancy.

More recently, Campoalegre et al. [22] proposed a block-
based compression scheme for interactively visualizing 3D
medical datasets on mobile devices. This scheme is based
on Haar wavelets for 3D volumes [39] and quantization. To
increase the compression rate the transfer function (TF) is
applied in a previous step, then the resulting volume is
smoothed and null blocks are tagged. The wavelet coeffi-
cients are quantized based on visual metrics in order to limit
the compression error. The compressed volume is sent to
the client, where it is decompressed and rendered by using
ray-casting (see Section 4.2.1), considering different levels of
detail (LOD) per block.

TABLE 3
Performance of Thin Client Approaches

Reference Device tested Server Bandwidth
kbit/s

Video
Codec

FPS Screen
resolution

Volume
resolution

Lamberti et al.
[17]

HP iPaq H5500 8 � Pentium IV, NVIDIA
Quadro FX-1100

500 - 1,000 MPEG 11.4 5122 5123

Jeong and
Kaufman [13]

Dell Axim X50v Dual Xeon, NVIDIA
Quadro FX 4500

120 JPEG 4.0 480� 576 5122 � 361
Park et al. [14] HP iPaq Hx4700 9 � Pentium IV n/a MPEG 1/8.8 480� 640 2563
Meir and
Rubinsky [19]

HTC G1 Core 2 Duo laptop n/a JPEG 178s
(batch of
36 frames)

n/a 2562 � 80

Hachaj [29] Samsung Galaxy
tab 2 7.0

Core 2 Duo, NVIDIA
GeForce GTX 770

n/a Lossless 1.7 5122 5122 � 415
Gutenko et al.
[32]

IBM Thinkpad X41,
Microsoft Surface

6 � Dell Precision T7600,
NVIDIA Quadro K5000

12,288 H.264 30.0 10242 5122 � 431

1168 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016



4.1.3 Fat Client / Local Rendering

In fat client and local methods, the rendering task is per-
formed exclusively on the client side. These methods do
not involve any rendering on the part of the server, and
consequently, they do not require a server with graphics
capabilities. In fat client approaches the volume data
resides in a remote file server. Clear examples of this
approach are all WebGL-based [40] applications [20], [24],
[26]. On the contrary, in local approaches [6], [18], [28] all
the data is available in the device’s local memory, so no
network connection is required and the mobile device is
completely self-sufficient.

With the improvement of the graphics capabilities of
mobile devices, fat client/local approaches are becoming
widely adopted by most recent proposals in the literature,
see Table 2. This stems from the fact that they can take full
advantage of the graphics capabilities of modern devices
while removing the dependence on an external server and
the network suffered by thin client approaches.

Table 4 shows the performance details of most fat client
and local approaches reported in Table 2. From left to right,
Table 4 provides the mobile device model used in the evalu-
ation, the technique used to render the volume (see
Section 4.2), the number of frames per second, the device’s
screen resolution, the voxel resolution of the model and the
number of times that the volume is sampled in order to
visualize it. Similarly to Table 3, the general criteria we

followed to compile the table was to depict for each paper
the configuration that achieved the best visual quality level.

From Table 4 we can observe that, as of this writing,
mobile volume rendering is feasible, although real-time per-
formance is still not possible using the current mobile
hardware.

Only the most recent solutions such as V�azquez and
Balsa [6] or Movania et al. [31] achieve a performance that
can be considered as nearly interactive: 7 and 5 FPS respec-
tively. In fact, by comparing Tables 3 and 4 we see that thin
client solutions can still provide a better performance and
visualize a larger volume than fat client/local solutions, at
the cost of requiring a remote server and a permanent net-
work connection.

For these reasons, up to the moment the major research
challenge of the papers that fall into this category is to
find efficient strategies for visualizing large volumes at a
decent frame rate while guaranteeing high visual quality.
As the development of fat client/local approaches largely
depends on the rendering technique used to visualize the
volume, we will review these proposals in more detail in
Section 4.2.

Finally, we consider that ImageVis3D Mobile [23] (see
Fig. 2h) deserves a special mention since it combines the
best of two worlds. By default, this volume rendering appli-
cation for iOS visualizes the volume data using purely local
resources. However, it can optionally work as a thin client

Fig. 2. Screenshots of representative volume rendering solutions. (a) An early attempt to achieve remote volume rendering on a mobile device [4]. (b)
The image shown in the screen was remotely rendered by a PC cluster [17]. (c) A virtual colonoscopy [13]. (d) One of the first attempts at locally ren-
dering a volume using an early GPU-enabled PDA [18]. (e) A WebGL implementation of a volume renderer [20]. (f) Combination of volume graphics
and standard geometry in a simulation of deep brain stimulation therapy [28]. (g) An example of an educational tool for physiotherapists on an iPad
[30]. (h) Imagevis3D, a freeware volume renderer for iOS [23].

NOGUERA AND JIM�ENEZ: MOBILE VOLUME RENDERING: PAST, PRESENT AND FUTURE 1169



application in order to visualize high quality images of
larger datasets with the help of a remote server.

4.2 Rendering Techniques

Below we categorize the different volume rendering techni-
ques that have so far been used successfully in mobile envi-
ronments by using a fat client/local rendering strategy, see
Section 4.1.3. Up to now most research carried out in this
regard has focused on adapting and optimizing the classical
direct volume rendering techniques developed years ago
for desktop computers [1]. Historically, these techniques
have been classified into two different categories: ray-cast-
ing and texture-based approaches. Ray-casting approaches
will be reviewed in Section 4.2.1. Texture-based approaches,
on the other hand, are usually subdivided into two
subcategories: 2D-textured and 3D-textured slicing, see
Sections 4.2.2 and 4.2.3, respectively.

4.2.1 Ray-Casting

All mobile proposals within the ray-casting category
employ a GPU implementation of the classic volume ray-
casting technique. This technique was originally proposed
by Levoy [41] and, afterwards, adapted to the programma-
ble GPU by Kr€uger and Westermann [42]. This method
defines the color of each screen pixel by tracing a ray into
the volume and solving the ray integral along it, see Fig. 3a.
This integral is computed as a ray-traversal loop within the
fragment shader of the GPU.

When compared with the textured-based approaches,
ray-casting usually provides the best image quality, but also
the worst performance on mobile hardware, as confirmed

by the comparisons provided by several authors such as
Noguera et al. [25], Balsa and V�azquez [6], and Movania
et al. [31], and summarized in Table 4. By looking at the
number of FPS we observe that ray-casting is clearly outper-
formed by textured-based alternatives.

This is due to the differences in the number and complex-
ity of the fragments to be processed within the fragment
shader of the GPU. Textured-based approaches require
computing a large number of very light fragments, and
most of the work is done in the later composition phase. By
contrast, ray-casting requires processing just one fragment
per screen pixel, but this fragment includes a large traversal
loop that samples the whole volume range. Note that loops
and branching notably slow down the performance of
today’s mobile GPUs, and thus a larger number of lighter
fragments becomes more efficient. As an illustrative exam-
ple, adding a simple if-else clause within the inner loop of
the ray-casting algorithm can slow-down the FPS up to an
order of magnitude in devices such as the iPad2 [25],
although this performance cost is expected to be reduced on
newer OpenGL ES 3.0-capable devices [43].

Another inherent limitation of today’s mobile GPUs that
affects the visual quality of the ray-casting solutions is the
restricted number of operations that can be run within a
shader before the execution aborts. This limiting factor is a
recurrent issue found by several researchers [24], [27], [31]
that caps the maximum number of iterations of the ray-tra-
versal loop. For example, Movania and Feng [24] reported
that the maximum number of ray-casting steps supported
by the Samsung Galaxy S II smartphone was around 100.

Another major drawback of ray-casting is the require-
ment of hardware 3D texture support in the GPU. Most

Fig. 3. Rendering strategies typically used in the mobile environment. (a) Ray-casting. (b) 2D-textured slicing (object-aligned). (c) 3D-textured slicing
(view-aligned). (d) 3D-textured slicing. The fixed slices are view-aligned by rotation of the 3D texture-coordinates [25].

TABLE 4
Performance of Fat Client and Local Rendering Approaches

Reference Device tested (GPU) Rendering technique
(Section 4.2)

FPS Screen
resolution

Volume
resolution

Number
slices/steps

Moser and Weiskopf [18] Dell Axim X50v (Intel 2700G) 2D-textured slicing 2.0 480 � 640 642 � 128 128
Tapna [21] Nokia N900 (PowerVR SGX530) 2D-textured slicing 1.2 n/a 5123 n/a
Congote et al. [20] Samsung Galaxy S (PowerVR SGX540) Ray-casting 2.0 - 3.0 n/a n/a n/a
Campoalegre et al. [22] HTC Desire Z (Adreno 205) Ray-casting 0.8 - 1.2 480 � 800 5122 � 282 n/a
Movania and Feng [24] Samsung Galaxy S II (PowerVR SGX540) Ray-casting 1.3 - 1.6 n/a 1022 � 97 100
Noguera et al. [25] iPad2 (PowerVR SGX543MP2) 3D-textured slicing 2.4 1,024 � 768 1282 � 186 40

Ray-casting 1.4 1,024 � 768 1282 � 186 40
Noguera and Jim�enez [26] iPad2 (PowerVR SGX543MP2) Ray-casting 0.8 430 � 320 5122 � 384 80
Balsa and V�azquez [6] HTC Desire Z (Adreno 205) 2D-textured slicing 7.3 480 � 800 2563 128

3D-textured slicing 5.1 480 � 800 2563 128
Ray-casting 1.5 480 � 800 2563 128

Movania et al. [31] Samsung Galaxy S II (PowerVR SGX540) 3D-textured slicing 4.3 - 5.1 1;0242 2563 100
Ray-casting 1.0 - 1.1 1;0242 2563 100

1170 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016



available mobile hardware does not support this feature, as
it has not been mandatory until OpenGL ES 3.0. This is a
common issue for several techniques and the different solu-
tions are detailed in Section 4.3.

Nevertheless, with the fast evolution of mobile GPUs
most recent proposals in the literature widely embrace this
technique [20], [22], [24], [26] because it usually provides
better visual quality than textured-based rendering techni-
ques. Below we review the most prominent ones and how
they contribute to the mobile volume rendering world.

We start with the work of Congote et al. [20] as they pre-
sented the first documented attempt to implement a ray-
casting volume renderer on a mobile device. Their proposal
accommodates the Kr€uger and Westermann approach [42]
to the WebGL web environment [40], which guarantees
cross-compatibility between mobile and desktop platforms.
However, their performance evaluation focused on desktop
platforms, and only a quick experiment is described on a
mobile device. This explains the n/a values of Table 4.
However, later authors such as Noguera and Jim�enez [26]
and Movania and Feng [24], [31] used Congote’s solution as
a baseline to compare their own proposals, and in turn, a
more exhaustive evaluation of the Congote’s solution can be
found in these later studies.

In addition,Movania and Feng [24] proposed a number of
optimizations over the Congote solution that doubled the
rendering performance. The most remarkable one is the pro-
posal for an efficient ray-casting algorithm that only requires
a single rendering pass, whereas the original approach [20],
[42] required two passes to achieve the same goal.

It is important to remark that, despite the low number of
FPS of the ray-casting solutions reported in Table 4, in prac-
tice all these solutions allow an interactive user experience
by reducing the number of ray samples while the user is
interacting until a fluent frame-rate is achieved. Another
usual trade-off employed to improve interactiveness con-
sists of reducing the screen resolution for the same purpose.
In both cases, as soon as the interaction ends, a new higher
quality image is generated and displayed to the user.

4.2.2 2D-Textured Slicing

Texture-based volume rendering is a popular set of techni-
ques that perform the sampling and composition of a vol-
ume by rendering a stack of 2D slices (known as proxy
geometry) inside the volume [44], as shown in Figs. 3b, 3c
and 3d. These slices are rendered in order, back-to-front or
front-to-back, and the corresponding color value of each
pixel is accumulated using texture blending. This proxy
geometry is represented by object-aligned (Figs. 3b) or
view-aligned (Figs. 3c and 3d) hardware primitives.

If the stack of slices is aligned with the volume we want
to visualize, the technique is called 2D-textured slicing. This
technique requires the storage of three slice sets, one for
each axis. Only the set that is most perpendicular to the
view direction is actually used for rendering, see Fig. 3b.

The 2D-textured slicing technique is usually considered
an obsolete approach on desktop platforms because of the
visual artifacts that appear when switching from one slice
set to another, and to the extra memory requirement for
storing the three sets of slices. But in spite of these issues,
several researchers [6], [18], [23], [27], [28] have recently

dusted off this technique because it provides a number of
advantages that makes it very akin to the constrained
mobile platforms:

� The volume data itself can be stored in the device’s
GPUmemory by only using 2D textures (Section 4.3).
This is very convenient on current mobile hardware,
given the usual lack of 3D texture support.

� It does not require programmable shaders in the
GPU, and thus this technique was feasible on early
mobile GPUs that only supported OpenGL ES 1.0
and 1.1.

� Its superior performance on mobile hardware. For
example, the experiments of Balsa and V�azquez [6]
reported a performance of 7.3 FPS, whereas the per-
formance of 3D-textured slicing and ray-casting
under the same conditions was, respectively, 5.1 and
1.5 FPS, see Table 4.

Owing to this simplicity, Moser and Weiskopf [18] used
this technique when they developed their pioneer proposal
to locally render volumes using an early GPU-enabled PDA
(a Dell Axim, see its specs in Table 1). Fig. 2d depicts a
screenshot of their proposal. Because of the limitations of
the hardware, they suggested performing the visualization
on a low-resolution intermediate image that was later
scaled-up to cover the whole screen. In this way the number
of fragments to compute could be drastically reduced,
resulting in a better overall performance at the cost of a
lower image quality.

It is important to remember that, up to this writing,
2D-textured slicing is the only volume rendering technique
capable of achieving an interactive experience on current
mobile hardware without considerably sacrificing the visual
quality when the user interacts. For this reason, this tech-
nique is the typical choice of commercial applications such
as ImageVis3D Mobile [23].

4.2.3 3D-Textured Slicing

The 3D-textured slicing technique is similar to 2D-textured
slicing alternative, but the proxy geometry is aligned with
the view, instead of the volume [45] (see Figs. 3c and 3d). As
a result, 3D-textured slicing methods do not suffer from
the visual artifacts experienced by the object-aligned
approaches. On the downside, graphics hardware support
for 3D textures is needed and the proxy geometry must be
recalculated each time the view position varies. For these
reasons this technique is not very popular in the mobile sce-
nario, with exceptions such as the proposal of Movania
et al. [31].

Noguera and Jim�enez. [25] presented a volume rendering
strategy for mobile devices that circumvents the recalcula-
tion of the proxy geometry by using a unique stack of slices
that always remains view-aligned, see Fig. 3d. If the view
position varies the relative position of the observer and the
slices does not vary, but instead the 3D texture coordinates
of the proxy geometry are properly rotated according to the
desired view angle. In this way the volume can be visual-
ized from any view angle with a fixed set of 2D square-
shaped slices.

In general, we can affirm that this technique is an inter-
mediate solution between ray-casting and 2D-textured

NOGUERA AND JIM�ENEZ: MOBILE VOLUME RENDERING: PAST, PRESENT AND FUTURE 1171



slicing. While ray-casting provides a superior visual quality,
it is more costly in term of GPU usage, as shown in the com-
parisons of Movania et al. [31] and Noguera et al. [25] and
in Table 4. On the other hand, this technique lacks the visual
issues suffered by the 2D-slicing technique at the cost of a
more complex implementation and higher computation
requirements.

4.3 Strategies for Volume Management

Volume rendering requires a large amount of memory, a
resource that is typically very scarce on mobile platforms.
The thin client solutions, described in Section 4.1.1, over-
come this problem by simply delegating the rendering task
to a remote server. However, solutions that perform the
rendering on the mobile device require the data to be mem-
ory-resident. That is, all the data should fit into the video
memory. According to the storage method, we can classify
current efforts into the following categories: 3D textures
(Section 4.3.1), stack of 2D textures, (Section 4.3.2) and flat
3D textures (Section 4.3.3).

4.3.1 3D Texture

3D textures represent the most natural way to store a vol-
ume dataset. Unfortunately, as of this writing their support
is still limited on mobile GPUs. Nevertheless this situation
will likely change in the future, as new APIs such as
OpenGL ES 3.0 [16] include in their specifications the sup-
port of 3D texture mapping.

4.3.2 Stack of 2D Textures

In the case of a stack of 2D textures, the volume is stored as
three sets of axis-aligned 2D textures, see Fig. 4a. This way
of storing the volumetric data is usually coupled with the
2D-textured slicing rendering technique described in
Section 4.2.2. The great advantage of this storage solution is
its common availability in almost every device, and its high
performance. Conversely, the memory requirements, the
interpolation error, the artifacts due to changing among the
different sets and the inconsistent sampling rate are its
main disadvantages [1].

4.3.3 Flat 3D Texture

Rendering techniques such as ray-casting and 3D-textured
slicing (see Sections 4.2.1 and 4.2.3) require the use of 3D

textures to store the volume data. Congote et al. [20] (see
Fig. 2e) presented a solution that circumvented this limita-
tion by tiling each slice of the 3D texture into a single 2D tex-
ture following a matrix configuration as shown in Fig. 4b.
This layout is usually known as flat 3D texture. Since then,
the flat 3D texture technique has been widely embraced by
most ray-casting and 3D-textured slicing mobile solutions
running OpenGL ES 2.0 enabled GPUs [20], [21], [24], [25],
[31], as a way towork around the lack of 3D textures.

Unfortunately, this technique is not free from additional
problems [27]. First, it requires additional computations in
the GPU in order to transform 3D texture coordinates into
2D coordinates, which can slow down the process. Next,
this strategy presents several issues related to interpolation:
since 2D textures do not provide 3D interpolation, a costly
manual emulation is required within the shader. In addi-
tion, special care has to be taken to avoid invalid interpola-
tion at the borders of each slice. On top of these problems,
while flat 3D textures successfully removes the need of 3D
textures, they also severely limit the size of the volume that
can be represented.

To understand what this limitation entails, let us con-
sider a single 2;0482 texture (the maximum texture size sup-
ported by most devices prior to the iPad2 and the iPhone4).

This texture can hold a volume of only 1613 voxels by using
a flat 3D structure. By looking at Table 4 we can find several
studies limited by this restraint [24], [25]. Now let us con-

sider a texture of 4;0962 texels, which is the maximum size
we can find nowadays in devices such as the iPad Air 2. In

this case, the maximum volume size increases to 2563 vox-
els. Note that currently this limitation poses an upper limit
to all solutions in Table 4.

Noguera and Jim�enez [26] are a particular exception, as
they extended the flat 3D texture technique in order to
exploit the maximum texture capacity of the GPU. Their
proposal uses the multi-texturing storage capacity of the
device with all the available texture units in the GPU and all
four color channels to encode large volumetric models on a
set of 2D textures representing a flat 3D texture. Their
results showed that a model of up to 5123 voxels can be suc-
cessfully stored within a mobile GPU featuring eight texture

units of 2; 0482 texels each.

4.4 Applications

Since mobile volume rendering is still a young discipline,
there are still several technical issues, such as performance
or visual quality, that need to be fixed in order to be usable
in practical applications. However, as the technology
matures a new range of proposals are gradually appearing
in the literature that seek to join volume visualization tech-
niques with the mobile devices’ unique features in order to
develop new practical applications.

Most current proposals suggest using mobile volume
rendering in the following fields: visualization of scalar
data, as a support tool in the clinical workflow, and m-
learning.

4.4.1 Visualization

The visualization of scalar data, including medical radiolog-
ical images, is the most direct application of volume

Fig. 4. Strategies for volume management. (a) Stack of axis-aligned 2D
textures. (b) Flat 3D texture.

1172 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016



rendering. There exist some commercial mobile visualiza-
tion applications available in the major app markets. They
allow the user to explore volumetric data anywhere and at
any time, without relying on bulky desktop computers that
might not be available directly at the user location. These
applications allow us to perform rotations, cuts, etc on the
volume as well as to modify the transfer function. Among
these applications we can cite ImageVis3D Mobile [23], Sie-
mens syngo [37] and CTvox [46].

4.4.2 Support Tool in the Clinical Workflow

Mobile devices can also play an interesting supporting role
in several stages of the image-based clinical workflow: diag-
nostics (including data acquisition and the radiologist’s
image review), treatment planning (such as preoperative
surgery planning), support for clinical decision making and
actual treatment (such as surgery). Using mobile devices,
3D MRI (magnetic resonance imaging) or CT (computed
tomography) images of the patient to be diagnosed can be
sent wirelessly to the diagnosing physician, who can ana-
lyze such images from his home, another hospital or even
his car, thus saving valuable time.

Siemens syngo [37] is a thin client commercial visualiza-
tion application designed with this concept in mind.
Although it cannot legally be used for diagnosis, it is
intended to be used within a hospital network to share
information with fellow physicians or to illustrate and dis-
cuss results directly with patients without moving them to a
reading room.

Butson et al. [28], on the other hand, presented an iPad
application whose goal was to translate complex simula-
tion models of deep brain stimulation therapies to a plat-
form which would be easy to carry in clinical
environments, see Fig. 2f. ImageVis3D Mobile [23] was
used to visualize the patient’s brain and the electrode
contacts required to perform the simulation. The evalua-
tors found the application very intuitive to use (thanks to
the multi-touch interface) and reported that it led to a
more efficient clinical workflow.

Telemedicine is another promising field to which mobile
technologies can be applied effectively. Telemedicine
includes scenarios such as in-hospital care management,
remote teleconsulting, collaborative diagnosis and emer-
gency situation handling [14]. In this line, Meir and
Rubinsky [19] took advantage of the ubiquitous nature of
mobile devices to develop a telemedicine framework
intended for use in undeveloped or remote regions of the
world. The key idea is to acquire and produce 3D ultra-
sound scans using cloud computing and cheap hardware
on the client side (a commodity mobile device connected to
a low-end transducer). Raw data is collected at the patient
site and later, when the practitioner is back at the local clinic
where Internet is available, it is sent to a centralized server.
The server in turn returns high quality 3D visualizations
which can be used for diagnosis.

4.4.3 M-Learning

Mobile learning is a key trend of educational applications
[47], [48], [49] that can also benefit from 3D medical imag-
ing. Following this line, Noguera et al. [30] proposed

combining both technologies and described a new educa-
tional tool designed for learning anatomy in scenarios that
require high mobility of the practitioner, e.g., when practis-
ing physical therapy on living patients in a physiotherapy
teaching laboratory. Their experiments in an actual learning
scenario highlighted the positive impact of mobile volume
graphics on the learning outcomes of the students. The les-
sons were able to focus on the manual therapy techniques
in a more efficient way because students no longer had to
constantly move away from the stretchers to consult anat-
omy on a desktop PC.

5 USER INTERFACES

Interactivity is a key feature of the 3D user experience with
mobile devices [50]. However, up to now this issue has
remained relatively untouched in most existing publica-
tions. This stems from the fact that these publications typi-
cally present simple prototypes consisting of a single
volumetric model centered on the screen (see Fig. 2) and
that the exploration is limited to rotations, panning and
zooming.

Fortunately all of today’s smartphones and tablets fea-
ture a multi-touch screen, which has been recognized as a
natural and appealing style of input for mobile 3D applica-
tions [50]. In this context, the touch-based arc-ball technique
[51] has emerged as the de facto standard interaction meta-
phor for volumetric data exploration. In this technique, the
touch-screen is used to manipulate an invisible ball that
contains the volume to be rotated. The resulting rotation
depends on where on the ball the user began the interaction
and in which direction he dragged his finger. The arc-ball
technique has proved to be faster and more effective than
other input methods such as keyboards [52]. Although most
proposals referenced in this survey adhere to this scheme,
some alternative solutions have arisen. For example, the
solution proposed by Park et al. [14] allows the user to draw
a NURBS on the touch-screen to predefine a path for the
camera in order to generate an animation.

Note that the arc-ball technique is usually limited to
inspecting objects from outside. But Jeong and Kaufman
[13] went a step further and allowed users to enter into the
volume itself to perform free virtual colonoscopies. In order
to ease the orientation of the user, they complemented the
virtual view with several additional thumbnails of the
patient’s colon (axial, coronal, sagittal and cross sectional),
see Fig. 2c.

This idea of complementing the virtual view with
additional information is very recurrent, although most
proposals resorted to overlapping vector data. For exam-
ple, Jeong and Kaufman [13] and Park et al. [14] allow the
user to draw vector data directly over the volume using
the touch-screen, typically for annotation purposes. Over-
lapped vector lines are also the standard way to represent
a graphical transfer function editor [6], [18], [23], [24],
[30], [32].

The role of the TF is fundamental in volume rendering, as
it essentially makes the volume visible. A TF is a user-
defined function that indicates how to assign optical proper-
ties (like color and opacity) to the rendered volume data
based on the grey-tone of the original images [1].

NOGUERA AND JIM�ENEZ: MOBILE VOLUME RENDERING: PAST, PRESENT AND FUTURE 1173



Unfortunately, defining a good TF is a tedious, trial-and-
error task [53], [54], which makes an easy-to-use graphical
editor a must-have for any volume rendering application.
Over the years, several types of TFs have arisen [1],
although all mobile volume renderers reported in the litera-
ture have adhered to the simplest type: the one-dimensional
TF. The reason is twofold: On the one hand, 1D TFs are eas-
ier to compute, which is a clear advantage on limited hard-
ware. On the other hand, the definition of 1D TFs requires
less input from the user than other, more complex, multidi-
mensional TF types [54].

Fig. 5 displays the TF editors implemented by several
mobile solutions. Clearly, we see that they share a similar
appearance and characteristics. These editors present a
curve that the user can modify with his finger in order to
identify interesting parts of the volume. This curve is used
to map a color and a transparency value (vertical axis) to
each grey tone of the original image (horizontal axis). Most
solutions [18], [23], [46] typically allow the user to indepen-
dently control four curves, which are associated with the
red, green, blue and transparency color channels, see
Figs. 5a and 5b. Noguera et al. [30], on the contrary, realized
that the TF editor should be more accessible to inexperi-
enced mobile users, so they opted for reducing the number
of color channels that the user can adjust to just one. Fig. 5c
shows their proposal. As a trade-off, this simplification
reduces the flexibility of the editor and limits the visualiza-
tion to gray-scale colors.

Note that the use of a touch-screen to define a TF has
some inherent problems not presented in a traditional
mouse-based desktop TF editor. For example, the size of
human fingers and the lack of sensing precision can hamper
the definition of a thin curve with sufficient accuracy. This
is a considerable issue, because a small shift of some pixels
can considerably alter the visualization. For this reason
CTvox [46] proposed a spline-based editor, see Fig. 5b. By
using this spline, users only have to worry about a small
number of control points instead of freely drawing the com-
plete length of the curve as with most other solutions [18],
[23], [30]. Another inherent issue of touch-screen interfaces
is the occlusion of the curve by the finger. This issue was cir-
cumvented by Balsa and V�azquez [6] by adding a mini-
zoom tool that appears over the finger while interacting
with the curve, see Fig. 5d.

6 RESEARCH AGENDA

Thus far we have covered most past and present work on
mobile volume rendering. In this section we will shift our
focus to the future in order to highlight some challenges
and possibilities for this rapidly developing field.

The potential landscape for improving the current solu-
tions is quite diverse. Below are some potential areas for
additional research.

6.1 Technological Trends

Through this survey we have seen that mobile volume ren-
dering has become a palpable reality. However, with the
current state of the technology it is still a challenge to
achieve interactive visualizations of large enough volume
datasets, as was reported in Tables 3 and 4. Only a thin cli-
ent strategy with a powerful server workstation can today
achieve real-time (see Table 3). Nonetheless, current band-
width capability hinders the quality and the scalability of
this kind of solution.

However, the current achievements are very promising if
we take into account how quickly this field has evolved
since its recent origins in the late 2,000’s. Current mobile
displays exceed the resolution of the human retina, and
newer GPUs are embracing the new universally accepted
standard OpenGL ES 3.0, which will gradually overcome
the limitations in terms of 3D textures, performance, loops
and branching penalization within the shaders.

Nevertheless, as we mentioned in Section 3.1, an
apparent gap of around 10 years is kept between the
graphics capabilities of mobile devices and their desktop
counterparts [15]. Regarding the future, it is not an easy
task to foresee how mobile technology will evolve in the
forthcoming five or 10 years. If we assume that the mobile
industry will maintain the current developmental pace,
then it is highly feasible that in a decade or less, mobile
devices will have a computing power comparable to
today’s mid-end desktop home computers. Clearly, at
that point mobile devices will be fully capable platforms
for executing volume rendering apps in real time (30 FPS
or beyond) at full screen resolution.

In parallel, the expected evolution of mobile telecommu-
nication standards (such as the implantation of 4G and sub-
sequent standards like 5G) and the development of cloud

Fig. 5. Screenshots of different transfer function editors. (a) ImageVis3D Mobile [23]. (b) CTvox [46]. (c) Noguera et al. [30]. (d) V�azquez and
Balsa [6].

1174 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016



infrastructures will also help to improve all network-based
techniques, including the thin client, balanced, and fat client
strategies.

Regarding the future development of mobile volume
rendering, we believe that thin client techniques will
gradually be phased out and replaced by balanced, and
fat client/local approaches. This stems from scalability
and resource economy factors: once mobile devices are
able to fully support volume rendering by themselves, it
is just wasteful to ignore their potential and place all the
workload on a centralized server.

Additionally, and regarding fat client/local rendering
techniques, we can expect that, similarly to the desktop sce-
nario, ray-casting will prevail over the texture-based techni-
ques. In this scenario the superior visual quality of ray-
casting will be preferable to the better performance of the
texture-based techniques.

However, we should bear in mind that, although the
expected technological development will undoubtedly
overcome some of their limitations in the forthcoming
years, mobile devices will still be limited by their size
and dependence on batteries. Therefore, it is not expected
that mobile devices will ever catch up with the desktop
platforms in terms of graphics capabilities. As a result,
newer and smarter techniques will be required in order
to put them at comparable levels, especially if we aim at
dealing with larger datasets with more quality (see
Section 6.2). In parallel, the development of new applica-
tions (see Section 6.3) and the establishment of innovative
user interaction techniques (see Section 6.4) will be key
research areas if we aim to take full advantage of volume
rendering on handheld devices.

6.2 Large Volume Management

Large volume rendering on mobile devices is interesting for
a number of reasons. The size of volume datasets is increas-
ing everyday as the quality of the capture devices (scanners,
etc.) also increases. Moreover, mobile displays are becoming
larger and their current resolutions have caught up with
television screens. However, in this paper we have seen that
large datasets can easily exceed the available video memory
and texture size of these devices. That is, as reported by
Table 4, a voxel resolution of only 2563 appears to be the
current top limit achievable on today’s technology. This res-
olution can be too limited for visualizing real-world data-
sets that can reach the order of gigabytes. As an illustrative
example, the full human body provided by the Visible

Human Project has a resolution of 5122 � 1; 877 voxels and
occupies around half a gigabyte. In addition, typical clinical
medical applications require interactive visualization of
models in the order of 512� 512� 400� 600 voxels.

Obviously this limitation does not apply to the thin client
rendering techniques reviewed in Section 4.1.1, as the hard-
work falls on the server. Unfortunately, thin client techni-
ques are not always a solution due to the additional require-
ments that they entail (the server and a permanent
connection). Therefore, it is very convenient to research
new techniques for dealing with large real-world volume
datasets on the limited hardware of the mobile devices.
Below we analyze the techniques that are potentially suit-
able for mobile platforms.

6.2.1 Multi-Resolution Volume Rendering

These volume rendering algorithms employ a spatial hierar-
chy (e.g., an octree [55], [56]) to adapt the resolution of the
projection onto the screen using different levels of detail.
Considering the small size of the mobile displays, multi-res-
olution rendering is a very interesting research line on
mobile platforms because it would allow us to avoid spend-
ing resources on parts of the volume that are not visible. In
fact, multi-resolution volume rendering is a mature and
active research field on desktop platforms [1], although
these techniques have not yet been applied on mobile plat-
forms. This is owing to the fact that these techniques typi-
cally require conditional branching and logical decisions
within the GPU, which can severely hurt the performance
of today’s mobile hardware [25].

6.2.2 Data Compression

Compression and GPU decompression of volume data is
very important in order to reduce the volume size and the
bandwidth required for transmitting and rendering it. GPU
volume compression is a well studied topic in the desktop
context [5], but its presence on mobile platforms is still con-
siderably minor. Nevertheless, although not specifically
designed for volume rendering, mobile GPUs already
include some built-in lossy texture compression schemes,
for instance PVRTC [57], [58]. It is also possible to store the
volume textures in smaller precision color formats such as
RGB565. Unfortunately, these lossy solutions are only
available for RGB(A) data and could not be appropriate for
certain applications such as medical diagnosis [38]. Addi-
tionally, although the textures generated by the methods
mentioned above require less video memory than the origi-
nal ones, the volume resolution is still limited by the maxi-
mum texture size supported by the device.

Therefore, it is very interesting to research for com-
pression schemes specially designed for mobile volume
rendering. In fact, Campoalegre et al. [22] already proved
that a wavelet-based compression algorithm can be suc-
cessfully applied in the mobile scenario. Following this
line, forthcoming compression schemes should ideally
not require a computer-intensive decoding in run-time. In
this sense, schemes that delay the decompression step
until it is strictly required and perform only partial
decoding are especially valuable.

6.2.3 Cloud Infrastructures

The current increasing interest in moving many resources to
the cloud promotes the development of progressive model
transmission schemes across wireless networks. This is
undoubtedly a promising research line as it would allow us
to achieve interactive rendering of arbitrarily large volumes
on mobile platforms using balanced rendering techniques,
see Section 4.1.2. Observe that cloud-based visualizations of
large volumes would probably require the use of multi-res-
olution and data compression methods.

6.3 Applications

We firmly believe that the widespread availability of inter-
active volume rendering solutions on cheap and ubiquitous

NOGUERA AND JIM�ENEZ: MOBILE VOLUME RENDERING: PAST, PRESENT AND FUTURE 1175



platforms opens a wide and exciting field of new applica-
tions. But given the expected technological evolution, it
makes sense to invest research efforts today into developing
new applications even if the current performance of mobile
volume rendering is still moderate in terms of interactivity
and dataset size. Some potential fields of application
include m-learning, remote-assisted operation theatres,
medical simulations, collaborative work in a medical envi-
ronment (the so-called CSCW, or Computer Supported
Cooperative Work), etc.

We also need further research evaluating the effective-
ness of the new proposals on mobile devices. In particu-
lar, existing mobile apps have not yet undergone the
rigorous quality assurance programmes required in order
to be considered valid tools for medical diagnosis [59]. It
is also important to assess the user experience and the
level of acceptance of this kind of application with proper
user studies using experts in the field at hand (as Butson
et al. [28] did).

Finally, current efforts have focused exclusively on medi-
cal visualization. While medicine is undoubtedly one of the
fields that can more clearly benefit from this technology,
volume rendering can also lead to a number of interesting
applications in other disciplines, e.g., visualization of scalar
maps in physics, civil engineering, etc.

6.4 User Interfaces

In Section 5 we already remarked that the interactivity of
current solutions is mostly limited to single object inspec-
tions. Although this may be enough for many applications,
a further step would be to allow a true navigation inside
such an object. However, how to perform this kind of navi-
gation is a largely under-researched area. Designing a navi-
gation inside a volume implies a number of collateral
issues: (a) how to map a 2D input device (the touch-screen)
to a 3D movement; (b) collision detection of the virtual cam-
era with the inner parts of the volume; and (c) orientation of
the user in a complex environment through a small display.
Therefore, there is a clear need to develop new methods in
order to visualize volume data in an engaging and user-
friendly way by taking into consideration mobile devices’
displays and input methods. In addition, mobile devices are
also well suited platforms for the development of aug-
mented reality interfaces, which are a promising way to
present more informative and realistic 3D visualizations of
volumetric data [60].

The difficulty of defining a good transfer function is
another problem recognized in the literature [53], [54], that
is exacerbated by the mobile devices’ intrinsic limitations,
e.g., small display size and limited input modalities. As we
reviewed in Section 5, current proposals of TF editors for
mobile solutions present a quite similar aspect to their desk-
top counterparts. However, users expect mobile apps to be
easy-to-use and to deliver fast access to the information
they want, which can conflict with the time-consuming task
of defining TFs.

Current proposals simply reduce the functionality of the
TF editor in order to make them more accessible. Therefore
a considerable research effort is needed to achieve intuitive
editors without reducing functionality. This problem could
be circumvented by defining the TF in an external desktop

computer, and then transferring it to the mobile device.
This solution, however, is far from ideal as they would
require an additional step using a non-mobile platform. An
interesting alternative could be the use of semi-automatic
TF editors, such as the proposal of Kindlman and Durkin
[61] for desktop computers. A semi-automatic editor would
be able to guide the user or to present a good starting point
that can later be further refined.

Once this problem is solved, a next step would be the
adaptation of multi-dimensional TFs to the mobile context,
as they provide a better way to isolate interesting elements
within a volume. These TFs would, however, be harder to
be defined by the user than current 1D TFs, which would
require new imaginative solutions specifically designed for
the mobile scenario.

7 CONCLUDING REMARKS

Given the increasingly wide diffusion of mobile devices
equipped with low-energy GPUs, large display sizes and
wireless networking, mobile volume visualization has
gained increasing interest during the last decade. Unfor-
tunately, the constrained hardware of these platforms has
severely restricted the application of volume graphics to
this ubiquitous scenario. As a result, a young and active
research area has arisen aiming not only at making inter-
active volume rendering on mobile platforms possible,
but also at visualizing these volumetric graphics in an
engaging manner by taking into consideration these
devices’ display, battery-dependence and computing
constraints.

In this survey we have explored the landscape of mobile
volume rendering, providing a comprehensive characteriza-
tion of the basic concepts common to all current proposals.
A broad categorization is proposed on the basis of the strat-
egy used to distribute the rendering task, the rendering
method, the strategy used to manage the volumetric data
and the field of application of the proposal. We have also
considered user interaction aspects, which are a vital point
when working with handheld devices. Finally, a research
agenda has been proposed, highlighting the main research
challenges and open issues to overcome in the near future.
We hope that this survey will be inspiring for the research
community, and will lead to new innovations in this young,
vibrant field.

ACKNOWLEDGMENTS

The authors would like to thank prof. Antonio J. Rueda for
his valuable comments. This work has been partially sup-
ported by the Spanish “Ministerio de Ciencia e Innovaci�on”
and the European Union (via ERDF funds) through the
research project TIN2011-25259.

REFERENCES
[1] M. Hadwiger, J. M. Kniss, C. Rezk-Salama, D. Weiskopf, and K.

Engel, Real-time Volume Graphics. Natick, MA, USA: A. K. Peters,
Ltd., 2006.

[2] T. Akenine-Moller and J. Strom, “Graphics processing units for
handhelds,” in Proc. IEEE, vol. 96, no. 5, pp. 779–789, May 2008.

[3] F. Lamberti and A. Sanna, “A solution for displaying medical data
models on mobile devices,” in Proc. 4th WSEAS Int. Conf. Softw.
Eng., Parallel Distrib. Syst., Wisconsin, USA, 2005, pp. 16:1–16:7.

1176 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016



[4] H. Zhou, H. Qu, Y. Wu, and M. Chan, “Volume visualization on
mobile devices,” in Proc. 14th Pacific Conf. Comput. Graph. Appl.,
2006, pp. 76–84.

[5] M. Balsa Rodriguez, E. Gobbetti, J. IglesiasGuiti�an, M. Makhinya,
F. Marton, R. Pajarola, and S. Suter, “State-of-the-art in com-
pressed GPU-based direct volume rendering,” Comput. Graph.
Forum, vol. 33, pp. 77–100, 2014.

[6] P. V�azquez Alcocer and M. Balsa Rodr�ıguez, “Practical volume
rendering in mobile devices,” in Proc. Int. Symp. Visual Comput.,
2012, vol. 7431, pp. 708–718.

[7] Ryan Reith. (2013). IDC worldwide tablet tracker. [Online]. Avail-
able: https://www.idc.com/getdoc.jsp?containerId=prUS24129713

[8] T. K. Çapin, K. Pulli, and T. Akenine-M€oller, “The state of the art
in mobile graphics research,” IEEE Comput. Graph. Appl., vol. 28,
no. 4, pp. 74–84, 2008.

[9] J. M. Noguera and J. C. Torres, “Interaction and visualization of
3d virtual environments on mobile devices,” Personal Ubiquitous
Comput., vol. 17, no. 7, pp. 1485–1486, 2013.

[10] D. Ivetic and D. Dragan, “Medical image on the go!” J. Med. Syst.,
vol. 35, no. 4, pp. 499–516, 2011.

[11] E. Kotter, T. Baumann, D. Jger, and M. Langer, “Technologies for
image distribution in hospitals,” Eur. Radiol., vol. 16, no. 6,
pp. 1270–1279, 2006.

[12] C. P. Botha, B. Preim, A. Kaufman, S. Takahashi, and A.
Ynnerman, “From individual to population: Challenges in medi-
cal visualization,” ArXiv e-prints, 2012.

[13] S.-J. Jeong and A. E. Kaufman, “Interactive wireless virtual
colonoscopy,” Visual Comput., vol. 23, no. 8, pp. 545–557, Jul. 2007.

[14] S. Park, W. Kim, and I. Ihm, “Mobile collaborative medical display
system,” Comput. Methods Programs Biomed., vol. 89, no. 3, pp. 248–
260, 2008.

[15] T. Koskela and J. Vatjus-Anttila, “Optimization techniques for 3D
graphics deployment on mobile devices,” 3D Res., vol. 6, no. 1,
2015.

[16] Benj Lipchak. (2013). OpenGL ES 3.0 specifications. [Online].
Available: http://www.khronos.org/registry/gles/

[17] F. Lamberti and A. Sanna, “A streaming-based solution for remote
visualization of 3d graphics on mobile devices,” IEEE Trans. Vis.
Comput. Graph., vol. 13, no. 2, pp. 247–260, Mar.-Apr. 2007.

[18] M. Moser and D. Weiskopf, “Interactive volume rendering on
mobile devices,” in Proc. Conf. Vision, ModelingVis., 2008,
pp. 217–226.

[19] A. Meir and B. Rubinsky, “Distributed network, wireless and
cloud computing enabled 3-d ultrasound; A new medical technol-
ogy paradigm,” PLoS ONE, vol. 4, no. 11, pp. e7974, Nov. 2009.

[20] J. Congote, A. Segura, L. Kabongo, A. Moreno, J. Posada, and
O. Ruiz, “Interactive visualization of volumetric data with webgl
in real-time,” in Proc. 16th Int. Conf. 3D Web Technol., 2011,
pp. 137–146.

[21] D. Tapna, “Interactive volume rendering of large scalar fields on
mobile devices using subsampling techniques,” master’s thesis,
Comput. Sci. and Autom., Indian Inst. of Sci., Bangalore, India,
2011.

[22] L. Campoalegre, P. Brunet, and I. Navazo, “Interactive visualiza-
tion of medical volume models in mobile devices,” Personal Ubiq-
uitous Comput., vol. 17, no. 7, pp. 1503–1514, Oct. 2013.

[23] CIBC. (2014). ImageVis3D: A real-time volume rendering tool for
large data. Scientific Computing and Imaging Institute (SCI).
[Online]. Available: http://www.imagevis3d.org

[24] M. M. Movania and L. Feng, “Ubiquitous medical volume render-
ing on mobile devices,” in Proc. Int. Conf. Inform. Soc., 2012,
pp. 93–98.

[25] J. Noguera, J. Jim�enez, C. Og�ayar, and R. Segura, “Volume render-
ing strategies on mobile devices,” in Proc. Int. Conf. Comput. Graph.
Theory Appl., 2012, pp. 447–452.

[26] J. Noguera and J. Jim�enez, “Visualization of very large 3d volumes
on mobile devices and WebGL,” in Proc. WSCG Commun., 2012,
pp. 105–112.

[27] C. J. Noon, “A volume rendering engine for desktops, laptops,
mobile devices and immersive virtual reality systems using GPU-
based volume raycasting,” Master’s thesis, Iowa State University,
Ames, IA, USA, 2012.

[28] C. R. Butson, G. Tamm, S. Jain, T. Fogal, and J. Kruger, “Evaluation
of interactive visualization on mobile computing platforms for
selection of deep brain stimulation parameters,” IEEE Trans. Vis.
Comput. Graphics, vol. 19, no. 1, pp. 108–117, Jan. 2013.

[29] T. Hachaj, “Real time exploration and management of large
medical volumetric datasets on small mobile devices-evalua-
tion of remote volume rendering approach,” Int. J. Inform.
Manage., vol. 34, no. 3, pp. 336–343, Jun. 2014.

[30] J. M. Noguera, J. J. Jim�enez, and M. C. Osuna-P�erez,
“Development and evaluation of a 3d mobile application for
learning manual therapy in the physiotherapy laboratory,” Com-
put. Educ., vol. 69, no. 0, pp. 96–108, 2013.

[31] M. M. Movania, W. Chiew, and F. Lin, “On-site volume rendering
with GPU-enabled devices,” Wireless Personal Commun., vol. 76,
no. 4, pp. 795–812, 2014.

[32] I. Gutenko, K. Petkov, C. Papadopoulos, X. Zhao, J. H. Park, A.
Kaufman, and R. Cha, “Remote volume rendering pipeline for
mhealth applications,” in Proc. SPIE Med. Imaging 2014: PACS
Imaging Inform.: Next Generation Innovations, 2014, vol. 9039,
pp. 903 904–903 904.

[33] H. Zhou, “A survey on ubiquitous graphics,” Comput. Sci. Dept.,
Hong Kong Univ. of Sci. and Technol., 2005.

[34] I. M. Martin, “Adaptive rendering of 3D models over networks
using multiple modalities,” IBM T. J. Watson Research Center,
NY, USA, Tech. Rep. RC 21722, 2000.

[35] A. Evans, M. Romeo, A. Bahrehmand, J. Agenjo, and J. Blat, “3D
graphics on the web: A survey,” Comput. Graph., vol. 41, pp. 43–
61, 2014.

[36] P. T. Johnson, S. L. Zimmerman, D. Heath, J. Eng, K. M. Horton,
W. W. Scott, and E. K. Fishman, “The ipad as a mobile device for
ct display and interpretation: Diagnostic accuracy for identifica-
tion of pulmonary embolism,” Emergency Radiol., vol. 19, no. 4,
pp. 323–327, 2012.

[37] Siemens. (2014). Siemens syngo.via webviewer. [Online]. Avail-
able: http://www.healthcare.siemens.com/medical-imaging-it/
syngoviaspecialtop ics/syngovia-webviewer

[38] J. E. Fowler and R. Yagel, “Lossless compression of volume data,”
in Proc. Symp. Volume Vis., New York, NY, USA, 1994, pp. 43–50.

[39] I. Ihm and S. Park, “Wavelet-based 3d compression scheme for
interactive visualization of very large volume data,” Comput.
Graph. Forum, vol. 18, no. 1, pp. 3–15, 1999.

[40] Dean Jackson. (2013). WebGL draft specifications. [Online]. Avail-
able http://www.khronos.org/registry/webgl/

[41] M. Levoy, “Display of surfaces from volume data,” IEEE Comput.
Graph. Appl., vol. 8, no. 3, pp. 29–37, May. 1988.

[42] J. Kr€uger and R. Westermann, “Acceleration techniques for GPU-
based volume rendering,” in Proc. 14th IEEE Vis., Washington,
DC, USA, 2003, p. 38.

[43] Apple Inc. (2014). OpenGLESprogramming guide for iOS. [Online].
Available: https://developer.apple.com/library/ios/documenta-
tion/3ddrawing/conceptual/opengles_programmingguide/Intro-
duction/Introduction.html

[44] J. M. Kniss, K. Engel, M. Hadwiger, and C. Rezk-Salama, “High-
quality volume graphics on consumer pc hardware,” in Proc.
Course 42, ACM SIGGRAPH, 2002, pp. 1–122.

[45] C. Rezk-Salama, K. Engel, M. Bauer, G. Greiner, and T. Ertl,
“Interactive volume on standard pc graphics hardware using
multi-textures and multi-stage rasterization,” in Proc. ACM SIG-
GRAPH/EUROGRAPHICS Workshop Graph. Hardware, New York,
NY, USA, 2000, pp. 109–118.

[46] Bruker microCT. (2014). CTVox for mobiles. [Online]. Available:
http://www.skyscan.be/products/ctvox.htm

[47] O. R. E. Pereira and J. J. P. C. Rodrigues, “Survey and analysis of
current mobile learning applications and technologies,” ACM
Comput. Surv., vol. 46, no. 2, pp. 27:1–27:35, Dec. 2013.

[48] W.-H. Wu, Y.-C. J. Wu, C.-Y. Chen, H.-Y. Kao, C.-H. Lin, and
S.-H. Huang, “Review of trends from mobile learning studies:
A meta-analysis,” Comput. Educ., vol. 59, no. 2, pp. 817–827,
2012.

[49] R. B. Trelease, “Diffusion of innovations: Smartphones and wire-
less anatomy learning resources,” Anatomical Sci. Educ., vol. 1,
no. 6, pp. 233–239 2008.

[50] C. Telkenaroglu, and T. K. Çapin, “Dual-finger 3d interaction
techniques for mobile devices,” Personal Ubiquitous Comput.,
vol. 17, no 13.

[51] M. Chen, S. J. Mountford, and A. Sellen, “A study in interactive
3-d rotation using 2-d control devices,” SIGGRAPH Comput.
Graph., vol. 22, no. 4, pp. 121–129, Jun. 1988.

[52] A. Henrysson, M. Billinghurst, and M. Ollila, “Virtual object
manipulation using a mobile phone,” in Proc. Int. Conf. Augmented
Tele-Existence, New York, NY, USA, 2005, pp. 164–171 .

NOGUERA AND JIM�ENEZ: MOBILE VOLUME RENDERING: PAST, PRESENT AND FUTURE 1177



[53] H. Pfister, B. Lorensen, C. Bajaj, G. Kindlmann, W. Schroeder, L.
Avila, K. Raghu, R. Machiraju, and J. Lee, “The transfer function
bake-off,” IEEE Comput. Graph. Appl., vol. 21, no. 3, pp. 16–22,
May 2001.

[54] J. Kniss, G. Kindlmann, and C. Hansen, “Multidimensional trans-
fer functions for interactive volume rendering,” IEEE Trans. Vis.
Comput. Graph., vol. 8, no. 3, pp. 270–285, Jul. 2002.

[55] E. C. La Mar, B. Hamann, and K. I. Joy, “Multiresolution techni-
ques for interactive texture-based volume visualization,” in Proc.
10th IEEE Vis. Conf., Washington, DC, USA, 1999, pp. 355–361.

[56] I. Boada, I. Navazo, and R. Scopigno, “Multiresolution volume
visualization with a texture-based octree,” The Visual Comput.,
vol. 17, no. 3, pp. 185–197, 2001.

[57] G. Connor. (2012). IMG_texture_compression_pvrtc. [Online].
Available: http://www.khronos.org/registry/gles/extensions/
IMG/IMG_texture_compres sion_pvrtc.txt

[58] S. Fenney, “Texture compression using low-frequency signal
modulation,” in Proc. ACM SIGGRAPH/EUROGRAPHICS Conf.
Graph. Hardware, Aire-la-Ville, Switzerland, Switzerland, 2003,
pp. 84–91.

[59] M. Rodrigues, A. Visvanathan, J. Murchison, and R. Brady,
“Radiology smartphone applications; current provision and
cautions,” Insights into Imaging, vol. 4, no. 5, pp. 555–562, 2013.

[60] T. Hachaj and M. R. Ogiela, “Visualization of perfusion abnormal-
ities with GPU-based volume rendering,” Comput. Graph., vol. 36,
no. 3, pp. 163–169, 2012.

[61] G. Kindlmann and J. W. Durkin, “Semi-automatic generation of
transfer functions for direct volume rendering,” in Proc. IEEE
Symp. Volume Vis., New York, NY, USA, 1998, pp. 79–86.

Jos�e M. Noguera received the MS degree in
computer engineering from the University of
Granada, Spain in 2006, and the PhD degree
from the University of Ja�en, Spain in 2011. He is
a research associate in the Department of
Computer Sciences at the latter University. His
research interests span computer graphics,
mobile computing and their applications.

J. Roberto Jim�enez received the PhD degree, in
2010, from the Technical University of Catalonia
under the supervision of Dr. Xavier Pueyo
and Dr. Karol Myszkowski working on globally
illuminated participating media and real time ren-
dering. He is an associate professor of the Com-
puter Science Department of the University of
Ja�en, Spain. His current research interest include
rendering and mobile devices.

" For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

1178 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 22, NO. 2, FEBRUARY 2016

















<<
  /ASCII85EncodePages false
  /AllowTransparency false
  /AutoPositionEPSFiles true
  /AutoRotatePages /None
  /Binding /Left
  /CalGrayProfile (Gray Gamma 2.2)
  /CalRGBProfile (sRGB IEC61966-2.1)
  /CalCMYKProfile (U.S. Web Coated \050SWOP\051 v2)
  /sRGBProfile (sRGB IEC61966-2.1)
  /CannotEmbedFontPolicy /Warning
  /CompatibilityLevel 1.4
  /CompressObjects /Off
  /CompressPages true
  /ConvertImagesToIndexed true
  /PassThroughJPEGImages true
  /CreateJobTicket false
  /DefaultRenderingIntent /Default
  /DetectBlends true
  /DetectCurves 0.0000
  /ColorConversionStrategy /sRGB
  /DoThumbnails true
  /EmbedAllFonts true
  /EmbedOpenType false
  /ParseICCProfilesInComments true
  /EmbedJobOptions true
  /DSCReportingLevel 0
  /EmitDSCWarnings false
  /EndPage -1
  /ImageMemory 1048576
  /LockDistillerParams true
  /MaxSubsetPct 100
  /Optimize true
  /OPM 0
  /ParseDSCComments false
  /ParseDSCCommentsForDocInfo true
  /PreserveCopyPage true
  /PreserveDICMYKValues true
  /PreserveEPSInfo false
  /PreserveFlatness true
  /PreserveHalftoneInfo true
  /PreserveOPIComments false
  /PreserveOverprintSettings true
  /StartPage 1
  /SubsetFonts false
  /TransferFunctionInfo /Remove
  /UCRandBGInfo /Preserve
  /UsePrologue false
  /ColorSettingsFile ()
  /AlwaysEmbed [ true
    /Algerian
    /Arial-Black
    /Arial-BlackItalic
    /Arial-BoldItalicMT
    /Arial-BoldMT
    /Arial-ItalicMT
    /ArialMT
    /ArialNarrow
    /ArialNarrow-Bold
    /ArialNarrow-BoldItalic
    /ArialNarrow-Italic
    /ArialUnicodeMS
    /BaskOldFace
    /Batang
    /Bauhaus93
    /BellMT
    /BellMTBold
    /BellMTItalic
    /BerlinSansFB-Bold
    /BerlinSansFBDemi-Bold
    /BerlinSansFB-Reg
    /BernardMT-Condensed
    /BodoniMTPosterCompressed
    /BookAntiqua
    /BookAntiqua-Bold
    /BookAntiqua-BoldItalic
    /BookAntiqua-Italic
    /BookmanOldStyle
    /BookmanOldStyle-Bold
    /BookmanOldStyle-BoldItalic
    /BookmanOldStyle-Italic
    /BookshelfSymbolSeven
    /BritannicBold
    /Broadway
    /BrushScriptMT
    /CalifornianFB-Bold
    /CalifornianFB-Italic
    /CalifornianFB-Reg
    /Centaur
    /Century
    /CenturyGothic
    /CenturyGothic-Bold
    /CenturyGothic-BoldItalic
    /CenturyGothic-Italic
    /CenturySchoolbook
    /CenturySchoolbook-Bold
    /CenturySchoolbook-BoldItalic
    /CenturySchoolbook-Italic
    /Chiller-Regular
    /ColonnaMT
    /ComicSansMS
    /ComicSansMS-Bold
    /CooperBlack
    /CourierNewPS-BoldItalicMT
    /CourierNewPS-BoldMT
    /CourierNewPS-ItalicMT
    /CourierNewPSMT
    /EstrangeloEdessa
    /FootlightMTLight
    /FreestyleScript-Regular
    /Garamond
    /Garamond-Bold
    /Garamond-Italic
    /Georgia
    /Georgia-Bold
    /Georgia-BoldItalic
    /Georgia-Italic
    /Haettenschweiler
    /HarlowSolid
    /Harrington
    /HighTowerText-Italic
    /HighTowerText-Reg
    /Impact
    /InformalRoman-Regular
    /Jokerman-Regular
    /JuiceITC-Regular
    /KristenITC-Regular
    /KuenstlerScript-Black
    /KuenstlerScript-Medium
    /KuenstlerScript-TwoBold
    /KunstlerScript
    /LatinWide
    /LetterGothicMT
    /LetterGothicMT-Bold
    /LetterGothicMT-BoldOblique
    /LetterGothicMT-Oblique
    /LucidaBright
    /LucidaBright-Demi
    /LucidaBright-DemiItalic
    /LucidaBright-Italic
    /LucidaCalligraphy-Italic
    /LucidaConsole
    /LucidaFax
    /LucidaFax-Demi
    /LucidaFax-DemiItalic
    /LucidaFax-Italic
    /LucidaHandwriting-Italic
    /LucidaSansUnicode
    /Magneto-Bold
    /MaturaMTScriptCapitals
    /MediciScriptLTStd
    /MicrosoftSansSerif
    /Mistral
    /Modern-Regular
    /MonotypeCorsiva
    /MS-Mincho
    /MSReferenceSansSerif
    /MSReferenceSpecialty
    /NiagaraEngraved-Reg
    /NiagaraSolid-Reg
    /NuptialScript
    /OldEnglishTextMT
    /Onyx
    /PalatinoLinotype-Bold
    /PalatinoLinotype-BoldItalic
    /PalatinoLinotype-Italic
    /PalatinoLinotype-Roman
    /Parchment-Regular
    /Playbill
    /PMingLiU
    /PoorRichard-Regular
    /Ravie
    /ShowcardGothic-Reg
    /SimSun
    /SnapITC-Regular
    /Stencil
    /SymbolMT
    /Tahoma
    /Tahoma-Bold
    /TempusSansITC
    /TimesNewRomanMT-ExtraBold
    /TimesNewRomanMTStd
    /TimesNewRomanMTStd-Bold
    /TimesNewRomanMTStd-BoldCond
    /TimesNewRomanMTStd-BoldIt
    /TimesNewRomanMTStd-Cond
    /TimesNewRomanMTStd-CondIt
    /TimesNewRomanMTStd-Italic
    /TimesNewRomanPS-BoldItalicMT
    /TimesNewRomanPS-BoldMT
    /TimesNewRomanPS-ItalicMT
    /TimesNewRomanPSMT
    /Times-Roman
    /Trebuchet-BoldItalic
    /TrebuchetMS
    /TrebuchetMS-Bold
    /TrebuchetMS-Italic
    /Verdana
    /Verdana-Bold
    /Verdana-BoldItalic
    /Verdana-Italic
    /VinerHandITC
    /Vivaldii
    /VladimirScript
    /Webdings
    /Wingdings2
    /Wingdings3
    /Wingdings-Regular
    /ZapfChanceryStd-Demi
    /ZWAdobeF
  ]
  /NeverEmbed [ true
  ]
  /AntiAliasColorImages false
  /CropColorImages true
  /ColorImageMinResolution 150
  /ColorImageMinResolutionPolicy /OK
  /DownsampleColorImages true
  /ColorImageDownsampleType /Bicubic
  /ColorImageResolution 150
  /ColorImageDepth -1
  /ColorImageMinDownsampleDepth 1
  /ColorImageDownsampleThreshold 1.50000
  /EncodeColorImages true
  /ColorImageFilter /DCTEncode
  /AutoFilterColorImages false
  /ColorImageAutoFilterStrategy /JPEG
  /ColorACSImageDict <<
    /QFactor 0.76
    /HSamples [2 1 1 2] /VSamples [2 1 1 2]
  >>
  /ColorImageDict <<
    /QFactor 0.40
    /HSamples [1 1 1 1] /VSamples [1 1 1 1]
  >>
  /JPEG2000ColorACSImageDict <<
    /TileWidth 256
    /TileHeight 256
    /Quality 15
  >>
  /JPEG2000ColorImageDict <<
    /TileWidth 256
    /TileHeight 256
    /Quality 15
  >>
  /AntiAliasGrayImages false
  /CropGrayImages true
  /GrayImageMinResolution 150
  /GrayImageMinResolutionPolicy /OK
  /DownsampleGrayImages true
  /GrayImageDownsampleType /Bicubic
  /GrayImageResolution 300
  /GrayImageDepth -1
  /GrayImageMinDownsampleDepth 2
  /GrayImageDownsampleThreshold 1.50000
  /EncodeGrayImages true
  /GrayImageFilter /DCTEncode
  /AutoFilterGrayImages false
  /GrayImageAutoFilterStrategy /JPEG
  /GrayACSImageDict <<
    /QFactor 0.76
    /HSamples [2 1 1 2] /VSamples [2 1 1 2]
  >>
  /GrayImageDict <<
    /QFactor 0.40
    /HSamples [1 1 1 1] /VSamples [1 1 1 1]
  >>
  /JPEG2000GrayACSImageDict <<
    /TileWidth 256
    /TileHeight 256
    /Quality 15
  >>
  /JPEG2000GrayImageDict <<
    /TileWidth 256
    /TileHeight 256
    /Quality 15
  >>
  /AntiAliasMonoImages false
  /CropMonoImages true
  /MonoImageMinResolution 1200
  /MonoImageMinResolutionPolicy /OK
  /DownsampleMonoImages true
  /MonoImageDownsampleType /Bicubic
  /MonoImageResolution 600
  /MonoImageDepth -1
  /MonoImageDownsampleThreshold 1.50000
  /EncodeMonoImages true
  /MonoImageFilter /CCITTFaxEncode
  /MonoImageDict <<
    /K -1
  >>
  /AllowPSXObjects false
  /CheckCompliance [
    /None
  ]
  /PDFX1aCheck false
  /PDFX3Check false
  /PDFXCompliantPDFOnly false
  /PDFXNoTrimBoxError true
  /PDFXTrimBoxToMediaBoxOffset [
    0.00000
    0.00000
    0.00000
    0.00000
  ]
  /PDFXSetBleedBoxToMediaBox true
  /PDFXBleedBoxToTrimBoxOffset [
    0.00000
    0.00000
    0.00000
    0.00000
  ]
  /PDFXOutputIntentProfile (None)
  /PDFXOutputConditionIdentifier ()
  /PDFXOutputCondition ()
  /PDFXRegistryName ()
  /PDFXTrapped /False

  /CreateJDFFile false
  /Description <<
    /CHS <FEFF4f7f75288fd94e9b8bbe5b9a521b5efa7684002000410064006f006200650020005000440046002065876863900275284e8e55464e1a65876863768467e5770b548c62535370300260a853ef4ee54f7f75280020004100630072006f0062006100740020548c002000410064006f00620065002000520065006100640065007200200035002e003000204ee553ca66f49ad87248672c676562535f00521b5efa768400200050004400460020658768633002>
    /CHT <FEFF4f7f752890194e9b8a2d7f6e5efa7acb7684002000410064006f006200650020005000440046002065874ef69069752865bc666e901a554652d965874ef6768467e5770b548c52175370300260a853ef4ee54f7f75280020004100630072006f0062006100740020548c002000410064006f00620065002000520065006100640065007200200035002e003000204ee553ca66f49ad87248672c4f86958b555f5df25efa7acb76840020005000440046002065874ef63002>
    /DAN <FEFF004200720075006700200069006e0064007300740069006c006c0069006e006700650072006e0065002000740069006c0020006100740020006f007000720065007400740065002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e007400650072002c0020006400650072002000650067006e006500720020007300690067002000740069006c00200064006500740061006c006a006500720065007400200073006b00e60072006d007600690073006e0069006e00670020006f00670020007500640073006b007200690076006e0069006e006700200061006600200066006f0072007200650074006e0069006e006700730064006f006b0075006d0065006e007400650072002e0020004400650020006f007000720065007400740065006400650020005000440046002d0064006f006b0075006d0065006e0074006500720020006b0061006e002000e50062006e00650073002000690020004100630072006f00620061007400200065006c006c006500720020004100630072006f006200610074002000520065006100640065007200200035002e00300020006f00670020006e0079006500720065002e>
    /DEU <FEFF00560065007200770065006e00640065006e0020005300690065002000640069006500730065002000450069006e007300740065006c006c0075006e00670065006e0020007a0075006d002000450072007300740065006c006c0065006e00200076006f006e002000410064006f006200650020005000440046002d0044006f006b0075006d0065006e00740065006e002c00200075006d002000650069006e00650020007a0075007600650072006c00e40073007300690067006500200041006e007a006500690067006500200075006e00640020004100750073006700610062006500200076006f006e00200047006500730063006800e40066007400730064006f006b0075006d0065006e00740065006e0020007a0075002000650072007a00690065006c0065006e002e00200044006900650020005000440046002d0044006f006b0075006d0065006e007400650020006b00f6006e006e0065006e0020006d006900740020004100630072006f00620061007400200075006e0064002000520065006100640065007200200035002e003000200075006e00640020006800f600680065007200200067006500f600660066006e00650074002000770065007200640065006e002e>
    /ESP <FEFF005500740069006c0069006300650020006500730074006100200063006f006e0066006900670075007200610063006900f3006e0020007000610072006100200063007200650061007200200064006f00630075006d0065006e0074006f0073002000640065002000410064006f00620065002000500044004600200061006400650063007500610064006f007300200070006100720061002000760069007300750061006c0069007a00610063006900f3006e0020006500200069006d0070007200650073006900f3006e00200064006500200063006f006e006600690061006e007a006100200064006500200064006f00630075006d0065006e0074006f007300200063006f006d00650072006300690061006c00650073002e002000530065002000700075006500640065006e00200061006200720069007200200064006f00630075006d0065006e0074006f00730020005000440046002000630072006500610064006f007300200063006f006e0020004100630072006f006200610074002c002000410064006f00620065002000520065006100640065007200200035002e003000200079002000760065007200730069006f006e0065007300200070006f00730074006500720069006f007200650073002e>
    /FRA <FEFF005500740069006c006900730065007a00200063006500730020006f007000740069006f006e00730020006100660069006e00200064006500200063007200e900650072002000640065007300200064006f00630075006d0065006e00740073002000410064006f006200650020005000440046002000700072006f00660065007300730069006f006e006e0065006c007300200066006900610062006c0065007300200070006f007500720020006c0061002000760069007300750061006c00690073006100740069006f006e0020006500740020006c00270069006d007000720065007300730069006f006e002e0020004c0065007300200064006f00630075006d0065006e00740073002000500044004600200063007200e900e90073002000700065007500760065006e0074002000ea0074007200650020006f007500760065007200740073002000640061006e00730020004100630072006f006200610074002c002000610069006e00730069002000710075002700410064006f00620065002000520065006100640065007200200035002e0030002000650074002000760065007200730069006f006e007300200075006c007400e90072006900650075007200650073002e>
    /ITA (Utilizzare queste impostazioni per creare documenti Adobe PDF adatti per visualizzare e stampare documenti aziendali in modo affidabile. I documenti PDF creati possono essere aperti con Acrobat e Adobe Reader 5.0 e versioni successive.)
    /JPN <FEFF30d330b830cd30b9658766f8306e8868793a304a3088307353705237306b90693057305f002000410064006f0062006500200050004400460020658766f8306e4f5c6210306b4f7f75283057307e305930023053306e8a2d5b9a30674f5c62103055308c305f0020005000440046002030d530a130a430eb306f3001004100630072006f0062006100740020304a30883073002000410064006f00620065002000520065006100640065007200200035002e003000204ee5964d3067958b304f30533068304c3067304d307e305930023053306e8a2d5b9a3067306f30d530a930f330c8306e57cb30818fbc307f3092884c3044307e30593002>
    /KOR <FEFFc7740020c124c815c7440020c0acc6a9d558c5ec0020be44c988b2c8c2a40020bb38c11cb97c0020c548c815c801c73cb85c0020bcf4ace00020c778c1c4d558b2940020b3700020ac00c7a50020c801d569d55c002000410064006f0062006500200050004400460020bb38c11cb97c0020c791c131d569b2c8b2e4002e0020c774b807ac8c0020c791c131b41c00200050004400460020bb38c11cb2940020004100630072006f0062006100740020bc0f002000410064006f00620065002000520065006100640065007200200035002e00300020c774c0c1c5d0c11c0020c5f40020c2180020c788c2b5b2c8b2e4002e>
    /NLD (Gebruik deze instellingen om Adobe PDF-documenten te maken waarmee zakelijke documenten betrouwbaar kunnen worden weergegeven en afgedrukt. De gemaakte PDF-documenten kunnen worden geopend met Acrobat en Adobe Reader 5.0 en hoger.)
    /NOR <FEFF004200720075006b00200064006900730073006500200069006e006e007300740069006c006c0069006e00670065006e0065002000740069006c002000e50020006f0070007000720065007400740065002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e00740065007200200073006f006d002000650072002000650067006e0065007400200066006f00720020007000e5006c006900740065006c006900670020007600690073006e0069006e00670020006f00670020007500740073006b007200690066007400200061007600200066006f0072007200650074006e0069006e006700730064006f006b0075006d0065006e007400650072002e0020005000440046002d0064006f006b0075006d0065006e00740065006e00650020006b0061006e002000e50070006e00650073002000690020004100630072006f00620061007400200065006c006c00650072002000410064006f00620065002000520065006100640065007200200035002e003000200065006c006c00650072002e>
    /PTB <FEFF005500740069006c0069007a006500200065007300730061007300200063006f006e00660069006700750072006100e700f50065007300200064006500200066006f0072006d00610020006100200063007200690061007200200064006f00630075006d0065006e0074006f0073002000410064006f00620065002000500044004600200061006400650071007500610064006f00730020007000610072006100200061002000760069007300750061006c0069007a006100e700e3006f002000650020006100200069006d0070007200650073007300e3006f00200063006f006e0066006900e1007600650069007300200064006500200064006f00630075006d0065006e0074006f007300200063006f006d0065007200630069006100690073002e0020004f007300200064006f00630075006d0065006e0074006f00730020005000440046002000630072006900610064006f007300200070006f00640065006d0020007300650072002000610062006500720074006f007300200063006f006d0020006f0020004100630072006f006200610074002000650020006f002000410064006f00620065002000520065006100640065007200200035002e0030002000650020007600650072007300f50065007300200070006f00730074006500720069006f007200650073002e>
    /SUO <FEFF004b00e40079007400e40020006e00e40069007400e4002000610073006500740075006b007300690061002c0020006b0075006e0020006c0075006f0074002000410064006f0062006500200050004400460020002d0064006f006b0075006d0065006e007400740065006a0061002c0020006a006f0074006b006100200073006f0070006900760061007400200079007200690074007900730061007300690061006b00690072006a006f006a0065006e0020006c0075006f00740065007400740061007600610061006e0020006e00e400790074007400e4006d0069007300650065006e0020006a0061002000740075006c006f007300740061006d0069007300650065006e002e0020004c0075006f0064007500740020005000440046002d0064006f006b0075006d0065006e00740069007400200076006f0069006400610061006e0020006100760061007400610020004100630072006f0062006100740069006c006c00610020006a0061002000410064006f00620065002000520065006100640065007200200035002e0030003a006c006c00610020006a006100200075007500640065006d006d0069006c006c0061002e>
    /SVE <FEFF0041006e007600e4006e00640020006400650020006800e4007200200069006e0073007400e4006c006c006e0069006e006700610072006e00610020006f006d002000640075002000760069006c006c00200073006b006100700061002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e007400200073006f006d00200070006100730073006100720020006600f60072002000740069006c006c006600f60072006c00690074006c006900670020007600690073006e0069006e00670020006f006300680020007500740073006b007200690066007400650072002000610076002000610066006600e4007200730064006f006b0075006d0065006e0074002e002000200053006b006100700061006400650020005000440046002d0064006f006b0075006d0065006e00740020006b0061006e002000f600700070006e00610073002000690020004100630072006f0062006100740020006f00630068002000410064006f00620065002000520065006100640065007200200035002e00300020006f00630068002000730065006e006100720065002e>
    /ENU (Use these settings to create PDFs that match the "Suggested"  settings for PDF Specification 4.0)
  >>
>> setdistillerparams
<<
  /HWResolution [600 600]
  /PageSize [612.000 792.000]
>> setpagedevice

