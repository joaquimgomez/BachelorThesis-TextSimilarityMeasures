




















































U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

Journal of Sports Analytics xx (20xx) x–xx
DOI 10.3233/JSA-200432
IOS Press

1

On the relationship between +/– ratings
and event-level performance statistics

1

2

Garry A. Geladea and Lars Magnus Hvattumb,∗3
aBusiness Analytic Ltd, I, Circus Lodge, Circus Road, London, UK4
bFaculty of Logistics, Molde University College, Britvegen, Molde, Norway5

Abstract. This work considers the challenge of identifying and properly assessing the contribution of a single player towards
the performance of a team. In particular, we study the use of advanced plus-minus ratings for individual football players,
which involves evaluating a player based on the goals scored and conceded with the player appearing on the pitch, while
compensating for the quality of the opponents and the teammates as well as other factors. To increase the understanding
of plus-minus ratings, event-based data from matches are first used to explain the observed variance of ratings, and then to
improve their ability to predict outcomes of football matches. It is found that event-level performance statistics can explain
from 22% to 38% of the variance in plus-minus ratings, depending on player positions, while incorporating the event-level
statistics only marginally improves the predictive power of plus-minus ratings.

6

7

8

9

10

11

12

13

Keywords: Association football, key performance indicator, adjusted plus-minus, ranking14

1. Introduction15

The development of ratings for individual play-16
ers in team sports has attracted increased attention17
from researchers in recent years, as the availability18
and quality of data have improved. Such individual19
ratings are not straightforward to derive, but poten-20
tially offer valuable inputs to fans (McHale et al.,21
2012), media (Tiedemann et al., 2011), clubs (Mac-22
donald, 2012), coaches (Schultze and Wellbrock,23
2018), associations (Hass and Craig, 2018), tour-24
nament organizers (McHale et al., 2012), gamblers25
and bookmakers (Engelmann, 2017), and the players26
themselves (Tiedemann et al., 2011).27

This paper contributes to the understanding of a28
particular type of rating system, collectively known29
as plus-minus (PM) ratings. PM ratings have been30
developed for basketball players (Engelmann, 2017),31
ice-hockey players (Gramacy et al., 2017), volley-32
ball players (Hass and Craig, 2018), and association33
football players (Sæbø and Hvattum, 2019). For addi-34
tional historical references and a discussion of key35

∗Corresponding author: Lars Magnus Hvattum, Faculty of
Logistics, Molde University College, Britvegen 2, 6410 Molde,
Norway. E-mail: hvattum@himolde.no.

publications on PM ratings, the reader can consult 36
a recently published review paper (Hvattum, 2019). 37
While simpler forms of PM ratings exist, the focus in 38
this paper is on (regularized) adjusted PM ratings, cal- 39
culated using some form of (regularized) regression 40
model. 41

A particular feature of PM ratings is that they only 42
use information about how the score changes during 43
matches and about which players appear on the play- 44
ing field at different points in time. This contrasts 45
to methods that apply detailed event-based data to 46
derive player ratings, typically focusing on particu- 47
lar aspects of play, such as goal scoring or passing 48
(Szczepański, 2015). 49

Arguments against the top-down perspective of 50
PM ratings include that it is unreasonable to distribute 51
credit of performance onto players without know- 52
ing the actual actions taken by players. However, 53
bottom-up ratings that depend on the actions taken 54
by players typically also miss some aspects of play 55
that the top-down perspective could capture, such as 56
the motivating influence on teammates. In addition, 57
unless tracking-data is available, bottom-up ratings 58
would have to ignore typical off-the-ball actions that 59
may be important in many team sports. 60

ISSN 2215-020X/20/$35.00 © 2020 – IOS Press and the authors. All rights reserved

mailto:hvattum@himolde.no


U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

2 G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics

The purpose of this work is to increase our under-61
standing about the relationship between PM ratings62
and event-based performance statistics of individual63
players in association football. This relationship has64
not previously been examined in football, but there is65
some related work from basketball.66

Rosenbaum (2004, 2005) examined adjusted PM67
ratings for basketball. He also calculated a set of68
game statistics, measured per 40 minutes of play-69
ing time. The adjusted PM ratings were regressed on70
the game statistics, to estimate how different actions71
can explain the players’ PM ratings. Using in total72
14 independent variables, including pure and derived73
game statistics, the multiple linear regression model74
could explain 44% of the variance in the PM rat-75
ing. Furthermore, the regression coefficients were76
used to directly calculate a statistical PM rating,77
which turned out to provide ratings with smaller stan-78
dard errors, and which in turn could be combined79
with the initial PM ratings for yet another rating80
measure.81

Fearnhead and Taylor (2011) used a Bayesian82
framework to calculate adjusted PM ratings, where83
each player received both an offensive and a defen-84
sive rating. Regressing the PM ratings on ten different85
dependent variables, they were able to explain 41%86
of the variance of the offensive ratings, but only 3%87
of the variance of the defensive ratings.88

There are few papers comparing the quality of89
PM ratings and alternative ratings. Engelmann (2011)90
developed an ad hoc player rating for basketball91
players that made use of information about individ-92
ual player actions. The ad hoc model was better at93
predicting point differentials than a regularized PM94
rating. Matano et al. (2018) compared regularized95
PM ratings for football with ratings from the FIFA96
computer game series, which are partly based on sub-97
jective inputs from scouts. They showed that the PM98
ratings outperformed the FIFA ratings in two out of99
three seasons. By using the FIFA ratings as priors for100
the PM ratings, the resulting ratings outperformed the101
other two ratings in all three seasons.102

Given the context of using PM ratings to evaluate103
individual players in football, the goal of this paper104
is three-fold. One goal is to test whether PM rat-105
ings capture the information contained in event-level106
player performance statistics. The second goal is to107
test the extent to which past event-level statistics con-108
tain information that is not captured by PM ratings109
and that can be used to improve predictions for out-110
comes of future football matches. The third goal is to111
test whether improved player ratings can be derived112

by combining the PM ratings with information from 113
player events. 114

The remainder of the paper is structured as fol- 115
lows. Section 2 provides information about the data 116
used, the calculation of the plus-minus ratings that are 117
analyzed, and the variables derived from event data. 118
Results from regressing PM ratings on the perfor- 119
mance statistics are presented in Section 3. Section 4 120
contains results from tests using PM ratings and per- 121
formance statistics to predict match outcomes. The 122
attempts at deriving improved player ratings are dis- 123
cussed in Section 5, and Section 6 concludes the 124
paper. 125

2. Experimental setup 126

The data consist of individual on-the-ball player 127
events recorded for the seasons 2009–2017 in five 128
European Tier 1 domestic competitions (English Pre- 129
mier League, French Ligue 1, German Bundesliga, 130
Italian Serie A and Spanish La Liga). Cartesian pitch 131
coordinates are given for each event, and passes are 132
encoded with origin and end-point coordinates. Four 133
matches were incomplete and excluded from the anal- 134
ysis, leaving 16,430 matches in the analysis dataset. 135
There were approximately 1,514 on-the-ball events 136
per match. In addition to the on-the-ball player events, 137
the data contain information about substitutions and 138
players sent off, so that at any time the players present 139
on the pitch are known. 140

2.1. Plus-minus ratings 141

The PM ratings that we analyze in this work are 142
based on a model presented by Pantuso and Hvattum 143
(2019), which is an extension of the work by Sæbø 144
and Hvattum (2015, 2019). The model is formulated 145
as an unconstrained quadratic program, which gen- 146
eralizes a multiple linear regression model estimated 147
using ridge regression (Tikhonov regularization). 148

Let M be a set of matches, where each match 149
m ∈ M is split into a set of segments Sm. For our 150
PM ratings this is done by creating one segment for 151
each interval with no changes to the players appear- 152
ing on the pitch. In other words, segments are created 153
for each substitution and each red card. The duration 154
of segment s ∈ Sm is denoted by d (m, s). Let t = 155
tMATCH (m) denote the time that match m is played, 156
and let T be the current time, at which ratings are 157
calculated. The parameters of the model associated 158
to the timing of events are illustrated in Fig. 1. Each 159



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics 3

Fig. 1. Illustration of the parameters referring to the time of events.

match belongs to a given competition type, such as160
the English Premier League, or the Spanish La Liga.161
Denote the competition type of match m by c (m).162

Let h = h (m) and a = a (m) be the two teams163
involved in match m, where h is the home team, unless164
the match is played on neutral ground. The goal dif-165
ference in favour of h in segment s ∈ Sm of match m166
is denoted by g (m, s). We also define g0 (m, s) as the167
goal difference in favour of h at the beginning of the168
segment, and g1 (m, s) as the goal difference at the169
end of the segment.170

The set of players of team t ∈ {h, a} that appear on171
the pitch for segment s is denoted by Pm,s,t . For n =172
1, ..., 4, define r (m, s, n) = 1 if team h has received173
n red cards and team a has not, r (m, s, n) = −1 if174
team a has received n red cards and team h has not,175
and r (m, s, n) = 0 otherwise. We let C be the set of176
competition types and define Cp as the set of compe-177
tition types in which player p has participated. Each178
player p is associated to a set PSIMp of players that are179
considered to be similar. This set is based on which180
players have appeared together on the same team for181
the most number of minutes. The last time that players182
p and p′ appeared together is denoted by tSIM

(
p, p′

)
.183

The model includes an age profile, as the play-184
ing strength of players is expected to improve while185
young and then decline when getting older. To this186
end, tAGE (m, p) is defined as the age of player p at the187
time of match m. A discrete set of possible age values188
Y =

{
yMIN, . . . , yMAX

}
is defined, and for a given189

match and player, the age of the player is taken as a190
convex combination of the possible age values. That191
is, by introducing parameters u

(
y, tMATCH (m) , p

)
192

to select among the age combinations, it holds193
194

that max
{

min
{
tAGE (m, p) , yMAX

}
, yMIN

}
= 195∑

y∈Y
u

(
y, tMATCH (m) , p

)
y, where at most two 196

values u
(
y, tMATCH (m) , p

)
are non-zero,

∑
y∈Y

u 197(
y, tMATCH (m) , p

)
= 1, and 0 ≤ u(y, tMATCH 198

(m) , p) ≤ 1. As an example, tMATCH (m) = 199
25.4 would result in the unique combi- 200
nation of u

(
25, tMATCH (m) , p

)
= 0.6, 201

u
(
26, tMATCH (m) , p

)
= 0.4, and u(y, tMATCH 202

(m) , p) = 0. for y /∈ {25, 26}. 203
Define the following parameters: λ is a regu- 204

larization factor, ρ1 is a discount factor for older 205
observations, ρ2 and ρ3 are parameters regarding the 206
importance of the duration of a segment, and ρ4 is a 207
factor for the importance of a segment depending on 208
the goal difference at the start of the segment. The 209
parameter wAGE is a weight to balance the impor- 210
tance of the age factors when considering similarity 211
of players. Finally, wSIM is a weight that controls the 212
extent to which ratings of players with few minutes 213
played are shrunk towards 0 or towards the ratings of 214
similar players. The values of the parameters are set 215
as in (Pantuso and Hvattum, 2019). 216

The variables used in the model can be stated as fol- 217
lows. Let βp. correspond to the base rating of player 218
p. The value of the home advantage in competition 219
c (m) is reesend by βH

c(m). For a given age y ∈ Y , the 220
rating of a player is adjusted by βAGEy . An adjustment 221
for each competition c ∈ C is given by the variables 222
βCOMPc . Let β be the vector of all the decision vari- 223
absf the model and let V be the set of elements from 224
β. 225

The full model for our PM ratings can now be
written as follows:

min
β

Z =
∑
m∈M

∑
s∈Sm

(
w (m, s) fLHS (m, s) − w (m, s) fRHS (m, s)

)2
+

∑
j∈V

(
f

REG
(
βj

))2



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

4 G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics

This is a way to express the estimation of a multiple linear regression model with Tikhonov regularization. 226
In particular, w (m, s) fLHS (m, s) corresponds to the values of the independent variables, w (m, s) fRHS (m, s) 227
represents the value of the dependent variable, and fREG

(
βj

)
expresses the regularization penalties. The rating 228

model defined here generalizes this by allowing fREG
(
βj

)
to deviate from the standard regularization terms. 229

Defining the details of the rating model, w (m, s) is a weight that is used to express the importance of a given 230
segment s of match m: 231

232

w (m, s) = wTIME (m, s) wDURATION (m, s) wGOALS (m, s) 233
w

TIME (m, s) = exp
(
ρ1

(
T − tMATCH (m)

))
234

w
DURATION (m, s) = (d (m, s) + ρ2)

ρ3
235

w
GOALS (m, s) =

{
ρ4 if|g0(m, s)| ≥ 2 and |g1(m, s)| ≥ 2
1 otherwise

236

The dependent variable is simply the observed goal difference from the perspective of the home team, multiplied
by the weight of the observation:

f
RHS (m, s) = g (m, s)

The independent variables can be split into those that describe properties of each player, fPLAYER (m, s, p), 237
those that describe properties of a given segment fSEGMENT (m, s), and those that describe a given match, 238
fMATCH (m). These are defined as follows: 239

240

90

d (m, s)
f

LHS (m, s) = 11∣∣Pm,s,h∣∣
∑

p∈Pm,s,h
f

PLAYER (m, s, p) − 11∣∣Pm,s,a∣∣
∑

p∈Pm,s,a
f

PLAYER (m, s, p) 241

+fSEGMENT (m, s) + fMATCH (m) 242

f
SEGMENT (m, s) =

⎧⎪⎨
⎪⎩

∑
n=1,...,4

r (m, s, n) βHOMEREDn if
∑

n=1,...,4
r (m, s, n) ≥ 0

∑
n=1,...,4

r (m, s, n) βAWAYREDn if
∑

n=1,...,4
r (m, s, n) < 0

243

f
MATCH (m) =

{
βH

c(m) if teamh (m) has home advantage

0 otherwise
. 244

f
PLAYER (m, s, p) = βp +

∑
y∈Y

u
(
y, t

MATCH (m) , p
)

β
AGE
y +

1∣∣Cp∣∣
∑
c∈Cp

β
COMP
c . 245

Finally, the form of fREG
(
βj

)
varies for the different regression coefficients. For the competition adjustment 246

coefficients, βCOMPc , and the home field advantage coefficients, β
H
c , the terms correspond to standard ridge 247

regression. The player rating coefficients, βp, and the age adjustments, β
AGE
y , are modified by taking advantage 248

of formulating the model as an unconstrained quadratic program: 249

fREG
(
βAGEy

)
=

⎧⎨
⎩

λ
(
βAGEy −

(
βAGE

y−1 + βAGEy+1
)

/2
)

ify ∈ Y \
{
yMIN, yMAX

}
0 ify ∈

{
yMIN, yMAX

} 250
fREG

(
βCOMPc

)
= λβCOMPc . 251

fREG
(
βHc

)
= λβHc . 252



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics 5

253

fREG
(
βp

)
= λ

⎛
⎜⎝fAUX (p, T, 1) − wSIM∣∣∣PSIMp

∣∣∣
⎛
⎜⎝ ∑

p′∈PSIMp
f

AUX
(
p

′
, t

SIM
(
p, p

′)
, w

AGE
)⎞⎟⎠

⎞
⎟⎠ .254

fAUX (p, t, w) = βp + w
∑
y∈Y

u (y, t, p) βAGEy +
1∣∣Cp∣∣

∑
c∈Cp

β
COMP
c255

The estimated rating for player p at time T can now256
be written as fAUX (p, T, 1). For large data sets, solv-257
ing the unconstrained quadratic programming can258
become time consuming. Sæbø and Hvattum (2015)259
described how a simpler version of the ratings can260
be estimated using commercially available software.261
However, in this model, regularization terms for the262
player ratings fREG

(
βp

)
and for the age effects263

fREG
(
βAGEy

)
. have been replaced by more complex264

expressions. Thus, it may no longer be possible to265
implement the model in frameworks targeted at esti-266
mating multiple linear regression models with ridge267
regression, as would otherwise be the case. Therefore,268
an ad hoc method has been implemented to solve the269
new model, using a gradient search where the calcu-270
lation of the gradient is implemented using parallel271
computing.272

The calculations outlined above provides a point273
estimate for the rating of each player. To provide274
a measure of the uncertainty in the rating of each275
player, we sugge to use bootstrapping (Fox, 2008,276
Chapter 21). In this procedure, observations from a277
regression modeare sampled with replacement, until278
the bootstrap sample has the same size as the original279
data set. The model is then estimated on the bootstrap280
sample and the relevant values are recorded, which281
in our case means recording fAUX (p, T, 1) for each282
player p. By repeating the bootstrap procedure multi-283
ple times, confidence intervals for the rating of a given284
player can be derived by referring to the percentiles285
of the recorded ratings for that player.286

2.2. Variables287

Key performance indicators (KPIs) are derived for288
each player from counts of the associated ball-touch289
events. In Table 1, definitions are provided of the290
different events that are counted. Then, Table 2 gives291
the definitions for how the KPIs are derived from the292
event counts.293

294

3. Regressing ratings on key performance 295
indicators 296

For this phase of the analysis we use matches in the 297
seasons 2009–2016. Because per 90 KPIs are unsta- 298
ble when a player has played only a few minutes, 299
players with fewer than 540 minutes playing time 300
(equivalent to six full-time matches) are excluded. 301
Twenty-four KPIs that are commonly used to eval- 302
uate players are entered into the analysis. One KPI 303
(Saves-to-Shots Ratio) is only defined for goalkeep- 304
ers. The correlations of the KPIs with PM ratings are 305
reported in Table 3. Statistical significance levels are 306
indicated by *** for p < 0.001, ** for p < 0.01, and 307
* for p < 0.05. 308

Most of the KPIs correlate positively with PM rat- 309
ings, indicating some convergence between the two 310
measures of player quality. This is further explored by 311
a series of ordinary least squares regression analyses 312
below. Separate regression equations were estimated 313
for each player position, and in each case, the pre- 314
dictors were selected by a filtering process (Saeys, 315
Inza, & Larrañaga, 2007). The data was resampled 316
according to a five-fold cross-validation scheme, and 317
a generalized additive model was used to screen for 318
a significant relationship between the plus-minus rat- 319
ings and a spline on each of the candidate predictors 320
(23 KPIs for outfield players, 24 for goalkeepers). 321
The procedure was repeated three times, producing 322
15 cross-validation samples. Table 4 reports statistics 323
for the R2 values obtained. 324

Predictors that survived this filtering process were 325
used in the positional regression equations reported 326
below. Residuals in each positional equation were 327
tested for normality and heteroscedasticity and outly- 328
ing/influential observations removed (Peña & Slate, 329
2006). After removal of these observations (only nec- 330
essary for defenders and midfielders), all tests for 331
heteroscedasticity and departures from skewness and 332
kurtosis were non-significant at p < = 0.05, indicating 333



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

6 G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics

Table 1

Definitions of counted events

Counted Event Definition

Aerial Duel When two players contest a 50/50 ball in the air, each player is awarded an aerial duel. The winning player is
awarded a successful aerial duel and the losing player is awarded an unsuccessful duel.

Assist A pass to a teammate who scores a goal.
Block An interception where the intercepting player is close to the passing player
Card Referee issues a yellow (warning) card or a red card. A player issued a red card is sent off the pitch for the rest of

the game.
Clearance A player under pressure kicks the ball clear of the defensive zone or out of play.
Dispossessed Player is tackled and loses possession of the ball.
Foul Attracted The player is fouled according to the referee, and is awarded a free kick.
Foul Committed The referee judges a player to have committed a foul.
Goal All goals, including penalty goals.
Ground Duel A ground duel event is counted for both players involved in a tackle or take on event. The winning player is

awarded a successful ground duel and the losing player is awarded an unsuccessful duel.
Interception Player intercepts a pass and prevents it reaching its intended destination.
Key Pass A pass to a teammate who makes an unsuccessful attempt on goal.
Loose Ball Recovered Player takes possession of a loose ball when both teams have lost possession.
Pass Pass from one player towards a teammate. Passes from dead-ball situations such as throw-ins, free-kicks,

goal-kicks and corner kicks are included. A pass is successful if it reaches a teammate or unsuccessful if it is
intercepted or goes out of play.

Save (Goalkeeper) Goalkeeper saves a shot on goal.
Save (Outfield player) Player blocks a shot on goal.
Shot on Target An attempt on goal that is on target (includes goals).
Tackle Made Player dispossess an opponent of the ball.
Take-On Player attempts to dribble ball past an opponent. A successful take on is awarded if the player dribbles past.
Through Ball A pass made for an attacker to run on to and create a goal attempt.
Touch Any touch of the ball.

Table 2

Definitions of key performance indicators

Key Performance Indicator Definition

. . . /90 Per 90 event count. Event count divided by the number of minutes played and multiplied by 90 to give a
per 90 statistic.

% Aerial Duels Won Count of successful aerial duels as a percentage of total aerial duels.
% Ground Duels Won Count of successful ground duels as a percentage of total ground duels.
% Passes Completed Count of Successful passes as a percentage of total passes.
Mean Pass Length Total Pass Length/Total number of passes.
Pass Value Pass value is calculated by an algorithm which awards positive values to successful passes that move the

ball incrementally closer to the opposition goal and penalizes unsuccessful passes that concede
position close to player’s own goal.

Saves-to-Shots Ratio Goalkeepers only. Count of saves divided by count of saves plus goals conceded.
Times Dispossessed per Touch Count of dispossessions divided by count of touches.
Total Pass Length Sum of lengths of successful passes (m.)

that the linear model assumptions of normality and334
constant variance were satisfied.335

Tables 5 to 10 show the regression models for the336
full positional datasets. Table 11 shows the relative337
importance of the predictors for each position.338

Tables 5 through 10 show that player PM ratings339
are related to a wide variety of KPIs which are con-340
ditional upon player position, and suggest that PM341
ratings capture a range of positionally relevant skills.342

Table 11 shows the relative importance (CAR343
scores; Zuber and Strimmer, 2011) of the KPIs in each344
regression equation, and the values in each column345
sum to 100%. So for example, the value of 8.4% for346

Successful Aerial Duels/90 in the defenders column 347
means that this KPI contributes 8.4% of the explained 348
variance in PM ratings for defenders, while the value 349
of 1.8% for Assists/90 means that this KPI contributes 350
a much smaller proportion, and is accordingly a less 351
important predictor of PM ratings. 352

The overall pattern of results seems plausible. For 353
instance, the most important predictors of PM rat- 354
ings for forwards are Goals Scored/90, Key Passes/90 355
and Shots on Target/90. For attacking midfielders, the 356
most important predictors are Key Passes/90, Suc- 357
cessful Take-Ons/90, and Successful Passes/90. For 358
the other outfield positions, Goals, Key Passes and 359



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics 7

Table 3

Correlations of KPIs with PM ratings

KPI r

Touches/90 0.35∗∗∗
Successful Passes/90 0.34∗∗∗
Saves-to-Shots Ratio† 0.30∗∗∗
% Passes Completed 0.27∗∗∗
Successful Take-Ons/90 0.25∗∗∗
Total Pass Length/90 0.24∗∗∗
Assists/90 0.23∗∗∗
Key Passes/90 0.22∗∗∗
Goals Scored/90 0.18∗∗∗
Shots on Target/90 0.16∗∗∗
Loose Balls Recovered/90 0.15∗∗∗
Clearances/90 –0.12∗∗∗
Saves/90 –0.09∗∗∗
Cards/90 [neg] 0.09∗∗∗
Fouls Committed/90 [neg] 0.09∗∗∗
Through Balls/90 0.07∗∗∗
Pass Value/90 0.07∗∗∗
Interceptions & Blocks/90 0.07∗∗∗
% Ground Duels Won 0.06∗∗∗
% Aerial Duels Won –0.03
Mean Pass Length 0.03
Tackles Made/90 0.02
Times Dispossessed per Touch [neg] 0.01
Successful Aerial Duels/90 0.00

Note: † = Goalkeepers only, N = 395, otherwise
outfield players only, N = 4,726.

Table 4

Variances explained statistics in 15 cross-validation samples

Position Mean R2 SD R2 Minimum R2 Maximum R2

Goalkeepers 21.7% 9.3% 7.7% 40.2%
Defenders 36.2% 3.8% 31.1% 44.6%
Defensive

Midfielders
27.0% 6.9% 15.7% 41.8%

Midfielders 33.3% 6.6% 23.6% 45.0%
Attacking

Midfielders
33.5% 10.0% 15.2% 47.7%

Forwards 36.1% 7.1% 25.7% 52.7%

Table 5

KPIs to explain PM of goalkeepers, explains 22.4% of variance

estimate std. error statistic

(Intercept) –0.330 0.063 –5.23∗∗∗
% Passes Completed 0.271 0.060 4.50∗∗∗
Saves-to-Shots Ratio 0.249 0.053 4.67∗∗∗
% Ground Duels Won 0.013 0.010 1.35
Successful Aerial Duels/90 0.069 0.021 3.30∗∗
Pass Value/90 –0.010 0.012 –0.86
F = 22.4, df = (5, 389)

Note: N = 395.

Shots are less important, and Successful Passes/90360
and % Passes Completed dominate the other pre-361
dictors of PM ratings. For midfielders the dominant362
predictor is Touches/90, but if this KPI is forced out of363

Table 6

KPIs to explain PM of defenders, explains 36.1% of variance

estimate std. error statistic

(Intercept) –0.088 0.029 –3.00∗∗∗
Successful Passes/90 0.003 0.000 14.07∗∗∗
Successful Aerial Duels/90 0.016 0.002 9.77∗∗∗
Key Passes/90 0.029 0.005 5.76∗∗∗
Pass Value/90 0.026 0.005 5.45∗∗∗
Successful Take-Ons/90 0.014 0.003 4.54∗∗∗
Interceptions & Blocks/90 0.007 0.002 4.51∗∗∗
Fouls Committed/90 [neg] 0.005 0.003 1.52
Goals Scored/90 0.022 0.028 0.79
Saves/90 0.004 0.006 0.75
Assists/90 0.031 0.033 0.94
Cards/90 [neg] 0.003 0.011 0.31
% Passes Completed 0.000 0.039 0.01
F = 88.61, df = (12, 1802)

Note: N = 1,815.

Table 7

KPIs to explain PM of defensive midfielders, explains 30.7% of
variance

estimate std. error statistic

(Intercept) –0.156 0.037 –4.19∗∗∗
Successful Passes/90 0.002 0.000 5.11∗∗∗
Successful Take-Ons/90 0.028 0.005 5.08∗∗∗
Interceptions & Blocks/90 0.014 0.004 3.13∗∗
% Ground Duels Won 0.062 0.048 1.28
% Passes Completed 0.052 0.061 0.86
Tackles Made/90 0.000 0.005 –0.08
F = 20.86, df = (6, 283)

Note: N = 290.

Table 8

KPIs to explain PM of midfielders, explains 35.0% of variance

estimate std. error statistic

(Intercept) –0.247 0.021 –11.53∗∗∗
Touches/90 0.001 0.000 5.27∗∗∗
Successful Take-Ons/90 0.018 0.003 6.94∗∗∗
% Passes Completed 0.217 0.029 7.63∗∗∗
Goals Scored/90 0.074 0.019 3.84∗∗∗
Key Passes/90 0.022 0.004 5.48∗∗∗
Interceptions & Blocks/90 0.010 0.002 4.46∗∗∗
Assists/90 0.065 0.027 2.4∗
Times Dispossessed per Touch [neg] 0.179 0.142 1.26

per Touch [neg]
Through Balls/90 –0.002 0.007 –0.35
Fouls Committed/90 [neg] 0.003 0.003 0.93
Tackles Made/90 0.000 0.002 –0.2
Saves/90 0.013 0.010 1.34
F = 48.73, df = (12, 1084)

Note: N = 1,097.

the regression equation, it is replaced by Successful 364
Passes/90 as the most dominant predictor. 365

The shared variance between KPIs and PM rat- 366
ings indicates a modest degree of convergent validity 367
(Campbell and Fiske, 1959) between the top-down 368



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

8 G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics

Table 9

KPIs to explain PM of attacking midfielders, explains 36.4% of
variance

estimate std. error statistic

(Intercept) –0.126 0.037 –3.39∗∗∗
Key Passes/90 0.025 0.005 5.44∗∗∗
Successful Take-Ons/90 0.019 0.003 7.29∗∗∗
Goals Scored/90 0.063 0.022 2.82∗∗∗
% Passes Completed 0.103 0.051 2.05∗
Assists/90 0.055 0.032 1.75
Fouls Committed/90 [neg] 0.003 0.004 0.75
Successful Aerial Duels/90 0.003 0.003 1.18
Pass Value/90 0.012 0.006 1.96
Successful Passes/90 0.001 0.000 2.87∗∗
Cards/90 [neg] 0.015 0.019 0.82
Clearances/90 0.015 0.005 2.77∗∗
F = 28.78, df = (11, 553)

Note: N = 565.

Table 10

KPIs to explain PM of forwards, explains 37.9% of variance

estimate std. error statistic

(Intercept) –0.155 0.027 –5.82∗∗∗
Shots on Target/90 0.012 0.005 2.49∗
Successful Take-Ons/90 0.012 0.003 4.49∗∗∗
Goals Scored/90 0.087 0.014 6.36∗∗∗
Key Passes/90 0.024 0.004 6.14∗∗∗
Interceptions & Blocks/90 0.018 0.004 4.94∗∗∗
% Passes Completed 0.129 0.033 3.95∗∗∗
Assists/90 0.099 0.025 4.05∗∗∗
Pass Value/90 0.015 0.004 3.62∗∗∗
Successful Aerial Duels/90 0.005 0.002 3.00∗∗
Cards/90 [neg] 0.022 0.014 1.53
% Ground Duels Won 0.046 0.034 1.37
F = 49.45, df = (11, 890)

Note: N = 902.

and bottom-up metrics of evaluating players. Never-369
theless, it is clear that most of the variance in PM370
ratings cannot be explained by the bottom-up indica-371
tors we have examined here.372

4. Predicting match outcomes using ratings373
and key performance indicators374

PM ratings can be used as a basis for predicting375
outcomes of football matches where the starting line-376
ups are known (Sæbø and Hvattum, 2019), by using377
the difference of the average ratings of home team378
players and away team players as a single covariate379
in an ordered logit regression (OLR) model (Greene,380
2012). In this section we test whether information381
from KPIs can be used as additional covariates to382
improve the prediction quality.383

To this end, seasons 2009 through 2015 are used 384
to calculate initial values for PM ratings and KPIs for 385
each player. Seasons 2016 and 2017 provide initial 386
observations for the OLR, where player ratings and 387
KPIs are updated before each new day with matches 388
played. Finally, season 2017 is used as the valida- 389
tion set: before each day of matches, player ratings 390
and KPIs are updated and the regression model is 391
re-estimated using all current information. Then, the 392
predictions are generated for each match of the day, 393
and the quadratic loss (Witten et al., 2011) of the 394
prediction is calculated. 395

Five models are considered. Model 1 has only one 396
covariate, based on the PM ratings of the players in 397
the starting line-up. Model 2 has 32 covariates, one 398
based on PM ratings, and the rest derived from KPIs. 399
The KPIs included are the 24 from Table 1, in addi- 400
tion to Aerial Duels Won/90, Aerial Duels Lost/90, 401
Unsuccessful Passes/90, Unsuccessful Take-Ons/90, 402
Challenges/90, Saves by Goalkeeper/90, and Fouls 403
Attracted/90. For the KPI-based covariates, the val- 404
ues are first calculated for each individual player in 405
the starting line-up, and then the covariate is calcu- 406
lated as the difference between the averages for the 407
two teams. 408

To improve the second model, a form of recursive 409
feature elimination (Guyon et al., 2002) is used. The 410
feature selection is performed before considering the 411
data in the validation set and is based on recursively 412
eliminating the covariate that leads to the greatest 413
improvement in the Bayesian information criterion 414
(BIC) until no covariates are left. The final set of 415
covariates retained is the set that provided the best 416
value of BIC throughout the procedure. Starting from 417
Model 2 and performing such feature selection results 418
in Model 3. Models 4 and 5 are created in the same 419
manner as Model 2 and Model 3, respectively, but 420
without including the PM ratings as one of the initial 421
covariates. 422

Table 12 presents, for each model, the log- 423
likelihood when estimating the model on the full data 424
set, the quadratic loss from out-of-sample predic- 425
tions in the validation set, and the final regression 426
coefficients. Model 2 and Model 4 are omitted from 427
the table. Their log-likelihood measures are –5112.2 428
and –5157.6, respectively, while their quadratic loss, 429
which is more importantly addressing their out-of- 430
sample performance, is 0.5684 and 0.5731. Despite 431
their performance thus being slightly better than that 432
of Model 3 and Model 5, we prefer to focus our fur- 433
ther analysis on the more parsimonious models. The 434
main reason for this is that the regression coefficients 435



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics 9

Table 11

Relative importance of KPIs by position

KPI GK D DM M AM FW

Successful Aerial Duels/90 11.9% 10.0% 0.0% 0.0%
Assists/90 2.2% 6.8% 11.6% 9.4%
Clearance/90 0.0%
Cards/90 [neg] 0.6% 1.8% 0.9%
Fouls Committed/90 [neg] 0.8% 0.9% 1.9%
Saves-to-Shots Ratio 28.6%
Goals Scored/90 0.9% 4.8% 8.3% 22.4%
Interceptions & Blocks/90 3.1% 10.6% 7.2% 3.4%
Key Passes/90 10.3% 10.3% 26.2% 22.3%
Times Dispossessed per Touch [neg] 1.3% 0.4%
Successful Passes/90 50.6% 47.4% 13.9%
% Ground Duels Won 3.6% 3.3% 4.1%
% Passes Completed 48.2% 13.1% 13.7% 20.5% 8.0% 6.7%
Pass Value/90 7.7% 3.2% 2.6% 3.4%
Saves/90 0.2% 0.1%
Shots on Target/90 14.2%
Tackles Made/90 3.7% 0.5%
Successful Take-Ons/90 4.9% 21.3% 16.3% 25.7% 12.8%
Through Balls/90 1.1%
Touches/90 30.4%

Table 12

Ordered logit estimation of three different models. Log-likelihoods and regression
coefficients are reported for models using observations from seasons 2015 to 2017.

Quadratic loss is calculated out-of-sample for season 2017. Standard errors are reported
in parentheses. All the reported coefficients have significance levels of p < 0.001

Model 1 Model 3 Model 5

Log-likelihood –5161.0 –5141.1 –5193.1
Quadratic loss 0.5704 0.5689 0.5770
θ1. –0.197 (0.029) –0.206 (0.029) –0.206 (0.029)
θ2 1.015 (0.033) 1.014 (0.033) 0.995 (0.033)
PM Rating –1.215 (0.042) –0.998 (0.056)
Successful Passes/90 –0.045 (0.005)
Clearance/90 –0.289 (0.069)
Loose Balls Recovered/90 –0.235 (0.055)
Saves/90 0.967 (0.225) 1.718 (0.254)
Key Passes/90 –0.559 (0.133) –1.093 (0.137)
Goals Scored/90 –3.477 (0.625)
Saves-to-Shots Ratio –1.096 (0.233)

in Model 2 and Model 4 are largely not statistically436
significant.437

The models without PM ratings are worse at pre-438
dicting future matches, with a higher quadratic loss.439
On the other hand, Model 3, which adds covariates440
based on the number of saves and the number of key441
passes to the model with only PM ratings, is able442
to predict future matches slightly better. For com-443
parison, a model with no covariates, thus predicting444
future matches based on past frequencies of outcomes445
only, obtains a quadratic loss of 0.6442, and a log-446
likelihood value of –5668.1.447

This indicates that the PM ratings do not fully448
incorporate useful information derived from look-449
ing at the number of saves and the number of key450

passes during a match. As the regression coefficient 451
of Saves/90 is positive, it means that a higher number 452
of saves is associated with worse future results. An 453
increased number of key passes, on the other hand, is 454
associated with higher probabilities of better results. 455
In total, 24 different KPIs were included in Model 456
2 and Model 4, but were removed by the feature 457
selection for both Model 3 and Model 5 458

5. Improving ratings using key performance 459
indicators 460

In this section, we discuss two attempts at creating 461
improved PM ratings for individual football players. 462



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

10 G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics

-3700

-3650

-3600

-3550

-3500

-3450

-3400

0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0

L
og

-l
ik

el
ih

oo
d

Weight of statistical PM

Log-likelihood for training data

Fig. 2. Tuning of the overall rating combining statistical PM and
regular PM.

The first attempt is based on the regression results463
in Section 3, where the PM ratings were regressed464
on player KPIs. Rosenbaum (2004, 2005) did this for465
basketball players, and then suggested a statistical466
PM rating, where the rating of each player is calcu-467
lated directly from the regression formulas obtained468
and the observed KPIs. As a next step, a convex com-469
bination of the statistical PM and the regular PM was470
calculated so as to minimize an error measure.471

Rosenbaum (2004, 2005) proposed the statistical472
PM and its combination with regular PM ratings473
mainly to reduce the noise in the ratings. This work474
was performed on adjusted PM, before the use of reg-475
ularization was popularized (Sill, 2010). As noise is476
a much less significant issue in the PM ratings used477
here, the combination of statistical PM and regular478
PM ratings may be less effective. A difference to the479
statistical PM ratings of Rosenbaum (2004, 2005),480
is that our regressions are performed for each player481
position separately.482

To calibrate the overall rating, as a convex com-483
bination of statistical PM and regular PM, we484
consider the log-likelihood of an OLR model fitted485
on observed match results in the training data, with a486
single covariate based on the overall rating. The rela-487
tive weight of statistical PM is varied in a grid search488
from 0 to 1 in intervals of 0.05. Figure 2 shows the489
obtained log-likelihoods. The best log-likelihood is490
obtained for a weight equal to 0.05, which means that491
there is some value in the statistical PM, but not much.492
For comparison, in (Rosenbaum, 2005), a weight of493
0.4 was used for the statistical PM.494

Table 12 shows the results of Model 6, which uses495
the combined rating as the basis of a single co-variate496
to predict future matches. Comparing with the results497
of Model 1 in Table 12, we can see that the new rating498
performs only slightly better. Furthermore, Table 14499
and Table 15 show the top 20 rated players according500

Table 13

Ordered logit estimation of two additional models. Values reported
as in Table 12. All the reported coefficients have significance levels

of p < 0.001

Model 6 Model 7

Log-likelihood –5148.4 –5141.0
Quadratic loss 0.5701 0.5688
θ1 –0.199 (0.029) –0.206 (0.029)
θ2 1.016 (0.033) 1.013 (0.033)
PM + Statistical Rating –1.254 (0.044)
Enhanced PM Rating –1.448 (0.050)

to PM ratings and the new combined rating, cal- 501
culated based on the whole data set. The top-rated 502
players are mostly identical for the two ratings, which 503
is as expected, given that a weight of 0.95 is used on 504
the regular PM ratings in the combined rating. 505

To evaluate the uncertainty of the rating estimates, 506
Table 14 provides PM ratings based on 500 bootstrap 507
samples (Fox, 2008). For the bootstrapped ratings, 508
the median rating is shown together with the 5th and 509
the 95th percentile ratings, thus providing a 90 % con- 510
fidence interval for the PM rating. Additionally, we 511
show a 90 % confidence interval for the difference 512
in rating to Thomas Muller, the player with the high- 513
est PM rating. The latter is useful when determining 514
whether a given player has a rating that is signif- 515
icantly different from the rating of another player, 516
although only as a descriptive statistic of the players’ 517
performances in the data set. 518

A second attempt at finding an improved rating 519
is based on the regression results in Section 4. The 520
results of Model 3 presented there, suggested that 521
information about saves and key passes could be help- 522
ful to improve the regular PM ratings. To this end, 523
we define an enhanced PM rating by taking a lin- 524
ear combination of the regular PM rating and the 525
individual values for Saves/90 and Key passes/90 526
for each player. The weights of the linear combina- 527
tion are determined by maximizing the log-likelihood 528
for an OLR model on the training data. A variant 529
of coordinate search (Kolda et al., 2003; Schwefel, 530
1995) is used as a direct search method to optimize 531
the log-likelihood as a function of the weights of 532
the components in the enhanced PM rating. Start- 533
ing the search with weights (1.0, 0.0, 0.0), the best 534
weights found are (0.681, –0.0643, 0.0363), with a 535
log-likelihood of –3427.87, which is slightly better 536
than what was obtained using the combination of 537
statistical PM and regular PM ratings. 538

Table 13 provides results for Model 7, using 539
the enhanced PM rating as the basis for the sole 540



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics 11

Table 14

Top 20 players according to the regular PM rating. Also shown are results from the bootstrapping procedure, showing the median bootstrap
rating as well as the limits of a 90 % confidence interval for the estimated rating. All ratings calculated based on data from seasons 2009

through 2017

Bootstrapped ratings Diff. to Muller
Name Position Rating Minutes 5 % Median 95 % 5 % 95 %

Thomas Muller FW 0.278 21531 0.233 0.273 0.310 NA NA
Lionel Messi FW 0.269 25297 0.221 0.262 0.301 –0.042 0.070
T. Alcantara M 0.266 10207 0.214 0.258 0.301 –0.032 0.067
Neymar FW 0.260 11947 0.202 0.253 0.300 –0.038 0.080
David Alaba D 0.257 16080 0.215 0.250 0.291 –0.019 0.065
Ederson GK 0.257 3263 0.198 0.248 0.292 –0.036 0.086
Toni Kroos M 0.255 20767 0.205 0.247 0.287 –0.025 0.079
Danilo D 0.249 4694 0.188 0.237 0.293 –0.032 0.096
Marcelo D 0.240 20820 0.194 0.235 0.274 –0.013 0.090
Casemiro M 0.238 6077 0.188 0.228 0.265 –0.011 0.099
R. Lewandowski FW 0.237 20165 0.188 0.228 0.271 0.003 0.087
Jerome Boateng D 0.237 16084 0.193 0.231 0.274 –0.002 0.085
Mohamed Salah FW 0.228 9543 0.179 0.219 0.265 –0.007 0.108
James Rodriguez M 0.224 9377 0.171 0.218 0.261 0.001 0.108
Nacho F. D 0.223 7232 0.176 0.215 0.261 0.001 0.108
Kyle A. Walker D 0.218 20286 0.158 0.209 0.254 0.004 0.120
Mario Gotze AM 0.215 13305 0.166 0.209 0.253 0.007 0.122
Marco Verratti M 0.215 11185 0.169 0.203 0.241 0.013 0.119
Pedro FW 0.214 17301 0.161 0.207 0.253 0.006 0.122
Raphael Varane D 0.213 13136 0.168 0.210 0.249 0.013 0.118

Table 15

Top 20 players according to the combined rating using statistical PM and regular
PM, and the new enhanced PM based on PM in combination with saves and

key passes. All ratings calculated based on data from seasons 2009 through 2017.
For enhanced PM, only players with more than 540 minutes of playing time are included

Statistical + Regular PM Enhanced PM

Thomas Muller FW 0.270 Lionel Messi FW 0.313
Lionel Messi FW 0.268 Neymar FW 0.310
T. Alcantara M 0.262 Thomas Muller FW 0.304
Neymar FW 0.258 R. Lewandowski FW 0.300
David Alaba D 0.252 C. Ronaldo FW 0.269
Ederson GK 0.249 J. Rodriguez M 0.259
Toni Kroos M 0.249 Toni Kroos M 0.256
Danilo D 0.243 Luis Suarez FW 0.255
Marcelo D 0.234 Mohamed Salah FW 0.251
R. Lewandowski FW 0.233 Arjen Robben AM 0.248
Jerome Boateng D 0.232 Kevin de Bruyne AM 0.248
Casemiro M 0.230 Mario Gotze AM 0.247
Mohamed Salah FW 0.224 Karim Benzema FW 0.244
James Rodriguez M 0.221 Angel di Maria FW 0.237
Nacho F. D 0.217 Franck Ribery AM 0.236
Kyle A. Walker D 0.212 T. Alcantara M 0.234
Marco Verratti M 0.212 Mesut Ozil AM 0.229
Mario Gotze AM 0.211 David Silva AM 0.228
David Silva AM 0.208 M. Mandzukic FW 0.227
Pedro FW 0.208 Sadio Mane FW 0.222

covariate included in OLR to predict future match541
results. This model performs slightly better than the542
other models with only a single rating covariate, and543
even marginally better than Model 3. This confirms544
that information about saves and key passes can be545
used to improve the predictive ability of PM ratings.546

However, it is also worthwhile to look at Table 14, 547
showing the top 20 ranked players according to the 548
enhanced PM ratings. For the enhanced PM ratings, 549
it was necessary to enforce a cut-off based on the 550
number of minutes played to produce the top 20 list. 551
Whereas the regular PM ratings ensure that players 552



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

12 G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics

Table 16

Average rank for players of different positions, considering 5,499 players
with at least 540 minutes of playing time, and three different PM ratings

GK D DM M AM FW

PM 2891.6 2793.8 2758.3 2771.6 2607.6 2656.9
Statistical + Regular PM 2893.6 2794.9 2761.5 2774.0 2604.4 2651.7
Enhanced PM 5252.4 3292.3 2862.7 2488.8 1696.9 1483.8

with few minutes played are not represented in the553
extremes of the rating lists, this is not the case for554
enhanced PM ratings. Some players with few min-555
utes recorded may obtain very high values for Key556
Passes/90, and thus will dominate the other players557
on the list.558

When listing only players with more than 540559
minutes of playing time, the top 20 list looks very560
reasonable, and perhaps even more so than the list561
based on regular PM ratings. However, while the top562
list for PM ratings contain players of all positions, the563
enhanced PM ratings seem to favour offensive play-564
ers, and there are no goalkeepers and no defenders in565
the top 20.566

6. Discussion567

Our first main finding is that top-down and bottom-568
up performance indicators for football players share569
a non-trivial amount of variance. For goalkeepers,570
regression of KPIs on PM ratings finds an R2 of571
0.22, while for outfield players the R2 values range572
from 0.31 for defensive midfielders to 0.38 for for-573
wards. These findings are comparable to previous574
research on NBA player ratings. Rosenbaum (2004,575
2005) regressed PM ratings on fourteen different576
KPIs, reporting an R2 of 0.44. Fearnhead and Taylor577
(2011) regressed offensive and defensive PM ratings578
on a common set of ten KPIs, finding R2 values of579
0.42 and 0.03 respectively.580

Although these results show that some of the581
variance of PM ratings for football players can be582
explained by event data, most of the variance remains583
unexplained. It may be that some of the variance is584
due to properties not covered by the event data, such585
as a player’s ability to create or cover space, press-586
ing that does not lead to ball interaction, and physical587
abilities such as pace. However, it may also be that588
a substantial part of the variance is simply noise, as589
was the case in early versions of PM ratings (Hvattum,590
2019).591

Our second main finding is that marginal improve-592
ments in the prediction of match results can be593

achieved by combining information from player 594
top-down and bottom-up ratings. However, the appli- 595
cation of multiple rating perspectives produces 596
comparatively little change in the predicted proba- 597
bilities of match results. Correlations between the 598
modelled probabilities of a home win for the pure 599
(Model 1), statistical (Model 6) and enhanced PM 600
models (Model 7) are all over 0.98, as are the cor- 601
relations between away win probabilities, while the 602
correlations between draw probabilities are all over 603
0.97. 604

As the improvement in prediction quality for the 605
versions of PM ratings incorporating event-based 606
data is modest, it may be argued that the PM 607
ratings, aggregated on a team level, provides a rea- 608
sonable assessment of team quality. However, on a 609
player level, the new enhanced PM rating has some 610
interesting differences to the standard PM rating; 611
while the two methods evaluate players within a 612
given player position similarly, the different player 613
positions are ranked differently. Within position cor- 614
relations between the standard and enhanced ratings 615
are uniformly high, ranging from 0.85 for goalkeepers 616
to 0.94 for forwards. However, taken over all players, 617
the correlation is 0.61. 618

For standard PM ratings and the mix of standard 619
and statistical PM ratings, the average ranks for each 620
player position are similar, as shown in Table 16. On 621
the other hand, the enhanced PM rating suggests that 622
forwards are the most influential, followed by attack- 623
ing midfielders, whereas defenders and goalkeepers 624
are less influential and receive lower ratings. 625

As two opposing teams will use a similar number 626
of players from each position at any time, this shift 627
in relative evaluation of players of different positions 628
does not in itself lead to significant differences in 629
predictions. For example, since all teams will almost 630
always use exactly one goalkeeper, any shift in ratings 631
of goalkeepers will not have any consequences for 632
predictions made. Therefore, although enhanced PM 633
has slightly better predictive power than the other two 634
variants, it would be premature to conclude that goal- 635
keepers and defenders are less important for winning 636
football matches. 637



U
nc

or
re

ct
ed

 A
ut

ho
r 
P

ro
of

G.A. Gelade and L.M. Hvattum / On the relationship between +/– ratings and event-level performance statistics 13

Combining different base learners often leads to638
reductions in noise and improvements in predictive639
accuracy (see e.g. Hanson and Salamon, 1990). A nat-640
ural extension to the present research would therefore641
be to investigate a stacked ensemble that combines642
match predictions from a model based on PM ratings643
alone and a model based only on player KPIs.644

References645

Campbell, D.T. and Fiske, D.W., 1959, Convergent and dis-646
criminant validation by the multitrait-multimethod matrix,647
Psychological Bulletin 56, 81-105.648

Engelmann, J., 2011, A new player evaluation technique for players649
of the National Basketball Association (NBA), Proceedings650
of the MIT Sloan Sports Analytics Conference.651

Engelmann, J., 2017, Possession-based player performance anal-652
ysis in basketball (adjusted +/- and related concepts). In J.653
Albert, M. Glickman, T. Swartz, and R. Koning, editors.,654
Handbook of Statistical Methods and Analyses in Sports,655
pages 215-228. Chapman and Hall/CRC, Boca Raton.656

Fearnhead, P. and Taylor, B., 2011, On estimating the ability of657
NBA players. Journal of Quantitative Analysis in Sports 7,658
https://doi.org/10.2202/1559-0410.1298.659

Fox, J., 2008, Applied Regression Analysis and Generalized Linear660
Models, Sage Publications, California, USA, 2nd edition.661

Gramacy, R., Taddy, M. and Tian, S., 2017, Hockey performance662
via regularized logistic regression. In J. Albert, M. Glickman,663
T. Swartz, and R. Koning, editors., Handbook of Statistical664
Methods and Analyses in Sports, pages 287-306. Chapman665
and Hall/CRC, Boca Raton.666

Greene, W., 2012, Econometric Analysis. Pearson, Harlow, Eng-667
land, 7th edition.668

Guyon, I., Weston, J., Barnhill, S. and Vapnik, V., 2002, Gene selec-669
tion for cancer classification using support vector machines,670
Machine Learning 46, 389-422.671

Hansen, L.K. and Salamon, P., 1990, Neural network ensembles,672
IEEE Transactions on Pattern Analysis and Machine Intelli-673
gence 12, 993-1001.674

Hass, Z. and Craig, B., 2018, Exploring the potential of the675
plus/minus in NCAA women’s volleyball via the recovery676
of court presence information, Journal of Sports Analytics 4,677
285-295.678

Hvattum, L.M., 2019, A comprehensive review of plus-minus679
ratings for evaluating individual players in team sports, Inter-680
national Journal of Computer Science in Sport 18, 1-23.681

Kolda, T.G., Lewis, R.M. and Torczon, V.J., 2003, Optimization by682
direct search: New perspectives on some classical and modern683
methods, SIAM Review 45, 385-482.684

Macdonald, B., 2012, Adjusted plus-minus for NHL players using 685
ridge regression with goals, shots, Fenwick, and Corsi, Jour- 686
nal of Quantitative Analysis in Sports 8. 687

Matano, F., Richardson, L., Pospisil, T., Eubanks, C. and Qin, J., 688
2018, Augmenting adjusted plus-minus in soccer with FIFA 689
ratings, ArXiv:1810.08032v1. 690

McHale, I., Scarf, P. and Folker, D., 2012, On the development 691
of a soccer player performance rating system for the English 692
Premier League, Interfaces 42, 339-351. 693

Pantuso, G. and Hvattum, L.M., 2019, Maximizing performance 694
with an eye on the finances: A chance constrained model for 695
football transfer market decisions, ArXiv: 1911.04689v1. 696

Peña, E.A. and Slate, E.H., (2006). Global validation of linear 697
model assumptions. Journal of the American Statistical Asso- 698
ciation 101(473), 341-354. 699

Rosenbaum, D., 2004, Measuring how NBA players help 700
their teams win, http://www.82games.com/comm30.htm, 701
Accessed 2018-08-31. 702

Rosenbaum, D., 2005, Defense is all about keeping the other 703
team from scoring, http://82games.com/rosenbaum3.htm, 704
Accessed 2018-09-28. 705

Saeys, Y., Inza, I. and Larrañaga, P., (2007). A review of fea- 706
ture selection techniques in bioinformatics. Bioinformatics 707
23, 2507-2517. 708

Schultze, S. and Wellbrock, C., 2018, A weighted plus/minus met- 709
ric for individual soccer player performance. Journal of Sports 710
Analytics 4, 121-131. 711

Schwefel, H.P., 1995, Evolution and Optimum Seeking. Wiley- 712
Interscience. 713

Sill, J., 2010, Improved NBA adjusted +/- using regularization and 714
out-of-sample testing, Proceedings of the 2010 MIT Sloan 715
Sports Analytics Conference. 716

Szczepański, Ł., 2015, Assessing the skill of football players using 717
statistical methods. PhD thesis, University of Salford. 718

Sæbø, O.D. and Hvattum, L.M., 2015, Evaluating the efficiency 719
of the association football transfer market using regression 720
based player ratings. In NIK: Norsk Informatikkonferanse, 721
12 pages. Bibsys Open Journal Systems. 722

Sæbø, O.D. and Hvattum, L.M., 2019, Modelling the financial 723
contribution of soccer players to their clubs. Journal of Sports 724
Analytics 5, 23-34. 725

Tiedemann, T., Francksen, T. and Latacz-Lohmann, U., 2011, 726
Assessing the performance of German Bundesliga football 727
players: A non-parametric metafrontier approach, Central 728
European Journal of Operations Research 19, 571-587. 729

Witten, I., Frank, E. and Hall, M.A., 2011, Data Mining: Practical 730
Machine Learning Tools and Techniques. Morgan Kaufmann 731
Publishers, 3rd edition. 732

Zuber, V. and Strimmer, K., 2011, High-dimensional regression 733
and variable selection using CAR scores, Statistical Applica- 734
tions in Genetics and Molecular Biology 10. 735

https://doi.org/10.2202/1559-0410.1298
http://www.82games.com/comm30.htm
http://82games.com/rosenbaum3.htm

