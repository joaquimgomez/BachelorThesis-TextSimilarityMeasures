deepao: effici screen space ambient occlus gener deep network receiv februari 19, 2020, accept march 24, 2020, date public april 1, 2020, date current version april 16, 2020. digit object identifi 10.1109/access.2020.2984771 deepao: effici screen space ambient occlus gener deep network dongjiu zhang 1, chuhua xian 1, guoliang luo 2, yunhui xiong3, chu han4 1guangdong provinci kei laboratori comput intellig cyberspac information, school scienc engineering, south china univers technology, guangzhou 510006, china 2virtual realiti interact techniqu institute, east china jiaotong university, nanchang 330013, china 3school mathematics, south china univers technology, guangzhou 510006, china 4depart radiology, guangdong provinci peopl hospital, guangdong academi medic sciences, guangzhou 510080, china correspond authors: chuhua xian guoliang luo work support natur scienc foundat guangdong provinc grant 2019a1515011793 grant 2017a030313347, nation natur scienc foundat china grant 61962021 grant 51978271, china postdoctor scienc foundat grant 2019m662261, kei research develop program jiangxi provinc grant 20192bbe50079. abstract ambient occlus (abbr. ao) plai import role realist render applic ao produc realist ambient lighting, achiev calcul bright certain screen part base object geometry. however, baselin comput ao algorithm time-consuming, limit applic real-tim rendering. currently, ao algorithm base screen space reduc comput consumption, lead unrealist result usag artifici features. overcom challenges, paper, creat well-craft dataset pair defer shade buffer data ground-truth ao shade images. then, design effici deep neural network screen space ao imag generation, base design comput shader librari comput shade ao images. extens experiment result method achiev compet perform exist screen space ambient volumetr ambient base ao method visual qualiti efficiency. index term ambient occlusion, rendering, shading, deep neural network. i. introduct ambient occlus (abbr. ao) plai vital role light scene, determin percentag light block environment. origin ao complex rai trace process requir high com- putat cost, normal work pre-process applic [1], [2]. reduc comput cost, approxim methods: screen space ambient occlus (abbr. ssao) [3][7], volumetr ambi- ent occlus (abbr. vao) [8][10]. ssao-bas method util screen space information, includ depth normal, store g buffer comput occlus independ complex scene. method extens real-tim applic simpl implement high efficiency. differ ssao, vao-bas method transform sampl domain smaller tangent sphere formul ao problem associ editor coordin review manuscript approv public xiaogang jin . volumetr integration. however, exist method produc incorrect result artifici features. recent years, method base neural network propos domain [11], [12]. major featur method base dataset, train neural network learn map input data surround pixel ao pixel. however, defici network structures, method difficult fulli learn inform samples, i.e., gener train model satisfactory. develop graphic hardware, ray-trac ao method run real-tim advanc graphic cards, limit high cost regular applic scenario [13]. paper, propos effici ssao method, name deepao, gener accur ao map deep neural network. creat dataset contain camera space depth, normal ground truth ao com- pute ray-trace-bas render. then, design light u-net [14]-like fulli convolut neural network learn 64434 work licens creativ common attribut 4.0 license. information, volum 8, 2020 d. zhang et al.: deepao: effici ssao gener deep network figur 1. exampl scene render deepao model enabl (bottom row) disabl (top row). result render uniti game engine. map input g-buffer inform ground truth ao shade imag dataset. compar exist machin learn base methods, pro- pose method achiev better accuraci effici run-time. fig. 1 show exampl scene gener deepao. base method, devel- op comput shade library, simple, fast effici implement neural network game engine. librari easili appli render tasks. instead defeat ray-trac ao method high perform computers, motiv work gener high qualiti ao result effici mid-and-low perform devices. summarize, main contribut follows: propos improv structur gener compar result off-lin ray-trac method efficiently.th sourc code shade librari releas [15]. present complex dataset, better support gener train base methods. ii. relat work ao perenni topic graphics, rang approach propos task. earli meth- od us ray-trac algorithm gener imag [1], [2], [16]. subsequ method pre- process step real-tim interact applic limit static scene. support dynam scenes, kontkanen aila citekontkanen2005ambi appli ambient occlus field handl anim scene [18]. figur 2. sampl method ssao-bas models: sampl view spheric space (left) sampl hemispher space (right). bunnel [19] present gpu-bas method deform surface. [20], chistensen extend method render color bleeding. mention method base rai trace surfac discretization. date 2007, feasibl method comput ambi- ent occlus real-tim affect virtual world name screen-spac ambient occlus (abbr. ssao) method develop [3][7]. method sampl depth buffer view sphere space count number occlud point estim occlus factor (fig. 2 (a)). address self-occlud flaw, ssao+ [21] method chang spheric space hemispher space, illustr fig. 2 (b). greatli improv perform andmak ssao-bas method work dynam environ conjunct anim physics. moreover, ssao- base method requir pre-calcul occlus data reliev artist memori budget. base ssao, extend method proposed. [22], bavoi et al. introduc horizon base ambient occlus volum 8, 2020 64435 d. zhang et al.: deepao: effici ssao gener deep network figur 3. exampl invis geometr inform perspect z-buffer. point dot contribut ao. case, hbao method point consideration. (abbr. hbao). method comput occlus esti- mate open horizon sampl point. rai march depth buffer, horizon estim calcul differ depth. however, method take account visibl point current trace perspective, inte- grate global influence. shown fig. 3, point invis current view contribut ambient occlusion. moreover, sampl mechan hbao, difficult deal point rel far awai sampl space. drawback lead incorrect shadow absenc shadows. differ ssao, techniqu call volumetr ambient occlusion(abbr. vao) propos [10], [23]. methodsmeasur portion tangent sphere sur- face belong set occlud point replac rai trace contain tests. integr new formula low variat allow estim accur samples. however, differ pure ao vao, vao method produc overli smooth result lack detail scene. ssao vao, penmatsa et al. propos vxao method [24]. instead reli screen space data, method gather inform world space voxel represent scene, cover larg area viewer. representation, object rel far surfac contribut occlusion. however, order reduc comput cost, method requir us lower resolut voxel lead low resolut shade result guarante render quality, limit applications. moreover, comput cost remain expens hbao method sampl space low resolution. success applic deep learning, research studi deep learn base method treat render problems. [25], yang et al. us deep convolut network perform quick reconstruct mont carlo rendering. address ao problem, figur 4. exampl scene dataset. row show normal maps, second row correspond depth maps. correspond ground truth ao shade imag shown bottom. holden et al. [11] introduc neural network, name nnao, learn featur dataset predict optim approxim ambient occlus affect. network nnao multi-layer-percept 4 layers, network poor featur learn abil gener high qualiti ao results. afterwards, nal- bach et al. [12] introduc convolut neural network name deep shade learn map posit camera space normal ao shade image. however, deep shade method poor perform gener low varieti object train dataset. recently, real-tim aomethod develop special graphic hardwar support, nvidia rtx 2080ti [13]. rtx graphic card achiev 1080p real-time, fp vari 30-60, depend complex scene. however, devic nvidia rtx graphic card, mobil device, method gener high qualiti ao real- time. contrast, ssao-bas method effici run devic opengl 3.1 (or later version) support, allow broad usag common applications. iii. propos method a. dataset gener exist public dataset ao: nnao [11] deep shade [12] datasets. however, nnao dataset contain 600 annot record lack vari- eti objects, limit gener train model. deep shade dataset, geometri detail scene rel coarse, facilit guarante qualiti ao results. overcom limitations, build dataset defer shade buffer ground truth ao shade images. creat dataset, 17 scene 200 classifi object util gener pair annot data. scene contain wide varieti 64436 volum 8, 2020 d. zhang et al.: deepao: effici ssao gener deep network figur 5. workflow deepao model, consist modules: deep learn module, storag module, cpu comput modul gpu render module. object high resolut geometri details, car, ship, aircraft, building, status, etc. scenes, 15 gener train data 2 gener valid data. total, dataset contain 42, 000 pair defer shade buffer ground truth ao shade imag resolut 512 512 px. ground truth ao shade imag gener profession render engin (v-rai [26]) rai trace algorithm offline. gen- erat 42, 000 ao shade images, creat 6 8 virtual camera scene set field view 50 degre cameras. then, rotat camera 90, 180, 270 degre perpendicular angl view, bind pre-design path andmak shoot paths. took dai render scene data ray-trac v-rai engin pc high perform gpu devic offline. size gener dataset 500 g. releas collect scene code includ shade librari gener dataset publicli work accepted. believ research benefit explor studi ao. worth point defer shade buffer includ depth map normal map gener base camera space. fig. 4 show annot pair dataset. reasons: 1) normal depth map camera space retriev directli g-buffer delai render enabled, 2) addit benefit normal vector posi- tion world coordinates. work, us 33, 800 annot pair train propos deep network model dataset, us 7, 200 pair valid train model. besides, test gener train model common household scene famou public scene sponza palac experi (see fig. 7), includ train dataset. b. workflow deep ao holden et al. [11] nalbach et al. [12] design pixel shader integr implementations. frameworks, user requir modifi implement shader updat ao algorithms. order improv workflow flexibl inde- pendent neural network, propos divid workflow independ modules. illustr fig. 5, workflow mainli consist independ modules: deep learn module, storag module, cpu comput module, gpu render module. power parallel compu- tation capabl gpu device, design parameter- iz comput shader oper convolution, batch norm, activation, pooling, up-sample, concaten task. packag shader library, shown volum 8, 2020 64437 d. zhang et al.: deepao: effici ssao gener deep network figur 6. network structur propos ao gener model. input depth map camera space normal map resolut w h . resolut output input. fig. 5(b). librari includ encode-decod model reflect operations. comput shader library, pre-sav model automat decod re- gener conduct differ deep learn framework updat code, network structur modified. therefore, user need focu design deep learn framework workflow. reduc run-tim algorithm, provid encapsu- late shader combin oper shaders. structur reduc number drawcal greatli improv render efficiency. similar screen- space ambient occlus methods, input method includ normal vector depth easili obtain g-buffer delai render enabled. c. network method util network structur u-net commonli appli medic imag segment [14], [27]. illustr fig. 6, propos network includ down-sampl branch left up-sampl branch right. down-sampl branch net- work consist 3 3 convolut kernel stride 1 leaky-relu activ layers, 2 2 average-pool structur stride 2. step up- sampl branch consist bi-linear upper sampl layer, convolut (reduc number channel half) layer, batch normalization, leaky-relu activ layer. layer us 1 1 convolut kernel map channel singl channel. worth mention resolut shade imag dataset 512 512, propos network base convolut network, output size input arbitrari resolution. loss function. train step network, structur similar (abbr. ssim) index loss function window size 11. output layer xi [0, 1], yi [0, 1] real sampl tag. then, defin loss function follows: ssim (x, y) = (2uxui + c1)(2xy + c2) (u2x + u 2 y + c1)( 2 x + 2 y + c2) (1) ux uy mean patch; x , y xy variances. c1 > 0 c2 > 0 constant avoid error divid zero. set c1 = 1e 4, c2 = 9e 4 implementation. train parameters. train step, adapt moment estim [28] network, learn rate 0.0001. implementation, batch size set 16, leaky-relu neg slope set 0.01. iv. experi implement platform experi pycharm pytorch port. experi paper conduct pc intel(r) core(tm) i7-9700 cpu 64438 volum 8, 2020 d. zhang et al.: deepao: effici ssao gener deep network figur 7. comparison exist ssao-bas methods. left right: hbao [6], nnao [11], deep shade [12], model, ground truth. note exampl fourth row sponza palac scene, includ train validation. nnao output conduct bilater filter oper allevi noise. 3.6g nvidia geforc gtx 1080ti graphic card. memori 16g, os 64-bit window 10 profession version. test measur uniti profiler. quantit evaluation: evalu perform method, test train model datasets: nnao dataset [11], deep shade dataset [12], new dataset. statist result verif volum 8, 2020 64439 d. zhang et al.: deepao: effici ssao gener deep network tabl 1. comparison model ssao-bas methods. averag rmse, averag ssim averag run-tim method comput datasets: nnao [11], deep shade [12] new dataset. given tabl 1. compar method state-of-the-art ssao-bas methods: hbao [6], nnao [11], deep shade method [12]. averag valu structur similar (abbr. ssim) index root-mean-squar error (abbr. rmse) reported. test averag run-tim dataset. best perform mark bold table. seen, method outperform compar method datasets. conduct set visual comparisons, fig. 7. origin nnao method adopt bilater filter post-process output, origin result contain lot noise. thus, experiment, thennao output process bilater filter oper fair comparison. seen, method show signif- icantli better result methods: hbaomethod yield good result smaller structure, gen- erat poor result larger structure, especi partial occlusions. result gener nnao method poor shadow regions. worth point number sampl point origin nnao [11] 8, ao result nnao method highli depend sampl points. is, sampl point input comput time, nnao show better ao results. fair comparison, set input sampl number 64 comparisons. shown tabl 1, method achiev better perform visual qualiti run-time. network nnao simpl multi-lay percept 4 neural layer strongli limit learn ability. furthermore, compar deep shade method [12], method show better perform visual effect run-time. analyz reason follows: deep shade method requir input camera coordin (px ,py,pz) comput transform depth camera coordinates. con- trary, method directli read depth valu z-buffer, comput efficient. convolut kernel sampl step network deep shade method 8, 16, 32, 64, 128, respectively. convent convolut 40 ms input. acceler computation, deep shade method adopt group convolut operations. experiments, figur 8. comparison vao++ method [10]. left right: ground truth, model, vao++ method. correspond ssim rmse shown top-right corner shade ao result. convent convolut gener better results. balanc effect efficiency, us convolut kernel 4, 8, 16, 32 sampl step, respectively. ground truth ao shade imag deep shad- ing dataset contain noise, loss function ssim sensit noise. reason, learn abil deep shade method strongli limit. moreover, varieti scene gener deep shade dataset simpl scene contain high resolut mesh models, limit gener deep shade method complex scenes. obviou contrast deep shade dataset, collect scene new dataset contain larg differ object high reso- lutions. varieti greatli improv gener method. worth point re-train deep shade network new dataset re-train propos network deep shade dataset fair comparisons. comparison vao-bas method: vao techniqu gener ao [10], [23]. experiments, compar method latest vao-bas method: vao++ [10]. fig. 8 show exampl comparison results. vao++ result gener addin uniti [29]. seen, visual qualiti result better vao++method. additionally, numer measur ssim rmse outper- form vao++ method. v. conclus paper, propos effici screen space ambi- ent occlus gener method deep network. construct dataset pair defer shade buffer ground truth shade ao images. then, design u-net-lik network train dataset gener ambient occlusions. evalu method compar exist tradit deep-learn base method 64440 volum 8, 2020 d. zhang et al.: deepao: effici ssao gener deep network public dataset datasets. experiment result method achiev better perform visual qualiti run-tim method datasets. furthermore, improv workflow design comput shader librari contain com- mon convolut network operation, encode-decod model, reflection. allow automat gener neural network shader produc fast accur results. comput shader librari easi user add exist render pipelin post-process step accord configur file store frozen model. refer [1] s. zhukov, a. iones, g. kronin, ambient light illumin model, render techniques. berlin, germany: springer, 1998, pp. 4555. [2] h. landis, production-readi global illumination, siggraph cours notes, vol. 16, p. 11, jul. 2002. [3] m. mittring, find gen: cryengin 2, proc. acm siggraph courses, 2007, pp. 97121. [4] h. nguyen, gpu gem 3. reading, ma, usa: addison-wesley, 2007. [5] p. shanmugam o. arikan, hardwar acceler ambient occlus techniqu gpus, proc. symp. interact. 3d graph. game (id), 2007, pp. 7380. [6] l. bavoil m. sainz, screen space ambient occlusion, nvidia, santa clara, ca, usa, tech. rep., 2008, vol. 6. [online]. available: [7] p. clarberg t. akenine-mller, exploit visibl correla- tion direct illumination, comput. graph. forum, vol. 27, no. 4, pp. 11251136, jun. 2008. [8] l. szirmay-kalos, t. umenhoffer, b. toth, l. szecsi, m. sbert, volumetr ambient occlus real-tim render games, ieee comput. graph. appl., vol. 30, no. 1, pp. 7079, jan. 2010. [9] m. ruiz, l. szirmay-kalos, t. umenhoffer, i. boada, m. feixas, m. sbert, volumetr ambient occlus volumetr models, vis. comput., vol. 26, nos. 68, pp. 687695, jun. 2010. [10] j. bokansky, a. pospil, j. bittner, vao++: practic volumetr ambient occlus games, proc. eurograph. symp. rendering, experim. idea implement., 2017, pp. 3139. [11] d. holden, j. saito, t. komura, neural network ambient occlusion, proc. siggraph asia tech. briefs, 2016, p. 9. [12] o. nalbach, e. arabadzhiyska, d. mehta, h.-p. seidel, t. ritschel, deep shading: convolut neural network screen space shading, comput. graph. forum, vol. 36, no. 4, pp. 6578, jul. 2017. [13] e. liu, i. llamas, p. kelly, cinemat render ue4 real- time rai trace denoising, inrai tracinggems. berkeley, ca, usa: springer, 2019, pp. 289319. [14] x. wu l. zhao, studi iri segment algorithm base dens u-net, ieee access, vol. 7, pp. 123959123968, 2019. [15] deepao. accessed: 2020. [online]. available: [16] a. iones, a. krupkin, m. sbert, s. zhukov, fast, realist light video games, ieee comput. graph. appl., vol. 23, no. 3, pp. 5464, 2003. [17] j. kontkanen s. laine, ambient occlus fields, proc. symp. interact. 3d graph. game (sid), 2005, pp. 4148. [18] j. kontkanen t. aila, ambient occlus anim characters, proc. eurograph. symp. rendering, cyprus, jun. 2006, pp. 343348. [19] m. bunnell, dynam ambient occlus indirect lighting, gpu gems, vol. 2, no. 2, pp. 223233, 2005. [20] p. christensen, point-bas approxim color bleeding, pixar tech. notes, vol. 2, no. 5, p. 6, 2008. [21] ssao+. accessed: 2015. [online]. available: news/introducing-ssao-and-loot-system [22] l. bavoil, m. sainz, r. dimitrov, image-spac horizon-bas ambi- ent occlusion, inproc. acmsiggraphtalk (siggraph), 2008, p. 22. [23] l. szirmay-kalos, t. umenhoffer, b. toth, l. szecsi, m. sbert, volumetr ambient occlus real-tim render games, ieee comput. graph. appl., vol. 30, no. 1, pp. 7079, jan. 2010. [24] r. penmatsa c. wyman, voxel-spac ambient occlusion, proc. symp. interact. 3d graph. game (sid), 2010, p. 1. [25] x. yang, d. wang, w. hu, l. zhao, x. piao, d. zhou, q. zhang, b. yin, q. cai, x. wei, fast reconstruct mont carlo render deep convolut networks, ieee access, vol. 7, pp. 2117721187, 2019. [26] vray. accessed: 2014. [online]. available: [27] o. ronneberger, p. fischer, t. brox, u-net: convolut network biomed imag segmentation, proc. int. conf. med. imag comput. comput.-assist. intervent. cham, switzerland: springer, 2015, pp. 234241. [28] d. p. kingma j. ba, adam: method stochast opti- mization, 2014, arxiv:1412.6980. [online]. available: org/abs/1412.6980 [29] vao++. accessed: 2017. [online]. available: github.io/vaopaper/ dongjiu zhang current pursu mas- ter degre school scienc engineering, south china univers tech- nology. current research interest includ com- puter graphics, imag processing, vision. chuhua xian receiv ph.d. degre scienc state kei labora- tori cad&cg, zhejiang university, 2012. postdoctor research cuhk, novemb 2013 2014, septemb 2015 april 2016. current associ professor school scienc engineering, south china univer- siti technology. current research interest includ intellig graphics, imag pro- cessing, geometri model processing, 3d vision. guoliang luo receiv ph.d. degre scienc univers stras- bourg, 2015. current associ professor east china jiaotong university. research interest includ graphic artifici intelligence. enrol ganjiang outstand youth talent program, 2018. yunhui xiong receiv ph.d. degre scienc engin south china univers technology, 2010. current associ professor school mathematics, south china univers tech- nology. research interest includ graphics, distribut sourc coding, geometri model processing, 3d reconstruction, 3d printing. chu han receiv b.sc. degre south china agricultur university, m.sc. degre scienc south china univers technology, ph.d. degre fromthechi- nese univers hong kong, super- vision prof. tien-tsin wong. current postdoctor fellow guangdong provin- cial peopl hospital, guangdong academi medic sciences, supervis prof. zaiyi liu prof. changhong liang. current research interest includ medic imag analysis, graphics, imag processing, vision, deep learning. volum 8, 2020 64441