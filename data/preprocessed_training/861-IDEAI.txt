1 pattern recognit letter journal homepage: www.elsevier.com deep analysi ag estim ivan huertaa,, carl fernandezb, carlo segurab, javier hernandoc, andrea pratia adpdce, univers iuav, santa croce 1957, 30135 venice, itali bherta security, pau clari 165 4-b, 08037 barcelona, spain cuniversitat politecnica catalunya, jordi girona 1, 08034 barcelona, spain abstract automat estim ag face imag increasingli gain attention, facilit applic includ advanc video surveillance, demograph statist collection, custom pro- filing, search optim larg databases. nevertheless, challeng estim ag uncontrol environments, insuffici incomplet train data, deal strong person-specif high within-rang variance. difficulti recent address complex strongli hand-craft descriptors, difficult replic compare. paper present novel approaches: first, simpl effect fusion descriptor base textur local appearance; second, deep learn scheme accur ag estimation. method evalu divers settings, extens experi carri larg databas (morph frgc) demonstr state-of-the-art result previou work. c 2015 elsevi ltd. right reserved. 1. introduct estim ag imag histor challeng problem field facial analysis. reason uncontrol natur ag- ing process, strong specif individu trait (weng et al. (2013)), high varianc observ ag range, camouflag beards, moustache, glass makeup (thi specif alter perceiv age), difficulti gather complet suffici train data (geng et al. (2013)). imag recognit tasks, larg represen- tativ data/imag requir successfulli train classifier. moveover, case supervis classifiers, data/imag need annotated, real ag case. past, however, avail databas limit strongli skewed. especi disadvantag video surveil- lanc forensics, unknown subject common correspond author: tel.: +39-041-257-2169; fax: +39-041-257-2424; e-mail: (ivan huerta) i. huerta c. fernandez contribut equally. collaborative. fortunately, avail larg databas like morph (ricanek tesafay (2006)) frgc (phillip et al. (2005)) offer opportun progress field. however, train data set repres popul fully, method substanti robust- ness need develop order exploit larg databases. inher difficulti facial ag estim prob- lem, limit imagery, challeng subject variability, subtl visual ag patterns, deriv research field build particularli complex featur extract schemes. typic on consist hand-tun multi-level filter bank (guo et al. (2009); geng et al. (2013); han et al. (2013)), intend emul behavior primari visual cortex cells, fine-grain facial mesh accomplish pre- cise align dozen facial landmark (chang et al. (2011); geng et al. (2007); laniti et al. (2004)). case, result extract scheme difficult replicate, high-dimension visual descriptor case con- sider time computed. paper address issu practic per- spective: given above-ment limit exist approaches, fulli handl issues, aim propos possibl orthogon ways. aim simplifi estim process avoid hand- craft features, propos simpl effect fusion ruben pocul texto escrito mquina notice: author version work accept public pattern recognit letters. chang result publish process, peer review, editing, corrections, structur formatting, qualiti control mechan reflect document. chang work submit publication. definit version subsequ publish pattern recognit letter vol.68, 2, (15/12/2015) doi:10.1016/j.patrec.2015.06.006 ruben pocul texto escrito mquina ruben pocul texto escrito mquina ruben pocul texto escrito mquina 2 well-known descriptors. carefulli select featur fuse ideal borrow best them. hand, previous hand-craft complex scheme extract visual featur progress replac deep learn procedures, automat train layer network architectur tackl defin problem. best knowledge, paper conduct thorough evalua- tion deep learn framework estim ag face images. premises, titl paper contain pun: word deep twofold meaning, refer thor- ough (deep) analysi commonli local visual descriptor propos deep learn approaches, order investig util automat facial ag estima- tion problem. base limit exist propos face ag estimation, main contribut state next: 1. extens review effect descriptor base tex- ture appearance, fusion improv complex, state-of-the-art featur extract schemes. new descriptor proposed, com- prehens evalu demonstr supe- rior perform achiev fuse (or- thogonal) features, repres interest result sci- entif community. 2. investig learn scheme automat train deep neural network ag estimation. mention above, conduct thorough evalu deep learn- ing ag estimation. deep learn propos past prove viabl effect classifi applications. however, perform ag estim questionable, given high variabl limit data available. 3. propos method exhaust evalu larg databases, optim paramet regular- ization. method show state-of-the-art results, de- spite us simpl ey align preprocessing. paper structur follows. section gather previou work facial ag estimation. section 3 re- view propos candid descriptors, cho- sen classif scheme, comment investig deep learn scheme. evalu method present section 4, review avail age-annot larg databases, describ experi carri fuse local descriptor deep neural networks. finally, sec- tion 5 summar result draw conclusions. 2. relat work initi attent automat ag estim imag date earli 2000 (laniti et al. (2004, 2002); minear park (2004)). however, research field experienc renew 2006 on, avail larg databas like morph-album 2 (ricanek tesafay (2006)), increas 55 real age-annot data compar databas time. databas consist evalu recent work differ featur extract classif schemes. featur extract scheme. ag estim images, typic phase pre-process extract vi- sual featur need (1) discrimin dif- ferent classes, (2) robust class, (3) minim dimensionality. class method reli flexi- ble shape appear model asm (activ shape model) aam (activ appear model) model ag pattern (chang et al. (2011); geng et al. (2013, 2007); laniti et al. (2004)). statist model captur main mode variat shape intens observ set faces, allow encod face signatur base characteri- zations. method extract set visual featur fed classifi estim age. instance, bio- inspir featur (bif) (riesenhub poggio (1999)) deriv consist ag estim year (geng et al. (2013); han et al. (2013)). feed-forward model intertwin number convolut pool layers. first, input imag map higher- dimension space convolv bank multi-scal multi-orient gabor filters. later, pool step down- scale result non-linear reduction, typic max std operation, progress encod result vec- tor signature. guo et al. (2009), author carefulli design two-lay simplif model ag estim manual set number band orient con- volut pooling. featur pos- terior works, e.g. guo mu (2011, 2013, 2014). featur extract local neighborhood purpos ag estimation, exampl yang ai (2007), gunai nabiyev (2008) choi et al. (2011). weng et al. (2013), lbp histogram featur combin princip compon bif, shape textur featur aam, pca project origin imag pixels. in- depend hog featur ag estim fernandez et al. (2014) huerta et al. (2014). classif scheme. regard learn al- gorithm, approach proposed, including, others, support vector machin / regressor (guo et al. (2009); han et al. (2013); chang et al. (2011); weng et al. (2013)), neural network (laniti et al. (2004)) variant condit probabl neural network (geng et al. (2013)), random forest (montillo ling (2009)), project techniqu partial squar (pls) canon correl analysi (cca), regular kernel version (guo mu (2011, 2013, 2014)). ex- tensiv comparison classif scheme ag esti- mation report (fernandez et al. (2014); huerta et al. (2014)), advantag cca demonstr others, accuraci efficiency. reason, specif attent given cca technique. pl cca subspac learn algorithm origin conceiv model compat multidimension variables. pl us latent variabl learn new space variabl maximum cor- 3 relation, cca find basi vector pro- jection variabl vector maxim correl other. techniqu adapt label regression. best knowledge, best current result morph achiev combin bif fea- ture kernel cca (guo mu (2013)), case size train fold limit 10k sampl comput limitations. deep learning. recently, convolut network deep learn scheme successfulli emploi task relat facial analysis, includ face detection, face align (sun et al. (2013)), face verif (taigman et al. (2014)), demograph estim (yang et al. (2011)). work actual exploit ag gender cue order address face recognition, specif focu analyz evalu convolut network architectur ag estimation. basic methodolog gener common all, i.e., combin number convolutional, pool fulli partial connect neuron layers, variat order, repetit connect layers. nonetheless, particular choic parameters, typic share layers, kei success. main contribut paper propos novel combin well-known local descriptor captur textur contour cue purpos facial ag estima- tion. differ natur featur allow exploita- tion benefit them, bring perform superior case appli separately. contribut evalu deep learn frame- work problem ag estimation. field, best knowledge, approach base local featur deep learn compar experiment settings, databases. experi demonstr compar perform propos respect state-of-the-art result provid complex fine-tun featur extract scheme bif (guo mu (2014)). moreover, sake simplic efficiency, simpl ey align oper carri similar transformation, oppos precis align- ment approach typic fit activ shape appear model ten facial landmarks. 3. methodolog present approaches, base local featur combination, exploit deep learning. methodolog emploi basic preprocessing, describ next. global view methodolog present figur 1. preprocessing. facial region imag detect face detector describ oro et al. (2011). differ method reli ten facial landmark accur align (e.g., asm aam), exploit rel align invari local descriptor base concaten cell histogram work simpl fig. 1. gener view methodolog present paper. eye-align images. fiduci marker correspond ey center obtain convolut neural network face align present sun et al. (2013). align version detect face obtain non-reflect similar imag transform yield optim least-squar correspond ey center target locations, symmetr place 25% 75% align template. unlik previou work like guo mu (2013), us input imag 6060 pixels, align imag resiz 5050. descriptors. choic visual featur extract align imag plai fundament role result esti- mation accuracy. paper, select number signific local invari descriptor us imag match object recognit past expressiveness, fast computation, compactness, invari misalign monoton illumin changes. in- clude local appear descriptor hog textur descrip- tor lbp surf. histogram orient gradient (hog) (dalal trigg (2005)) larg robust visual descriptor vision applic relat object detect recognition. imag region divid cx cy grid cells. histogram orient assign cell, bin account evenli split sector [0, ] [, ] domain (for unsign sign versions, re- spectively). pixel location, gradient magnitud orient computed, pixel increment assign orient bin correspond cell gradient mag- nitude. cell histogram concaten provid final descriptor. us hogsc,b denot cc squar grid (where c = cx = cy) b orient bins, s differ scales. local binari pattern (lbp) (ojala et al. (2002)) long textur descriptor imag classification, recently, variat origin propos provid state-of-the-art result field like face object recogni- tion. origin oper describ pixel imag threshold surround 33-neighborhood in- tensiti value, concaten 8 boolean test binari number. build lbp compact descriptor, histogram comput filter result, bin correspond lbp code. typic extens reduc dimen- sional descriptor assign non-uniform code 4 singl bin, uniform code defin have 2 bitwis transit 0 1 vice versa (e.g., 00111000, versu non-uniform 01001101). lbp de- scriptor gener neighborhood size p radiu r uni- form pattern s scale refer lbpu2sp,r , e.g. lbp u21 8,2 . speeded-up robust featur (surf) (bai et al. (2006)) point detector descriptor particularli in- variant scale rotation. commonli imag match object recognit faster compa- rabl altern sift. case, concentr upright version techniqu (u-surf). squar imag region partit 44 subregions. hori- zontal vertic wavelet respons dx dy comput weight gaussian. sum respons absolut valu stored, gener 4-dimension vector ( dx, dy, |dx|, |dy| ) subregion, concaten form final 64-dimension descriptor imag region, surf64. common extens consist doubl number features, separ comput sum dx |dx| dy < 0 dy 0, equal dy given sign dx, yield surf128. us no- tation surfsd refer concaten d-dimension surf descriptor s differ scales. gradient inform imag content descriptors, includ raw magnitud gradient imag (i := ( x )2 + ( y )2 ) baselin experi evalu propos descriptors. classification. wide varieti learn scheme present literatur facial ag estimation, canon correl analysi (cca) deriv recent obtain state-of-the-art result challeng larg databas morph (guo mu (2014)). project tech- niqu involv low comput effort unpreced ac- curaci field, us chosen regress learn algorithm. cca pose problem relat data x label y find basi vector wx wy, project variabl respect basi vector maxim correl coeffici = wxt xyt wy (wxt xxt wx)(wyt yyt wy) , (1) or, equivalently, find maxwx,wi wx t xyt wy subject scale wxt xxt wx=1 wyt yyt wy=1. ag estimation, data matrix x mn label matrix y m1, m number exampl n dimens descrip- tor. hence, y vector, vector wy turn simpl scale factor, squar fit suffic re- late label y project data featur wxt x. thus, wx (of size m1) need computed, solv follow gener eigenvalu problem: xyt ( yyt +y )1 yxt wx = ( xxt + ) wx (2) project solut wx, dimension data featur reduc dimens output (a singl numer valu case), aforement label fit simpli consist find scalar valu optim adapt project valu ground truth age, least-squar sense. describ procedur stabil regu- larization, modifi eigenvalu problem follows: xyt ( (1 y)yyt + yi )1 yxt wx = ( (1 x)xxt + xi ) wx (3) regular term x, y [0, 1] includ eq. 3 prevent overfitting. cca admit extens kernel version, kcca, case covari matric computation intract 10k samples. practice, regular cca (rcca) work compar kcca (guo mu (2013)), computation demanding, allow reproduc exact valid scheme algorithm larg databases. deep learning. neural network formul regain remark popular vision machin learn communities, form deep learn schemes. explain number reasons, avail- abil larger dataset exploit automat schemes, recent avail effici hardwar devot scalabl computation. larg dataset crucial gener vi- sion solut non-constrain settings, multi- ple sourc variability, e.g. view, illumination, occlu- sion. previous popular machin learn techniqu support vector machin subspac learn method (pca, lda, ica, cca) serious limit deal larg train sets. instance, mention kcca work practic 10k train sampl (guo mu (2013)), larg volum data actual recom- mend requir conduct deep learning. more- over, deep learn framework especi us problem involv exploit non-trivi features, fact featur extract classif step jointli optim learn process. result- ing network intern extract suitabl featur minim object cost function, craft adequ featur better tack problem. follow success recent work deep learn facial analysis, incorpor type layer devot learn appropri featur problem, follow layer serv interrel inform global conduct regress classif process. type typic includ convolut pool layers, second type repres local fulli con- nect neurons. problems, best repeat group layer number times, order extract featur progress higher order, edg contour blob textures. particular choic layer-specif paramet (e.g. filter size number), relat learn process (e.g. learn rates, weight regulariza- tion) describ follow section. 5 tabl 1. descript popular databas ag estimation. evalu consid bold. databas refer sampl subject comment pal minear park (2004) 580 580 limit number sampl fg-net laniti et al. (2002) 1,002 82 limit number sampl subject group gallagh chen (2009) 28,231 28,231 ag discret seven ag interv frgc v2.0 phillip et al. (2005) 44,278 568 larg database; sampl subject morph-ii ricanek tesafay (2006) 55,134 13,618 larg database; high divers 4. experiment result ag databases. natur ag estim prob- lem, restrict number publicli avail databas provid substanti number face imag label ac- curat ag information. tabl 1 show summari exist- ing databas main reference, number samples, number subjects, comments. pal fgnet 0 10k 20k 30k 40k 50k ag databas comparison - sampl n um r s pl es group frgc morph 10 20 30 40 50 60 70 80 2k 4k 6k 8k 10k 12k ag s pl es p er ge morph frgc ag databas comparison - densiti fig. 2. left: number face sampl database. right: global densiti age. pal fg-net rel negligible, group an- notat intervals. focu morph-ii fgrc. sampl skew 2030 year old. tabl 1, clear older dataset like pal fg-net compos neglig number sampl compar newer datasets. groups, instead, contain good number samples. however, ag annot discret seven ag intervals, make unsuit- abl train accur ag estim models. moreover, fg-net contain 82 subjects, leave-one-person-out valid scheme emploi convention, avoid opti- mistic bias ident replication. given limitations, recent tendenc us morph standard ag estimation, concentr databas frgc provid experiment evaluations. frgc databas compar morph number samples, imag qualiti ag rang coverage, previou public ag estim includ frgc experi (fernandez et al. (2014)). figur 2 offer graphic visual comparison analyz databases, number sampl ag density. figur 2 show ag distribut differ datasets: evid morph frgc sampl ag concentr rang 20-55. metrics. evalu accuraci ag estimators, convent metric mean averag error (mae) cumul score (cs). mae comput averag ag deviat error absolut terms, mae = m i=1 |ai ai|/m, ai estim ag i-th sample, ai real ag m total samples. cs defin percentag imag error e higher given number year l, cs (l) = mel/m (chang et al. (2011); weng et al. (2013); han et al. (2013)). relat public typic suppli eleven-point curv ag deviat [0 10], simpli valu cs (5). rest paper, optim paramet search minim mae score morph, 5-fold cross-valid case 1. particular, divis train valid set instanc subject contain singl fold time; appli present experiments. descriptor extract align version detect faces. cx cy b 7 8 9 10 11 12 13 14 15 16 17 18 19 20 3 3 7.11 6.97 6.88 6.86 6.73 6.77 6.66 6.58 6.60 6.56 6.55 6.48 6.48 6.49 4 4 6.62 6.56 6.35 6.42 6.28 6.28 6.17 6.18 6.16 6.16 6.08 6.06 6.04 6.06 5 5 5.76 5.75 5.55 5.53 5.47 5.44 5.39 5.37 5.38 5.35 5.33 5.31 5.31 5.29 6 6 5.53 5.43 5.30 5.32 5.26 5.23 5.17 5.18 5.16 5.14 5.13 5.11 5.12 5.10 7 7 5.13 5.10 4.98 4.99 4.93 4.93 4.89 4.89 4.88 4.85 4.85 4.85 4.85 4.84 8 8 4.97 4.94 4.84 4.86 4.80 4.80 4.76 4.77 4.75 4.75 4.74 4.73 4.74 4.73 9 9 4.86 4.81 4.73 4.75 4.71 4.69 4.66 4.67 4.64 4.64 4.65 4.64 4.63 4.64 10 10 4.77 4.73 4.68 4.69 4.64 4.61 4.61 4.60 4.59 4.58 4.59 4.59 4.59 4.59 11 11 4.66 4.62 4.55 4.57 4.54 4.50 4.50 4.50 4.49 4.47 4.50 4.49 4.49 4.50 12 12 4.84 4.82 4.77 4.78 4.72 4.71 4.70 4.72 4.70 4.69 4.70 4.70 4.71 4.71 13 13 4.66 4.65 4.60 4.61 4.57 4.56 4.54 4.56 4.55 4.54 4.55 4.56 4.56 4.57 14 14 4.57 4.55 4.50 4.51 4.47 4.46 4.45 4.48 4.46 4.46 4.47 4.47 4.48 4.49 15 15 4.47 4.45 4.41 4.42 4.39 4.38 4.38 4.40 4.39 4.39 4.40 4.41 4.41 4.43 16 16 5.14 5.09 5.08 5.10 5.04 5.06 5.05 5.06 5.07 5.04 5.09 5.10 5.11 5.11 17 17 5.00 4.95 4.96 4.97 4.92 4.92 4.92 4.94 4.95 4.92 4.96 4.98 4.99 5.01 18 18 4.84 4.81 4.81 4.82 4.77 4.77 4.79 4.80 4.81 4.80 4.83 4.85 4.88 4.88 19 19 4.65 4.64 4.62 4.63 4.61 4.60 4.62 4.63 4.63 4.63 4.67 4.69 4.71 4.72 20 20 4.55 4.55 4.54 4.54 4.54 4.53 4.54 4.56 4.57 4.57 4.60 4.63 4.65 4.67 fig. 3. result hogc,b featur singl scale imag size 5050 px grid size c = cx = cy (rows) b bin (columns). border cell show best value. paramet analysi local features. order evalu depth perform analyz featur ag es- timation, conduct deep analysi differ paramet compar featur detectors. tabl 2 list parametr choic considered, give name success configur hog, lbp surf descrip- tor fusion experiments. multiscal 15 cross-valid folder structur imag databas avail comparison purpos 6 cx cy b 5 6 7 8 9 10 11 12 13 14 15 16 17 18 8 8 4.62 4.63 4.58 4.59 4.58 4.58 9 9 4.50 4.51 4.48 4.48 4.47 4.48 10 10 4.72 4.67 4.56 4.55 4.51 4.52 4.49 4.49 4.48 4.50 4.50 4.49 4.64 4.52 11 11 4.61 4.56 4.48 4.47 4.43 4.44 4.42 4.43 4.43 4.44 4.45 4.44 4.47 4.48 12 12 4.72 4.68 4.60 4.61 4.57 4.59 4.57 4.58 4.58 4.61 4.60 4.63 4.64 4.66 13 13 4.74 4.73 4.61 4.62 4.58 4.60 4.57 4.57 4.57 4.59 4.58 4.59 4.59 4.62 14 14 4.63 4.62 4.53 4.53 4.48 4.52 4.49 4.49 4.49 4.53 4.52 4.54 4.55 4.57 15 15 4.52 4.51 4.45 4.45 4.41 4.45 4.42 4.43 4.44 4.47 4.46 4.49 4.51 4.54 16 16 5.04 5.04 5.08 5.04 5.07 5.07 5.09 5.12 fig. 4. result concaten hog3c,b featur 3-scale im- ag 5050, 2525, 1313 px, grid size c = cx = cy (rows) b bin (columns). border cell show best value. cx cy b 6 7 8 9 10 11 12 13 14 15 16 17 7 7 5.39 5.13 5.09 4.97 4.95 4.87 4.88 4.85 4.82 4.82 4.81 4.80 8 8 5.15 4.93 4.91 4.80 4.79 4.73 4.72 4.70 4.67 4.66 4.65 4.66 9 9 4.85 4.70 4.65 4.59 4.59 4.53 4.51 4.49 4.48 4.48 4.47 4.48 10 10 4.87 4.67 4.62 4.54 4.55 4.49 4.49 4.46 4.44 4.44 4.44 4.43 11 11 4.64 4.50 4.48 4.41 4.42 4.37 4.37 4.36 4.34 4.35 4.34 4.34 12 12 4.63 4.51 4.47 4.41 4.42 4.38 4.38 4.37 4.36 4.36 4.35 4.36 13 13 4.52 4.41 4.38 4.33 4.33 4.30 4.29 4.28 4.28 4.28 4.28 4.28 14 14 4.47 4.36 4.33 4.31 4.30 4.28 4.29 4.27 4.26 4.28 4.27 4.29 15 15 4.37 4.28 4.26 4.23 4.23 4.21 4.22 4.20 4.20 4.21 4.22 4.24 16 16 4.44 4.35 4.33 4.30 4.31 4.30 4.28 4.29 4.27 4.29 4.29 4.30 17 17 4.36 4.28 4.26 4.24 4.25 4.23 4.23 4.23 4.22 4.24 4.24 4.25 18 18 4.30 4.23 4.21 4.20 4.20 4.19 4.18 4.19 4.19 4.20 4.21 4.22 19 19 4.26 4.20 4.18 4.17 4.18 4.17 4.16 4.17 4.17 4.19 4.19 4.22 20 20 4.41 4.34 4.24 4.33 4.33 4.32 4.34 4.34 4.35 4.38 4.37 4.40 fig. 5. result hogc,b featur singl scale imag size 100100 px, grid size c = cx = cy (rows) b bin (columns). border cell show best value. tabl 2. refer tabl summar parametr choic took conduct experiments, name recurr configurations. scheme paramet descript valu imag size (px px) hogxsc,b c=cx=cy #cell {3, 4 . . . , 20} b #bin {7,8. . . ,20} s #scale { 1 50 100 3 50, 25 13 lbpu2xsp,r p #neighbor {8,16} r radiu {2,3,. . . ,10} s #scale { 1 50 3 50, 25 13 s urfxsd d dimens (for {64,128} base descriptor) s #scale {1,2,3} v scale valu {1.6,1.8,2, 50 2.4,3,4,5} dnn architectur nckrpk nckrpk ufrdk f 50 n #filter {16,. . . ,128} ck convolut {3,. . . ,11} pk pool 2 u #unit {256,. . . ,1000} f fulli connect r rectifi dk dropout 0.5 paramet imag size (px px) hoga cx=cy=8, b=9, s=1 50 hogb cx=cy=15, b=13, s=1 50 lbpa p=16, r=3, s=3 50, 25 13 s urfa d=64, s=3, v={1.6, 2, 2.4} 50 s urfb d=128, s=3, v={1.6, 2, 2.4} 50 version result concaten base descriptor differ scales. hog parameters. refer hogc,b, con- sider grid size cxcy number bin b, opti- mal valu obtain exhaust logarithm grid search 5-fold cross-validation, singl multipl scales. best result obtain cx=cy=c. im- plement detail, 50% cell overlap smooth global l2 normalization, instead per-cell, experiments. sophist systemat ap- proach reduc paramet combinations, main focu paper. multiscal variat achiev concaten featur vector obtain descriptor differ scales. order fair com- parison result report guo mu (2014), imag process 5050 (similar 6060 size paper). however, evalu effect differ imag size final perform figur 5, imag size 100100 used. summary, figur 3, 4 5 report individu analysi hog descriptor singl scale 5050 pixels; multipl scale (3 scale 5050, 2525, 1313; singl scale 100100, respec- tively. figur 5 show 100100 imag provid better score tradit size literature, conduct rest experi 5050 pixel fair comparison. singl hog scale perform better. lbp parameters. lbpu2p,r analysi carri search optim number sampl neighbor p radiu r, scales, constrain neigh- bor 8 16, tabl 3. multiscal case, smallest imag size restrict maximum radiu 6 pixels. tabl 3. mae single-scal descriptor lbpu2p,r 5050 pixels, 3-scale lbpu23p,r concaten 5050, 2525, 1313. neigh- borhood 8 16 shown. (size) radiu r 2 3 4 5 6 7 8 9 10 lbpu28,r (59) 7.17 7.12 7.15 7.30 7.55 7.82 8.04 8.11 8.08 lbpu216,r (243) 6.88 6.70 6.66 6.76 7.06 7.25 7.40 7.51 7.81 lbpu238,r (177) 6.48 6.49 6.66 6.82 10.75 - - - - lbpu2316,r (729) 6.18 6.13 12.41 11.32 12.26 - - - - surf parameters. case surf, 5 descriptor extract certain scale fiduci marker eyes, nose tip mouth corners, provid alignment, concaten singl descriptor. multipl scale test origin extend descriptor (surf64 surf128), shown tabl 4. tabl 4. mae result surf multipl scale combin (size brackets). scale surf64 surf128 multiscal surfs64 surf s 128 1.6 6.09 (320) 5.72 (640) {1.6, 2} 5.73 (640) 5.39 (1280) 1.8 6.21 (320) 5.77 (640) {1.6, 2.4} 5.71 (640) 5.41 (1280) 2.0 6.24 (320) 5.81 (640) {2, 3} 5.95 (640) 5.60 (1280) 2.4 6.65 (320) 6.24 (640) {1.6, 1.8, 2} 5.67 (960) 5.34 (1920) 3.0 6.93 (320) 6.59 (640) {1.6, 2, 2.4} 5.59 (960) 5.30 (1920) 4.0 7.46 (320) 7.12 (640) {1.6, 2.4, 3} 5.60 (960) 5.33 (1920) 5.0 7.52 (320) 7.26 (640) {2, 2.4, 3} 5.84 (960) 5.53 (1920) 7 cca optim regularization. optim regular cost , defin section 3, differ comput featur parameter. reason, initi above-ment grid search perform regular ( = 0). best paramet featur detector identified, optim regular cost search look minimum mae. additionally, impos x = y. however, experi suggest signific chang notic incorpor regular rel size databas descriptor, shown fig. 6. curv repres subset exampl differ- ent size. number databas exampl m increas featur dimension n, i.e. mn, optim reg- ular cost (minimum curve) tend zero. 0 0.5 1 1.5 2 2.5 3 x 103 4 4.5 5 5.5 6 6.5 7 regular cost m e ( ye ar s) effect train size regular requir 100 200 500 1000 2000 5000 10000 20000 50000 number exampl fig. 6. need regular depend strongli ratio train exampl m featur dimension n. figur show 5cv result 576-dimension hoga singl scale 5050 px cca, differ valu increas exampl 100 50k. m increas optim decays, drop zero mn. featur combination. order improv accuraci estimation, take advantag orthogon natur differ descriptors, thorough analysi fusion combi- nation featur candid carri out. dif- ferent featur combin simpli concaten them, proposed, instance, pedestrian detect liang et al. (2012). featur pool and/or dimension reduct tech- niqu (huang et al. (2014)) well, pre- fer stick simpl approach obtain result re- port follow promising. similarly, em- ploi early-fus strategy, combin featur beginning, classif decis place. strategi used, late- fusion strategy, featur coupl clas- sification, fusion perform decis level, tan trigg (2010). combin tested, tabl 5 show signific ones: single-scal hog8,9 hog15,13, 5050 px imag (hoga hogb); 3-scale lbpu2316,3 , comput 5050, 2525 13513 px images, concaten (lbpa); raw gradient magnitud 5050 px images; 3-scale surf364 surf 3 128 com- pute 5 fiduci point scale 1.6, 2, 2.4, con- caten (surfa surfb). featur combin con- caten descriptor best paramet individu found, describ above. tabl 5. mae fusion best descriptors. hoga, hogb comput singl scale (50 px). lbpa, s urfa s urfb aggreg 3 scales. best result achiev fuse hogb + lbpa + s urfa. # hoga hogb lbpa s urfa s urfb (size) mae 1 (576) 4.84 2 (2925) 4.38 3 (729) 6.13 4 (2500) 5.58 5 (960) 5.59 6 (1920) 5.30 # hoga hogb lbpa s urfa s urfb (size) mae 7 (1305) 4.66 8 (3805) 4.53 9 (2265) 4.42 10 (3225) 4.61 11 (4765) 4.51 12 (5725) 4.72 # hoga hogb lbpa s urfa s urfb (size) mae 13 (3654) 4.33 14 (5420) 4.33 15 (6154) 4.30 16 (3885) 4.30 17 (4845) 4.33 18 (4614) 4.27 19 (5574) 4.33 20 (7114) 4.31 21 (8074) 4.34 # hoga hogb lbpa s urfa s urfb (size) mae 22 (3229) 5.07 23 (1689) 5.31 24 (2649) 6.45 column tabl 5 report refer row number eas descript follow text, featur names, size combin descriptor, mae. tabl vertic divid parts. uppermost (row 1 6) shows, bullet correspond column, result singl feature. second (row 7 12) show combin hoga lbpa common, (row 13 21) fourth (row 22 24) result differ combinations, keep hogb lbpa fixed, respectively. observ summari result tabl 5, s urfb reduc mae fuse featur (from 5.30 year row 6 4.33 combin hogb lbpa row 17 19), perform wors s urfa combin (see row 9-10, 11-12, 16-17, 18-19, 20- 21 23-24). however, consid isolation, s urfb perform better s urfa (row 6 compar row 5). best result obtain combin hogb, lbpa s urfa. combin advantag fuse textur local appearance-bas descriptors. no- ticeabl remark so-cal curs dimensionality: addit descriptor higher dimension featur enhanc result (compare, instance, row 15 20 21, row 8 12). specif size accur descriptor 8 correl accuraci either, af- ter proper regular applied. hog famili descriptor behav particularli differ gran- ular tested, hoga hogb, 576 2925 dimens respectively. suggest local appear inform particularli us suffici cap- ture ag patterns. size descriptor deserv impor- tant consider case cca, strongli affect comput effici train process, plai import role stabil solution: higher mn ratio result stabl pseudo-invers matric search cca project matrix. tabl 6. result non-regular cca ( = 0) cca regular cost yield best mae, descriptor (bif guo mu (2014)). hogb lbpa s urfb bif fusion (size) (2925) (2500) (729) (1920) (4376) (4614) mae ( = 0) 4.38 5.58 6.13 5.30 5.37 4.27 mae (best ) 4.34 5.49 6.13 5.29 4.42 4.25 =0.001 =0.002 0 0 =0.05 0 tabl 6 show effect regular featur yield best mae score experiments, morph databas regular cca regress technique. optim regular cost provided. in- clude best result (to best knowledge) achiev bif descriptor, commonli ag estim provid lowest mae morph literatur (guo mu (2014)). size bif dimen- sional reduct (4376) similar propos fu- sion process (4614). nonetheless, propos fusion local descriptor improv best reg- ister result database, reduc 4.42 4.25. noteworthi differ regular con- tribut descriptor. instance, affect lbp, improv bif 18%. tabl 7. mae cs(5) score morph frgc. best possibl de- scriptor used. mae cs(5) hogb lbpa s urfb fus. hogb lbpa s urfb fus. morph5cv 4.34 5.49 6.13 5.29 4.25 69.5% 57.6% 52.1% 60.2% 71.2% frgc5cv 4.19 4.38 4.45 4.44 4.17 76.0% 77.9% 77.4% 77.5% 76.2% finally, result obtain frgc well. tabl 7 contain global mae error cs(5) valu morph frgc, figur 7 show complet cumul score curv error level 0 10. figur 7(a) seen morph database, fusion descriptor consist improv individu features, optim configur paramet regularization. hand, frgc curv practic identical. state begin section, lack variabl imag database, individu averag 80 images, alike. term mae, fusion descriptor obtain best score. 0 1 2 3 4 5 6 7 8 9 10 0 10 20 30 40 50 60 70 80 90 100 c um ul iv e sc e (% ) error level (years) 5 crossvalid morph fusion morph5cv hog morph5cv morph5cv lbp morph5cv surf morph5cv (a) 0 1 2 3 4 5 6 7 8 9 10 0 10 20 30 40 50 60 70 80 90 100 c um ul iv e sc e (% ) error level (years) 5 crossvalid frgc fusion frgc5cv hog frgc5cv frgc5cv lbp frgc5cv surf frgc5cv (b) fig. 7. 5-fold cross-valid (5cv) cumul score curv tech- niqu evalu (a) morph (b) frgc. paramet analysi deep learning. experiment eval- uation deep neural network conduct variat relev paramet net- work architecture: number natur layers, rate learn process, specif intern paramet number filter size convolut kernels. valid scheme continu 5cv, i.e. divid dataset folds, train network paramet scratch uniqu 5050 imag folds, test network remain one, averag test result possibl assignments. axial symmmetri face exploit form data augmentation. choic adapt learn rate crucial success model, figur 8. currently, common good practic includ (i) automatic, progress rate updat iter progress, (ii) fix rate sig- nific manual decrement learn curv stabilizes. intend learn finer characterist optim minimum coars approached. evalua- tion, decid us fix learn rate manual read- reason number iterations, enabl 9 0 1 2 3 4 5 6 7 8 9 10 x 10 4 0 50 learn rate = 5e05 0 1 2 3 4 5 6 7 8 9 10 x 10 4 0 50 learn rate = 5e06 0 1 2 3 4 5 6 7 8 9 10 x 10 4 0 50 learn rate = 5e07 averag train 5cv iter iter iter lo ss lo ss lo ss fig. 8. learn rate paramet chosen criticality. valid loss evolv 3 fix valu learn rate, architecture. valu yield, bottom, instability, convergence, slow learning. better assess effect singl paramet network, modifi differ experiments. tabl 8 show signific subset experi carri train network. common practic deep learn approaches, initi setup replic previous success cnn (lenet), adjust appli initi state. architectur consist number convolut pool layers, follow number fulli connect layers. case, final stage singl regress unit. evalu architectur differ number layer (rang 1 3), layer types, number units, activ functions, regular techniques. concretely, us notat ck convolut unit kernel size k; pk max-pool unit kernel size k; f layer featur connect units. stride set 1 pixel convolutions, pool us valu kernel size. r includ layer employ- ing rectifi linear unit (relu), form f (x) = max(0, x). layer dn incorpor dropout, i.e. random subsampl n total unit layer, prove us prevent overfitting. here, half neuron randomli disconnected. instance, 32c11p2 500fr f repres layer 32 convolut filter 11-pixel kernels, follow max-pool oper reduc output half, layer 500 full-connect unit relu activation, output regressor. learn rate weight decai network explicitli state experi table. comput requir train deep neural network differ substanti previou approach. train time fold 5cv-morph, 2-layer architectur usual 67 hour i7-3770k nvidia gtx770 graphic card caff frame- work (jia et al. (2014)), 3-layer on need 89 hours. tabl 8. select network configur 5cv valid re- sult morph 105 iterations. architectur learn weight mae rate decai 32c11p2 500fr f 105 106 4.09 20c11p2 500fr f 105 106 4.15 32c7p2 64c7p2 500fr f 105 106 4.39 20c7p2 50c9p2 500fr f 105 106 4.48 20c7p2 50c9p2 500fr f 5 104 5 105 3.96 20c5p2 50c5p2 500fr f 5 105 5 106 3.97 20c5p2 50c5p2 500fr f 5 106 5 106 4.17 20c5p2 50c5p2 500fr f 5 107 5 108 5.75 32c11p2 64c9p2 500fr f 5 105 5 106 4.31 32c11p2 64c9p2 500fr f 5 106 5 106 4.25 32c11p2 64c9p2 500fr f 5 107 5 108 6.14 16c3rp2 32c7r 512fr f 5 105 5 104 3.98 16c3rp2 32c7r 512fr f 104 103 4.01 16c3rp2 64c7r 256fr f 5 105 104 3.96 16c3rp2 64c7r 256fr f 5 105 5 104 4.00 32c3rp2 16c7r 512fr 256fr f 5 105 103 4.12 20c5p2 50c5p2 512fr f 5 106 5 107 4.14 20c5p2 50c5p2 512fr f 5 106 5 108 4.16 20c5p2 50c5p2 512fr f 5 106 5 109 4.14 20c5p2 50c5p2 512fr f 5 106 5 1010 4.10 20c5p2 50c5p2 512fr f 5 106 5 1011 4.12 20c5p2 50c5p2 500frd0.5 f 5 106 5 1011 3.90 20c5p2 50c5p2 1000frd0.5 f 5 106 5 1011 3.88 32c3p2 64c5p2 128c3p2 500fr f 105 106 4.07 compar them, extract chosen descriptor take approxim 1 minut hog, 2 minut surf 12 second lbp (less 4 minut fusion), learn cca model fuse descriptor take 15 seconds. predict time differ: deep learn model take 6 seconds, cca fuse descriptor order milliseconds. general, observ deep learn architectur produc similar results, fine parametr adjust progress decreas error. inclus layer unit increas learn capac model, contribut instability. leverag regular techniqu weight decay, rectifi sparsity, unit dropout, manag achiev stabl accur network, yield 5cv-mae 3.88 morph. discussion. tabl 9 summar relev con- tribut facial ag estim date suppli cross- valid mae morph frgc, includ method propos paper. unlik ours, con- tribut reli flexibl model ten fiduci (asm aam), hand-craft bif features. moreover, propos exploit avail set 55k sampl morph 44k sampl fgrc, train 4 folds, test remain averag combinations. 5cv-mae given earli fusion local descriptor improv best 5cv approach. hand, model obtain deep learn techniqu produc 5cv-mae 3.88 morph. valu reduc previ- 10 tabl 9. ag estim result morph ii frgc compar algorithm visual descriptors, varieti settings. morph-5cv techniqu propos featur train / test mae cs(5) laniti et al. (2002) aam+bif 55k 9.21 aa geng et al. (2013) aas+bif 55k 10.10 ag geng et al. (2007, 2013) aam+bif 55k 6.61 red (svm) chang et al. (2011) aam 6k 6.49 48.9% ohrank chang et al. (2011) aam 6k 6.07 56.4% ohrank chang et al. (2011) aam+bif 55k 6.28 pl guo mu (2011, 2013) bif 10k/55k 4.56 kpl guo mu (2011, 2013) bif 10k/55k 4.04 iis-lld geng et al. (2013) aam+bif 55k 5.67 cpnn geng et al. (2013) aam+bif 55k 4.87 cca guo mu (2013) bif 10k/55k 5.37 rcca guo mu (2013) bif 10k/55k 4.42 kcca guo mu (2013) bif 10k/55k 3.98 mfor weng et al. (2013) pca+lbp+bif 4k 4.20 72.0% svm+svr han et al. (2013) bif+asm 78k 4.20 72.4% svr fernandez et al. (2014) hog 55k 4.83 63.4% rcca paper fusion 55k 4.25 71.17% cnn paper cnn 55k 3.88 frgc-5cv techniqu propos featur train / test mae cs(5) rcca paper fusion 44k 4.17 76.24% cnn paper cnn 44k 3.31 ou best result databas (guo mu (2013)), addition emploi standard 5cv scheme comput limit caus kcca approach. result cnn architectur valid frgc, result 5cv-mae 3.31, decreas previou result fuse local descriptors. 5. conclus differ techniqu propos ag estim facial images. method base earli fusion local invari descriptor coupl standard subspac learn technique, requir fea- ture tuning, demonstr local appear tex- ture suffici captur ag information. hand, provid power deep learn framework coupl extract regress meaning cue jointli optim stages. approach appli eye-align 5050 images, requir complex statis- tical facial model precis align addit cues, unlik tradit techniqu ag estimation. provid thorough evalu stabil effect approaches. local descrip- tors, experi earli fusion hog, lbp surf improv best mae score report non-kernel cca technique, result 4.25 year com- pare 4.42 hand-craft bif 6060 pixels. ex- periment distanc increas larger imag demonstr singl hog descriptor (mae 4.16). hand, deep learn architecture, requir specif pa- ramet tuning, decreas minimum error date 3.98 3.88, impos restrict number train- ing sampl caus kernel matrix size kcca. ex- plore robust techniqu term paramet set presenc lack regularization. overall, conduct comprehens set experi largest dataset date (morph frgc). experi aim demonstr superior accuraci propos ap- proach (a describ above), draw consider- ation dimension featur used. fact, lesson learned, combin multipl orthogon featur result lower mae, increas com- plexity, classifi cca kcca bring instability. imagin futur direct research. all, altern featur fusion strategies, featur pool sophist dimension reduct techniques, late-fus strategies, develop test confirm simpl combin featur suffic better performance. next, featur test isol combin features. pos- sibl futur direct includ addit frontal stage preprocessing, particularli import deal- ing real images, rare frontal. additionally, propos deep learn approach refin new form data augmentation, exploit multiscal ver- sion input image, carefulli design deeper network architectures. finally, evalu extend investig distribut error ag ranges, gender ethnicity; gener capabl test cross-databas valid schemes. 11 acknowledg work partial support spanish ministri scienc innov (micinn) torres-quevedo fund program (ptq-11-04401 ptq- 11-04400). thank review us comment suggestions. refer bay, h., tuytelaars, t., van gool, l., 2006. surf: speed robust features, in: visioneccv 2006. springer, pp. 404417. chang, k.y., chen, c.s., hung, y.p., 2011. ordin hyperplan ranker cost sensit ag estimation, in: cvpr, ieee. pp. 585592. choi, s.e., lee, y.j., lee, s.j., park, k.r., kim, j., 2011. ag estim hierarch classifi base global local facial features. pattern recognit 44, 12621281. dalal, n., triggs, b., 2005. histogram orient gradient human detec- tion, in: cvpr, ieee. pp. 886893. fernandez, c., huerta, i., prati, a., 2014. compar evalu regres- sion learn algorithm facial ag estimation, in: ffer conjunct icpr, press, ieee. gallagher, a.c., chen, t., 2009. understand imag group people, in: vision pattern recognition, 2009. cvpr 2009. ieee confer- enc on, ieee. pp. 256263. geng, x., yin, c., zhou, z.h., 2013. facial ag estim learn label distributions, in: tpami, ieee. pp. 24012412. geng, x., zhou, z.h., smith-miles, k., 2007. automat ag estim base facial ag patterns. tpami 29, 22342240. gunay, a., nabiyev, v.v., 2008. automat ag classif lbp, in: inform sciences, 2008. iscis08. 23rd intern symposium on, ieee. pp. 14. guo, g., mu, g., 2011. simultan dimension reduct human ag estim kernel partial squar regression, in: cvpr, ieee. pp. 657664. guo, g., mu, g., 2013. joint estim age, gender ethnicity: cca vs. pls, in: 10th int. conf. automat face gestur recognition, ieee. guo, g., mu, g., 2014. framework joint estim age, gender ethnic larg database. imag vision comput . guo, g., mu, g., fu, y., huang, t.s., 2009. human ag estim bio- inspir features, in: cvpr, ieee. pp. 112119. han, h., otto, c., jain, a.k., 2013. ag estim face images: human vs. machin performance, in: intern confer biometr (icb), ieee. huang, r., ye, m., xu, p., li, t., dou, y., 2014. learn pool high-level featur face representation. visual , 113. huerta, i., fernandez, c., prati, a., 2014. facial ag estim fusion textur local appear descriptor, in: soft biometr conjunct eccv, press, ieee. jia, y., shelhamer, e., donahue, j., karayev, s., long, j., girshick, r., guadar- rama, s., darrell, t., 2014. caffe: convolut architectur fast featur embedding. arxiv preprint arxiv:1408.5093 . lanitis, a., draganova, c., christodoulou, c., 2004. compar differ clas- sifier automat ag estimation. tsmc-b 34, 621628. lanitis, a., taylor, c.j., cootes, t.f., 2002. automat simul ag effect face images. tpami 24, 442455. liang, j., ye, q., chen, j., jiao, j., 2012. evalu local featur descriptor combin pedestrian representation, in: pattern recognit (icpr), 2012 21st intern confer on, ieee. pp. 24962499. minear, m., park, d.c., 2004. lifespan databas adult facial stimuli. be- havior research methods, instruments, & comput 36, 630633. montillo, a., ling, h., 2009. ag regress face random forests, in: icip, ieee. pp. 24652468. ojala, t., pietikainen, m., maenpaa, t., 2002. multiresolut gray-scal rotat invari textur classif local binari patterns. pattern analysi machin intelligence, ieee transact 24, 971987. oro, d., fernandez, c., saeta, j.r., martorell, x., hernando, j., 2011. real- time gpu-bas face detect hd video sequences, in: iccv work- shops, pp. 530537. phillips, p.j., flynn, p.j., scruggs, t., bowyer, k.w., chang, j., hoffman, k., marques, j., min, j., worek, w., 2005. overview face recognit grand challenge, in: cvpr, ieee. pp. 947954. ricanek, k., tesafaye, t., 2006. morph: longitudin imag databas normal adult age-progression, in: automat face gestur recognition, pp. 341345. doi:10.1109/fgr.2006.78. riesenhuber, m., poggio, t., 1999. hierarch model object recognit cortex. natur neurosci 2, 10191025. sun, y., wang, x., tang, x., 2013. deep convolut network cascad facial point detection, in: cvpr, ieee. pp. 34763483. taigman, y., yang, m., ranzato, m., wolf, l., 2014. deepface: close gap human-level perform face verification, in: vision pattern recognit (cvpr), 2014 ieee confer on, ieee. pp. 1701 1708. tan, x., triggs, b., 2010. enhanc local textur featur set face recog- nition difficult light conditions. imag processing, ieee transac- tion 19, 16351650. weng, r., lu, j., yang, g., tan, y.p., 2013. multi-featur ordin rank facial ag estimation, in: afgr, ieee. yang, m., zhu, s., lv, f., yu, k., 2011. correspond driven adapt human profil recognition, in: vision pattern recognit (cvpr), 2011 ieee confer on, ieee. pp. 505512. yang, z., ai, h., 2007. demograph classif local binari patterns, in: advanc biometrics. springer, pp. 464473.