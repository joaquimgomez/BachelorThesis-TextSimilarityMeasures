depth estim semant segment singl rgb imag hybrid convolut neural network articl depth estim semant segment singl rgb imag hybrid convolut neural network xiao lin 1,2*, dalila snchez-escobedo 2, josep r. casa 2, monts pards2, 1 2 3 4 5 6 7 8 9 10 11 12 13 1 visual interact commun technolog (vicomtech), donostia/san sebastin 20009, spain 2 imag process group, tsc department, technic univers catalonia (upc), barcelona, 08034, spain; (d.s.-e.); (j.r.c.); (m.p.) * correspondence: version april 14, 2019 preprint accept journal sensor abstract: semant segment depth estim import task vision, method develop tackl them. commonli task address independently, recent idea merg problem sole framework studi assumpt integr highli correl task benefit improv estim accuracy. paper, depth estim semant segment jointli address singl rgb input imag unifi convolut neural network. analyz differ architectur evalu featur relev share task featur kept separ achiev mutual improvement. likewise, approach evalu differ scenario design review result versu single-task multi-task methods. qualit quantit experi demonstr perform methodolog outperform state art single-task approaches, obtain competit result compar multi-task methods. keywords: depth estimation; semant segmentation; convolut neural networks; hybrid architecture14 1. introduction15 semant segment depth inform intrins related, piec of16 inform need consid integr manner succe challeng applications, such17 robot [1] autonom navig [2]. robotics, perform task interact environments18 requir identif object distanc camera. likewise, autonomous19 navig applic need 3d reconstruct scene semant inform to20 ensur agent devic inform avail carri navig safe21 independ manner. rgb-d sensor current applications,22 system provid rgb information. therefore, address depth estim semantic23 segment unifi framework special interest.24 hand, deep learn techniqu shown extraordinari success task [3] in25 recent years. context, feature-extract process specif task model parameter26 estim problem convolut neural network (cnns) base set training27 data. words, featur extractor creat learn prior knowledg we28 have. provid possibl combin differ task (differ sourc prior knowledge)29 train featur extractors, particular highli correl task depth estimation30 semant segmentation. specifically, idea integr depth estim semantic31 segment sole structur motiv fact segment inform and32 preprint accept sensor journal, page 1 20 www.mdpi.com/1424-8220/19/8/1795 version april 14, 2019 preprint accept sensor journal 2 20 depth map repres geometr inform scene. manner, featur extractor be33 better train enrich prior knowledge.34 paper, introduc hybrid convolut network integr depth estimation35 semant segment unifi framework. propos build model the36 featur extract suitabl tasks, lead improv accuraci estimated37 information. main advantag propos approach straightforward manner38 semant segment depth map estim singl image, provid feasibl solution39 problems.40 2. relat work41 depth estim semant segment wide studi problem image42 process commun recent tackl deep learn techniqu its43 success result term accuraci efficiency. section make review state art44 introducing, first, single-task approaches, and, afterwards, method focus solv multipl tasks.45 2.1. single-task approaches46 2.1.1. semant segmentation47 semant segment methodolog approach imag segment problem by48 perform pixel-level classifications. compar tradit imag segment approaches, such49 superpixel segment method [4,5], activ contour method [6,7] watersh segmentation50 method [8,9], introduc semant imag segment process emploi classifier51 train annot data. semant segment method gener limited52 gener predefin semant annotations, advantag semant segmentation53 obvious. introduc semant provid higher level knowledg help obtain more54 meaning segment comparison homogen regions.55 cnn-base techniqu appli semant segmentation; handcraft features56 usual emploi repres pixel train classifi [10]. emerg of57 cnn-base techniqu provid approach train neural network extract featur with58 higher discrimin power. known work appli cnn semantic59 segment fulli convolut network (fcn) [11]. popular cnn architectur dense60 predict fulli connect layers. allow segment map gener for61 imag size reduc number paramet architectur fully62 connect layer involved. subsequ state-of-the-art approach semantic63 segment adopt paradigm.64 apart fulli connect layers, main problem cnn segment are65 pool layers. pool layer increas field view abl aggreg context while66 discard information. however, semant segment requir exact alignment67 class map thus, need inform preserved. differ class of68 architectur evolv literatur tackl issue.69 encoder-decod architecture. encod gradual reduc spatial70 dimens pool layer decod gradual recov object detail spatial71 dimension. usual shortcut connect encod decod help decoder72 recov object detail better. u-net [12] popular architectur class. consist of73 contract path captur context encod symmetr expand path encoder74 layer decod layer enabl precis localization. seg-net [13] propos base on75 fcn. introduc shortcut connect encod decoder. furthermore,76 copi indic max-pool layer encod decod instead copying77 encod featur fcn, make easier segnet recov spatial inform and78 provid memori effici fcn. ghiasi et al. [14] present laplacian pyramid semantic79 version april 14, 2019 preprint accept sensor journal 3 20 segment refin incorporating, decod step, spatial inform contain in80 high-resolut featur map spatial inform destroi pooling. thus, better81 dens pixel-accur label obtained.82 architectur second class us known dilated/atr convolut [1517].83 pool layer help classif network increas recept field network.84 however, mentioned, suitabl semant segment task pool drop the85 spatial inform decreas resolution. dilated/atr convolut comput responses86 imag posit n time larger recept field resolut imag convolved87 filter holes, origin filter upsampl factor n, zero introduced88 filter values. effect filter size increases, necessari into89 account non-zero filter values, number filter paramet number of90 oper posit stai constant.91 2.1.2. depth estimation92 work tackl depth estim problem cnn presented93 [18]. novel network architectur main components. first, coarse-scale94 network estim low-resolut depth map singl image. then, depth estim along95 origin imag input fine-scal network. way, local network can96 incorpor finer-scal detail global prediction. additionally, appli scale-invariant97 error help measur depth relat instead scale.98 likewise, similar work base [18] present [19]. approach author included99 extra model present [18] estim gradient information. idea behind100 addit improv fine-tun ad gradient inform the101 global depth estim input image. additionally, normal loss function applied102 result better depth estimation.103 2.2. multi-task approaches104 approach address depth estim semant segment multi-task learning105 scheme receiv larg attent potenti improv perform multiple106 tasks. idea merg task architectur motiv fact differ correlated107 task commonli share basic attribut pars process. approach together108 mutual beneficial. practice, multi-task approach state art seek extract109 featur suitabl perform divers task time, lead improv estimated110 inform simplif system multipl modal required, autonomous111 navig [2], robot [1] augment realiti [20].112 [21], author provid common network differ tasks, including113 estim depth map, surfac normals, semant segmentation. task are114 address jointly, prove network specif task obtain fine-tuning115 network architectur train correl task. result obtain [21]116 outperform on present [18] prove strategi tackl multipl task with117 common network lead better performance.118 [22] unifi framework proposed, incorpor global local predict where119 consist depth semant segment learn joint train process.120 input image, cnn jointli predict global depth map semant labels.121 then, decompos imag local region train cnn predict depth122 map semant label region. global local predictions, re-formulate123 problem two-lay hierarch condit random field produc final depth and124 semant map.125 recent multi-task approach introduc [23]. methodolog propos work126 make initi estim depth semant label pixel level joint network. later,127 version april 14, 2019 preprint accept sensor journal 4 20 depth estim solv possibl confus similar semant categori to128 obtain final semant segmentation.129 multi-task approach teichmann et al. [24] present network architectur named130 multinet perform classification, semant segmentation, detect simultaneously. they131 incorpor task unifi encoder-decod network encod stage is132 share task specif decod task produc output real time. these133 work effort focus improv comput effici real-tim applic as134 autonom driving.135 similar approach pixel-level encod depth layer (pledl) [25], work extended136 fcn [11] output channel jointli train estim semant labeling, direct the137 instanc center depth pixel level.138 tabl 1 present brief comparison pro con differ type methods.139 tradit imag segment approach [49] usual perform low-level segmentation, which140 obtain segment gener assumptions, local homogeneity. hand,141 semant segment method [10,11,13,16,26] improv imag segment introduc semantic142 annotations, provid higher level mean (semant object level) low-level143 featur exploit tradit methods. approach multi-task learn schemes, as144 propos approach [21,25] exploit correl semant segment depth145 estim benefit tasks, gener imag segment depth estimation146 take input single-color image. unlik multi-task method state art [21,25], the147 propos approach focus separ common distinct tasks, which148 obtain promis result shown experiments.149 tabl 1. comparison differ type approaches. unsupervis object level segm. depth estim joint estim eigen [21] pledl [25] superpixel [4,5] - activ contour [6,7] - watersh [8,9] - semant segm. [10,11,13,16,26] - depth predict [19] - 2.3. proposal150 multi-task approach aim directli estim segment depth map input151 color imag unifi cnn work singl task sole hybrid convolut neural152 network. state-of-the-art work unifi task feature-extract block output153 input group decod design carri task.154 preliminari work [27], present hybrid network multi-task learn scheme155 benefit semant segment depth estimation, applic autonomous156 drive scenes. hybrid network emploi global depth estim network estim separately157 global layout scene input imag addition common featur extraction.158 paper, focu compar differ hybrid network unifi strategi and159 investig task help other. specifically, emploi unifying160 strategies, hybrid architectur propos previou work [27] from161 state-of-the-art work [21,23,24]. experiments, compar perform obtain from162 differ hybrid architectures, name hybridnet a1 a2 (see figur 1 2), appli different163 unifi strategi single-task architectures, order clarifi task help164 hybrid system. appli challeng indoor scene verifi the165 valid unifi strategy.166 version april 14, 2019 preprint accept sensor journal 5 20 refin network upsampl network color imag featur network semant segmetn network depth estim network depth map segment mask input/output semant segment network figur 1. architectur 1 figur 2. architectur 2 rest paper organ follows: section 3 introduc propos methodology;167 detail explan propos architectur present section 4, training168 details. section 5, present experi result approach differ dataset and169 compar approach state-of-the-art approaches. finally, conclus drawn section 6.170 3. hybrid convolut framework171 section, gener explan hybrid convolut neural network its172 applic depth estim semant segment presented. end, description173 single-task architectur [16,19] emploi approach presented. then, we174 propos hybrid architectur discuss approach problem to175 unifi task sole framework.176 depth estim architectur [19], denot depthnet paper, three177 components: global depth network, gradient network, refin network, shown figur 3.178 compon follow alexnet structure. depthnet estim depth map the179 scene global level singl input rgb imag global depth network. meanwhile,180 predict depth gradient map input rgb imag gradient network. finally,181 refin network us input imag depth gradient map local refin global182 depth map produc better detail depth map. explain [19], components183 depthnet train separately. train global depth network, downsampl depth184 map ground truth. global depth network, gradient network trained185 base magnitud depth gradient x y direct comput depth map. along186 global depth network gradient network, refin network train the187 downsampl depth map train data.188 main reason consid emploi depthnet depth estim component189 approach: (1) depthnet follow state-of-the-art framework depth estim is190 repres bunch methods. (2) depthnet modular architecture, allow us191 analyz compon better integr depthnet hybrid architecture.192 version april 14, 2019 preprint accept sensor journal 6 20 figur 3. depth estim network. semant segment architectur [16] shown figur 4, divid main parts:193 featur network atrou upsampl network. featur network, follow vggnet194 architectur propos [28]. charg extract robust featur input image, which195 benefit deep structur network. hand, atrou upsampl network is196 group atrou spatial pyramid pool layer [16] output class score map number197 channel equal number labels. atrou upsampl layer allow explicitli control198 resolut featur respons comput architecture, enlarg the199 field view filter incorpor larger context semant segment task. semantic200 segment architectur denot deeplab-atr spatial pyramid pool (deeplab-aspp) in201 paper. deeplab-aspp, part train together.202 figur 4. semant segment network. deeplab-aspp emploi semant segment compon approach its203 outstand perform task.204 unifi single-task architectur multi-tasks205 consid function compon depthnet deeplab-aspp, propose206 compar differ hybrid architectur joint depth estim semantic207 segment task.208 architectur 1: intuit wai unifi task sole architectur total share the209 feature-extract process tasks. follow idea repres architectures210 state art [21,23,24], common convolut network share extracting211 features. follow feature-extract block, custom layer task, decod the212 commonli extract featur appli differ tasks. share feature-extract process213 differ task common convolut network link tasks, parameters214 share network optim respect loss defin task training215 phase. advantag architectur obvious. layer share tasks,216 paramet involv train process, make easi trained. practice,217 exploit vgg structur [28] feature-extract network tasks. base the218 version april 14, 2019 preprint accept sensor journal 7 20 extract features, atrou upsampl network deeplab-aspp emploi semantic219 segment task, refin network depthnet leverag decod depth220 estim task. denot architectur 1 hybridnet a1 rest paper.221 architectur 2: motiv build architectur clarifi common and222 specif attribut tasks. thus, build hybrid network substitut gradient223 network depthnet common feature-extract network tasks, keep the224 global depth estim network depth task. advantag hybrid architecture225 two-fold. hand, strong power extract object inform color image226 learn semant segment task benefit depth layer predict depth227 map, strong power extract rich depth boundari color imag learn the228 depth estim task share semant segment task improv segment accuracy229 object boundaries. hand, global layout scene relev depth230 estim semant segment estim independ global network depth231 estim task. avoid interf common featur extract tasks. practice,232 global network refin network depthnet changes, replac the233 structur gradient network vgg structure, order structur consistent234 featur network deeplab-aspp. denot architectur 2 hybridnet a2 rest235 paper.236 4. architectur details237 propos architectur assembl basic compon single-task238 architectures, explain propos architectur describ single-task239 architectur section.240 4.1. depth estim network241 describ section 3, depth estim network modular calcul refined242 depth map singl input imag stage convolut network. shown in243 figur 3, global depth network form 5 convolut layer fulli connect layers,244 correspond architectur alexnet [29]. follow convolut layer, rectified245 learner unit (relu) introduc activ function provid non-linear system.246 local normal perform convolut layer local respons normalization247 layer (lrn), help gener system. max-pool layer place first248 convolut layer provid basic translat invari intern representation249 reduc number paramet system. network max-pool perform over250 3 3 window stride 2. global depth network aim describ global layout251 scene, introduc fulli connect layer follow convolut layer, capture252 inform contain intermedi represent recept field. practice,253 1024 neuron includ fulli connect layer 1681 neuron includ the254 second fulli connect layer. reshap 1681 neuron 41 41 matrix treat the255 output global depth network. manner, predict global depth map 18 resolution256 input imag size 321 321.257 gradient network aim estim depth gradient input color image. practice,258 emploi architectur global depth estim fulli connect layers.259 finally, refin network take concaten output global depth network,260 gradient network, color imag input comput refin depth map. refining261 network improv rough estim global depth network, gradient estim by262 gradient network input color image. practice, convolut layer process the263 input color image, follow relu layer, lrn layer, max-pool layer, produces264 featur map extract color image. featur map concaten output of265 global depth network gradient network, fed remain convolutional266 version april 14, 2019 preprint accept sensor journal 8 20 layers. follow relu layer. output 5th convolut layer the267 refin network treat output (a refin depth map size 81 81).268 4.2. semant segment network269 figur 4 present overview semant segment network. figur show detailed270 manner input imag process go group convolut layer for271 featur extract (featur network) upsampl procedur final provides272 segment map (upsampl network). divid architectur part help to273 understand single-task network integr hybrid model.274 featur network contain 5 group convolut layers, form deep architecture.275 convolut layer kernel size 3 3. simplicity, plot276 convolut kernel convolut layer featur network. follow each277 convolut layer, relu layer provid activ function. pool layer place after278 group convolut layer reduc comput cost downsampl internal279 representation, provid basic translat invari intern representation.280 hand, atrou upsampl network contain 4 parallel group three281 convolut layers, perform upsampl oper differ scales. branch upsampl the282 output featur network convolut layer atrou convolution. atrous283 convolut emploi dilat convolut template, convolut templat enlarg by284 fill zero respect defin rate. manner, explicitli control resolution285 upsampl oper enlarg field view filter incorpor larger context in286 semant segment task introduc parameters. practice, emploi atrous287 convolut rate 6, 12, 18, 24 respect branch. 2 convolut layer in288 branch perform 1 1 convolutions, increas non-linear decis function289 affect recept field convolut layers. take output 4 branches290 upsampl layer input, soft-max layer produc final semant segment mask.291 4.3. train details292 explain section 3, propos architectur (hybridnet a1 a2) base on293 deeplab-aspp [16] depthnet [19]. hybridnet a1 a2 construct merging294 single-task architectures, train process hybrid architectur perform as295 single-task architectures.296 hybridnet a1, initi featur network atrou upsampl network the297 model provid deeplab [16] pre-train classif purpos imagenet. the298 part hybridnet a1 initi random number gener (rng). rng is299 set gaussian distribut zero mean 0.1 variance.300 hybridnet a2, initi featur network upsampl network training301 process model provid deeplab [16]. additionally, initi global depth302 network model provid [19]. part hybridnet a2 randomli initialized303 rng.304 initi hybrid architecture, compon trained305 simultaneously. hybrid architectur train 100 k iter learn rate 2.5 106,306 polynomi learn rate decai policy. momentum set 0.9 weight decai 0.005. input307 imag randomli crop size 320 320. set batch size 7, maximum308 allow memory.309 loss function architectur same. semant segment task, ls310 sum cross-entropi term spatial posit output class score map, being311 target ground truth labels. posit label output class score map equally312 weight overal loss function unlabel pixel ignored. loss313 function depth estim task euclidean loss layer ldab ldmvn .314 version april 14, 2019 preprint accept sensor journal 9 20 ldab comput euclidean distanc absolut valu depth map ground truth315 estim depth map, ldmvn comput euclidean distanc estimation316 ground truth perform mean varianc normal them. ldab stands317 pixel-level metric evalu local estim depth valu match the318 ground truth regardless geometri scene. hand, ldmvn introduc global319 regular depth estim align depth valu estim ground320 truth zero mean unit variance.321 hybrid loss function lh defin linear combin them:322 lh = ls + (ldab + ldmvn) (1) term balanc loss function depth estim semantic323 segment tasks. experiments, set 1000, given analysi valu ldab + ldmvn324 ls respectively, train separ single-task architectures.325 5. experiments326 quantifi perform propos architectur semant segment and327 depth estim differ scene caff implementation. evalu proposed328 architectur road scene current practic autonom driving329 relat problems. secondly, propos architectur evalu indoor scene of330 immedi possibl augment realiti (ar) applications.331 5.1. road scene332 section, present evalu propos architectur road scenes. several333 road scene dataset avail semant pars [3032]. evalu proposed334 architectur semant segment depth estim perspective, emploi cityscapes335 dataset [32] experiment, provid ground truth semant label the336 depth inform frame. cityscap contain 5000 rgb imag manual select from337 27 differ citi dens pixel-level annot ensur high divers foreground objects,338 background, overal scene layout. 5000 rgb images, cityscap dataset339 provid depth map obtain stereo vision system. 5000 imag dataset split340 2975 train rgb imag size 1024 2048 correspond 2d ground truth341 object label 19 outdoor scene class depth information, 500 rgb imag test validation342 correspond annot and, benchmark purposes, 1525 test rgb images.343 practice, train process approach perform 2975 imag of344 cityscap train set provid depth map object label 19 class rgb345 image. evalu perform propos architectures, group 500 imag of346 valid set 1525 imag test set cityscap dataset singl evaluation347 set 2025 images. train phase, imag train set shuffl randomli cropped348 fit input imag size hybrid architecture. train data augment flipping349 mirror origin images, enlarg train set. test phase, crop test350 imag origin size 1024 2048 group imag size 321 321 which351 cover test imag have minimum overlap area. imag test one352 group obtain final predict segment mask depth map. please353 note score map obtain image, show degre pixel belong label.354 overlap area, compar normal score map label higher score355 predict label segment mask. likewise, overlap area, predict depth356 valu depth map comput mean values.357 aim determin featur obtain share proposed358 architectur solv task simultan provid better result on would359 version april 14, 2019 preprint accept sensor journal 10 20 obtain ident network train separately. why, addit result the360 propos architectures, present result obtain model solv tasks361 separ comparison. model train semant segment depth estimation362 independ denot deeplab-aspp [16] depthnet [19], respectively. train these363 model code provid author train data cityscap dataset364 train configur propos architectures. apart that, compare365 differ wai unifi single-task architectur propos section 3, justifi the366 unifi strategi better. besides, comparison propos architectur hybrid367 method state art [25] cityscap dataset. hybrid approach proposed368 [25] similar hybridnet a1, encod network fcn [11] emploi the369 featur network share differ task decod network fcn emploi for370 task decod commonli extract features. task [25] tackl semantic371 segmentation, depth layering, boundari detection, similar target. however, the372 depth layer task, ref. [25] focus estim depth label object, instead estimating373 real depth valu scene pixel level. reason compar the374 perform approach [25] semant segmentation. present result our375 experi follow subsect specifi evalu semant segment and376 depth estimation, respectively.377 5.1.1. semant segmentation378 figur 5 provid exampl evalu set visual comparison the379 result obtain hybrid model ground truth obtain deeplab-aspp.380 purpos figur depict differ single-task multi-task approach.381 figur 5 input imag displai column, second column results382 obtain deeplab-aspp hybrid model, respectively. finally, fourth column the383 ground truth present reference. figur show segment perform the384 propos hybridnet a2 retain greater geometr characterist objects385 contain scene. instance, 3rd row shape pedestrian car be386 better distinguish estim obtain hybrid a2 obtain deeplab-aspp.387 input imag hybridnet a2 ground truthdeeplab-aspp figur 5. semant segment qualit results. comparison semant segment estim ground truth presented. left right, input imag depict column. column 2 segment map estim deeplab-aspp semant segment network [28] presented, column 3 estim segment map hybrid method present final ground truth depict column 4. version april 14, 2019 preprint accept sensor journal 11 20 addit qualit results, emploi commonli metrics, measure388 quantit segment performance: global accuraci (g), class averag accuracy389 (c) mean intersect union (miou). global accuraci count percentag pixels390 correctli label respect ground truth labeling. class averag accuraci is391 mean pixel accuraci class. mean intersect union measur average392 jaccard score classes. tabl 2 present quantit result confirm proposed393 hybridnet outperform result obtain deeplab-aspp. note global accuracy394 class averag accuraci evalu pledl provid unavail the395 sourc code, evalu miou report [25].396 improv obtain method deeplab-aspp confirm hypothesi that397 share feature-extract network task lead improv term segmentation398 accuracy. strategi unifi single-task architectur affect segment performance399 hybrid methods. hybridnet a2 common specif attribut differ tasks400 better clarifi outperform hybridnet a1 feature-extract process total shared401 tasks. improv hybridnet a1 obtain deeplab-aspp limited402 (hybridnet a1 58.1% miou deeplab-aspp 58.02% miou); however, hybrid a2 improv the403 miou 8%. compar architectur state-of-the-art hybrid method [25]404 tabl 2. hybridnet a2 better segment perform metrics, work405 [25]. addit evaluation, comparison approach adopted406 single-task method [11,13,16,33] present tabl 2.407 tabl 2. evalu hybridnet multi-task single-task approach (best result bold). g c miou hybridnet a2 93.26 79.47 66.61 hybridnet a1 89.31 77.22 58.1 pledl [25] - - 64.3 deeplab-aspp [16] 90.99 74.88 58.02 fcn [11] - - 65.3 segnet [13] - - 57.0 googlenetfcn [26] - - 63.0 5.1.2. depth estimation408 depth estim evaluation, figur 6 present visual comparison result obtain by409 hybrid a2 obtain single-task approach present [19] ground410 truth. figur displays, row-wis exampl depict figur 5. figur 6 depicts411 input imag column, depth map obtain depthnet second column,412 fourth column depth map obtain hybridnet a2 ground truth,413 respectively. note result obtain hybrid a2 consist ground truth414 obtain depthnet term depth layering.415 addition qualit analysis, evalu perform methodolog depth416 estim emploi 6 commonli metrics: percentag pixel (pp), mean varianc normalized417 percentag pixel (pp-mvn), absolut rel differ (ard), squar rel difference418 (srd), linear root mean squar error (rmse-linear), log root mean squar error (rmse-log)419 scale-invari error (sie).420 tabl 3 show definit metric emploi evalu process. d d421 repres estim depth ground truth, respectively. n stand number pixel with422 valid depth valu ground truth depth map.423 version april 14, 2019 preprint accept sensor journal 12 20 tabl 3. definit evalu metrics: depth estimation: percentag pixel (pp), pp-mvn absolut rel differ (ard), squar rel differ (srd), rmse-linear, rmse-log scale-invari error (sie). metric definit pp max ( di di , di di ) = < threshold pp-mvn max ( mvn(di) mvn(di ) , mvn(di ) mvn(di) ) = < threshold ard 1n di di /di srd 1n di di 2 /di rmse-linear 1 n di di 2 rmse-log 1 n log (di) log (di )2 sie 1n ( log (di) log ( di ) + 1n j ( log ( dj ) log ( dj )))2 input imag hybridnet a2 ground truthdepthnet figur 6. depth estim qualit results. visual comparison estim depth map ground truth presented. column input imag presented, column 2 3 depict estim depth map obtain depthnet [19] hybrid model a2, respectively. finally, ground truth present column 4. quantit experiment, compar propos hybrid architectur depthnet.424 tabl 4 show quantit result propos hybrid architectur depthnet the425 differ evalu metric introduc above. hybridnet a2 outperform 6 9 metrics, which426 prove train feature-extract network simultan task semant segmentation427 depth estim improv depth estim results. better perform hybridnet428 a2 comparison depthnet illustr share featur obtain semantic429 segment task hybridnet a2 richer inform relev depth430 estim task inform extract depth gradient depthnet. comparison431 hybrid a2 hybrid a1 show necess clarifi common specif attributes432 differ tasks. share common attribut task feature-extract process leads433 better perform in-depth estimation. verifi standard deviat performance434 method test sampl ensur statist signific results. since435 similar result observed, present tabl 4 conciseness.436 version april 14, 2019 preprint accept sensor journal 13 20 tabl 4. depth estimation. quantit evaluation: pp, pp-mvn, ard, srd, rmse-linear, rmse-log, sie (best result bold). hybridnet a2 hybridnet a1 depthnet [19] < 1.25 (mvn) 0.7483 0.6834 0.7248 higher better < 1.25 0.5968 0.5037 0.6048 < 1.252 0.8221 0.8172 0.8187 < 1.253 0.9292 0.9194 0.9152 ard 0.24 0.2879 0.23 lower better srd 4.27 4.35 4.43 rmse-linear 12.09 12.67 12.35 rmse-log 0.4343 0.3407 0.4340 sie 0.19 0.2 0.25 5.2. indoor scene437 road scene imag rel limit variat term involv semant their438 spatial arrangements. usual captur camera fix move vehicl view439 direct camera parallel ground. limit variabl road scene images440 make easier convolut network learn segment robustly. comparison,441 imag indoor scene complex free view point, larger number semantics442 scene, wide vari size object spatial arrangements. hand,443 indoor scene smaller depth rang road scenes, usual complex444 spatial layout, provid challeng depth estimation.445 section, evalu propos architectur indoor scene data semantic446 segment depth estimation. emploi rgb-d scene understand benchmark dataset [34]447 (sun-rgbd) experiments. sun-rgbd contain 10k rgb-d imag indoor scenes448 captur 4 type depth sensors, includ rgb-d imag nyu depth v2 [35], berkeley449 b3do [36], sun3d [37]. provid 2d ground truth object label 37 indoor scene classes, such450 wall, floor, ceiling, table, chair etc. depth map differ resolutions. task segment451 object 37 class imag estim depth. practice, split the452 dataset 5285 train 5050 test images, follow experi configur introduced453 [13].454 similarli experi cityscap dataset, perform train data augment by455 random cropping, flipping, mirror origin train images. however, test phase,456 instead crop test imag cityscap dataset, downsampl test image457 fit input size hybrid architecture. differ size test image458 input size larg sunr-gbd dataset, directli downsampl test imag fit input459 size strongli improv effici test phase, lose import information460 test data.461 5.2.1. semant segmentation462 sun-rgbd challeng indoor scene dataset semant segmentation, object463 class come shapes, sizes, differ poses. frequent partial occlusions464 objects, typic indoor scenes, fact object class presented465 test images. figur 7 provid visual comparison estim segment mask466 ground truth. figur presents, row-wise, 7 out-of-train exampl row467 show input images, 2nd 3rd row estim segment mask hybridnet468 a2 deeplab-aspp respectively, row show ground truth. hybridnet a2 exhibits469 stronger perform distinguish differ object indoor scene compar deeplab-aspp.470 version april 14, 2019 preprint accept sensor journal 14 20 color imag s . m k ground truth hybridnet a2 deeplab- aspp figur 7. semant segment qualit results. comparison semant segment estim ground truth presented. input imag depict row. 2nd 3rd row, estim segment mask obtain hybridnet a2 ground truth presented, respectively. additionally, qualit results, follow metric introduc section 5.1.1: the471 global accuraci (g), class averag accuraci (c) mean intersect union (miou) evaluate472 segment perform quantitatively. benchmark propos architectur against473 adopt architectur semant segmentation, fcn [11], segnet [13],474 deeplab [16] deconvnet [38]. fcn, paramet deconvolut layer are475 learn train process instead fix paramet perform bilinear upsampling.476 deeplab, architectur employed, deeplab-aspp, deeplab-largefov,477 deeplab-largefov-densecrf. us vggnet architectur featur map478 extraction, similar propos architectures. deeplab-largefov perform single479 scale upsampl featur map, deeplab-aspp perform multi-scal upsampling.480 deeplab-largefov-densecrf introduc dens condit random field post-processing481 step deeplab-largefov. tabl 5 show quantit result propos architectures482 (hybridnet a1 a2) compar methods. hybridnet a2 achiev best result in483 c miou 7 method obtain (71.63%) g close best (73.87%)484 obtain deeplab-aspp. higher global accuraci lower per-class accuraci obtain in485 deeplab-aspp comparison hybridnet a2 illustr deeplab-aspp prefer better cover486 larg object scene floor wall, provid good result global evaluation.487 however, affect perform smaller objects, result lower per-class accuracy,488 miou. improv deeplab-aspp verifi idea multi-task489 learning, estim depth addit semant segment help segment task490 (6.1% 5.1% improv c miou respectively). perform hybridnet a1 is491 wors single-task method deeplab-aspp, indic idea benefiting492 unifi singl task hybrid architectur hardli achiev simpli sharing493 feature-extract process complex indoor scenes. best segment performance494 obtain hybridnet a2 compar hybridnet a1 show import select suitable495 unifi strategi multi-task learn problem verifi effici strategi employed496 hybridnet a2.497 5.2.2. depth estimation498 depth estim evalu figur 8 depict qualit analysi results. figure499 presents, column-wise, 7 out-of-train exampl present figur 7, row500 show input images, 2nd 3rd row estim depth map hybridnet a2 and501 deeplab-aspp respectively, row show ground truth. depth map estim by502 hybridnet a2 consist ground truth obtain depthnet term of503 depth layering.504 version april 14, 2019 preprint accept sensor journal 15 20 tabl 5. semant segmentation. quantit evalu (best result bold). g c miou hybridnet a2 71.63 46.20 34.30 hybridnet a1 69.34 38.64 28.68 deeplab-aspp [16] 73.87 40.09 29.22 segnet [13] 72.63 44.76 31.84 deeplab-largefov [16] 71.90 42.21 32.08 deeplab-largefov-densecrf [16] 66.96 33.06 24.13 fcn(learn deconv) [11] 68.18 38.41 27.39 deconvnet [38] 66.13 32.28 22.57 color imag d ep th m ap ground truth hybridnet a2 depthnet figur 8. depth estim qualit results. comparison depth estim ground truth presented. input imag depict row. 2nd, 3rd 4th row present estim depth map method, depthnet ground truth, respectively. additionally, qualit analysis, evalu perform follow metrics505 introduc section 5.1.2: pp, mean varianc normal pixel percentag (pp-mvn), ard,506 srd, linear root mean squar error (rmse-linear), log root mean squar error (rmse-log) and507 sie. tabl 6 show quantit result propos architectur (hybridnet a1 a2) and508 depthnet differ metrics. hybridnet a2 outperform metric prove that509 perform semant segment addit depth estim help depth estim task.510 better perform hybridnet a2 comparison a1 confirm effici unifying511 strategi propos hybridnet a2 complex indoor scenes.512 tabl 6. depth estimation. quantit evaluation: pp, pp-mvn, ard, srd, rmse-linear, rmse-log, sie (best result bold). hybridnet a2 hybridnet a1 depthnet < 1.25 (mvn) 89.63 62.81 83.59 higher better < 1.25 61.33 38.63 57.73 < 1.252 89.17 69.38 87.42 < 1.253 97.43 86.28 97.08 ard 0.202 0.301 0.218 lower better srd 0.186 3.02 0.204 rmse-linear 0.682 8.35 0.715 rmse-log 0.25 0.432 0.27 sie 0.122 0.316 0.126 5.2.3. comparison hybrid architectures513 compar hybridnet a2 hybrid architectur state art, method514 propos [21] chosen. method address differ task includ semantic515 segmentation, depth estimation, surfac normal estimation. architectur design as516 stack vgg structur [28] repres differ scale featur extract (shown in517 version april 14, 2019 preprint accept sensor journal 16 20 figur 9). vgg structur take output previou input color518 imag input. tasks, depth estimation, surfac normal estim two519 task tackl jointly, mean task share network scale 1 networks520 scale 2-3 separ assembl task. semant segment task, architecture521 shown figur 9 again. however, differ tasks, architectur of522 semant segment allow addit input channel depth normal channels.523 architectur fine-tun model previous train depth normal estimation524 gener semant segment masks.525 figur 9. hybrid architectur propos eigen [21]. sourc code method available, perform evalu reported526 public dataset (nyu depth v2 dataset [35]). comparison approach, we527 train evalu approach nyu depth v2 dataset. data set includ rgb images528 correspond 2d ground truth object label 40 indoor scene class depth map.529 nyu depth v2 dataset divid 795 imag train 654 testing. small530 number imag avail training, augment train set random cropping, flipping,531 mirroring.532 tabl 7 8 quantit result hybridnet a2 task provides533 comparison approach propos [21], denot eigen. semant segment result in534 tabl 7 hybridnet a2 outperform eigen class averag accuraci (c) mean intersection535 union (miou) keep similar result eigen global accuraci (g). illustrates536 address rgb-d-base semant segment task multi-task learn scheme better537 us depth inform directli feed depth inform network extra538 input channel. hand, depth estim result tabl 8 hybridnet a2 has539 better perform rel measur sie, absolut measur eigen outperforms540 version april 14, 2019 preprint accept sensor journal 17 20 hybridnet a2. better perform hybridnet a2 rel measur show hybridnet541 a2 better depth layer capabl eigen, relev real applications. for542 absolut measures, believ wors perform hybridnet a2 weaker543 abil describ global layout scene. hybridnet a2 emploi simpler architecture544 (alexnet structure) global depth network compar network scale 1 (vgg structure)545 eigen.546 tabl 7. quantit segment result nyu v2: g, c miou (best result bold). g c miou hybridnet a2 64.7 48.4 36.5 eigen [21] 65.6 45.1 34.1 tabl 8. depth estim result nyu v2 quantit evaluation: pp, pp-mvn, ard, srd, rmse-linear, rmse-log, sie (best result bold). hybridnet a2 eigen [21] < 1.25 (mvn) 0.7293 - sie 0.1571 0.171 < 1.25 0.5006 0.769 < 1.252 0.8013 0.95 < 1.253 0.9422 0.98 ard 0.2787 0.158 srd 0.3236 0.121 rmse-linear 0.9423 0.64 rmse-log 0.3219 0.214 6. conclus futur work547 paper, introduc methodolog depth estim semant segmentation548 singl imag unifi convolut network. main goal propos method549 seek better hybrid architectur cnn modular feature-extract process550 separ distinct featur extract specif task common featur extract for551 tasks. manner, task benefit extract common featur being552 affect featur relev task, lead better performance. also553 prove solv correl task semant segment depth estim can554 improv perform method tackl task separately.555 qualit quantit result shown section 5 demonstr unifi strategy556 emploi hybridnet a2 produc better hybrid architectur semant segment and557 depth estim compar hybrid a1. hybrid a2 outperform result obtain single-task558 approaches, prove share underli featur extract help improv final559 perform tasks. likewise, prove methodolog obtain compar results560 benchmark hybrid approaches.561 hand, interest problem pend futur study:562 design better loss function multi-task learn scheme. loss function emploi the563 state-of-the-art approach normal balanc linear combin loss singl tasks.564 however, loss total differ physic mean task (e.g.,565 cross entropi euclidean loss), make hard combin them. find higher level566 evalu metric help defin loss function multi-task learn system. instance,567 evalu predict 3d orient bound box object requir both568 semant segment depth estim result, natur combin loss function569 tasks.570 version april 14, 2019 preprint accept sensor journal 18 20 appli higher level task requir 3d analysis. propos approach produc an571 object level segment depth map input image, appli estim result to572 applic requir 3d analysi (such traffic violat detection) great interest.573 author contributions: conceptualization, x.l., j.r.c. m.p.; formal analysis, x.l.; investigation, x.l.574 d.s.-e.; methodology, x.l. supervision, j.r.c. m.p.; validation, d.s.-e.; writingorigin draft, x.l.;575 writingreview & editing, x.l., d.s.-e., j.r.c. m.p.576 funding: work develop framework project malegra tec2016-75976-r, financ by577 spanish ministerio economia y competitividad european region develop fund (erdf).578 conflict interest: author declar conflict interest.579 references580 1. ball, d.; ross, p.; english, a.; milani, p.; richards, d.; bate, a.; upcroft, b.; wyeth, g.; corke, p. farm workers581 future: vision-bas robot broad-acr agriculture. ieee robot. autom. mag. 2017, 24, 97107.582 2. shah, u.; khawad, r.; krishna, k.m. deepfly: complet autonom navig mav with583 monocular camera. proceed tenth indian confer vision, graphic image584 processing, guwahati, india, 1822 decemb 2016; acm: new york, ny, usa, 2016; p. 59.585 3. leo, m.; furnari, a.; medioni, g.g.; trivedi, m.; farinella, g.m. deep learn assist computer586 vision. proceed european confer vision, munich, germany, 814 september587 2018; pp. 314.588 4. yang, j.; gan, z.; li, k.; hou, c. graph-bas segment rgb-d data 3-d geometri enhanced589 superpixels. ieee trans. cybern. 2015, 45, 927940.590 5. stutz, d.; hermans, a.; leibe, b. superpixels: evalu state-of-the-art. comput. vis. image591 underst. 2018, 166, 127.592 6. ciecholewski, m. edge-bas activ contour model inflation/defl forc damping593 coefficient. expert syst. appl. 2016, 44, 2236.594 7. ding, k.; xiao, l.; weng, g. activ contour driven local pre-fit energi fast imag segmentation.595 pattern recognit. lett. 2018, 104, 2936.596 8. cousty, j.; bertrand, g.; najman, l.; couprie, m. watersh cuts: thinnings, shortest path forests, and597 topolog watersheds. ieee trans. pattern anal. mach. intell. 2010, 32, 925939.598 9. gaetano, r.; masi, g.; poggi, g.; verdoliva, l.; scarpa, g. marker-control watershed-bas segmentation599 multiresolut remot sens images. ieee trans. geosci. remot sens. 2015, 53, 29873004.600 10. shotton, j.; johnson, m.; cipolla, r. semant texton forest imag categor segmentation.601 proceed ieee confer vision pattern recognition, anchorage, ak, usa,602 2328 june 2008; pp. 18.603 11. long, j.; shelhamer, e.; darrell, t. fulli convolut network semant segmentation. proceedings604 ieee confer vision pattern recognition, boston, ma, usa, 712 june 2015;605 pp. 34313440.606 12. ronneberger, o.; fischer, p.; brox, t. u-net: convolut network biomed imag segmentation.607 proceed intern confer medic imag comput computer-assisted608 intervention, munich, germany, 59 octob 2015; pp. 234241.609 13. badrinarayanan, v.; kendall, a.; cipolla, r. segnet: deep convolut encoder-decod architectur for610 imag segmentation. arxiv 2015, arxiv:1511.00561.611 14. ghiasi, g.; fowlkes, c.c. laplacian pyramid reconstruct refin semant segmentation.612 proceed european confer vision, amsterdam, netherlands, 816 october613 2016; pp. 519534.614 15. yu, f.; koltun, v. multi-scal context aggreg dilat convolutions. arxiv 2015, arxiv:1511.07122.615 16. chen, l.c.; papandreou, g.; kokkinos, i.; murphy, k.; yuille, a.l. deeplab: semant imag segmentation616 deep convolut nets, atrou convolution, fulli connect crfs. arxiv 2016, arxiv:1606.00915.617 17. chen, l.c.; papandreou, g.; schroff, f.; adam, h. rethink atrou convolut semant image618 segmentation. arxiv 2017, arxiv:1706.05587.619 version april 14, 2019 preprint accept sensor journal 19 20 18. eigen, d.; puhrsch, c.; fergus, r. depth map predict singl imag multi-scal deep620 network. proceed advanc neural inform process systems, lake tahoe, nv, usa,621 38 decemb 2014; pp. 23662374.622 19. ivanecky, b.j. depth estim convolut neural networks. master thesis, brno univers of623 technology, brno, czechia, 2016.624 20. abdi, l.; meddeb, a. driver inform system: combin augment realiti deep learning.625 proceed symposium appli computing, marrakech, morocco, 46 april 2017; acm: new626 york, ny, usa, pp. 228230.627 21. eigen, d.; fergus, r. predict depth, surfac normal semant label common multi-scale628 convolut architecture. proceed ieee intern confer vision,629 santiago, chile, 1316 decemb 2015; pp. 26502658.630 22. wang, p.; shen, x.; lin, z.; cohen, s.; price, b.; yuille, a.l. unifi depth semant prediction631 singl image. proceed ieee confer vision pattern recognition,632 bostion, ma, usa, 810 june 2015; pp. 28002809.633 23. mousavian, a.; pirsiavash, h.; koeck, j. joint semant segment depth estim deep634 convolut networks. proceed fourth intern confer 3d vision (3dv),635 stanford, ca, usa, 2528 octob 2016; pp. 611619.636 24. teichmann, m.; weber, m.; zoellner, m.; cipolla, r.; urtasun, r. multinet: real-tim joint semantic637 reason autonom driving. arxiv 2016, arxiv:1612.07695.638 25. uhrig, j.; cordts, m.; franke, u.; brox, t. pixel-level encod depth layer instance-level639 semant labeling. proceed german confer pattern recognition, hannover, germany,640 1215 septemb 2016; pp. 1425.641 26. szegedy, c.; liu, w.; jia, y.; sermanet, p.; reed, s.; anguelov, d.; erhan, d.; vanhoucke, v.; rabinovich, a.642 go deeper convolutions. proceed ieee confer vision pattern643 recognition, boston, ma, usa, 810 june 2015, pp. 19.644 27. sanchez-escobedo, d.; lin, x.; casas, j.r.; pardas, m. hybridnet depth estim semantic645 segmentation. proceed ieee intern confer acoustics, speech signal646 process (icassp), calgary, ab, canada, 1520 april 2018; pp. 15631567.647 28. simonyan, k.; zisserman, a. deep convolut network large-scal imag recognition. arxiv 2014,648 arxiv:1409.1556.649 29. krizhevsky, a.; sutskever, i.; hinton, g.e. imagenet classif deep convolut neural networks.650 proceed advanc neural inform process systems, lake tahoe, ak, usa, 38651 decemb 2012; pp. 10971105.652 30. brostow, g.j.; fauqueur, j.; cipolla, r. semant object class video: high-definit ground truth653 database. pattern recognit. lett. 2009, 30, 8897.654 31. geiger, a.; lenz, p.; urtasun, r. readi autonom driving? kitti vision benchmark suite.655 proceed ieee confer vision pattern recognition, rhode, island, 1820656 june 2012; pp. 33543361.657 32. cordts, m.; omran, m.; ramos, s.; rehfeld, t.; enzweiler, m.; benenson, r.; franke, u.; roth, s.; schiele, b.658 cityscap dataset semant urban scene understanding. proceed ieee confer on659 vision pattern recognition, la vegas, nv, usa, 26 june1 juli 2016; pp. 32133223.660 33. papandreou, g.; chen, l.c.; murphy, k.; yuille, a.l. weakly-and semi-supervis learn dcnn for661 semant imag segmentation. arxiv 2015, arxiv:1502.02734.662 34. song, s.; lichtenberg, s.p.; xiao, j. sun rgb-d: rgb-d scene understand benchmark suite. proceedings663 ieee confer vision pattern recognition, boston, ma, usa, 810 june 2015;664 pp. 567576.665 35. silberman, n.; hoiem, d.; kohli, p.; fergus, r. indoor segment support infer rgbd666 images. proceed european confer vision, firenze, italy, 713 octob 2012;667 pp. 746760.668 36. janoch, a.; karayev, s.; jia, y.; barron, j.t.; fritz, m.; saenko, k.; darrell, t. category-level 3d object dataset:669 put kinect work. consum depth camera vision; springer: london, uk, 2013;670 pp. 141165.671 version april 14, 2019 preprint accept sensor journal 20 20 37. xiao, j.; owens, a.; torralba, a. sun3d: databas big space reconstruct sfm object labels.672 proceed ieee intern confer vision, portland, or, usa, 2527 june673 2013; pp. 16251632.674 38. noh, h.; hong, s.; han, b. learn deconvolut network semant segmentation. proceed of675 ieee intern confer vision, santiago, chile, 713 decemb 2015; pp. 15201528.676 c 2019 authors. submit journal specifi possibl open access677 public term condit creativ common attribut (cc by) license678 ( introduct relat work single-task approach semant segment depth estim multi-task approach propos hybrid convolut framework architectur detail depth estim network semant segment network train detail experi road scene semant segment depth estim indoor scene semant segment depth estim comparison hybrid architectur conclus futur work refer