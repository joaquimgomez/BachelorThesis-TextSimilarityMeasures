automat speech recognit deep neural network impair speech cristina espana-bonet1,2 jose a. r. fonollosa1 1 talp research center, universitat politecnica catalunya, barcelona, spain 2 universitat de saarlandes, saarbrucken, germani abstract. automat speech recognit reach human perform control scenarios. however, recognit im- pair speech difficult task main reasons: data (i) scarc (ii) heterogeneous. work train differ architectur databas dysarthr speech. comparison architectur show that, small database, hybrid dnn-hmm model out- perform classic gmm-hmm accord word error rate measures. dnn abl improv recognit word error rate 13% sub- ject dysarthria respect best classic architecture. improv higher given deep neural network cnns, tdnn lstms. experi kaldi toolkit speech recognit adapt recip deal dysarthr speech work torgo database. recip publicli available. keywords: speech recognition, speaker adaptation, deep learning, neu- ral networks, dysarthria, kaldi 1 introduct automat speech recognit (asr) consist automat transcrib voic text. easi task: deal noise, differ speaker spontan speech phenomena others. control scenario minimis effect phenomena, asr approach exce accuraci human benchmark [2, 19]. despit good perform recent propos end-to-end neural speech recogn [2], hidden markov model (hmm) backbon competit speech recognit system [19]. hmm model speech signal sequenc state associ probabl distribut observ vector. probabl repres differ approach gaussian mixtur model (gmm) artifici neural network (ann). 0 a. abad et al. (eds.): iberspeech 2016, lnai 10077, pp. 111, 2016. doi: 10.1007/978-3-319-49169-1 10 work, refer system classic architectur on neural network architectures. infanc ann abl deal long time-sequ speech signal themselves, hybrid system ann-hmm show state-of-the-art begin 90 [24]. ann solv problem respect gmm [3]: (i) assumpt shape statist distribut input featur requir (ii) train data train state (an align state). opposite, need larger comput capabl especi larg vocabularies. currently, exist huge comput capabilities, hybrid deep neural network architectur dnn-hmm abl improv signif- icantli asr respect gmm-hmm system larg vocabulari task [21, 4, 8]. increas number neuron hidden layer network improv word error rate (wer) recognition. however, spars data small data set paramet properli fit perform diminish [10]. deal impair speech, face problem data sparsity. gather data difficult case, databas exist, on exist small. besides, differ speaker larger databas tend heterogeneous. pose problem anns, gmm sensit differ train test data. here, studi perform classic neural network ar- chitectur train small databas speaker dysanthria, torgo databas [9]. discuss differ classic neural systems, suitabl speaker adapt techniqu case. system train kaldi speech recognit toolkit [15]. adapt recip order prepar data, ex- tract featur train systems3. remain paper organ follows. first, section 2 describ databas us experiments. next, section 3 introduc main architectur asr specif techniqu resourc use. sec- tion 4 make emphasi acoust model modul present differ recognit system evalu task. finally, discuss result draw conclus section 5 6 respectively. 2 torgo databas server speech disord alter correct utter sounds. speaker dysarthria difficulti articul phonem lesion nervou system. caus chang voic quality, slow rate speech abnorm pitch rhythm. 3 recip publicli avail tabl 1. figur 15 speaker torgo databas rank accord degre disord speaker f01 m01 m02 m04 m05 f03 f04 m03 degre sever sever sever sever sev-mid mid mild mild #audio 228 739 772 659 610 1097 675 806 speaker fc01 fc02 fc03 mc01 mc02 mc03 mc04 degre #audio 296 2183 1924 2141 1112 1661 1614 torgo databas [9] contain speech 15 subjects, 6 femal 9 males. total, databas contain 3 hour speaker record speech, correspond impair speech. speaker se- vere dysanthria, moderately-to-sever dysanthr moder dysanthric. subject mild dysanthria remain 7 subject control speaker disorder. tabl 1 describ 15 sub- ject includ number audio avail database. utter us both, audio obtain head-mount microphon obtain direct microphone. microphones, 5586 utter speaker dysan- thria (a mean 698 speaker) 10931 utter control speaker (a mean 1562). utter singl word sentence, mean word utter 3.5. 3 system architectur system describ follow section share common main archi- tectur modules: (i) featur extraction, (ii) acoust modeling, (iii) lan- guag model (iv) pronunci lexicon. featur extract acoust model differ systems. 3.1 featur extract basic acoust featur us 13 mel-frequ cepstral coeffici (mfccs). featur gener 25 ms window shift 10 ms control speaker 15 ms dysanthr speech. configur dysanthr speaker shown adequ ref. [9]. explain section 2, disord speaker talk slower widen shift consec- utiv frame help homogenis differ patient control speakers. convolut neural network (cnn), us 40 dimension fil- terbank featur order account correl signal, estim window intervals. besides, order obtain evolv speaker independ (si) features, appli linear discrimin analysi transform (lda) project sequenc frame 40 dimens and, afterwards, maximum likelihood linear transform (mllt) diagonalis matrix gather cor- relat vector [6]. speaker depend featur (sd), appli feature-spac maximum likelihood linear regress (fmllr) [16]. cases, add 100-dimension ivector gather specif inform speaker environ [5, 20]. 3.2 acoust model work us monophon model standard three-stat con- text depend triphon model differ featur used, train methodolog probabl associ hmm state calcu- lated. section 4 describ main characterist acoust model used. 3.3 languag model pronunci lexicon srilm toolkit [22] build standard 3-gram languag model interpol kneser-nei discount train data transcripts. lexicon, choos carnegi mellon univers pronounc dictionary4 north american english. contain 134,000 word pronunci arpabet phonem set 39 phonemes. 4 acoust model type model distinguish follow subsections: classic architectur gmm-hmm hybrid neural network architectur dnn-hmm. 4.1 classic architectur studi differ variat natur featur kind train standard gmm-hmm architecture. below, list system analys work main characteristics. easi comparison, parenthes nomenclatur kaldi. adapt kaldi recip fit data, train 7 classic system 1800 hmm state total 9000 gaussians: mono monophon model mfcc featur (mono) tri basic triphon model featur mfcc++ (tri2a) tri-si triphon model speaker-independ transform appli mfcc+lda+mllt (tri2b) 4 tri-sd triphon model speaker-depend transform ad mfcc+lda+mllt+fmllr (tri3b) tri-sddi triphon model tri-sd discrimin maximum mutual inform (mmi) feature-spac mmi train (fmmi), tri-sd+mmi+fmmi. us learn rate 0.001 (tri3b fmmi) discrimin train fit hmm parameters. experi mmi training, boost mmi, minimum phone er- ror (mpe), direct indirect feature-spac discrimin mmi train (fmmi) learn rates. model tri-sddi best perform dysarthr speaker and, therefore, includ analysis. finally, consid subspac gaussian mixtur model [14] 8000 state 19000 substates: sgmm subspac gmm sd featur mfcc+lda+mllt+fmllr (sgmm2 4a) sgmm2 subspac gmm addit speaker adapt transform fm- llr (sgmm2 4a fmllr) 4.2 neural network architectur hybrid systems, ann train estim probabl hmm states. differ network configur purpose: dnnce deep neural network train align obtain mfcc+ +lda+mllt+fmllr featur cross-entropy. dnn 6 hidden layers, 1024 neuron 1800 output units. net initialis stack restrict boltzmann machin (rbms) (dnn4b pretrain-dbn dnn) dnnsmbr introduc sequenc discrimin train minimis error state label sentence. depart dnnce, 6 itera- tion state-level minimum bay risk (smbr) appli (dnn4b pretrain- dbn dnn smbr) notic kind sequence-discrimin train used. refer [25] present experi mmi, mpe, smbr boost mmi. train set larger (300h 110h) small differ object functions, slightli better smbr, us follow sections. cnnba cnn convolut frequenc axis. us 40-dim filter- bank features, convolut layer learn rate 0.008 (cnn4c) cnnsmbr dnnsmbr built cnnba. first, cnn train build rbm top, train 6-layer dnn cross-entropi af- terward 6 iter discrimin train (cnn4c pretrain-dbn dnn smbr) finally, select kind neural network especi devot deal time sequences: time delai neural network recurr neural networks. tabl 2. wer score 8 speaker dysarthria set select systems. f01 m01 m02 m04 m05 f03 f04 m03 mono 70.86 80.10 76.55 88.62 77.71 57.02 29.10 43.32 tr1 70.68 91.18 81.09 88.62 84.59 41.80 18.62 26.01 tri-si 76.80 79.12 83.67 88.68 96.71 53.08 18.97 32.59 tri-sd 47.30 78.91 68.49 81.16 97.16 42.88 13.29 17.06 tri-sddi 45.68 74.74 66.49 79.29 70.46 39.87 12.82 11.57 sgmm 43.71 77.83 64.01 71.46 98.43 37.26 11.42 10.19 sgmm2 43.53 78.37 63.33 71.34 97.31 37.22 11.24 9.74 dnnce 39.57 62.20 42.89 69.05 62.60 39.30 13.06 17.71 dnnsmbr 35.61 62.30 47.95 69.30 62.53 37.01 10.95 12.76 cnnba 53.24 66.04 77.66 83.62 65.67 46.78 15.81 37.88 cnnsmbr 53.06 66.74 50.47 81.40 65.74 33.89 11.24 10.44 tdnn 66.19 69.50 62.28 73.51 88.18 47.46 14.34 28.04 tdnniv 94.96 95.62 84.14 92.59 93.94 91.98 39.29 70.97 lstm 59.71 71.61 67.33 72.97 84.73 48.28 12.00 27.50 lstmiv 71.04 75.01 76.13 77.30 72.85 69.33 19.61 32.20 tdnn multi-splic time delai neural network train align ob- tain mfcc+lda+mllt+fmllr features. us high-resolut mfcc features. network 3 hidden layer p-norm input dimen- sion 2000 output dimens 250. learn rate evolv 0.01 0.007 (nnet tdnn noivec) tdnniv characterist previou network add 100-dim ivector 40-dim high-resolut mfcc input featur speaker adapt (nnet tdnn a) lstm long-term short-term memori network 3 hidden layer 1024 neurons. network train 10 epoch learn rate evolv 0.0012 0.00036, momentum 0.5 (lstm noivec) lstmiv characterist previou network add 100-dim ivector 40-dim mfcc input (lstm ivec) 5 result discuss us 14 speaker train paramet acoust model test system 15th. so, training, distinct speaker dysarthria differ shift frame defi- nition extract features. data especi dysarthr speakers, train impair speech improv re- sults. similarly, languag model test estim 14 speakers, includ addit corpora differ domain train languag model improv result either. cross-valid neu- ral network training, us data come speaker mild tabl 3. wer score 7 control speakers. fc01 fc02 fc03 mc01 mc02 mc03 mc04 mono 22.40 30.27 29.88 39.52 42.99 33.59 51.19 tr1 13.06 24.06 23.38 36.73 30.66 30.10 42.07 tri-si 13.20 24.73 26.30 38.30 32.98 33.28 42.48 tri-sd 8.01 21.96 16.71 16.96 19.46 27.47 36.27 tri-sddi 7.42 21.72 15.43 17.49 18.23 26.51 37.40 sgmm 7.86 20.87 13.57 15.12 16.16 24.89 28.82 sgmm2 7.57 20.93 13.55 14.90 16.12 24.96 28.38 dnnce 6.53 19.62 11.01 15.32 14.72 22.11 27.06 dnnsmbr 6.38 19.24 10.41 12.03 13.38 20.37 23.76 cnnba 15.58 22.38 14.63 25.01 38.25 33.25 44.66 cnnsmbr 9.64 18.28 12.35 11.65 15.91 23.79 38.16 tdnn 10.98 18.97 12.90 35.67 58.69 32.90 31.90 tdnniv 16.32 24.51 21.48 51.31 62.00 49.92 62.99 lstm 8.46 19.30 13.21 24.06 41.80 25.53 21.78 lstmiv 6.38 19.93 13.91 21.47 37.20 27.25 29.92 dysarthria regardless natur test speaker us subject f03, f04 case test subject f03. tabl 2 show result speaker dysarthria. measur qual- iti system mean wer. notic sever dysarthr speakers, triphon model abl improv monophon models. fact, speakers, signific improv wer score appear speaker depend transform applied. happen control speaker (tabl 3) case base triphon better monophon systems. general, intrins differ 15 speaker necessari speaker adapt techniques. subspac gaussian mixtur model best perform classic models. case recognit extrem difficult (m01 m05) tri-sddi outperform sgmm family. remark hard task: mean error rate control speaker 18%, mean patient sever diseas reach 65%. patient mild patholog wer lower equival control speakers. best perform network result dnn train gmm-hmm alignments. dnn-hmm system lowest wer 11 15 test speakers, 6 8 speaker dysarthria. consid neural network architectur compar classic ones, figur increas 14 15 7 8 respectively. subject sever disease, differ dnn train minimis cross-entropi (dnnce) includ subsequ sequenc discrimin train (dnnsmbr), mean error rate vari 52.6 52.5. control speakers, wer diminish 16.6 15.1 ad discrimin training. work report improv cnns, tdnn lstm respect dnns, especi larg vocabulari [17, 1, 13, 18, 7, 11]. behaviour task. reason twofold: torgo databas small data heterogeneous. comparison small databases, author ref. [13] train tdnn resourc manag database, 3 hour record speech. study, standard dnn perform slightli better, larger data tdnn got better results. hand, cnn outperfom dnn 50-hour english broadcast new task [17] 18-hour microsoft-intern voic search task [1]. neural network architectur present appli speaker adaptation, fmllr featur seed classic model and/or train network itself. tdnn lstms, studi consequ includ ivectors. studi larger databas inclus ivector improv baselin [12, 23], task clearli damag performance. tdnn ivector tdnniv increment wer 24 point dysarthr speaker 12 point control speakers. result neg lstm prefer base lstm: dysarthr speaker inclus ivector caus increment 6 point wer control speaker system even. work devot build asr dysarthr speak- ers. creator torgo databas train asr ref. [9]. analysis, ours, simpl triphon model abl improv significantli monophon models. so, instead experi new architectur built triphon models, approach base adapt speaker acoust mod- el incorpor specif lexicon speaker. lexicon includ pro- nunciat word follow guidelin pronunci detect patient dysarthria. adapt acoust model dysarthr speakers, author report rel improv wer 23% av- erag 6 speaker sever dysarthria 3% addit lexicon. creation lexicon difficult gener automat de- pend analysi error commit new speaker. approach, hope deep neural network learn behaviour speaker similar problems. speaker adapt model tri-sd sgmm2 similar [9]. still, 6 speakers, minor improv adaptation: sgmm2 model achiev improv wer 10% respect baseline, smaller 23%. differ given mainli subject m05, best model [9] reach 15% wer, model surpass 70% wer speaker. differ explain differ data. best architectur neural networks, dnnsmbr, achiev 23% improv wer compar baseline, similar ref. [9] build resourc manually. 6 conclus recognis dysarthr speech difficult task. train asr speaker dysarthria torgo database, databas dysarthr articulation. hour record speech 15 subjects, moder word error rate score obtain control speakers. mean wer 15% obtain case, rise 52% test patient sever dysarthria. hybrid dnn-hmm system best performance. dnn out- perfom best classic 14 15 test speakers: wer score improv 3% control speaker 13% subject dysarthria respect best classic architecture, subspac gmm model ad- dition speaker adapt transform fmllr. classic neural architectures, speaker adapt techniqu import improv recognition. classic systems, fmllr transform qualit leap respect speaker independ transform mllt. neural network us tri-sd model training. however, task, ivector carac- teris speaker environ neg impact qualiti final systems. current result obtain databas combin impair normal speech. remain seen includ addit data normal speech abl improv recognition. acknowledg work support spanish ministerio economa y competi- tividad european region develop fund, contract innpacto ipt-2012-0914-300000 tec2015-69266-p (mineco/feder, ue). refer 1. abdel-hamid, o., deng, l., yu, d.: explor convolut neural network struc- ture optim techniqu speech recognition. in: interspeech 2013, lyon, france, august 25-29, 2013. pp. 33663370 (2013) 2. amodei, d., anubhai, r., battenberg, e., case, c., casper, j., catanzaro, b.c., chen, j., chrzanowski, m., coates, a., diamos, g., elsen, e., engel, j., fan, l., fougner, c., han, t., hannun, a.y., jun, b., legresley, p., lin, l., narang, s., ng, a.y., ozair, s., prenger, r., raiman, j., satheesh, s., seetapun, d., sengupta, s., wang, y., wang, z., wang, c., xiao, b., yogatama, d., zhan, j., zhu, z.: deep speech 2: end-to-end speech recognit english mandarin. corr abs/1512.02595 (2015) 3. bourlard, h.a., morgan, n.: connectionist speech recognition: hybrid ap- proach. kluwer academ publishers, norwell, ma, usa (1993) 4. dahl, g., yu, d., deng, l., acero, a.: context-depend pre-train deep neural network larg vocabulari speech recognition. ieee transact audio, speech, languag process 20(1), 3042 (januari 2012) 5. dehak, n., dehak, r., kenny, p., brummer, n., ouellet, p., dumouchel, p.: sup- port vector machin versu fast score low-dimension total variabl space speaker verification. in: interspeech 2009, 10th annual confer intern speech commun association, brighton, unit kingdom, septemb 6-10, 2009. pp. 15591562 (2009) 6. gopinath, r.a.: maximum likelihood model gaussian distribut classification. in: proceed 1998 ieee intern confer acous- tics, speech signal processing, icassp 98, seattle, washington, usa, 12-15, 1998. pp. 661664 (1998) 7. li, x., wu, x.: construct long short-term memori base deep recurr neural network larg vocabulari speech recognition. in: 2015 ieee intern con- ferenc acoustics, speech signal processing, icassp 2015, south brisbane, queensland, australia, april 19-24, 2015. pp. 45204524 (2015) 8. maas, a.l., hannun, a.y., lengerich, c.t., qi, p., jurafsky, d., ng, a.y.: increas- ing deep neural network acoust model size larg vocabulari continu speech recognition. corr abs/1406.7806 (2014) 9. mengistu, k.t., rudzicz, f.: adapt acoust lexic model dysarthr speech. in: proceed ieee intern confer acoustics, speech, signal process (icassp11). pp. 49244927. ieee (2011) 10. miao, y., metze, f.: improv low-resourc cd-dnn-hmm dropout multilingu dnn training. in: bimbot, f., cerisara, c., fougeron, c., gravier, g., lamel, l., pellegrino, f., perrier (eds.) interspeech. pp. 22372241. isca (2013) 11. miao, y., metze, f.: speaker adapt long short-term memori recurr neural networks. in: interspeech 2015, 16th annual confer inter- nation speech commun association, dresden, germany, septemb 6-10, 2015. pp. 11011105 (2015) 12. peddinti, v., chen, g., povey, d., khudanpur, s.: reverber robust acoust model i-vector time delai neural networks. in: interspeech 2015, dresden, germany, septemb 6-10, 2015. pp. 24402444 (2015) 13. peddinti, v., povey, d., khudanpur, s.: time delai neural network architectur effici model long tempor contexts. in: interspeech 2015, dresden, germany, septemb 6-10, 2015. pp. 32143218 (2015) 14. povey, d., burget, l., agarwal, m., akyazi, p., kai, f., ghoshal, a., glembek, o., goel, n., karafiat, m., rastrow, a., rose, r.c., schwarz, p., thomas, s.: subspac gaussian mixtur model-a structur model speech recognition. comput. speech lang. 25(2), 404439 (apr 2011) 15. povey, d., ghoshal, a., boulianne, g., goel, n., hannemann, m., qian, y., schwarz, p., stemmer, g.: kaldi speech recognit toolkit. in: ieee 2011 workshop automat speech recognit understanding. ieee signal pro- cess societi (2011) 16. povey, d., saon, g.: featur model space speaker adapt covari- anc gaussians. in: interspeech 2006 - icslp, ninth intern confer spoken languag processing, pittsburgh, pa, usa, septemb 17-21, 2006. isca (2006) 17. sainath, t.n., mohamed, a., kingsbury, b., ramabhadran, b.: deep convolu- tional neural network lvcsr. in: ieee intern confer acous- tics, speech signal processing, icassp 2013, vancouver, bc, canada, 26-31, 2013. pp. 86148618 (2013) 18. sak, h., senior, a.w., beaufays, f.: long short-term memori recurr neural network architectur larg scale acoust modeling. in: interspeech 2014, sin- gapore, septemb 14-18, 2014. pp. 338342 (2014) 19. saon, g., sercu, t., rennie, s.j., kuo, h.j.: ibm 2016 english convers telephon speech recognit system. corr abs/1604.08242 (2016) 20. saon, g., soltau, h., nahamoo, d., picheny, m.: speaker adapt neural network acoust model i-vectors. in: asru. pp. 5559. ieee (2013) 21. seide, f., li, g., yu, d.: convers speech transcript context- depend deep neural networks. in: interspeech 2011, 12th annual confer intern speech commun association, florence, italy, august 27-31, 2011. pp. 437440 (2011) 22. stolcke, a.: srilm - extens languag model toolkit. in: proceed- ing seventh intern confer spoken languag process (ic- slp2002). pp. 901904. denver, colorado, usa (2002) 23. tan, t., qian, y., yu, d., kundu, s., lu, l., sim, k.c., xiao, x., zhang, y.: speaker-awar train lstm-rnn acoust modelling. in: 2016 ieee intern confer acoustics, speech signal processing, icassp 2016, shanghai, china, march 20-25, 2016. pp. 52805284 (2016) 24. trentin, e., gori, m.: survei hybrid ann/hmm model automat speech recognition. neurocomput 37(14), 91126 (2001) 25. vesely, k., ghoshal, a., burget, l., povey, d.: sequence-discrimin train deep neural networks. in: interspeech 2013, lyon, france, august 25-29, 2013. pp. 23452349 (2013)