visual embed unsupervis extract abstract semant garcia-gasulla, d. & ayguade, e. & labarta, j. barcelona supercomput center (bsc) bejar, j. & cortes, u. universitat politecnica catalunya - barcelonatech suzumura t.& chen, r. ibm t.j. watson research center, usa decemb 16, 2016 abstract vector-spac word represent obtain neural network mod- el shown enabl semant oper base vector arith- metic. paper, explor exist similar inform vector represent images. purpos defin method- ologi obtain large, spars vector represent imag classes, gener vector state-of-the-art deep learn architectur googlenet 20k imag obtain imagenet. evalu result vector-spac semant correl word- net distances, vector distanc strongli correl linguist semantics. explor locat imag vector space, find element close wordnet cluster together, regardless signific visual varianc (e.g., 118 dog types). sur- prisingly, space unsupervisedli separ complex class prior knowledg (e.g., live things). afterwards, consid vector arithmetics. unabl obtain meaning result regard, discuss problem encountered, consid solv them. finally, discuss impact research cognit systems, focus role architectur used. 1 introduct deep learn network learn represent million featur compos network [8]. provid train deep network ex- ception rich represent language, allow perform detect classif remark precision. far represent languag learnt deep network straightforwardly, task like im- ag classification. however, deep network represent purposes, inform code featur extracted. 1 <2016>. manuscript version avail cc-by-nc-nd 4.0 licens doi: 10.1016/j.cogsys.2016.11.008 wai vector-spac representations. vector-spac explor vector arithmetics. approach taken [10], author syntact (e.g., singular/plural) semant (e.g., male/female) regular vector represent words. paper extract inform neural network model complex domain im- ages. lead work deep network capabl captur complex varieti inform visual domain. pre- viousli train network intern featur descriptors, build vector featur set imag train network. vector-spac built, analyz semant contains. result provid insight represent learnt deep network models, open new set applic exploit deep network representations. 2 motiv word vector represent obtain neural network model contain syntact semant inform [10]. inform extract arithmet oper vector-space, successfulli task machin translat [9]. motiv paper explor exist similar inform imag vector representations, us gener visual reasoning. imag vec- tor represent extract convolut neural network (cnn) previous explor applic imag recognit tasks. [3] explor perform featur learnt given data set recogniz- ing imag class differ data set. author layer network cluster imag accord high level semant (e.g., outdoor vs indoor). [14] went further, consid util featur imag recognit problem fine-grain classif attribut selection. work built imag vector represent solv imag recognit tasks. layer network opti- mize discrimin training, layer turn effect set featur avail task. however, repres abstract visual concept (e.g., imag classes) taught, rest layer useful, try maxim representative- ness instead discrimin power. mid-level layer paramet train dataset successfulli reus recogn differ dataset [12], show relev learnt models. popular field research right deep learn multimod systems, visual lan- guag model integrated. exampl devis [4] combin skip-gram model train larg corpu cnn train ilsvrc data. thank inform provid languag model, devis reason infer imag belong unknown classes, known zero-shot prediction. multimodel particularli relev work propos [7], combin image-sent embed long short-term memory. author exist regular per- form oper imag blue car - word blue + word red ' imag red car. work explor similar regularities, lan- guag model guid it. purpos build spars high-dimension represent imag classes, try obtain rich abstract empow 2 unsupervis process. 3 methodolog cnn train label imag learn visual pattern discrimin labels. deep network million patterns, imple- ment activ function (e.g., relu) network features. featur deep network consequ provid signific piec visual inform descript images, maxim rele- vant discrimin (onli layer featur are). consid featur activ valu given image, fact look every- thing network see image, learnt training. visual semant captur neural model featur values, valu repres vector analysis. precis specif vector represent bound qualiti vari- eti pattern deep network; network capabl discrimin imag class higher precis provid richer imag descriptions. maxim descript accuraci googlenet ar- chitectur [17], deep cnn (22 layers) won ilsvrc14 visual recognit challeng [15]. pre-train model avail caff deep learn framework [6], train 1.2m imag imagenet test set task discrimin 1,000 imagenet hierarchi categories. googlenet model compos 9 incept modules. captur output 1x1, 3x3 5x5 convolut layer 9 modul build vector represent activ values. imag run train network, 27 differ layer combin produc 1 million activations, express presenc relev differ visual pattern input image. vector-build process treat compos featur independ variables. thus, imag high- dimensional, spars vector represent compos 1m continu variables. execut describ paper perform intel sandybridge-ep e5-2670/1600 20m 8-core 2.6 ghz 64 gb ram. code process activ featur produc figur graph avail experi us 20,000 imag imagenet valid set, label 1,000 differ classes, includ larg varieti objects, animals, plants, etc. imagenet class map differ wordnet synset concept, us advantag evalu process (see evaluation). sampl imag shown figur 1. 3.1 imag class obtain vector 20,000 images, perform abstract step build vector represent abstract classes, 1,000 class imag label to. build imag class vector combin specif imag vector belong class. result aggregation, expect obtain repres valu variabl class, reduc variat specif imag brightness, context, scale etc.. number imag aggreg class rang 11 32. aggreg imag 3 figur 1: sampl imag experiments, obtain ima- genet 2012 valid set. row imag shown label class n02504458 african elephant, loxodonta africana, second row imag label class n02676566 acoust guitar, row imag label n02747177 ashcan, trash can, garbag can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin. class vector size imag vector (roughli 1m variables), comput arithmet mean imag avail class. end aggreg process obtain 1,000 vectors, correspond represent 1,000 leaf-nod categori imagenet hierarchy. altern aggreg methodolog considered, discuss parametr section. 1,000 categori imagenet hierarchi correspond divers entities. simpl objects, produc weak activations. complex rich contexts, involv stronger activations. variabl magnitud imag class vector affect result similar metrics, class have lower activ consid closer class actual are. second sourc variabl variabl behaviour neuron given locat cnn. typically, low-level neuron close input produc frequent stronger acti- vations, repres simpl pattern easier find. hand, neuron higher cnn produc spars activations, special role. elimin impact sourc variabl per- form normal process imag class vector. normal vector valu layer layer, guarante inform avail visual resolut equal relev representation, imag class vector contain information. alter- nativ normal methods, includ normalization, considered, discuss parametr section. imag class vector represent built aggreg normal activ imag singl vector, depict figur 2. studi inform contain result vector-spac comput imag class similar 4 figur 2: featur extraction, aggreg normal process build imag class vector representations. vector distanc measures. us cosin similar build distanc ma- trix 1,000 classes, us distanc vector-spac evalu (by compar distanc base wordnet) analysi (by find cluster classes). 4 evalu evalu consist inform captur propos em- bed space us label repres classes. imagenet label map wordnet concepts, provid access lexic semant implement wordnet. vector represent suppos captur visual semant instead, signific gap expected. nev- ertheless, wordnet remain sourc valid knowledg avail evaluation. distanc imag class comput wordnet measures, typic hypernym/hyponym lexic taxonomi [13]. time comput imag class distanc vector-space, previous defin methodology. result have, avail imag class, set similar respect rest imag classes, similar reduc ranking. spearman provid measur correl rankings, bound -1 1, valu close -1 1 indic strong correlation. obtain valu imag class, compar lexic visual rankings. consid valu imag class obtain distribut correlations, indic level semant coher wordnet taxonomi vector-spac whole. consid differ wordnet distanc maxim consistency: base path length concept (path, lch wup) corpus- base focus specif concept (res, jcn lin) [13]. addition- ally, us differ corpu corpus-bas measures, brown corpus, british nation corpus. figur 3 show distribut correl vector embed wordnet mea- sures. valu 0.4 0.6, indic strong correl rank 999 elements. result consist wordnet settings; averag distribut 0.44 wors 5 figur 3: histogram spearman correl imag class vector similar comput method, wordnet similar measur (three path length based: path, lch wup, corpus-bas res, jcn lin differ corpus). histogram contain 1,000 correl valu correspond correl class imagenet dataset. case (jcn bnc) 0.49 best case (re brown & re bnc). re- sult indic vector represent contain larg semant inform captur wordnet. particularli interesting, con- sider wordnet captur visual semant color pattern, proport context. 4.1 parametr altern solut consid vector-build process describ methodolog section. determin specif solut appropri follow evalu approach previous de- scribed. option consid following: aggregation: comput imag class vector represent set imag vector mean. consid arithmetic, geometr harmon mean. normalization: normal vector consid normal ap- pli vector whole, 27 sub-vector normal base 27 layer vector. consid perform option appli singl imag vectors, aggregation, imag class vectors, aggregations. consid avoid normal step. distance: comput distanc vector consid cosin euclidean distances. threshold: decreas variabl consid ad activ threshold disregard activ valu 0 1 build imag vector representations, increas vector sparsity. test combin parameters, evalu base distribut correl produced. best set arithmet mean, imag class normal layer, cosin distanc threshold. however, imperfect natur evalu (i.e., rank correl base lexic measure) allow definit 6 layer layer 22% middl 55% 22% mean 0.46 0.41 0.46 0.36 tabl 1: mean correl valu imag class vector similar comput method, wordnet similar measures, subset layer cnn model. assert set produc semant rich vector embedding. instead discuss paramet provid signific benefit term correlation, recommend futur works, caus definit effects. aggreg normal paramet largest impact distribut correlations, allow confid setting. arithmet mean clearli outperform geometr harmon means, normal layer aggreg imag class achiev higher correl whole, origin imag vectors, avoid normal together. hand, distanc algorithm, particularli us activ threshold, small impact distribut correlations. paramet choos option maxim correl (cosin threshold), differ choic remain competitive. differ paramet analyz layer build vector representation. previou contribut argu best consid layer activ imag recognit task [3, 14]. contrari approach, methodolog us featur layer network, goal maxim representativeness. valid notion, us certain layer network build embed space, explor correl wordnet setting. distribut correl fulli compar measur quality, provid formal evalu previou parameters. however, need provid evid contrast previou work [3, 14] layer used, decid mean obtain subset layers. valu tabl 1 taken definit evidence. consid featur belong 22% net- work (i.e., incept modul 5a 5b), featur middl 55% (i.e., incept modul 4a, 4b, 4c, 4d 4e) featur 22% network (i.e., incept modul 3a 3b). result indic correl achiev middl 55% similar correl achiev set 27 layers. hand, correl achiev consid featur 22% 22% layer significantli worse, show correlation. result indic layer network contain visual semant relev descript abstract imag classes, regardless location. differ result previou work [3, 14] explain differ method goals. previou contribut focus singl imag represent imag recognit tasks. singl imag highli variabl term brightness, context, etc., us dispers lower layer represent mayb counterproductive. hand target high-level imag class representations, 7 smaller variabl thank aggreg normal process apply. result consid larger volatil part input (i.e., non-top layers) potenti us knowledg represent process target abstract entities. 5 cluster imag class analyz semant captur defin vector-spac perform supervis analysi clusters, wordnet hierarchi ground truth; know imag class hyponym synset, explor distribut embed space. achiev visual results, appli metric multi-dimension scale [2] dimens 1,000 imag class distanc matrix. method build two-dimension map vector distanc respect pairwis origin similarities. us synset hyponym imagenet categories: dog (accord wordnet 118 special dog imag classes) wheel vehicl (with 44 special wheel vehicl imag classes1). highlight locat imag class belong set two-dimension similar map figur 4a. sight, set highlight imag compos defin clusters. precis perfect, imag class belong wordnet categori clearli assembl vector-spac representation. case dogs, relev wide varieti dog computed, visual featur common (e.g., chihuahua, husky, poodle, great dane). accord results, visual featur common dog weight vector represent variabl featur size, color proportion. probabl caus aggreg normal process, reduc import imag class volatil properties. cluster defin wheel vehicl imag class lower precis dogs, probabl wheel vehicl vari dog (e.g., monocycle, tank, train). wheel vehicl locat quadrant graph, indic larg reliabl set featur vector represent identifi type imag classes. wheel vehicl locat outsid middle-left quadrant, low-right figur 4a, correspond snowmobile, special type wheel vehicl differ everything. look figur 4a notic gap natur split imag class sets. separ consist spars area visibl sight graph. explain phenomenon explor basic categor wordnet, separ imagenet class live things, defin wordnet live (or living) entiti rest. paint imag belong live thing obtain graph figur 4b. graph show separ vector-spac correspond simpl categor strike precision, unsupervisedli cluster imag depend depict live thing not. mistak correspond organ uniqu shape textur (e.g., lobster, 1to 44 class ad school bus, minibu trolleybu imag classes, consid wheel vehicles. 8 b figur 4: scatter plot imag class vector similar built metric multi-dimension scaling. (a) black circl belong imag label hy- ponym synset dog, domest dog, cani familiari dark grei circl belong imag label hyponym synset wheel vehicle. (b) black circl belong imag label hyponym synset live thing, anim thing. basebal player, dragonfly) thing depict live thing (e.g., snorkel, dog sled). particular case controversial, coral reef live organ accord wordnet vector- space cluster such. encourag result tri obtain represent vector-spac show separ live organ rest clarity. purpos test non-linear map distanc dimens isomap algorithm [18]. featur extract network combin non-linearli obtain class image, kind transform highlight inher non-linear vector-space. figur 5 show evid separ synset complex structur class images. point assert vector represent captur larg amount high-level semantics. given sourc deep network provid 1,000 independ imag categori labels, semant captur vector space origin visual features. boundari semant captur wai hard define, requir state learnt seen images. best notion far limit visual semant provid distinct live thing rest. horses, salmons, eagles, lizard mushroom littl common visually, element cluster vector-space. structur pattern live thing particular motiv distinction. result open interest question intend address follow-up work. 9 figur 5: scatter plot built isomap, analog figur 4b. black circl belong imag label hyponym synset live thing, anim thing. 6 lesson imag equat word vector embed empow extract syntact semant reg- ular vector arithmet (e.g., king - man + woman = queen) [10]. regular explor linguist context far form b b, have applic field like machin translat [9]. imag class vector embed construct process defin method- ologi section allow consid exist similar regular domain images. if, result evalu section indicate, visual semant encod imag class vectors, possibl oper semant perform type visual arithmet rea- soning. comparison linguist context, imag embed space build larger dimension data variability. simplifi arithmet process consid simpler relat operands, form - b ' c. us subtract oper imag class vectors, combin cosin similar measur ' oper closest imag class result substract solv equa- tion. given images, i1 i2 featur f , subtract i2 i1 f defin f(i1 i2) = { f(i1) f(i2), f(i1) > f(i2) 0, substract oper defin featur level. solv imag equat substract vector level appli featur compos 10 vector. consid differ scenario equat applied. analyz imag class understood non-overlap concaten classes. exampl chair plu wheel, produc imag class like offic chair wheelchair. second scenario forese analyz imag class understood overlap combin classes. case visual properti mix class need strongli intertwin produc third. exampl wolf plu man, produc werewolf. explor imag equat describ limi- tation prevent obtain meaning results. work process limit here, intend solv them, hope research benefit experience. problem face relat evalu imag equations, obviou ground truth available. subject propos differ equat visual sense, platypu - duck = beaver, turtl - shield = lizard motorcycl - motor = bicycle. approach, hardli scalabl on imagin quickli run out, easili in- clude human bia implicit consider non-visu features. nevertheless, remain best avail evalu methodology. avail test dataset, instead comput possibl equations, subject decid exact on (those lower ' oper value) sens visual not. problem approach huge number possibl equat are, comput cost comput all. example, 1,000 differ class vector ob- tain imagenet dataset, compos roughli 997 million differ equat form - b ' c (notic cosin similar commut substract oper not). comput singl equat need substract vector compos million features, comput similar result vector. comput 997 million problem requir huge comput resources. thus, effici code run parallel high-perform infrastructur solv problem. relev problem caus curs dimensionality. imag class vector represent work compos roughli million features. consequently, result vector space defin million dimensions. high-dimension space object highli similar, distanc measures, euclidean distance, troubl find meaning differences. solv issu consid dimension reduct method (e.g., princip compon analysis), emploi distanc measur resist high dimension (see [1]). 7 implic cognit system deep learn network shown appropri solv spe- cific compon cognit systems: perception. unlik previou models, deep network process huge amount raw data, learn later iden- 11 tifi abstract pattern character data complex tasks. multipl non-linearities, deep learn model solv cognit problem transform sub-symbol data symbol knowledge; differ look seeing. case cnns, model mimic anim visual cortex process imag dimension matrix features. squar sub-part matrix process recept fields, look previ- ousli learnt pattern filter input pictur (i.e., convolution). output filter project dimension matrix, goal iter appli convolut process larger origin input matrix. eventually, neuron fed input matrix, produc data descriptor input. current deep cnn architec- ture includ million filter distribut layers, filter tune given purpose. design make cnn human essence, perceiv small visual pattern small visual patch input, iter aggreg visual percept obtained. deep learn appar solv problem percept definit larg rich represent language, model limit higher-level purpos relat cognit (e.g., reasoning) lack symbol oper mechanisms. situat natur lead solut addit machin learn method plug deep learn systems, process represent built achiev high-level cognit processes. particular architectur follow research, us represent languag learnt cnn (a pretrain googlenet model) obtain specif input data (imag vector class vectors) empow addit machin learn method (cluster algorithms). architectur capabl perform high-level cognit concept discovery, cnn do, find cluster entiti correspond entiti (e.g., live thing). current imposs overal impact deep learn cognit systems. assert lowest level cognition, perception, replic model cnns. combin architectur propos essenc deep learn success case (e.g., deep learn + classifi object recognit [5], deep learn + tree search reinforc learn boardgam video game [16, 11]), like gener cognit system follow architectur well. 8 conclus paper present methodolog build vector represent imag class base featur origin learnt deep learn network. goal extract visual semant captur deep network model, order avail learn reason methods. unlik previou research, focu repres abstract classes, aggreg normal singl imag belong concept. consist methodolog allow consid unpreced featur (over 1m). analyz result vector-spac look cluster 12 differ element common semant (e.g., dogs, wheel vehicles). varia- tion proportion, size color class domin essenti visual featur (e.g., share 118 kind dogs), element cluster embed space. exist high-level properti support untaught vector distinct be- tween live organ non-liv things. make wonder limit learnt visual information, straight- forward defin visual particular life. gener terms, propos methodolog take larg volum pixel (sub-symbol data) translat concept abstract semant (symbol knowledge). workflow clear implic artifici cogni- tive systems, tackl problem obtain symbol knowledg sub-symbol data, necessari step abstract reason real world perception. practice, approach extract high-level knowledg imag deep networks, make represent power cnn avail cognit purposes. promis architectur cognit systems. iden- tifi cluster imag distinct vector-space, find distinct trait set class visual learning, vector arith- metic reason artifici imag generation. main follow-up work research goe direction, solv problem appli vector arithmetics, explor us deep learn represent outsid deep learning. intend appli work zero-shot predict task, approach allow tackl complet unsupervis manner. 9 acknowledg work partial support joint studi agreement no. w156463 ibm/bsc deep learn center agreement, spanish govern- ment programa severo ochoa (sev-2015-0493), spanish min- istri scienc technolog tin2015-65316-p project generalitat catalunya (contract 2014-sgr-1051), core research evolut scienc technolog (crest) program japan scienc technolog agenc (jst). refer [1] charu c aggarwal, alexand hinneburg, daniel keim. surpris behavior distanc metric high dimension space. in: intern confer databas theory. springer. 2001, pp. 420 434. [2] ingwer borg patrick jf groenen. modern multidimension scaling: theori applications. springer scienc & busi media, 2005. [3] jeff donahu et al. decaf: deep convolut activ featur gener visual recognition. in: arxiv preprint arxiv:1310.1531 (2013). [4] andrea frome et al. devise: deep visual-semant embed model. in: advanc neural inform process systems. 2013, pp. 2121 2129. 13 [5] kaim et al. delv deep rectifiers: surpass human-level perform imagenet classification. in: proceed ieee in- ternat confer vision. 2015, pp. 10261034. [6] yangq jia et al. caffe: convolut architectur fast featur embedding. in: arxiv preprint arxiv:1408.5093 (2014). [7] ryan kiros, ruslan salakhutdinov, richard s zemel. unifi visual- semant embed multimod neural languag models. in: arxiv preprint arxiv:1411.2539 (2014). [8] yann lecun, yoshua bengio, geoffrei hinton. deep learning. in: natur 521.7553 (2015), pp. 436444. [9] toma mikolov, quoc v le, ilya sutskever. exploit similar languag machin translation. in: arxiv preprint arxiv:1309.4168 (2013). [10] toma mikolov, wen-tau yih, geoffrei zweig. linguist regulari- ti continu space word representations. in: hlt-naacl. 2013, pp. 746751. [11] volodymyr mnih et al. plai atari deep reinforc learning. in: arxiv preprint arxiv:1312.5602 (2013). [12] maxim oquab et al. learn transfer mid-level imag rep- resent convolut neural networks. in: vision pattern recognit (cvpr), 2014 ieee confer on. ieee. 2014, pp. 17171724. [13] ted pedersen, siddharth patwardhan, jason michelizzi. wordnet:: similarity: measur related concepts. in: demonstr pa- per hlt-naacl 2004. associ comput linguistics. 2004, pp. 3841. [14] ali s razavian et al. cnn featur off-the-shelf: astound baselin recognition. in: vision pattern recognit workshop (cvprw), 2014 ieee confer on. ieee. 2014, pp. 512519. [15] olga russakovski et al. imagenet larg scale visual recognit chal- lenge. in: intern journal vision (ijcv) (2015), pp. 1 42. doi: 10.1007/s11263-015-0816-y. [16] david silver et al. master game deep neural network tree search. in: natur 529.7587 (2016), pp. 484489. [17] christian szegedi et al. go deeper convolutions. in: arxiv preprint arxiv:1409.4842 (2014). [18] j. b. tenenbaum, v. silva, j. c. langford. global geometr framework nonlinear dimension reduction. in: scienc 290.5500 (dec. 2000), pp. 23192323. 14