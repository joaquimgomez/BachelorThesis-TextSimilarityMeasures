multim tool appl doi 10.1007/s11042-013-1605-7 gestur control interfac immers panoram displai marcel alcoverro xavier suau josep r. morro adolfo lpez-mndez albert gil javier ruiz-hidalgo josep r. casa springer science+busi media new york 2013 abstract paper, propos gesture-bas interfac design interact panoram scenes. combin novel static gestur fast hand track method. propos us static gestur shortcut activ function (i.e. volum up/down, mute, pause, etc.), hand track freeli explor panoram video. overal multi-user, incorpor user identif modul base face recognition, abl recogn return user add new user online. exploit depth data, make robust challeng illumin conditions. experiment result perform compon compar research lead result receiv fund european union seventh framework programm (fp7/2007-2013) grant agreement no. 248138. work partial support spanish ministerio ciencia e innovacin, project tec2010-18094. m. alcoverro x. suau (b) j. r. morro a. lpez-mndez a. gil j. ruiz-hidalgo j. r. casa depart signal theori communications, universitat politcnica catalunya, barcelona, spain e-mail: m. alcoverro e-mail: j. r. morro e-mail: a. gil e-mail: j. ruiz-hidalgo e-mail: j. r. casa e-mail: multim tool appl state art. result usabl studi perform untrain users. keyword interact panoram displai human-machin interfac 1 introduct need gestur control interfac emerg increas complex function inform system current demand natur user interfaces. commerci avail displai sets, instance, offer larger degre freedom manipul appear displai content. render capabl termin evolve, user tend feel constrain tradit interfaces, remot controls. compromis principl natur user interfac [19, 20], effect invis user commun modality. human gestur non-verbal, natur commun bodi [2]. gestur phases, differ wai kinemat function code [15], track [33] detect [17]. gestur interfac requir physic buttons, multi-touch devic second screen tangl user interact process. particular case user interact tv sets, need enabl interact new type data, high-qual panorama 3d/fvv video, foster studi new control modalities. remot control major drawbacks: misplac reach user, requir lot attent user control function increase. commerci innov field tv set focus natur user interfac base gestur speech recognit [24] overcom drawbacks. commerci innov follow studi gener field multimod human interact (mmhci). years, video transmiss experienc signific transformations. internet technolog new workflow current challeng tradit busi- ness model broadcast industry. new paradigm audiovisu sector aim offer new possibl viewer profession content providers. currently, viewer expect enjoi video content varieti displays, high-resolut cinemas, tvs, tablet, laptops, smart-phones, etc. furthermore, increasingli expect abl control audio-visu experi themselves. open path go awai fix product select suggest region (rois), freeli explor audio-visu scene. combin advanc panoram render gestur recognit tool allow viewer larger degre freedom select wai content displai freeli exploit scene natur non-intrus way. european project fascin [7] investig format-agnost approach production, deliveri render immers media. approach requir level interact user end hardli satisfi remotes, speech command second screens, experiment setup gestur control interfac introduc paper. multim tool appl purpose, propos novel interact paradigm exploit com- binat shortcut activ control functions, grasp-releas navig explor panoram scene. approach, shortcut implement robust static gestures, whilst navig base fast hand track system. us intuit easy-to-learn static gestur allow includ function system, keep interfac simple. addition, navig static gestur easili combinable, ad flexibl design. paper organ follows. section give overview relat work field user interaction, commerci sensor gestur interfaces. propos design gestur control interface, compon architectur state diagram, present section 3. technolog compon detail section 4, includ head tracking, hand track- ing, gestur local face identification. section 5 introduc setup user evalu propos system. experiment result provid main compon system, evalu accuraci performance. furthermore, overal result provid mean usabl studi untrain users. finally, section 6 outlin conclus possibl extens propos system. 2 relat work mmhci wide studi field survei previous pub- lish [12, 30]. moreover, mmhci crossroad relat area extens studi face detect identif [38], facial express analysi [23], ey track [13], gestur recognit [34], human motion analysi [25] audio-visu automat speech recognit [26]. recent commerci new game consol control kinect wiimote, rapidli follow releas proprietari driver sdk suitabl implement new form 3d user interfac base gestur [8]. side, author propos gestur control interfac base acceleromet wii control [16, 29]. side, kinect depth sensor allow device-less interfaces. solut zigfu [39] gesturepak [11] us skeleton track sdk [14, 22] input gestur recogni- tion base skelet poses. thus, approach requir human pose estim step, complex task high comput cost, prone error presenc clutter. alternatively, approach us raw kinect depth data input hand pose gestur recognit method [27, 28, 35]. contrast 2d color video, us depth data make method robust illumin chang suitabl dark environments. moreover, depth data provid 3d inform valuabl account scale invari human bodi parts. general, featur depth base method perform better color-bas counter part. introduc wach et al. [37], gesture-bas interfac entertain applications, tv control, address major issues: intuit gestur spotting. multim tool appl intuitiveness, mean type gestur select clear cognit associ function perform. however, gestur natur user unnatur others, strong associ cultur background experience. stern et al. [32] propos method design evalu gestur vocabulari take account psycho-physiolog measur (e.g. intuitiveness, comfort) machin factor (recognit accuracy). alternatively, nielsen et al. [18] propos procedur design gestur vocabulari base wizard-of-oz paradigm. wizard-of-oz experiment, user interact system, respons simul have person respond user commands. way, user on decid gestur best repres intentions. gestur spot [37] consist distinguish us gestur unintent movement. problem afford recognit technique, perform- ing tempor segment determin gestur start ends. how- ever, difficult problem recognit method assum tempor segment action [5]. recognit requir spatial segment bodi part (e.g hands) task prone errors. overcom problem, lpez-mndez et al. [17] focu problem local static gestur depth data. method learn local appear gestures, tempor spatial segment required. 3 design propos work device-less marker-less manner allow user control content tv set hand (fig. 1). respons locat peopl want interact understand recogn gestures. current implement focus control content high definit tv screen situat home scenario. content compos panorama imag (a high resolut view scene) audio track region (rois) associ panorama. fig. 1 user interact propos gestur interfac multim tool appl current setup allow user stand seat chair coach. singl user abl interact given time, interfac multi-us sens user ask control interact present scene (fig. 1). order allow user interact tv content, support follow functionalities: menu select menu overlaid current screen user select button menu point (fig. 2). navig user abl navig panorama scene panning, tilt zoom content. roi select inform user avail roi current view user abl chang them. pause/resum user abl paus / plai content time. audio volum user abl increas decreas volum mute completely. control control pass users. 3.1 user experi design aspect design compromis best user experi feasibl solut technic perspective. ensur provid responsive, conveni intuit experi user, follow design decis adopted: control function activ static gestures. gestur easi learn perform, provid fast wai simpl task (shortcuts). navig perform grab-releas manner. precisely, panoram scene act sheet grab (close hand), move (move close hand) releas (open hand). way, interfac simul virtual tablet user. fig. 2 displai content user feedback. icon centr (abov bar) feedback static gestur command (the icon show user lower volume). bar show 5 avail static gestur multim tool appl propos touch-less user stand far display. reason, interfac provid visual feedback user, provid inform state (e.g. identifi user, detect gestures, detect hand locat pointing). allow social aspect interact tv sets, provid easi mechan release, take/switch control multipl users. activ user freeli captur range. panoram navig gestur recognit mode separ improv user experi time reduc false/wrong detections. 3.2 architectur fulfil functionalities, current implement architectur depict fig. 3. divid main layers. layer, captur compon respons commun singl kinect camera feed imag system. kinect sensor provid color depth video vga resolut feed compon system. second layer core interface. processing, detect recognit algorithm place. compos follow components: head track (section 4.1), depth imag obtain captur modul analyz detect head (oval area depth) [33]. posit head subsequ compon locat possibl user system. person field view kinect sensor track gestur interfer system. face identif compon (section 4.4) recogn users. face de- tect modifi viola-jon detector [36] color imag recogn tempor fusion singl imag identifications. recogn user determin number peopl abl control system. fig. 3 architectur gestur control interfac multim tool appl user detected, hand track hand track compon (section 4.2) 3d virtual box head user control system. 3d blob virtual box segment treat hand [33]. gestur local compon (section 4.3) respons detect classifi static gestur (gestur perform hands). case, classif gestur pure shape posit hand, extract depth data provid captur component. classif base random forest [4], aim accur local gestur object class highli unbalanc problems. remark function distanc rang kinect user 1m 3.5m. place closer, difficult user head hand framed. place farther, kinect resolut ensur good perform propos system. nevertheless, propos algorithm adapt scale, provid consist perform suggest distanc range. final layer architectur contain applic control component. modul respons acquir detect track inform obtain compon middl block (head, hands, user recogn classifi gestures) map function list previou section. commun tv perform need interact (select rois, chang volume, pan-tilt-zoom panorama, etc.). control user interfac provid need feedback gui overlaid tv (fig. 2). 3.3 state diagram section describ state diagram current explain relat differ compon architecture. state diagram allow user perform specif gestur control system. applic control modul respons control gener statu perform transit states. end user need awar gener state diagram current state applic control compon inform user avail command stage feedback gui overlay. figur 4 show differ state possible. arrow fig. 4 state diagram gestur interfac multim tool appl yellow box indic gestur timeout transit interfac state one. start idl mode. state menu shown screen gestur avail ok control gestur (fig. 9). state, gestur local compon recogn ok gestur compon suspended. ok gestur detect gestur local component, user gestur take control interfac transit state. follow state user control recogn user present scene affect system. command mode princip state user interact system. state compon (head hand tracking, gestur local face identification) start report applic control. head track ensur user follow sub-sequ compon focu user control system. hand track track posit singl hand access menu gui overlay. select point singl hand menu item, wait second arrow shown, move hand direct arrow (like grab menu item centr screen). face identif recogn user allow access specif option interact system. finally, gestur local compon recogn 5 static gestur (fig. 9) applic control map follow functionalities: ok gestur (the user control system) idl mode. volum increas locat finger mouth lower put hand ear. volum complet mute cross sign mouth. video paus resum close hand (similar clapping). select menu shown gui overlay, interfac transit state navigation, roi select new user. state user command mode ok gestur wait second trigger timeout. navig mode allow user navig freeli panorama. mode menu shown screen hand user overlaid screen. user pan tilt panorama hand grab scene zoom hand (such map applic tablets). hand track compon respons track movement and, state, gestur local perform experiment result show increas false/posit detections. roi mode allow user navig avail roi move hand left right right left. also, hand track algorithm multim tool appl respons track hand user detect grab movement state possibl static gestures. finally, new user mode add new user system. mode creat new user model face identif component. 4 compon section compon (head hand tracking, gestur local face identification) present architectur system. 4.1 head track head track algorithm compos steps: head size estimation, head local search area resiz (fig. 5). head size estim foreground pixel, ellipt templat (e) size regular adult head (about 17 23 cm) place pixel depth level d project camera imag plane, obtain ellips appar head size (hx, hy) pixel dimens (see fig. 6). ellips call templat e head locat estimate. assum peopl interact tv stand-up seated, keep head vertical. head local aim find imag region better match (e), match score (e) global foreground mask (f) calcul pixel posit (m, n) image. match calcul rectangular search area size rx ry, slide e image. match score calcul accord condit ck present (1), b = background w = f oreground. condit check pixel posit (u, v) e template, center (m, n). condit ck sat- isfied, ck = 1, ck = 0. final match score pixel (m, n) fig. 5 head match score valu kinect sensor. differ situat present (from left right): view, view (with slight head tilt), far person long-hair person. cases, match score present maximum head zone multim tool appl fig. 6 head track snapshots. head templat (ellipses), search area (rectangles) obtain head locat (crosses) calcul sum score obtain templat pixels, shown (1) (fig. 5). c1u,v : (eu,v = b) (fu,v = b) c2u,v : (eu,v = w) (fu,v = w) (|du,v dhi | < dmax) c3u,v : (eu,v = b) (fu,v = w) (|du,v dhi | > dmax) mm,n = (u,v) (c1u,v + c2u,v + c3u,v) (1) pixel (m, n) higher score mh select best head posit esti- mation ph given search area. condit c2 c3 provid robust clutter partial occlusions, incorpor depth inform match score. search adapt posit size search area (rx, ry) adapt head posit varianc (x, y), confid estim m = mh mmax [0, 1], describ (2). rx = x + (1 + ) hx ry = y + (1 + ) hy = e m 1m (2) resiz effect fast head movements. example, horizont movement enlarg search area horizont axis. furthermore, in- clude match score (2) make robust noisi estimations. 4.2 hand track hand detect hand track reli robust head estim present section 4.1. hand suppos activ space place body. defin handbox virtual 3d box, attach head posit ph follow user head time instant, shown fig. 7. dens cluster search mean kd-tree structure, allow fast neighbor queri 3d point cloud [9]. list candid cluster obtain filter accord follow criteria: merg cluster merg singl cluster hausdorff distanc < min size filter result merg cluster filter size, keep largest on (size > smin) hand candidates. multim tool appl depth filter cluster fulfil previou criteria sort depth, keep- ing closer camera (up two). threshold min smin tune depend type camera scene. example, hand detect fig. 7. open/clos hand detect interact viewer render node increas determin user open close hands. propos comput area detect hand (section 4.2) threshold quickli decid close not. strategi assum observ area reason perpendicular camera. therefore, depth pixel replac mean depth observ region, simplifi physic area calculation. physic area open hand perpendicular camera 7090 cm2, whilst close hand 2030 cm2. reason set threshold 50 cm2 determin hand status. dynam gestur pan, tilt zoom angl panoram viewport control gesturing. navig panoram video perform seri gestur consist grab (close hand), move (while hand closed) releasing, screen piec tissue. pan tilt angl calcul depend current posit hand handbox . zoom case, grab (both hand closed), distanc hand calculated. zoom angl proport distance. addition, famili dynam gestur base trajectori included. setup, example, horizont movement consider speed (user-defined) util shift roi roi mode. tempor segment gestur perform entri exit point handbox, assum low initi speed hand handbox. fig. 7 caption propos approach, hand detect insid (green) handbox multim tool appl 4.3 gestur local gestur local build method propos [17], base class-specif (one-vs-all) random forest depth data. random forest localiza- tion depth data render effici local algorithm oper real- time realist conditions. impli detect gestur high accuraci presenc clutter unintent motion. local problem challeng main reasons. firstly, high unbal gestur non-gestur classes, non-gestur class contain set gestures, clutter unintent poses. secondly, accur segmentation, difficult accur model appear clutter limit number train samples. gestur local approach address issu main components: clipping: order better captur local appear static gestures, automat clip depth data local vicin train samples. manner, train prone over-fit problem caus learn specif background train data. boost learning: us specif learn approach deal high unbal train data [17]. advantag learn strategi random forest effici meaning sampl neg class. sake completeness, follow section summar detail approach propos [17] (extend version current submit ieee trans. mm). clip binari test random forest [4] ensembl m random trees, binari trees. tree train separ small subset train data obtain sampl replacement. learn base recurs split train data 2 subsets, accord binari test f threshold . binari test function featur vector v obtain train example. node tree, test f threshold randomli generated, maxim inform gain criteria selected. defin binari test base [31], introduc auxiliari paramet clip depth avail train examples. manner, test robust chang background, avoid segment step. specifically, clip paramet valu repres maximum minimum rel depth respect depth valu center pixel. formally, let denot clip parameter. then, given pixel x test f follow expression: f (i, x) = max ( min ( di ( x + u di(x) ) , di(x) + ) , di(x) ) max ( min ( di ( x + v di(x) ) , di(x) + ) , di(x) ) (3) di depth map associ imag u v randomli gener pixel displac fall patch size. pixel displac normal depth evalu pixel x order test featur invari depth changes. multim tool appl boost learn random forest local problem pose paper, gestur non-gestur class natur unbalanced. hand, real applic user constantli perform gestures. hand, actual appear gestur repres rel low number pixels. sum up, distribut gestur class (positive) respect non- gestur (negative) bias latter. unbal make low fals posit rate constitut actual larg number fals posit votes. take account phenomenon import train phase random forest since, unbalance, difficult optim inform gain. order overcom problem, adopt boost learn scheme, design tree-wis manner follows: train tree balanc set sampl class. tree trained, evalu out-of-bag set [4]. wrongli classifi sampl ad train set second tree (up maximum number train samples). new train set complet sampl replac train set balanc achieved. train second tree train subset repeat process forest fulli trained. gestur local gestur detect localization, set patch provid detect forest, cast vote posit class probabl neg class posit classes. figur 8 illustr cast vote posit class class-specif learn example. detect gesture, estim probabl densiti vote frame account tempor consist recurs updat distribut vote aggreg past time instants. order construct probabl density, us parzen estim gaussian kernel. order account time compon approxim density, sequenti updat densiti p(c|it) follows: p(c|it) = p(c|it) + (1 )p(c|it1) (4) (a) (b) fig. 8 gestur local random forest (best view color). number vote (green dots) cast target gestur b vote aggreg estim probabl densiti (overlaid red input depth map) local estim (green square) multim tool appl simpl effect method tempor consist cast votes, requir store singl probabl map. adapt rate = 0.8 work practice, prevent fals posit avoid delai response. finally, comput pixel locat gc gestur class c > 0 pixel locat maximum probability. ensur maximum repres target gestur threshold probabl volum v comput local integr estim pseudo-prob measure: v = xs p(c|it(x)) (5) s circular surfac element radiu invers proport depth, center global maximum. way, local depth-invariant. effici reasons, approxim segment scene relev non- relev pixel threshold depth valu znear = 0.8 m zfar = 3.5 m. user control perform gestur ok, emploi head track algorithm result (section 4.1) comput region interest, 4 gestur class-specif forest evaluated. way, run detect forest real-time. besides, region help discard gestur user perform, increas detect accuraci (fig. 9). 4.4 face identif purpos face identif allow user select prefer base ident enabl establish hierarchi user applic parent control. continu monitor environ offer possibl video-bas face recognition. permit improv perform face recognit singl imag captures. workflow face id following: face detect place forward face recognit module. face id compar test imag set model consist imag person, creat off-lin imag previou recordings. test face, set score defin probabl repres person model produced. finally, fusion modul combin individu result tempor group imag person final decision. fig. 9 exampl success local result approach ( = 15 cm) volum down, volum up, control, mute paus multim tool appl following, analyz modul (detection, imag identif tempor fusion). face detect face detect modul cascad head track module, describ section 4.1. face detect perform insid reduc region defin head tracker. allow reduc comput complex low probabl fals positives. us opencv [3] face detect modul reli adaboost cascad haar features, i.e. viola-jon algorithm [36]. application, user gener interact face camera. restrict detect frontal faces, allow pose variations. singl imag face recognit face recognition, set meaning face charac- terist extract form featur vector. vector convei relev inform face. featur extract techniqu base local binari pattern (lbp) [21] used. lbp oper non-parametr kernel repres local spatial structur image. provid high discrimin power textur classif good illumin invariance, unaffect monoton gray-scal transform preserv pixel intens order local neighborhood. pixel position, lbpp,r defin order set binari comparison intens center pixel intens center pixel p surround pixels, taken circumfer radiu r. decim form result lbp code express follows: lbp(xc, yc) = p n=1 s(in ic)2n (6) ic correspond grei valu center pixel (xc, yc), grei valu p surround locations. function s(x) defin as: s(x) = { 0 x < 0 1 x 0 (7) method base [1] pixel lumin compon face, lbp8,2 represent computed, is, 8 sampl taken circumfer radiu 2 pixel. result transform imag partit non-overlap squar block 7 7 pixels. featur vector form concaten histogram lbp valu block. result 49 local 64 bin histogram (face imag resiz 49 49). final featur vector dimension 3,136. k nearest neighbor (knn) classifi [6] obtain final decision. knn modifi vote penal invers distanc test vector t select neighbor, wai bigger distance, penalization. ki invers distanc normal overal sum k nearest neighbor invers distanc classes, lead posteriori probabl class [6]. probabl class allow classifi estim score confid classif test vector is. multim tool appl chi-squar distanc (8) compar featur vector shown perform better euclidean histogram base features. 2 (v1, v2) = (v1,i v2,i)2 v1,i + v2,i (8) v1 v2 featur vectors. model individu databas creat off-line, sequenc imag collect differ session test recordings. 150 train imag subject used, extract automat small ad-hoc recordings. tempor fusion face detect cascad head detect modul perform tempor track detect heads, ensur ident person maintain track, video base recognit used. tempor fusion combin inform imag perform recognition. face detection, track compos t consecut face imag individual. face identif algorithm comput vector score si singl frame. simpl score fusion scheme used, base averag score track. instantan final decis comput take averag ns score vector select class highest score. 5 experiment result user evalu evalu propos divid differ parts. one, object evalu differ technic compon performed. case, head hand tracking, gestur local face identif evalu object metric similar method state art. second part, entir evalu subject end user low prior knowledg system. experiment results, propos implement complet gestur control interfac panoram tv content creat standalon demonstrator. described, demonstr compos multipl algorithm connect differ ways; run independ parallel, need signal synchron run serial one. therefore, care signal share them. demonstr implement follow hardware: microsoft kinect sensor captur depth color video laptop 8 cpu (at 6 needed) 8gb ram us debian oper follow open-sourc libraries: openni captur driver kinect sensor smartflow transport commun middlewar opencv support face detect algorithm multim tool appl pointcloudlibrari (pcl) boost c++ librari algorithm describ section 4 (head hand tracking, gestur local- ization, face recognit applic control) implement c++ intern library. 5.1 object evalu technic compon section evalu perform individu compon present system. head track evalu analyz conveni condit c2 c3 (1), robust increas includ depth data queues. compar propos scheme limit version verifi condit c1. way, contribut c2 c3 shown. head locat error ground-truth (manual marked) head posit gh estim head locat calcul = |gh ph|, present fig. 10 version algorithm. note that, c1 plai role 2d method, depth data initi head size estimation. figur 10 show frame frame error c1 + c2 + c3 compar c1. c1 version lose target twice, reset algorithm need (frame 74 398). label arrow fig. 10 correspond advers clutter occlus situations. propos algorithm present error 10 pixels, head radius. hand track evalu tabl 1 summar averag error differ one- hand two-hand trajectories, comput averag 3d error (with respect fig. 10 error obtain head locat estim ground-truth multim tool appl tabl 1 hand detect 3d accuraci differ gestur trajectori # frame error r hand error l hand (cm) (cm) push 30 2.62 circl 30 6.61 replai 35 2.86 hand up-down 115 5.87 separ hand 75 2.36 3.80 ground-truth hand positions) durat movements. ground-truth trajectori extract hand, select reason hand center vari cm frames. despit advers noisi conditions, hand estim error rare goe 10 cm. averag error higher fast movements, result 6 cm error. gestures, error 3 cm, fairli adequ given size human hand. sake illustration, sampl zoom gestur includ fig. 11, show detect error ground-truth trajectori detect one. gestur local evalu conduct experi gestur local method provid quantit perform approach determin optim clip parameters. focu gestur defin fig. 9. record 5 train sequenc 5 differ actor perform set gestur actions, includ 5 target gestur classes. additionally, record 6 test sequenc 4 addit actor includ train set. emploi detect forest 15 tree maximum depth 20, tree train approxim 20,000 exampl class. fig. 11 ground-truth estim trajectori (r)ight (l)eft hands. estim hand posit nice close refer ground-truth positions. xy project 3d trajectori shown multim tool appl tabl 2 averag area curv (auc) differ learn approach method volum volum ok mute paus averag boost [10] 0.17 0.10 0.31 0.14 0.02 0.15 0.17 0.10 0.31 0.20 0.25 0.21 + = 15 cm 0.58 0.53 0.81 0.47 0.11 0.50 + = 30 cm 0.69 0.50 0.54 0.27 0.14 0.42 + = 50 cm 0.59 0.46 0.61 0.24 0.18 0.41 bold entri correspond best method column kei cases, emploi squar patch size 85 85 pixels. train class- specif forest boost learn method. additionally, order compar learn method, implement boost approach base [10]. measur accuraci propos methods, consid correct localiza- tion estim gestur actual gestur belong class estim locat radiu 10 pixels. comput curv repres 1-precis vs recal comput area curv (auc). averag auc gestur class shown tabl 2. comparison differ train approach clip ( parameter) show propos boost learn yield overal better performance. propos learn approach outperform boost scheme propos [10]. face identif icat evalu evalu face recognit levels. place, single-fram face id algorithm tested. measur abil recogn person given uniqu test frame. then, evalu perform fusion algorithm, us face track allow combin consecut individu result robust decision. design work small group peopl share access tv set (for instance, family). have mind, 12 individu record demo sessions: creat model second testing. gestur involv put hand face camera, good number partial face occlusions. pose frontal variat user look differ corner screen. medium degre express variabl user ask behav normal system. tabl 3 show result singl frame tempor fusion face id. occlus restrict settings, good number frame face detected. problem setup decis provid regular interv (currently, seconds). seen singl frame, identif result good, 37 error 6,605 detect faces. tempor fusion, ident person segment given correctly. tabl 3 face id result # frame detect error (%) singl frame 8,716 frame 6,605 frame 0.56 tempor fusion 266 segment 0.0 multim tool appl tabl 4 usabl questionnair question mean standard deviat 1. like interfac 4.13 0.96 2. interfac pleasant us 3.81 0.98 3. simpl us 4.00 0.73 4. easi learn us 4.31 0.79 5. organ inform present clear 4.25 0.68 6. inform provid easi understand 4.50 0.52 7. navig panoram video pleasant us 3.47 0.99 8. navig interfac menu item comfort 3.94 1.00 9. respond effect gestur 3.19 0.98 10. task 1 (zoom specif scene) easi perform 3.88 1.31 11. task 2 (chang audio volume) easi perform 4.13 1.36 12. task 3 (region selection) easi perform 4.00 0.89 13. felt comfort 3.63 0.89 14. overall, satisfi 3.69 0.87 sentenc mean standard deviat respons 15 particip (stronglydisagre = 1, . . ., stronglyagre = 5) test perform user good result (abov 96 % recognit rate) obtain 50 people. 5.2 usabl evalu order valid design interfac conduct usabl study. select set participants, ask interact answer questionnaire. usabl studi deriv similar studi recent conduct evalu gestur control interfac elderli [2]. procedur following: 1. first, user watch short video us interface.1 2. then, interact freeli familiar functionalities. 3. ask perform 3 specif conceptu tasks: chang volum (up, mute); zoom defin scene; select certain roi. 4. finally, answer questionnaire. total, number particip 15. question 5 answer choic accord degre agreement sentenc (strongli disagre = 1,. . ., strongli agre = 5). sentenc mean standard deviat result shown tabl 4. general, user satisfi perform effect assign task short time. success aspect user experi relat us static gestur activ control 1the video avail multim tool appl functions. report participants, simpl use, easi learn gui clear. respons accord observ participants, conclud select gestur intuit easi perform. moreover, us static gestur shortcut perform action reduc inform requir gui, improv clarity. navig panoram video successful. reason fact interact paradigm chosen zoom pan (i.e hand gestur hand open close simul touch virtual tablet user) result comfort intuit participants. research requir improv usabl studi offer insight better user experience. 6 conclus futur work paper present gestur recognit interfac design control tv set provid immers view functionalities, navig panorama. work device-less marker-less manner allow user control content displai hands. automat locat peopl want interact understand recogn small set natur easy-to-learn gestures. object evalu technolog integr result competit similar techniqu state art. complet integr evalu subject group 15 user overal satisfi simplic intuit interface. futur work includ extens gestur local success- fulli detect recogn fingers, order explor wai includ finger gestur pre-defin gestur database. perform user evalu studies, plan improv usabl navig panoram video order improv respons limit fatigu caus users. refer 1. ahonen t, hadid a, pietikainen m (2006) face descript local binari patterns: applic face recognition. ieee tran pattern anal mach intel 28(12):20372041. doi:10.1109/tpami.2006.244 2. bhuiyan m, pick r (2011) gestur control user interfac inclus design evalu- ativ studi usability. j softw eng appl 4(9):513521 3. bradski g (2000) opencv library. dr. dobb journal softwar tool 4. breiman l (2001) random forests. mach learn 45(1):532 5. demirdjian d, varri c (2009) recogn event tempor random forests. in: proceed- ing 2009 intern confer multimod interfaces, icmi-mlmi 09. acm, new york, pp 293296. doi:10.1145/1647314.1647377 6. duda r, hart p, stork d (2001) pattern classification, 2nd edn. wiley, new york 7. fascinate: format-agnost script-bas interact experience. access 28 feb 2013 8. frances r, passero i, tortora g (2012) wiimot kinect: gestur user interfac add natur dimens hci. in: proceed intern work confer advanc visual interfaces, avi 12. acm, new york, pp 116123. doi:10.1145/2254556.2254580 9. friedman jh, bentlei jl, finkel ra (1977) algorithm find best match logarithm expect time. tran math softw 3(3):209226. doi:10.1145/355744.355745 multim tool appl 10. gall j, yao a, razavi n, van gool l, lempitski v (2011) hough forest object detec- tion, tracking, action recognition. ieee tran pattern anal mach intel 33(11):21882202. doi:10.1109/tpami.2011.70 11. gesturepak: gestur record recognit toolkit. access 20 feb 2013 12. jaim a, sebe n (2007) multimod humancomput interaction: survey. comput vi imag underst 108(12):116134. doi:10.1016/j.cviu.2006.10.019 (special issu vision human- interaction) 13. ji q, wechsler h, duchowski a, flickner m (2005) editorial: special issue: ey detect tracking. comput. vis. imag underst. 98(1):13. doi:10.1016/j.cviu.2004.07.006 14. kinect window sdk. access 20 feb 2013 15. lausberg h, sloetj h (2009) code gestur behavior neuroges-elan system. behav re method 41(3):841849 16. liu j, zhong l, wickramasuriya j, vasudevan v (2009) uwave: accelerometer-bas per- sonal gestur recognit applications. pervas mobil comput 5(6):657675. doi:10.1016/j.pmcj.2009.07.007 (percom 2009) 17. lpez-mndez a, casa jr (2012) tv robustli understand human gestures?: real-tim gestur local rang data. in: proceed 9th european confer visual media production, cvmp 12. acm, new york, pp 1825. doi:10.1145/2414688.2414691 18. nielsen m, strring m, moeslund t, granum e (2004) procedur develop intuit ergonom gestur interfac hci. in: camurri a, volp g (eds) gesture-bas communica- tion human-comput interaction. lectur note science, vol 2915, pp 409420. springer berlin heidelberg 19. norman da (2010) natur user interfac natural. interact 17(3):610 20. nui group community. access 23 feb 2013 21. ojala t, pietikinen m, harwood d (1996) compar studi textur measur classif base featur distributions. patt recogn 29(1):5159 22. openni sdk. access 20 feb 2013 23. pantic m, rothkrantz ljm (2000) automat analysi facial expressions: state art. ieee tran pattern anal mach intel 22(12):14241445. doi:10.1109/34.895976 24. talk wave samsung remote-fre tv. electronics/audiovideo/ces-2012-talking-and-waving-to-samsungs-remotefree-tv. access 24 feb 2013 25. popp r: vision-bas human motion analysis: overview. comp vision imag underst 108(12):418 (2007). doi:10.1016/j.cviu.2006.10.016 (special issu vision human-comput interaction) 26. potamiano g, neti c, luettin j, matthew (2004) audio-visu automat speech recognition: overview. issu visual audio-visu speech processing, pp 356396 27. pugeault n, bowden r (2011) spell out: real-tim asl fingerspel recognition. in: iccv- cdc4cv 28. ren z, yuan j, zhang z (2011) robust hand gestur recognit base finger-earth mover distanc commod depth camera. in: acm mm, mm 11. acm, new york, pp 1093 1096. doi:10.1145/2072298.2071946 29. schlmer t, poppinga b, henz n, boll s (2008) gestur recognit wii controller. in: proceed 2nd intern confer tangibl embed interaction, tei 08. acm, new york, pp 1114. doi:10.1145/1347390.1347395 30. sebe n (2009) multimod interfaces: challeng perspectives. j ambient intel smart envi- ron 1(1):2330 31. shotton j, fitzgibbon a, cook m, sharp t, finocchio m, moor r, kipman a, blake (2011) real-tim human pose recognit part singl depth images. in: cvpr, pp 12971304. doi:10.1109/cvpr.2011.5995316 32. stern hi, wach jp, edan y (2008) design hand gestur vocabulari natur interact combin psycho-physiolog recognit factors. int j semant comput 02(01):137 160. doi:10.1142/s1793351x08000385 33. suau x, ruiz-hidalgo j, casa jr (2012) real-tim head hand track base 2.5d data. tran multim 1(99):1 34. turk m (2001) gestur recognition. handbook virtual environ technolog 35. uebersax d, gall j, van den bergh m, van gool l (2011) real-tim sign languag letter word recognit depth data. in: iccv-hci, pp 18 multim tool appl 36. viola p, jone mj (2004) robust real-tim face detection. int j comput vision 57(2):137154 37. wach jp, klsch m, stern h, edan y (2011) vision-bas hand-gestur applications. commun acm 54(2):6071 38. zhao w, chellappa r, phillip pj, rosenfeld (2003) face recognition: literatur survey. acm comput surv 35(4):399458. doi:10.1145/954339.954342 39. zigfu. motion control web. access 20 feb 2013 marcel alcoverro receiv b.s.c. telecommun 2007 master degre comput- ing 2009 technic univers catalonia (upc). 2007 work research assist equip traitement de imag et du signal (etis) institut delectroniqu et dinformatiqu gaspard-mong (igm) paris, france, take eros-3d project artwork 3d databases. current work imag process group upc ph.d degre involv project spanish scienc technolog (vision) european fp project (actibio, fascinate). research interest includ markerless motion capture, gestur recognition, 3d video process 3d graphics. xavier suau receiv degre telecommun engin universitat politcnica catalunya (upc), barcelona, spain 2007. receiv degre aeronaut engin ecol national laronautiqu et lespac (supaero), toulouse, franc 2007. multim tool appl septemb 2007 receiv master research automatics, informat decision system supaero. msc research carri gener navig system research depart thale avionics, valence, france. 2008 join thale avion full-tim research airbu a350-xwb navig project. octob 2009 phd student imag video process group upc. taken hesperia project develop algorithm compens illumin foreground extract applications. current work focus exploit rang inform featur extract bodi pose estimation, framework phd fp7 fascin project. josep r. morro josep ramon morro rubi receiv degre physic universitat barcelona (ub), barcelona, spain, 1989. receiv ph.d. universitat politcnica catalunya (upc) 2004. 1989 short stai research institut technic physic hungarian academi sciences, divis semiconductor microwav devices, budapest, hungary. 1989 1990 work mediterrnia denginyeria programm network administrator. 1991 1993 work instrumentacin electrnica promax, respons technic document department. octob 1994 februari 1997 teach telecommun upc. februari 1997, join escola universitria politcnica matar eupmt, matar, spain, taught electron scienc june 2001. gave cours pc hardwar sc2 formaci years. 2003 join universitat politcnica catalunya current associ professor. lectur area communications, signal processing, digit imag process acoustics. current research interest includ imag sequenc coding, segment problem video sequenc analysis. 1994 involv european project (mavt, momusys, similar, chil, fascin ...) research imag video process group upc. 2005 charg halfton compress investig project collabor hewlett packard espaola. 2005 2007 he act leader face tracking/detect task chil project. multim tool appl adolfo lpez-mndez receiv b.s.c. (2007) master degre signal theori commu- nicat (2009) technic univers catalonia (upc), current work ph.d degree. research interest includ action gestur recognition, markerless motion capture, 3d video process machin learning. adolfo recent involv fp7 project chil, actibio fascinate. albert gil receiv degre electr engin universitat politcnica catalunya (barcelonatech) work softwar design depart soni viladecavalls. 2007 join imag process group design softwar develop platform, collabor softwar librari applic differ project work manager. im mainli interest ubiquit computing, vision softwar design join master comput program upc mainli collabor project relat smartroom. multim tool appl javier ruiz-hidalgo receiv degre telecommun engin universitat politcnica catalunya (upc), barcelona, spain 1997. 1998 1999, develop msc research field vision univers east anglia (uea) norwich, uk. 1999 join imag process group upc work imag video index context mpeg-7 standard obtain phd thesi 2006. 1999 involv european project research imag process group upc. 1999 2000 work act (ac308) diceman project develop new descriptor represent imag video sequences. 2001 2003 involv ist/fet (2000-26467) project mascot develop effici compress scheme exploit metadata information. 2006 princip investig hesperia (cenit-2006) project involv develop new imag algorithm secur applications. 2001 associ professor universitat politcnica catalunya. current lectur area digit signal system imag processing. current research interest includ imag segmentation, imag sequenc coding, compress indexing. josep r. casa associ professor depart signal theori communication, technic univers catalonia (upc) barcelona. graduat telecommun engin 1990 receiv phd 1996, upc, current teach signal systems, imag process televis system school telecommun engin (telecom bcn). visit research csiro mathemat & inform multim tool appl scienc canberra, australia 2000 2001. josep r. casa princip investig project provec (video process control environments) spanish r&d&i plan start 2007, led contribut number industry-sponsor projects, project spanish scienc technolog (vision, hesperia) european fp project (actibio, schema, advisor). particular, coordin upc contribut chil (comput human interact loop), ip ist/eu 6th framework program strateg object multimod interfaces, involv video, audio natur languag technologies. josep r. casa author co-author 10 paper intern journals, 12 paper lncs, 50 contribut confer 9 book chapter teach book area video coding, analysis, index imag processing. gestur control interfac immers panoram displai abstract introduct relat work design user experi design aspect architectur state diagram compon head track hand track gestur local face identif experiment result user evalu object evalu technic compon usabl evalu conclus futur work refer