











































Data-based models for the prediction of dam behaviour:

a review and some methodological considerations

F. Salazar1,∗, M.Á. Toledo2, E. Oñate1, R. Morán2

Abstract

Keywords: Dam monitoring, Dam safety, Data analysis, Machine learning,
Statistical models, Behaviour models

1. Introduction

Behaviour models are a fundamental component of dam safety systems,
both for the daily operation and for long-term behaviour evaluation. They
are built to calculate the dam response under safe conditions for a given load
combination, which is compared to actual measurements of dam performance
[1]. The result is an essential ingredient for dam safety assessment, together
with visual inspection and engineering judgement [2].

Numerical models based on the finite element method (FEM) are widely
used to predict dam response, in terms of displacements, strains and stresses.
They are based on the physical laws governing the involved phenomena, what
gives them some interesting features: a) they are useful for the design and,
importantly, for dam safety assessment during the first filling, and b) they
can be conveniently interpreted, provided that their parameters have physical
meaning.

∗Corresponding author
Email addresses: fsalazar@cimne.upc.edu (F. Salazar),

matoledo@caminos.upm.es (M.Á. Toledo), onate@cimne.upc.edu (E. Oñate),
rmoran@caminos.upm.es (R. Morán)

URL: www.cimne.com (F. Salazar)
1International Center for Numerical Methods in Engineering (CIMNE). Campus Norte

UPC. Gran Capitán s/n. 08034. Barcelona, Spain
2Technical University of Madrid (UPM). Civil Engineering Department: Hydraulics

and Energy. Profesor Aranguren s/n, 28040, Madrid, Spain

Preprint submitted to To be determined September 18, 2014



On the contrary, some relevant indicators of dam safety, such as uplift
pressure and leakage flow in concrete dams, cannot be predicted accurate
enough with a numerical model [3], [4]. In addition, the knowledge on the
stress-strain properties of the dam and foundation materials is always limited
[5], and so is the prediction accuracy of FEM models [2].

These limitations, together with the availability of monitoring data, have
fostered the application of statistical models to predict dam response. They
have been used in dam safety analyses for decades as a complement to visual
inspection and numerical models, to support decision making.

In recent years, there is a tendency towards automatising dam monitoring
devices [2], what allows increasing the reading frequency and results in a
greater amount of data available. On the one hand, it invites to extract as
much information as possible in relation with dam safety condition [6]. On
the other hand, it has revealed certain limitations of traditional statistical
tools to manage dam monitoring data [7].

On another note, advanced tools have been developed in the machine
learning (ML) community to build data-based predictive models. They have
been applied in various fields of science and engineering, where similar prob-
lems have emerged even more dramatically, provided that the amount of data
is much larger or the underlying phenomena is much less understood. This
is the case, for example, of medicine, e-commerce, smartphone applications,
econometrics or business intelligence, among others. Most of these tools ex-
clusively rely on data to build predictive models, i.e. no prior assumptions
on the physics of the phenomenon have to be made beforehand [8].

The limitations of traditional statistical tools and the availability of these
advanced learning algorithms have motivated dam engineers to search the
possibilities of the latter for building dam behaviour models, as well as for
analysing dam behaviour.

The paper reports a review on dam behaviour models based on monitor-
ing data. The work focuses on prediction accuracy, although it also refers to
model suitability for interpreting dam performance. The most popular tech-
niques are dealt with in section 2, whereas some common issues in building
data-based models and evaluating their results are analysed in section 3. The
analysis is performed on the basis of the review of 39 papers on the field.

2



2. Statistical and machine learning techniques used in dam moni-
toring analysis

The aim of these models is to predict the value of a given variable Y ∈ R
(e.g. displacement, leakage flow, crack opening, etc.), in terms of a set of
inputs3 X ∈ Rd:

Y = Ŷ + ε = F (X) + ε (1)

ε is an error term, which encompasses the measurement error, the model
error, and the deviation of the dam response from the expected behaviour
[1]. This term is important, given that it is frequently used to define safety
margins and warning thresholds [2].

The models are fitted on the basis of a set of observed input data xi,
and the correspondent registered outputs yi, where i = 1, ..., N and N is the
number of observations. Note that each xi is a vector of d components, being
d the number of inputs.

The inputs may be of different nature, depending on the method:

• Raw data recorded by the monitoring system: reservoir level (h), air
temperature (T ), etc.

• Variables derived from observed data:

– Polynomials

– Moving averages

– Derivatives

2.1. Hydrostatic-seasonal-time (HST) model

The most popular data-based approach for dam monitoring analysis is
the hydrostatic-seasonal-time (HST) model. It was first proposed by Willm
and Beaujoint in 1967 [9] to predict displacements in concrete dams, and has

3Traditionally, the statistical models applied in dam monitoring analysis were based
on causal variables, e.g., hydrostatic load and temperature, which are often termed “inde-
pendent variables”. On the contrary, other algorithms make use of transformed variables
(such as gradients or moving averages), and non-causal observations (e.g. the previous
value of the output). This has led to the use of various terms to refer to the model inputs,
such as “predictors”, “covariates”, and “features”. In this paper they are used indistinctly.

3



been widely applied ever since. It is based on the assumption that the dam
response is a linear combination of three effects:

Ŷ = F1 (h) + F2 (s) + F3 (t) (2)

• A reversible effect of the hydrostatic load which is commonly considered
in the form of a fourth-order polynomial of the reservoir level (h) [1],
[10], [11]:

F1 (h) = a0 + a1h+ a2h
2 + a3h

3 + a4h
4 (3)

• A reversible influence of the air temperature, which is assumed to follow
an annual cycle. Its effect is approximated by the first terms of the
Fourier transform:

F2 (s) = a5cos(s) + a6sen(s) + a7sen
2(s) + a8sen(s)cos(s) (4)

where s = 2πd/365.25 and d is the number of days since 1 January.

• An irreversible term due to the evolution of the dam response over time.
A combination of monotonic time-dependant functions is frequently
considered. The original form is [9]:

F3 (t) = a9log(t) + a10e
t (5)

The model parameters a1...a10 are adjusted by the least squares method:
the final model is based on the values which minimise the sum of the squared
deviations between the model predictions and the observations.

Some authors used variations of the original HST model, by using some
heuristics or after a trial-and-error process. Mata [12] considered the irre-
versible effect by means of F3 (t) = a9t + a10e

−t. Chouinard and Roy [13]
used a linear term in t and a third-order polynomial of h. Simon et al. [11]
chose F3 (t) = a9e

−t + a10t+ a11t
2 + a12t

3 + a13t
4, whereas Yu et al. [14] used

F3 (t) = a9t + a10t
2 + a11t

3. Carrère applied a variation of HST in which
the possibility of a sudden change in the dam response at a certain time is
considered by adding a step function to the irreversible term [15].

The method makes use of strong assumptions on the response of the dam,
which might not be accurate in general. In particular, the three effects are
considered as independent, although it is well known that certain collinearity
exists. The reservoir level affects the thermal response of the dam, provided

4



that the air and water temperatures differ [16]. In some cases, the reser-
voir operation follows an annual cycle due to the evolution of the water
demand, so there is a strong correlation between h and T [3], [17], [18], [19].
Collinearity may lead to poor prediction accuracy and, more importantly, to
misinterpretation of the results [20].

Another limitation of the original form of HST model is that the actual
air temperature is not considered. On one hand, this makes it more flexible,
because it can be applied in dams where air temperature measurements are
not available. On the other hand, it reduces its prediction accuracy for
particularly warm or cold years [16], [17].

Several alternatives have been proposed to overcome this shortcoming.
Penot et al. [21] introduced the HSTT method, in which the thermal periodic
effect is corrected according to the actual air temperature. This procedure
has been applied at Electricité de France (EDF) [16], [22] with higher accu-
racy than HST, especially during the 2003 European heat wave. Although
the proposal of this method has been frequently attributed to Penot et al.,
Breitenstein et al. [23] applied a similar scheme 20 years earlier.

Other common choice is to replace the periodic function of the thermal
component by the actual temperature in the dam body, resulting in the
hydrostatic-thermal-time (HTT) method. One difficulty of this approach is
how to select the appropriate thermometers among those available. In arch
dams, some authors only consider the thermometers in the central cantilever,
assuming that it represents the thermal equilibrium between cantilevers in
the right and left margins [17]. Mata et al. [24] solved this issue by applying
principal component analysis (PCA), while other authors [18] considered all
the available instruments.

Although HST was originally devised for the prediction of displacements
in concrete dams, it has also been applied to predict other variables. Simon
et al. [11] estimated uplifts and leakage with HST, although they obtained
more accurate results with neural networks (NN). Guedes and Coelho [25]
built a model for the prediction of leakage in Itaipú Dam with the form
a1h

2
6,11 + a2t + a3t

2 + a4log (1 + t), where h6,11 is the average reservoir level
between 6 and 11 days before the measurement. Breitenstein et al. [23] also
studied leakage, although they discarded both the seasonal and the temporal
terms. Yu et al. [14] combined HST with PCA to predict the opening of a
longitudinal crack in Chencun Dam.

A common feature to HST and its variations is that the output is com-
puted as a linear combination of the inputs. Hence, they are all multi-lineal

5



regression models (MLR), so their coefficients can be fitted by least squares.
Other approaches based on MLR have been applied in dam safety, consider-
ing a larger set of inputs (e.g. [26], [27]).

2.2. Models to account for delayed effects

It is well known that dams respond to certain loads with some delay [4].
The most typical examples are:

• The change in pore pressure in an earth-fill dam due to reservoir level
variation [28].

• The influence of the air temperature in the thermal field in a concrete
dam body [11].

Other phenomena have been identified which are governed by similar
processes. For example, Lombardi [3] noticed that the structural response
of an arch dam to hydrostatic load comprised both an elastic and a viscous
components. Hence, the displacements not only depended on the instanta-
neous reservoir level, but also on the past values. Simon et al. [11] reported
that leakage flow at Bissorte Dam responded to rainfall and snow melt with
certain delay.

Several approaches have been proposed to account for these effects. The
most popular consists on including moving averages or gradients of some ex-
planatory variables in the set of predictors. In the above mentioned study,
Guedes and Coelho [25] predicted the leakage flow on the basis of the mean
reservoir level along a five-days period. Sánchez Caro [29] included the 30
and 60 days moving average of the reservoir level in the conventional HST
formulation to predict the radial displacements of El Atazar Dam. Popovici
et al. [30] used moving averages of 3, 10 and 30 days of the air temperature,
together with the pool level in the previous 3 days to the measurement to
predict displacements in a buttress dam with neural networks (NN). Crépon
and Lino [31] reported significant improvement in the prediction of piezo-
metric levels and leakage flows by considering the accumulated rainfall and
the derivative of the hydrostatic load as predictors.

This approach requires a criterion to determine which moving averages
and gradients should be considered for each particular case. Demirkaya and
Balcilar [27] performed a sensitivity analysis to select the number of past
values to include both in an MLR and in a NN model. They used the
same period for the external and internal temperatures, as well as for the

6



reservoir level, and found that the most accurate results were obtained with
an MLR model considering data from 30 previous days. Although their
results compared well to those proposed by the participants in the 6th ICOLD
Benchmark Workshop4 [32], they lacked physical meaning: they would imply
that the dam responded with the same delay to the water level, the air
temperature, and the internal temperature field.

Santillán et al. [33] proposed a methodology to select the optimal set
of predictors among various gradients of air temperature and reservoir level.
They used the gradients instead of the moving averages to ensure indepen-
dence among predictors (moving averages are correlated with the original
correspondent variables). They combined it with NN to predict leakage flow
in an arch dam.

A more formal alternative to conventional HST to account for delayed
effects was proposed by Bonelli and Royet [34]. It is based on the hypothesis
that the delayed effect depends on the convolution integral of the impulse
response function (IRF) and the loadings:

Ŷ = α
1

t0

∫ t
0

e
−
(

t·t′
t0

)
h (t′) ∂t′ (6)

where α is a damping coefficient, t0 is the characteristic time, which de-
pends on the phenomenon, and h (t′) is the reservoir level at time t′. Although
the analytical integration of this function is cumbersome, it can be solved
by means of numerical approximation. The advantage of this approach is
that the coefficients have physical meaning: the characteristic time provides
insight into the lag with which the dam reacts to a variation in the input
variable, whereas the damping reflects the relation between the amplitude
of the reservoir level variation and that of the pore pressure in the location
considered within the dam body.

A similar approach was followed by the same author in the frame of the
above mentioned 6th ICOLD Benchmark Workshop [10]. In this case, it
was intended to account for the delayed response of the dam in terms of the
temperature field, with the final aim of predicting radial displacements.

4In the 6th ICOLD Benchmark Workshop, the participants were asked to provide a
data-based model for predicting the radial displacement of Schlegeiss arch dam for the
period 1999-2000. Time histories of water level, air temperature and concrete temperatures
at various locations were provided for the period 1992-2000, as well as the observed values
of the target variable for the period 1992-1998.

7



Lombardi et al. [3] suggested an equivalent formulation, also to compute
the thermal response of the dam to changes in air temperature. Although
the development was slightly different, the numerical approximation to the
integral is totally equivalent. Lombardi arrived to the following expression
[4]:

Ŷ (t) = α ·Y (t−∆t)+
(

1 +
α

β
−

1

β

)
X (t)+

(
1

β
−
α

β
− α

)
X (t−∆t) (7)

where α = e
−∆t
t0 , β = ∆t

t0
, and ∆t is the measurement interval. It should

be noticed that the numerical integration of (6) by means of (7) leads to a
predictive model which is a linear combination of:

• the value of the predictors at t and t−∆t

• the value of the output variable at t−∆t

This is the conventional form of a first order auto-regressive (AR) model
with exogenous inputs. In general, AR models require specific algorithms to
determine the appropriate order of the model for a given case, i.e., the amount
of past values to consider for the output and each of the input variables. Next
section is devoted to this issue and to AR models.

In practice, the transformed of an input with equation (7) is similar to a
weighted moving average (WMA) [4]. Figure 1 shows the comparison between
both transformations of 4 inputs: a) a sinusoidal, b) a random variable, c)
a cyclic variable with random noise and d) an isolated pulse. It can be
seen that the transformed of a sinusoidal can be accurately modelled with
an appropriate moving average. The difference between IRF and WMA is
greater for random inputs, and the discrepancy increases as the signal-to-
noise ratio decreases.

IRF has the advantage of its physical meaning, and has offered accurate
results for determined outputs. Nonetheless, given that it makes a strong
assumption on the characteristics of the phenomenon, it is restricted to spe-
cific processes. Even when applied to a similar phenomenon, such as the
effect of precipitation on the pore pressure on an earth-fill dam, the accuracy
decreases [34]. Moreover, the coefficients lose their physical meaning in this
case.

8



−20

−10

0

10

20

0.0 0.3 0.6 0.9
t (years)

0

10

20

30

0.0 0.3 0.6 0.9
t (years)

0

10

20

30

40

50

0.0 0.3 0.6 0.9
t (years)

0

10

20

30

40

0.0 0.2 0.4 0.6
t (years)

IRF
WMA

INPUT
IRF
WMA

INPUT

IRF
WMA

INPUT

IRF
WMA

INPUT

(a)

(b)

(c)

(d)

Figure 1: Comparison between impulse response function (IRF) and weighted moving
average (WMA) for various inputs: a) sinusoidal, b) random, c) sinusoidal with random
noise and d) impulse.

2.3. Auto-regressive (AR) models

The use of the previous (lagged) value of the output to calculate a pre-
diction for current record may induce to question a) whether the observed
previous value or the precedent prediction should be used, and b) whether
the model parameters should be readjusted at every time step.

In general, using actual previous value and refitting the model should
provide better prediction accuracy, but such model would not be able to
detect anomalies: it would learn the abnormal behaviour and treat it as
ordinary [3]. It depends on the data acquisition frequency and the kind of

9



anomaly. Only sharp changes in dam response, occurring in a shorter lapse
than the time between two consecutive records, could be captured. On the
contrary, gradual changes would be incorporated to the model. Riquelme et
al. [35] improved the accuracy of an NN model by several orders of magnitude
by applying this approach.

The opposite alternative is to fit the model to data gathered for a given
time period, and make long-term predictions on a step-by-step basis [36], i.e.,
predict the output at t+ 1, and use it (the prediction; not the observation)to
estimate the value at t + 2. This procedure may fail in error propagation
[37], but in principle should be appropriate to unveil gradual anomalies.

An intermediate choice is to use the actual measurement of the output
variable, without readjusting the model parameters. In this case, the coef-
ficients obtained on the basis of a period of normal behaviour are applied
to future observations, hence the model could detect changes in the relation
between current and next values of the output.

Although several authors built predictive models based on lagged output
values, most of them did not mentioned which of the described approaches
applied. Palumbo et al. [36], should use the previous prediction, provided
that they presented a solution to the 6th ICOLD Benchmark Workshop,
and the observed values of the output were not provided to the participants
beforehand.

If the possibility of including past values of the variables is considered,
a criterion to select some of the available shall be defined. Otherwise, the
amount of predictors is quite high. For example, Piroddi and Spinelli [38]
considered the most general form of a non-linear autoregressive exogenous
model (NARX), which depended on current and previous values of the input
variables, on precedent values of the output, as well as on linear and non-
linear combinations of them. They applied a specific algorithm for selecting
11 predictors in the final model.

In general, these models prioritise prediction accuracy over explanatory
capability. The greater the number of variables in the model, the harder it is
to interpret and to isolate the effect of each component. Nonetheless, some
procedures have been proposed to interpret models which parameters do not
have physical meaning, as described in section 3.2.

2.4. Neural networks (NN)

Linear models are not well suited to reproduce non-linear behaviour, even
though some actions are considered in the form of high order polynomials

10



[13]. On the contrary, NN models are flexible, and allow modelling complex
and highly non-linear phenomena. Although there are various types of NN
models [39], the vast majority of applications for dam monitoring data analy-
sis are based on the multilayer perceptron (MLP). Such models, as their name
suggests, are comprised by a number of perceptrons (also called “units”, or
“neurons”) organised in different layers: input, hidden, and output (Figure
2). In principle, several hidden layers can be used (see section 2.6), but one
is mostly adopted in practice [39].

X 1

X 2

X d

wl
2 

wl
1

wl
d

bl

cl g zl

1

Y

U1

U2

UL

Ul

X 1

X 2

X d

Uout

INPUT HIDDEN OUTPUT

Figure 2: Left: schematic model of a perceptron Ul. Right: Multilayer Perceptron formed
by L units, U1...UL

The input of each unit Ul is a linear combination of the predictors X
j:

cl =
d∑
j=1

Xj · wjl + bl (8)

which is later transformed by an activation function g to compute the
neuron’s output:

zl = g(cl) (9)

Several forms of g can be chosen (non-linear in general), although sigmoid
functions are often employed, such as the logistic (10) and the hyperbolic
tangent (11) (Figure 3).

g(cl) =
1

1 + e−cl
(10)

11



logistic
tanh

1.0

0

-1.0

0 5-5

Figure 3: Common activation functions in NN models: logistic and hyperbolic tangent.

g(cl) =
ecl − e−cl
ecl + e−cl

(11)

The output layer may be composed of one of the described neurons, al-
though a linear transform is frequently chosen, so that the overall model
output is computed as:

Ŷ =
L∑
l=1

wlout · g

(
d∑
j=1

Xjw
j
l + bl

)
+ bout (12)

NN models can be thought of as an extension of MLR, which output cl
is expanded by the perceptron through a non-linear transformation g [8]. It
should be noted (Figure 3) that the sigmoid functions have a linear interval,
thus an unit with small weights performs a linear transform. On the contrary,
it has horizontal asymptotes, which may cause numerical problems. While it
is widely acknowledged that the variables shall be normalized before fitting
an NN model, some authors restrict them to the range [0.1, 0.9] to avoid the
above mentioned problems [40], [5], [41].

The most common learning algorithm is called bac-kpropagation: NN
model parameters {wjl , bl, w

l
out, bout} are randomly initialised, and iteratively

updated to minimise a cost function (typically the sum of the squared errors),
by means of the gradient descent method [8].

The issues to be considered for building an NN model are the following:

1. The best network architecture, i.e., number of layers and perceptrons
in each layer, is not known beforehand. Some authors focus on the def-

12



inition of an efficient algorithm for determining an appropriate network
architecture [33], whereas others use conventional cross-validation [12]
or a simple trial and error procedure [5].

2. The training process may reach a local minimum of the error func-
tion. The probability of occurrence of this event can be reduced by
introducing a learning rate parameter [5].

3. The NN models are prone to over-fitting. Various alternatives are suit-
able to solve this issue, such as early stopping and regularisation [8].

The fitting procedures greatly differ among authors. While Simon et al.
[11] trained an MLP with three perceptrons in one hidden layer for 200,000
iterations, Tayfur et al. [5] used regularization with 5 hidden neurons and
10,000 iterations. Neither of them followed any specific criterion to set the
number of neurons. For his part, Mata [12] tested NN architectures with one
hidden layer having 3 to 30 neurons on an independent test data set. He
repeated the training of each NN model 5 times with different initialisation
of the weights.

Kao and Loh [42] proposed a two-step procedure: first, the number of
neurons was fixed whereas the optimal amount of iterations was computed.
Second, NN models with different number of hidden nodes were trained with
the selected amount of iterations, and the final architecture was chosen as
the one which provided the lowest error in a validation set. However, their
results showed no error increase with a greater number of units, which may
be due to the small size of the validation set.

The results of the different studies are not comparable, due to the specific
features of each case. Nonetheless, the lack of agreement on the training
process suggests that similar results can be obtained with different criteria,
provided enough care is taken to avoid over-fitting. This is in accordance
with Hastie et al. [8], who stated that in general it is enough to set the
architecture and compute the appropriate regularisation parameter, or vice
versa.

NN models have been used regularly in dam monitoring in recent years.
There is an increasing number of published studies, both in academic and
professional journals. The most recent ICOLD bulletin on dam surveillance
[2] mentions NN as an alternative to HST and deterministic models, although
it terms the tool as a “possible future alternative” to be developed, what
proves that it is far from being implemented in the daily practice.

13



2.5. Adaptive neuro-fuzzy systems (ANFIS)

NN models do not require any previous knowledge on the dam behaviour.
The consequences are twofold: on the one hand, unexpected interactions may
be “discovered”. On the other hand, engineering knowledge can hardly be
exploited, apart from input selection and results interpretation.

Fuzzy logic allows inclusion of prior knowledge of the phenomenon, as
opposed to the NN, which “learn” from the data. ANFIS models bring
together the flexibility and ability to learn of the NNs with the feasibility of
interpretation of fuzzy logic. In fact, ANFIS can be considered a class of NN
[43]. They are meant for highly non-linear, complex phenomena which vary
with time [44].

Among the different types of ANFIS schemes, most previous references in
dam monitoring used Takagi-Sukeno (T-S) type, which singularity is that its
output is a combination of linear functions [45]. As an exception, Opyrchal
[46] used fuzzy logic to qualitatively locate seepage paths in Tresna and
Dobczyce dams.

Fuzzy logic is based on the concept of membership function. Each con-
tinuous variable is decomposed into classes (for example, the reservoir level,
which is continuous, can be transformed into ”low”, ”medium” and ”high”;
see Figure 4). The particularity of fuzzy logic is that these classes have
certain overlap. Thus, a given reservoir level will generally have a different
degree of membership (between zero and one) for at least two classes. The
number of classes must be prescribed by the modeller, whereas the shape
and position of their membership functions are determined by the premise
parameters ν, λ and µ (Eq. 17), to be determined during training.

The other essential component in an ANFIS model is a set of rules. Con-
sider a simple example with two input variables Xj; j = 1, 2 and two mem-
bership functions for each: MFjk; k = 1, 2. With this configuration, 4 rules
(Ri)can be defined:

R1 : if X
1 ∈MF11 ∧X2 ∈MF21 ⇒ f1 = p1X1 + u1X2 + v1 (13)

R2 : if X
1 ∈MF11 ∧X2 ∈MF22 ⇒ f2 = p2X1 + u2X2 + v2 (14)

R3 : if X
1 ∈MF12 ∧X2 ∈MF21 ⇒ f3 = p3X1 + u3X2 + v3 (15)

14



D
eg

re
e 

o
f 

m
em

b
er

sh
ip

 (
D

M
) 1.00

0.75

0.50

0.25

0.00

low

medium

high

Normalised reservoir level
1.000.750.500.250.00

Figure 4: Possible transformation of the normalised reservoir level into three fuzzy sets
with Gaussian form: ”low”, ”medium” and ”high”.

R4 : if X
1 ∈MF12 ∧X2 ∈MF22 ⇒ f2 = p4X1 + u4X2 + v4 (16)

where pr, ur, vr are the consequent parameters, to be adjusted during
model training. It should be noticed that some of these rules can be omitted,
i.e., pr = ur = vr = 0 for certain rules.

The model output is computed by means of 5 steps:

1. Compute the degree of membership of every input to each fuzzy cate-
gory; for Gaussian membership functions:

DMjk =
1

1 +

[(
Xj−νjk
λjk

)2]µjk ; j, k = 1, 2 (17)
where νjk, λjk and µjk are the premise parameters.

2. Compute the product of the correspondent DMjk, in accordance with
the rules. In ANFIS terminology, these terms are referred to as the
firing strengths (wr; r = 1...R) for each rule:

w1 = DM11 ·DM21 (18)
w2 = DM11 ·DM22 (19)
w3 = DM12 ·DM21 (20)
w4 = DM12 ·DM22 (21)

15



3. Normalise the firing strengths:

wr =
wr∑
wr

4. Compute the output of each rule, as a linear function of the consequent
parameters:

Or = wrfr = wr
(
prX

1 + urX
2 + vr

)
, r = 1...4 (22)

5. Combine the outputs of each rule to compute the overall output of the
ANFIS model:

Ŷ =
∑

wrfr, r = 1...4 (23)

The final result is a combination of linear functions of the input vari-
ables. The non-linearity is modelled in the membership functions, which are
typically Gaussian, as shown in the example of Figure 4. Each membership
function is determined on the basis of 3 premise parameters. Therefore, the
presented model has 24 parameters (12 for the membership functions, and
12 for the rules).

The parameters of these models are fitted with a hybrid method, in which
the following steps are alternated:

1. The membership functions are fixed, and the consequent parameters
are adjusted by least squares.

2. The premise parameters are modified by means of the gradient descent
method.

The criterion of the user is more important for building ANFIS than for
other kind of models. Both the prediction accuracy and the possibility of
interpreting the results may vary greatly according to the number of inputs
(d), membership functions (K) and rules (R). It should be noted that the
number of parameters in a first order T-S ANFIS model is d·K ·3+R·(d+ 1).

Rankovic et al. [47] prioritised prediction accuracy over model interpre-
tation, by considering lagged values of both the input and output variables
as predictors, resulting in an ANFIS model with d = 5, K = 2 and R = 32.
They used a zero-order T-S model, in which pr = ur = 0, ∀r ∈ R, and two-
sided Gaussian membership functions, defined by 4 parameters each. No
attempt was made to interpret the 32 rules.

On the contrary, Xu and Li [48] considered only 9 rules and could identify
the worst environmental conditions for crack opening in Chencun Dam.

16



For his part, Demirkaya [49] chose d = 5 and K = 4. Although he limited
the number of rules to 4, the final model had 84 parameters.

ANFIS models can be as flexible and accurate as NN, while allowing for
introducing engineering knowledge to some extent. If the amount of rules
and membership functions is low, the resultant model can be interpreted.
Furthermore, an ANFIS model can be used for qualitatively describe dam
behaviour, especially if the output is ”fuzzyfied” into linguistic variables [48].

On the contrary, they may comprise a high number of parameters, even
with a few rules, what results in high risk of over-fitting and low interpretabil-
ity.

2.6. Principal component analysis (PCA) and dimensionality reduction

PCA is a well known technique in statistics. It was devised to transform a
set of partially dependent variables into independent features called principal
components (PCs), which are linear combination of the original variables. It
is acknowledged that the first PCs contain the relevant information, whereas
the less influential correspond to the signal noise. It has been used in dam
monitoring for various purposes.

Mata et al. [24] used PCA to select the most useful thermometers to pre-
dict radial displacements in an arch dam. They pointed out the potentiality
of this tool to select a group of sensors to be automatised in a given dam.

Yu et al. [14] applied PCA to a group of sensors to measure the opening
of a longitudinal crack in an arch dam. They reported that PCA was useful
for reducing the dimensionality of the problem, as well as to separate the
signal from the noise. They also defined alarm thresholds as a function of
the first PCs. Cheng and Zheng [50] also applied PCA to the outputs, to
separate the effect of the causal variables from the signal noise.

Similar applications were due to Chouinard et al. [19], and Chouinard
and Roy [13], who extracted PCs from a set of outputs (radial displacements
at pendulums) to better understand the behaviour of the structure. They
focused in the model interpretation, rather than in the prediction accuracy.
In this line, Nedushan [51] extracted PCs from a group of sensors to analyse
them jointly, as well as to identify the cause-effect relations by means of
stepwise linear regression. He defined a set of predictors (reservoir level,
temperature and time), and built linear regression models by adding the
most relevant one by one.

A limitation of PCA is that only linear relations between variables are
considered. If the dependency is non-linear, it may lead to misinterpretation

17



of the results. Non-linear principal component analysis (NPCA) can be an
alternative, as showed by Loh et al. [52] and Kao and Loh [42], who applied
it by means of auto-associative neural networks (AANN) to predict radial
displacements in an arch dam.

AANN are a special kind of NN models, formed by 5 layers (Figure 5),
which can be viewed as two NN models put in series. The intermediate
(bottleneck) layer has fewer neurons than the number of model inputs, and
the target outputs equal the inputs. Thus, the first part of the model reduces
its dimensionality, computing some sort of non-linear PCA. The right-hand-
side of the AANN is a conventional NN which inputs are the non-linear PCs.

U11

U

U1L

X 1

X 2

X d

U31

U32

U3Q

U21

U22

2M

Bottleneck layer: M < d 

12

U

X
2'

X
d'

X
1'

Figure 5: Architecture of an auto-associative neural network. There are 3 hidden layers
between the inputs and the output. The central one is called ”bottleneck” layer, and
shall have fewer nodes than model inputs, so that each one can be considered a non-linear
principal component of the inputs.

Jung et al. [53] developed a methodology to identify anomalies in piezo-
metric readings in an earth-fill dam by means of moving PCA (MPCA),
which is conventional PCA applied to different time periods. The goal was
to detect significant variations in the PCs over time, which would reveal a
change in dam behaviour.

PCA is mostly applied to input and/or output variable selection. The
first option may increase the prediction accuracy, whereas the second can
be useful for managing very large dams with a large amount of devices. For
example, more than 8,000 instruments were installed to control the behaviour
of the Three Gorges Dam [14].

18



2.7. Other ML techniques

There is a wide variety of ML algorithms which can be useful for dam
monitoring data analysis. Their accuracy depends on the specific features
of every prediction task. Given that research on ML is a highly active field,
the algorithms are constantly improved and new practical applications are
reported each year. Some of them have been applied to dam monitoring
analysis. They are considered in this section more briefly than others, be-
cause they have been scarcely applied in dam engineering so far. This does
not mean that they can not offer advantages over the methods described
previously.

Support Vector Machines (SVM) stand among the most popular ML algo-
rithms nowadays. They combine a non-linear transformation of the predictor
variables to a higher dimensional space, a linear regression on the transformed
variables, and an ε-insensitive error function that neglects errors below a
given threshold [54]. Cheng and Zheng [50] used SVM in combination with
PCA for short-term prediction of the response of Minhuatan gravity dam.
Although the results were highly accurate, the computational time was high.
Rankovic et al. [55] built a behaviour model based on SVM for predicting
tangential displacements.

K-nearest neighbours (KNN) is a non-parametric method which requires
no assumptions about the physics of the problem; it is solely based on the
observed data. The KNN method basically consists on estimating the value
of the target variable as the weighted average of observed outputs in similar
conditions within the training set. The similarity between observed values
is measured as the Euclidean distance in the d -dimensional space defined by
the input variables.

A clear disadvantage of this type of model is that if the Euclidean dis-
tance is used as measure of similarity, all the predictors are given the same
relevance. Hence, including a low relevant variable may result in a model
with poor generalisation capability. As a consequence, variable selection is a
critical aspect for fitting a KNN model.

Saouma et al. [56] presented a solution to the 6th ICOLD Benchmark
Workshop based on KNN. To determine the similarity of observations, they
used only two significant predictors (the reservoir level and a thermometer
in the dam body) among the eight available. This selection of variables was
performed by trial and error, although other criteria exist, as described in
the next section.

19



Stojanovic et al. [26] combined greedy MLR with variable selection by
means of genetic algorithms (GA). Unlike HST, they considered all the ob-
served variables in various forms (e.g. h, h2, h3,

√
h, etc.). They defined a

methodology to select the best set of predictors which could be useful to
update the predictive model in case of missing variables. A similar approach
was followed by Xu et al. [57], though with a smaller set of potential inputs.

The authors [58] performed a comparative study among various statistical
and ML methods, including HST, NN, and others which had been never
used before in dam monitoring, such as random forests (RF) or boosted
regression trees (BRT). It was reported that innovative ML algorithms offered
the most accurate results, although no one performed better for all 14 outputs
analysed, which corresponded to radial and tangential displacements and
leakage flow in an arch dam.

3. Methodological considerations for building behaviour models

While each model has specific issues to take into account, there are also
common aspects to consider when developing a prediction model, regardless
of the technique. They are discussed in this section, in comparison with a
selection of papers presented at conferences and scientific journals in recent
years. It is not an exhaustive review: the studies were selected on the basis
of their relevance and interest, following the authors’ criterion.

The Tables ?? and ?? summarise the main characteristics of the studies
reviewed. It was found that most of them (28/39) considered radial displace-
ments, especially in arch dams (22/39). This reflects the greater concern of
dam engineers for this variable and dam typology, although other indicators
such as leakage or uplift are acknowledged as equally relevant for dam safety
[4]. The lower frequency with which the latter are chosen as target vari-
ables may be partly due to their more complex behaviour, what makes them
harder to reproduce and interpret [4]. The HST and MLR methods, which
have been the only available for a long time, are often incapable to model
them accurately [11], although some references exist [25], [23].

Table 1: Review summary (1)

Id Author Year Dam Country Typology Output # Outputs
1 Breitenstein [23] 1985 Limberg, Mooser,

Drossen
Switzerland ARC, GRA,

ARC
RAD 7

2 Breitenstein [23] 1985 Limberg, Mooser,
Drossen

Switzerland ARC, GRA,
ARC

LEAK 6

Continued on next page

20



Table 1 – continued from previous page
Id Author Year Dam Country Typology Output # Outputs
3 Guedes [25] 1985 São Simão Brazil EF+GRA RAD 1

4 Guedes [25] 1985 Água Vermelha Brazil EF+GRA RAD 1
5 Guedes [25] 1985 Funil Brazil ARC PIEZ 1
6 Guedes [25] 1985 Sobradinho Brazil EF+GRA JOINT 1
7 Guedes [25] 1985 Itaipú Brazil GRA LEAK 1
8 Bonelli [34] 2001 Alzitone, Cham-

boux, La Verne
France EF PIEZ 9,6,4

9 Bonelli [10] 2001 Schelegeis Austria ARC RAD 1
10 Carrere [15] 2001 Schelegeis Austria ARC RAD 1
11 Saouma [56] 2001 Schelegeis Austria ARC RAD 1
12 Palumbo [36] 2001 Shclegeis Austria ARC RAD 1
13 Nedushan [51] 2002 Chute-à-Caron Canada GRA RAD, TAN,

VERT
1,1,1

14 Piroddi [38] 2003 Schelegeis Austria ARC RAD 1
15 Tayfur [5] 2005 Jeziorsko Poland CFRD PIEZ 4
16 De Sortis [59] 2006 Ancipa Italy BUT RAD 5
17 De Sortis [59] 2006 Sabbione Italy BUT RAD 3
18 De Sortis [59] 2006 Malga Bissina Italy BUT RAD 5
19 S. Caro [29] 2007 El Atazar Spain ARC RAD 46
20 Léger [18] 2007 Schelegeis Austria ARC RAD 1
21 Su [60] 2007 ? China AG VERT 1
22 Panizzo [61] 2007 Pieve di Cadore Italy AG RAD 1
23 Lombardi [4] 2008 ? ? ARC RAD 1
24 Lombardi [4] 2008 ? ? ARC LEAK 1
25 Bonelli [62] 2007 ? ? EF PIEZ 14
26 Bonelli [28] 2008 ? ? EF PIEZ 16
27 Yu [14] 2010 Chencun China AG CRACK 5
28 Perner [63] 2010 Zillergruendl Austria ARC RAD 2
29 Demirkaya [49] 2010 Schelegeis Austria ARC RAD 1
30 Riquelme [35] 2011 La Baells Spain ARC RAD 1
32 Mata [12] 2011 Alto Rabagão Portugal ARC RAD 1
31 Rankoviĉ [47] 2012 Bocac Bosnia

Herzegovina
ARC RAD 2

33 Xu [57] 2012 Chencun China AG CRACK 1
34 Demirkaya [27] 2012 Schelegeis Austria ARC RAD 1
35 Demirkaya [27] 2012 Schelegeis Austria ARC RAD 1
36 Cheng [50] 2013 Mianhuatan China GRA RAD 12
37 Cheng [50] 2013 Mianhuatan China GRA UP 16
38 Popovici [30] 2013 Gura Râului Romania BUT RAD, TAN,

ROCK
2, 2, 3

39 Tatin [16] 2013 Castelnau France GRA RAD 1
40 Tatin [16] 2013 Castelnau France GRA RAD 1
41 Li [64] 2013 Wanfu China ARC RAD 4

Continued on next page

21



Table 1 – continued from previous page
Id Author Year Dam Country Typology Output # Outputs
42 Li [64] 2013 Wanfu China ARC RAD 4
43 Simon [11] 2013 Pareloup France ARC PIEZ 1
44 Simon [11] 2013 Bissorte France GRA LEAK 4
45 Simon [11] 2013 Monteynard France ARC RAD 1
46 Simon [11] 2013 Monteynard France ARC RAD 1
47 Nourani [65] 2013 Sahand Iran EF PIEZ 4
48 Kao [42] 2013 Fei-Tsui Taiwan ARC RAD 13
49 Kao [42] 2013 Fei-Tsui Taiwan ARC RAD 13
50 Kao [42] 2013 Fei-Tsui Taiwan ARC RAD 13
51 Mata [24] 2013 Alto Lindoso Portugal ARC RAD 5
52 Jung [53] 2013 ? USA EF PIEZ 1
53 Stojanovic [26] 2013 Bocac Bosnia

Herzegovina
ARC RAD 1

54 Rankoviĉ [41] 2014 Iron Gate 2 Serbia/ Ro-
mania

EF+GRA PIEZ 2

55 Rankoviĉ [41] 2014 Iron Gate 2 Serbia/ Ro-
mania

EF+GRA PIEZ 2

56 Santillán [33] 2014 La Baells Spain ARC LEAK 1
57 Salazar [58] 2014 La Baells Spain ARC RAD, TAN,

LEAK
5, 5, 4

58 Rankoviĉ [55] 2014 Iron Gate 2 Serbia/ Ro-
mania

EF+GRA TAN 2

Table legend

Table 2: Review summary (2)

Id Model Inputs Training set Validation set %Test Error metric
1 MLR H,S,t,Tair, d(Tair), d(H) 10/14600 0.0/ 0% R2

2 MLR H 10/14600 0.0/ 0% R2

3 MLR H, mav(Tair) 1/103 0.0/ 0% r
4 MLR H, mav(Tair) 0.5/63 0.0/ 0% r
5 MLR t, mav(H) 2/230 0.0/ 0% r
6 MLR t, mav(Tc) 2.5/66 0.0/ 0% r
7 MLR t, mav(H) 0.5/86 0.0/ 0% r
8 IRF H, lag(H), P, lag(P), t Var/Var 0.0/ 0% -
9 IRF H, Tair 7/2557 2.0/730 22% -
10 HST H, Tair 7/2557 2.0/730 22% r, R2, σ�
11 KNN H, Tc 7/2557 2.0/730 22% r, R2, σ�
12 NARX H, Tair, Tc, lag(H),

lag(Tc), lag(Tair)
7/2555 2.0/730 22% RMSE

13 NN Tc, t 1.5/548 1.5/548 50% R2

14 NARX H, Tair, Tc, lag(H),
lag(Tc), lag(Tair)

7/2555 2.0/730 22% MSE

Continued on next page

22



Table 2 – continued from previous page
Id Model Inputs Training set Validation set %Test Error metric
15 NN H 1/26 2.0/52 67% RMSE, MAE,

R2
16 HST H, S, t 2 to 15/730 to

5475
0.0/ 0% r, σ�,

σ�
D/2

17 HST H, S, t 5/1825 0.0/ 0% r, σ�,
σ�
D/2

18 HST H, S, t 9/3285 0.0/ 0% r, σ�,
σ�
D/2

19 MLR H, mav(H), S, Tair,
mav(Tair)

24.5/8943 0.0/ 0% σ�, MSE

20 HTT H, Tc, t 5/1825 0.0/ 0% r
21 WNN H, S, t 11/44 2.0/8 15% MAE
22 NN H, lag(rad), Tair, Tc 7/2555 0.0/ 0% R2, pdf(ε),

MSE
23 IRF H, lag(H), lag(rad), Tair 4/? 0.0/ 0% σ�
24 IRF H, lag(H), lag(seep) 5/? 0.0/ 0% -
25 IRF H, lag(P) 3/167 0.0/ 0% R2

26 IRF H, Hd, lag(P) var/var 0.0/ 0% R2

27 HST H, S, t 10/1200 0.0/ 0% r
28 HYB H, Tc, t 22/8030 0.0/ 0% -
29 ANFIS H, Tair, Tc 6/2044 1.0/365 15% r, RMSE,

MAE
30 NN H, T, mav(T), lag(rad) 18/706 12.0/470 40% MAPE
32 NN H,S 23/914 1.8/69 7% MAE,

MaxAE, r
31 ANFIS lag(H), lag(S), lag(rad) 9/657 2.0/140 18% r, MAE,

RMSE
33 ANFIS Tair, H 15/400 ?/? 0% RMSE
34 MLR H, Tair, Tc, lag(H),

lag(Tair), lag(Tc)
7/2555 2.0/730 22% ME, σ�, R

2

35 NN H, Tair, Tc, lag(H),
lag(Tair), lag(Tc)

7/2555 2.0/730 22% ME, σ�, R
2

36 PCA,
SVM

H, Tair, P 4.2/1525 0.1/30 2% -

37 PCA,
SVM

H, Tair, P 3/900 0.2/56 6% -

38 NN t, H, Tair, lag(H),
mav(Tair)

14/? 2.0/? 13% r, R2, σ�

39 GRAD H, S, t, IRF(Tair, Tw) 12/? 0.0/ 0% σ�
40 SLICE H, S, t, IRF(Tair, Tw) 12/? 0.0/ 0% σ�
41 HTT H, S, Tc 3.2/169 0.4/20 11% R2adj , σ�, pdf(ε)

42 ECM H, S, Tc, e(t-1) 3.2/169 0.4/20 11% R2adj , σ�, pdf(ε)

43 NN H, S, t ?/429 0.0/ 0% σ�, MSE
44 IRF+NN H, S, t, Tair, IRF(P),

IRF(M)
?/? 0.0/ 0% R2

45 NN H, S, t, IRF(Tair) ?/? 0.0/ 0% σ�
46 HSTT H, S, t, IRF(Tair) ?/? 0.0/ 0% σ�

Continued on next page

23



Table 2 – continued from previous page
Id Model Inputs Training set Validation set %Test Error metric
47 NN H, Hd, lag(P) 1.1/58 0.4/18 24% R2

48 NN H, Tc 22/8120 0.3/62 1% R2, pdf(ε),
MSE

49 NARXNN H, lag(H), lag(out) 22/8120 0.3/62 1% R2, pdf(ε),
MSE

50 AANN lag(rad) 22/8120 0.3/62 1% R2, pdf(ε),
MSE

51 HTT H,Tc 5/95 0.0/ 0% R2adj , σ�, εmax,
εmin, SSE

52 PCA, RR H 6/4380 0.0/ 0% -
53 MLR H, Tc, Tair, P, t 6/2550 1.0/365 13% R2adj , RMSE

54 NN Hd, lag(Hd) 8/163 1.0/20 11% r, r2, MSE,
MAE

55 MLR Hd, lag(Hd) 8/163 1.0/20 11% r, MSE, MAE
56 NN H, Tair, d(H), d(Tair) 25.5/918 3.0/103 10% RMSE
57 NN,

MARS,
RF, BRT,
SVM

H, Tair, S, t, mav(H),
mav(Tair), P, d(H)

18/600 10.0/400 40% MAE, ARV

58 SVM H, Hd, lag(H), lag(Hd),
lag(out)

11/573 3.0/156 21% r, MAE, MSE

Review summary (2). Models: MLR = multilineal regression; IRF = impulse re-
sponse function; HST = hydrostatic seasonal time; KNN = k-nearest neighbours; NN
= neural networks; NARX = non-linear autoregressive exogenous; HTT = hydrostatic
thermal time; HYB = hybrid; ANFIS = adaptive neuro-fuzzy system; PCA = princi-
pal component analysis; SVM = support vector machine; HSTT = hydrostatic seasonal
thermal time; NARXNN = non-linear autoregressive exogenous neural network; AANN =
auto-associative neural network; RR = robust regression; MARS = multivariate adaptive
regression splines; RF = random forest; BRT = boosted regression trees. Inputs: H =
upstream pool level; S = season; t = time; d = derivative; Tc = concrete temperature;
Tair = air temperature; Tw = water temperature; IRF (·) = impulse response function;
lag(·) = lagged variable; d(·) = derivative; P = precipitation; out = output; mav(·) =
moving average; Hd = downstream pool level

3.1. Input selection

In previous sections, it was pointed out that the model performance de-
pended on the predictor variables considered. The range of options for vari-
able selection is wide. Most of the papers reviewed do not use any specific
method for variable selection, apart from “a priori knowledge” (e.g. [47]) or
trial and error (e.g. [42]).

This issue has arisen in combination with the use of NN [42], [61], [27],
[41], [52], NARX [38], [52], MLR [26] and ANFIS models [47].

First, the selection is limited by the available data. While the reservoir
level and the temperature are usually measured at the dam site, other poten-
tially influential variables, such as precipitation, are frequently not available.

24



One of the advantages of HST method is that only the reservoir level is
required.

Second, it must be decided whether or not to use the lagged values of
the target variable for prediction. The consequences of making predictions
from the output itself have already been mentioned, regardless whether the
observed or the estimated previous value is used. It can be concluded that
the AR models prioritise prediction accuracy over model interpretation.

Third, the possibility of adding derived variables (and which ones), such
as moving averages and gradients, can be considered. They can be set before-
hand, on the basis of engineering judgement, or selected by means of some
performance criterion from a wide set of variables.

Finally, consideration should be given to include non-causal variables in
the model. For example, is it appropriate to base the prediction of radial
displacements at a given location on the displacement recorded at another
point of the dam? Will it improve the model accuracy? What consequences
would it have in the interpretation of the results?

Some models like the HST are often used with a set of specific predictors,
and therefore variable selection is restricted to the order of the polynomial
of the reservoir level, and the shape of the time dependent functions. The
opposite case is the NARX method, which can be used with a high amount
of predictor variables.

Hence, the criterion to be used depends on the type of data available, and
the characteristics of the phenomenon to be modelled. Again, engineering
judgement is essential to make these decisions.

The selection of predictors may be useful to reduce the dimensionality
of the problem (essential for NARX models), as well as to facilitate the
interpretation of the results. PCA can be used for this purpose [24], as
well as AANN [52]. Some specific methods for variable selection in dam
monitoring analysis have been proposed, by means of backward elimination
[33] genetic algorithms (GA) [26], and singular spectrum analysis (SSA) [52],
although the vast majority of authors applied trial and error or engineering
judgement.

3.2. Model interpretation

The main interest of this work focuses on model accuracy: a more accurate
predictive model allows defining narrower thresholds, and therefore reducing
the number of false anomalies. Nonetheless, once a value above (or below, if
appropriate) the warning threshold is registered, an engineering analysis of

25



the situation is needed to assess its seriousness, for which the ability of the
model to interpret dam behaviour may be useful.

The HST method has been traditionally used to identify the effect on the
response of the dam of each considered action: hydrostatic load, temperature
and time (e.g. [12]). However, it is clear that this analysis is only valid if the
predictor variables are independent, which is not generally true [3], [17].

On the contrary, the ability of NN and similar models for interpreting
dam behaviour is often neglected. They are frequently termed ”black box”
models, in reference to its lack of interpretability.

It turns out that NN models are well suited to capture complex interac-
tions among inputs, and non-linear input-output relations. If an NN model
offers a much better accuracy than HST for a given phenomenon, it is prob-
able that it does not fulfil the hypothesis of HST (input independence, lin-
earity). Hence, it would be more appropriate to extract information on the
dam behaviour from the interpretation of the NN model.

The effect of each predictor can be analysed by means of computing the
response of the NN model to a set of simulated data distributed along the
range of variation of the variable under consideration, while keeping the rest
at constant values (ceteris paribus, [12]). They can be set either to the
correspondent mean or to several other values, in order to gain more detailed
information on the dam response. Analyses of this kind can be found in the
literature: Mata [12] calculated the effect of the reservoir level on the radial
displacements of an arch dam for each season of the year, and the effect of
temperature when setting the pool level at several constant values. Similar
studies are due to Santillán et al. [66], Simon et al. [11] and Popovici et al.
[30].

More complex algorithms have been proposed in related fields to unveil
the relevance of each input in NN models (see for example [67], [68] and [69]),
which may be helpful in dam monitoring.

Therefore, even though NN and similar models must be interpreted with
great care, their ability to extract information on the dam behaviour should
not be underestimated.

3.3. Training and validation sets

It is common and convenient to divide the available data into two subsets:
the training set is used to adjust the model parameters, whereas the valida-

26



tion set is solely used to measure the prediction accuracy5. In statistics, this
need is well known, since it has been proven that the prediction accuracy of
a predictive model, measured on the training data, is an overestimation of
its overall performance [70]. Any subsetting of the available data into train-
ing and validation sets is acceptable, provided the data are independent and
identically distributed (i.i.d.). This is not the case in dam monitoring series,
which are time-dependant in general.

The amount of available data is limited, what in turn limits the size of
the training and validation samples. It is convenient that both training and
validation data cover all the range of variation of the most influential vari-
ables. It is not infrequent that reservoir level follows a relatively constant
yearly cycle by which situations from the lowest to the highest pool level are
presented each year. Temperature, which is the second most influential vari-
able on average, responds to a more defined annual cycle. As a consequence,
many authors measure the size of the training and validation sets in years.

Moreover, dam behaviour models are used in practice to calculate the
future response, on the basis of the observed, normal functioning, and draw
conclusions about the safety state. Therefore, it seems reasonable to estimate
the model accuracy with a similar scheme, i.e., to take the most recent data
as the validation set. This is the procedure used in the vast majority of the
reviewed papers (38/39), with the unique exception of Santillán et al. [33],
who made a random division of the data.

Models based on the underlying physics of the phenomenon and those
with fewer parameters (HST, IRF and MLR), are less prone to over-fitting.
As a result, a higher value can be given to the training error. This is probably
the reason why most studies do not consider a validation set, but rather use
all the data for the model fit e.g. [34], [24] (Figure 6 (a))

When a validation set is used, 10 % of the available data is reserved for
that purpose on average. The higher frequency observed around 20 % corre-
sponds to the papers dealing with the data from the 6th ICOLD Benchmark
Workshop, where the splitting criterion was fixed by the organisers.

Tayfur et al. [5] reserved only one year for training, but explicitly men-
tioned that it contained all the range of variation of the reservoir level. Some
authors proposed to set a minimum of 5 to 10 observations per model pa-

5the terminology is not universal; the data which is not used to fit the model is some-
times called test or prediction set.

27



rameter to estimate [1].

0

10

20

30

0.0 0.2 0.4 0.6

validationMdata/availableMdata

0

2

4

6

8

0 10 20

trainingMsetMsizeMXyears#

HST,MMLR,MIRFNN,MANFIS,MSVM,MNARX

I
Ms

tu
d

ie
s

I
Ms

tu
d

ie
s

Figure 6: Training and validation sets in the papers reviewed. Left: ratio of validation
data with respect to available data. Rigth: training set size (years)

A fundamental premise for the successful implementation of any predic-
tion model is that the training data correspond to a period in which the dam
has not undergone changes in its behaviour. In practice, it is not easy to
ensure that this condition is fulfilled. While the history of mayor repairs and
events is usually available, it is well known that the behaviour in the first
years of operation usually corresponds to a transient state, which may not be
representative of its response in normal operation afterwards [3]. Therefore,
the use of data corresponding to the first period to adjust the model parame-
ters may lead to an increase in prediction error. Lombardi [3] estimated that
12 years from dam construction are required for a data-based model to be
effective.

This issue can be checked by analysing the training error: ideally, errors
shall be independent, with zero mean and constant variance [1]. Some au-
thors compute some of these values for evaluating the goodness of fit (e.g.
[11], [64], [42]).

On another note, a minimum amount of data is necessary to build a pre-
dictive model with appropriate generalisation ability. De Sortis and Paoliani
[59] run a sensitivity analysis of the prediction error as a function of the
training set size. They concluded that 10 years were necessary for obtaining
stable results. For his part, Chouinard and Roy [13] performed a similar
work on a dam set. Provided that most of them were run-of-the-river small
dams, which remained full most of the time, the thermal effect was the pre-

28



ponderant variable. As this is almost constant every year, 5 years of data
were enough for most cases to achieve high accuracy.

According to the Swiss Comittee on Dams [1], a minimum of “5 yearly
cycles” should be available, what suggests that they refer to filling-emptying
cycles throughout a year (to account for the thermal variation). On the
contrary, ICOLD [2] recommended to set thresholds as a function of the
prediction error along “2 or 3 years of normal operation”.

The authors performed a similar analysis for 14 instruments in an arch
dam [58], and reported that the prediction accuracy was higher in some
cases for models trained over the most recent 5 years of data (the maximum
training set length was 18 years).

The size of the validation set ranges from 1 to 25 years (Figure 6 (b)),
and depends on the amount of data available, rather than on the type of
model.

Again, engineering judgement is essential to assess the appropriateness
of the train and validation sets, as well as to assess the model performance.
Both subsets should cover the whole range of variation of the most influential
variables, and belong to the same density function.

Such verifications are not performed in general in dam monitoring analy-
ses, probable due to a) the number of data available at a given time cannot be
arbitrarily increased, and b) the validation data shall be the most recent. In
practice, there is not agreement on the appropriate criterion to define train-
ing and validation sets, which depends on the available data. Consequently,
the comparison between models which predict different variables has limited
reliability, although it is sometimes considered [26], [41].

3.4. Prediction accuracy measurement

It is very important to appropriately estimate the prediction error of a
model, since a) it provides insight into its accuracy, b) it allows comparing
different models, and c) it is used to define warning thresholds.

There are various error measures to assess how well a model matches the
observed data, among which the most commonly used are included in Table
3.

The result of using any of these indexes is frequently equivalent when re-
ferred to a given prediction task: the more accurate model will have a smaller
RMSE value, but also the lowest MSE, and higher r and R2. However, they
also present differences which can be relevant, and are often not considered.

29



Mean squared error MSE =
∑N

i=1(yi−F (xi))
2

N

Root mean squared error RMSE =

√∑N
i=1(yi−F (xi))

2

N
=
√
MSE

Mean absolute error MAE = 1
N

∑N
i=1 |yi − F (xi)|

Correlation coefficient r =
∑N

i=1(yi−y)(F (xi)−F (xi))
(
∑N

i=1 (yi−y)
2)

0.5
(
∑N

i=1 (F (xi)−F (xi)))
0.5

Coefficient of determination R2 = 1−
∑N

i=1(yi−F (xi))
2∑N

i=1(yi−ȳ)
2

Standard error of estimate σε =

√∑
(yi−f(xi))2

N

Mean absolute percentage error MAPE = 100
N

∑N
i=1

∣∣∣yi−F (x)yi ∣∣∣
Maximum absolute error MaxAE = |ε|max

Adjusted R2 R2adj = R
2 − (1−R2) p

N−p−1

Sum of squared error SSE =
∑N

i=1 (yi − F (xi))
2

Average relative variance ARV =
∑N

i=1(yi−F (xi))
2∑N

i=1(yi−ȳ)
2 =

MSE
σ2

= 1−R2

Mean error ME = 1
N

∑N
i=1 (yi − F (xi))

Table 3: Measures of accuracy

Provided that MSE = (RMSE)
2
, they can be used indistinctly for model

comparison. The only difference is that RMSE is measured in the same units
as the target variable, so its value is more intuitive on the model accuracy.
It should be noted that they are computed on the basis of the squared resid-
uals, therefore they are sensitive to the presence of outliers, i.e., a few large
prediction errors. In this sense, MAE could be considered a better choice,
provided that it shares the advantage of RMSE (it is measured in the same
units as the output), and not its drawback. Mindful of this fact, both can
be used interchangeably, if the analysis is complemented with a graphical
exploration of the model fit, and/or other error measures.

The drawback to both MSE and RMSE is that they are not suitable
for comparing models fitting different variables, provided that they do not

30



consider neither the mean nor the deviation of the output.
This limitation can be overcome by using the correlation coefficient r,

since r ∈ [−1, 1]. On the contrary, it is not exactly an error rate, but rather
an index of the strength of the linear relationship between observations and
predictions. In other words, it indicates to what extent one variable increases
as the other does, and vice versa. It can be checked that the value of r for
a prediction calculated as Ŷ = AY +B is equal to 1, while the error can be
very large and will generally be non-zero (unless A = 1 and B = 0) [71]. As
an example, Rankovic et al. [41] considered r and r2, as well as MAE and
MSE. While the results were similar for the training and validation sets in
terms of r and r2, both MAE and MSE were much greater in the validation
set (as much as 7 times grater). These results may reflect some degree of
over-fitting.

If r is used as a measure of goodness of fit, its value always increases
with increasing number of model parameters (except in the highly unlikely
event that the functions are completely independent of output). To take into
account the number of parameters of each, the Radj parameter can be used
(e.g. [26], [64]).

As an alternative, R2, or its equivalent ARV can be chosen. They have
the advantage over the correlation coefficient of being sensitive to differences
in the means and variances of observations and predictions, while maintaining
the ability to compare models fitted to different data [58].

Finally, it should be noted that the reading error of the devices may
be relevant when predictions of variables of different nature are compared,
although it is often not taken into account. It cannot be expected to obtain
a model with an error below the measurement resolution [14]. Popovici et al.
[30] reported that the overall accuracy of NN models was lower for tangential
than for radial displacements, and attributed it to the lower range of variation
of the former. It is possible that the reading error (which in principle should
be the same for tangential and radial displacements) were relevant in the first
case and negligible in the second.

The authors found that models with relatively high ARV corresponded
with very low MAE, close to the measurement error [58].

Measurement error (εr) should always be considered for evaluating model
accuracy. One possibility would be to neglect the errors below that value be-
fore computing the prediction accuracy, by means of substituting (yi − F (xi))
by |yi−F (xi)|−εr, in the calculation of MSE, RMSE, r and R2. Similarly,
MAE should be computed as:

31



MAE∗ =
1

N

N∑
i=1

(|yi − F (xi)| − εr) (24)

It is convenient to compute more than one error rate, especially if the
aim is to compare models predicting variables of different kind. In addition,
a graphical analysis of the error is highly advisable.

4. Conclusions

There is a growing interest in the application of innovative tools in dam
monitoring data analysis. Although only HST is fully implemented in en-
gineering practice, the number of publications on the application of other
methods has considerably increased in recent years.

NN are by far the most frequently used ML technique, which has been
applied to a great variety of problems: displacements, leakage, crown set-
tlement, crack opening, etc. Other tools are less frequent, and restricted to
specific cases so far.

It seems clear that the models based on ML algorithms can offer more
accurate estimates of the dam behaviour than the HST method in many
cases. In general, they are more suitable to reproduce non-linear effects and
complex interactions between input variables and dam response.

On the contrary, they must be employed rigorously. Given their high
number of parameters and their flexibility, they are susceptible to over-fit
the training data. It is thus essential to check their generalisation capability
on an adequate validation data set, not used for fitting the model parameters.

Regardless of the technique used, engineering judgement based on expe-
rience is critical for building the model, for interpreting the results, and for
decision making with regard to dam safety.

5. Acknowledgements

The research has been partially supported by the Spanish Ministry of
Economy and Competitiveness (Ministerio de Economı́a y Competitividad,
MINECO) through the projects iComplex (IPT-2012-0813-390000) and AIDA
(BIA2013-49018-C2-1-R and BIA2013- 49018-C2-2-R).

32



References

[1] Swiss Committee on Dams (2003). Methods of analysis for the prediction
and the verification of dam behaviour. Technical report, ICOLD.

[2] International Commission on Large Dams (2012). Dam surveillance
guide. Technical Report B-158, ICOLD.

[3] G. Lombardi (2004). Advanced data interpretation for diagnosis of con-
crete dams. Technical report, CISM.

[4] G. Lombardi, F. Amberg, G. Darbre (2008). Algorithm for he prediction
of functional delays in the behaviour of concrete dams. Hydropower and
Dams, (3):111–116.

[5] G. Tayfur, D. Swiatek, A. Wita, V. P. Singh (2005). Case study: Finite
element method and artificial neural network models for flow through
jeziorsko earthfill dam in poland. Journal of Hydraulic Engineering,
131(6):431440.

[6] F. Restelli (2010). Systemic evaluation of dam monitoring using PCA.
In Proceedings of the Sixth Argentinian Conference on Dams. Neuquén,
Argentina. [in Spanish].

[7] F. Restelli (2013). Systemic evaluation of the response of large dams
instrumentation. Application at El Chocón dam. In Proceedings of the
9th ICOLD European Club Symposium. Venice, Italy.

[8] T. Hastie, R. Tibshirani, J. Firedman (2009). The Elements of Statisti-
cal Learning - Data Mining, Inference, and Prediction, Second Edition.
Springer, 2 edition.

[9] G. Willm, N. Beaujoint (1967). Les mthodes de surveillance des barrages
au service de la production hydraulique d’electricit de france-problmes
ancients et solutions nouvelles. In 9th ICOLD Congres, pages Q34–R30,
529–550. [in French].

[10] S. Bonelli, H. Félix (2001). Delayed response analysis of temperature
effect. In Proceedings of the Sixth ICOLD Benchmark Workshop on
Numerical Analysis of Dams. Salzburg, Austria.

33



[11] A. Simon, M. Royer, F. Mauris, J. Fabre (2013). Analysis and inter-
pretation of dam measurements using artificial neural networks. In Pro-
ceedings of the 9th ICOLD European Club Symposium. Venice, Italy.

[12] J. Mata (2011). Interpretation of concrete dam behaviour with
artificial neural network and multiple linear regression models.
Engineering Structures, 3(3):03 – 910. ISSN 141-0296. doi:
10.1016/j.engstruct.2010.12.011.

[13] L. Chouinard, V. Roy (2006). Performance of statistical models for dam
monitoring data. In Joint International Conference on Computing and
Decision Making in Civil and Building Engineering, Montreal, pages 14–
16.

[14] H. Yu, Z. Wu, T. Bao, L. Zhang (2010). Multivariate analysis in
dam monitoring data with PCA. Science China Technological Sciences,
53(4):1088–1097. ISSN 1674-7321, 1862-281X. doi:10.1007/s11431-010-
0060-1.

[15] A. Carrère, C. Noret-Duchêne (2001). Interpretation of an arch dam
behaviour using enhanced statistical models. In Proceedings of the
Sixth ICOLD Benchmark Workshop on Numerical Analysis of Dams.
Salzburg, Austria.

[16] M. Tatin, M. Briffaut, F. Dufour, A. Simon, J. Fabre (2013). Thermal
displacements of concrete dams: Finite element and statistical mod-
elling. In Proceedings of the 9th ICOLD European Club Symposium.
Venice, Italy.

[17] A. F. Silva Gomes, D. Silva Matos (1985). Quantitative analysis of dam
monitoring results. state of the art, applications and prospects. In 15th
ICOLD Congres, pages Q56–R39, 319–334.

[18] P. Léger, M. Leclerc (2007). Hydrostatic, temperature, time-
displacement model for concrete dams. Journal of engineering mechan-
ics, 133(3):267277.

[19] L. Chouinard, D. Bennett, N. Feknous (1995). Statistical analy-
sis of monitoring data for concrete arch dams. Journal of Perfor-
mance of Constructed Facilities, 9(4):286–301. ISSN 0887-3828. doi:
10.1061/(ASCE)0887-3828(1995)9:4(286).

34



[20] F. Amberg (2009). Interpretative models for concrete dam displace-
ments. In 23th ICOLD Congres, pages Q91–RXXX, XXX–XXX.

[21] I. Penot, B. Daumas, J. Fabre (2005). Monitoring behaviour. Water
Power and Dam Construction.

[22] J. Fabre, G. Geffraye (2013). Estudio y control de los desplazamien-
tos trmicos de la presa gage II (francia) por aportacin de dispositivos
especiales de calefaccin y enfriamiento. San Juan.

[23] F. Breitenstein, W. Klher, R. Widman (1985). Safety control of the
dams of the glockner-kaprun hydro-electric development. In 15 Congreso
Internacional de Grandes Presas, pages Q56–R59, 1121–1134.

[24] J. Mata, A. Tavares de Castro, J. S da Costa (2014). Constructing
statistical models for arch dam deformation. Structural control health
monitoring, 21(3):423–437. doi:10.1002/stc.1575.

[25] Q. Guedes, P. Coelho (1985). Statistical behaviour model of dams. In
15th ICOLD Congres, pages Q56–R16, 319–334.

[26] B. Stojanovic, M. Milivojevic, M. Ivanovic, N. Milivojevic, D. Divac
(2013). Adaptive system for dam behavior modeling based on linear
regression and genetic algorithms. Advances in Engineering Software,
65:182190.

[27] S. Demirkaya, M. Balcilar (2012). The contribution of soft computing
techniques for the interpretation of dam deformation. Rome, Italy.

[28] S. Bonelli, K. Radzicki (2008). Impulse response function analysis of
pore pressure in earthdams. European Journal of Environmental and
Civil Engineering, 12(3):243–262.

[29] F. J. Sánchez Caro (2007). Dam safety: contributions to the deformation
analysis and monitoring as an element of prevention of pathologies of
geotechnical origin. Ph.D. thesis, UPM. [In Spanish].

[30] I. C. Popovici, A., T. Ayvaz (2013). The performance of the neural
networks to model some response parameters of a buttress dam to en-
vironment actions. In Proceedings of the 9th ICOLD European Club
Symposium. Venice, Italy.

35



[31] O. Crépon, M. Lino (1999). An analytical approach to monitoring.
Water Power and Dam Construction.

[32] G. Zenz, P. Obernhuber (2001). Icold benchmark workshops on dam
safety. Hydropower and Dams, (2):75–78.

[33] D. Santillán, J. Fraile-Ardanuy, M. Toledo (2014). Seepage prediction
in arch dams by means of artificial neural networks. Water Technology
and Science, V(3). [in Spanish].

[34] S. Bonelli, P. Royet (2001). Delayed response analysis of dam monitoring
data. In Proceedings of the Fifth ICOLD European Symposium on Dams
in a European Context. Geiranger, Norway.

[35] F. Riquelme, J. Fraile, D. Santillán, R. Morán, M. Toledo (2011). Ap-
plication of artificial neural network models to determine movements in
an arch dam. In Proceedings of the 2nd International Congress on Dam
Maintenance and Rehabilitation, pages 117–123. Zaragoza, Spain.

[36] P. Palumbo, L. Piroddi, S. Lancini, F. Lozza (2001). Narx modeling
of radial crest displacements of the schlegeis arch dam. In Proceedings
of the Sixth ICOLD Benchmark Workshop on Numerical Analysis of
Dams. Salzburg, Austria.

[37] B.-J. Chen, M.-W. Chang, et al. (2004). Load forecasting using support
vector machines: A study on eunite competition 2001. Power Systems,
IEEE Transactions on, 19(4):1821–1830.

[38] L. Piroddi, W. Spinelli (2003). Long-range nonlinear prediction: a case
study. In Decision and Control, 2003. Proceedings. 42nd IEEE Confer-
ence on, volume 4, pages 3984–3989. IEEE.

[39] C. M. Bishop (1995). Neural networks for pattern recognition. Oxford
university press.

[40] R. S. Govindaraju (2000). Artificial neural networks in hydrology. ii:
hydrologic applications. Journal of Hydrologic Engineering, 5(2):124–
137.

[41] V. Ranković, A. Novaković, N. Grujović, D. Divac, N. Milivojević (2014).
Predicting piezometric water level in dams via artificial neural networks.
Neural Computing and Applications, 24(5):1115–1121.

36



[42] C.-Y. Kao, C.-H. (2013). Monitoring of long-term static deforma-
tion data of fei-tsui arch dam using artificial neural network-based ap-
proaches. Structural Control and Health Monitoring, 20(3):282–303.

[43] H. Ruiz (2013). Fisher networks: a principled approach to retrieval-based
classification. Ph.D. thesis, Liverpool John Moores University.

[44] J.-S. Jang (1993). Anfis: adaptive-network-based fuzzy inference system.
Systems, Man and Cybernetics, IEEE Transactions on, 23(3):665–685.

[45] T. Takagi, M. Sugeno (1985). Fuzzy identification of systems and its
applications to modeling and control. Systems, Man and Cybernetics,
IEEE Transactions on, (1):116–132.

[46] L. Opyrchal (2003). Application of fuzzy sets method to identify seepage
path through dams. Journal of Hydraulic Engineering, 129(7):546–548.

[47] V. Ranković, N. Grujović, D. Divac, N. Milivojević, A. Novaković (2012).
Modelling of dam behaviour based on neuro-fuzzy identification. Engi-
neering Structures, 35:107113. doi:10.1016/j.engstruct.2011.11.011.

[48] H. Xu, X. Li (2012). Inferring rules for adverse load combinations to
crack in concrete dam from monitoring data using adaptive neuro-fuzzy
inference system. Science China Technological Sciences, 55(1):136141.

[49] S. Demirkaya (2010). Deformation analysis of an arch dam using AN-
FIS. In Proceedings of the second international workshop on application
of artificial intelligence and innovations in engineering geodesy. Braun-
schweig, Germany, page 2131.

[50] L. Cheng, D. Zheng (2013). Two online dam safety monitoring models
based on the process of extracting environmental effect. Advances in
Engineering Software, 57:4856.

[51] B. Nedushan (2002). Multivariable statistical analysis of monitoring data
for concrete dams. Ph.D. thesis, McGill University.

[52] C.-H. Loh, C.-H. Chen, T.-Y. Hsu (2011). Application of advanced
statistical methods for extracting long-term trends in static monitoring
data from an arch dam. Structural Health Monitoring, 10(6):587–601.

37



[53] I.-S. Jung, M. Berges, J. H. G. Jr, C. J. Kelly (2013). Interpreting
the dynamics of embankment dams through a time-series analysis of
piezometer data using a non-parametric spectral estimation method. In
Computing in Civil Engineering (2013), page 2532. ASCE.

[54] A. J. Smola, B. Schlkopf (2004). A tutorial on support vector regression.
Statistics and computing, 14(3):199222.

[55] V. Ranković, N. Grujović, D. Divac, N. Milivojević (2014). Development
of support vector regression identification model for prediction of dam
structural behaviour. Structural Safety, 48:33–39.

[56] V. Saouma, E. Hansen, B. Rajagopalan (2001). Statistical and 3d non-
linear finite element analysis of schlegeis dam. In Proceedings of the
Sixth ICOLD Benchmark Workshop on Numerical Analysis of Dams,
pages 17–19.

[57] C. Xu, D. Yue, C. Deng (2012). Hybrid GA/SIMPLS as alternative
regression model in dam deformation analysis. Engineering Applications
of Artificial Intelligence, 25(3):468475.

[58] F. Salazar, M. Toledo, E. Oñate, R. Morán (2014). An empirical com-
parison of machine learning techniques for dam behaviour modelling.
Structural Safety, submitted.

[59] A. De Sortis, P. Paoliani (2007). Statistical analysis and structural
identification in concrete dam monitoring. Engineering structures,
29(1):110–120.

[60] H.-z. Su, Z.-r. Wu, Z.-p. Wen (2007). Identification model for dam
behavior based on wavelet network. Computer-Aided Civil and Infras-
tructure Engineering, 22(6):438–448.

[61] A. Panizzo, A. Petaccia (2009). Analysis of monitoring data for the
safety control of dams using neural networks. In New Trends in Fluid
Mechanics Research, page 344347. Springer.

[62] S. Bonelli, K. Radzicki, et al. (2007). The impulse response function
analysis of pore pressures monitoring data. In 5th International Confer-
ence on Dam Engineering.

38



[63] F. Perner, P. Obernhuber (2010). Analysis of arch dam deformations.
Frontiers of Architecture and Civil Engineering in China, 4(1):102–108.

[64] F. Li, Z. Wang, G. Liu (2013). Towards an error correction model for
dam monitoring data analysis based on cointegration theory. Structural
Safety, 43:1220.

[65] V. Nourani, A. Babakhani (2012). Integration of artificial neural net-
works with radial basis function interpolation in earthfill dam seepage
modeling. Journal of Computing in Civil Engineering, 27(2):183–195.

[66] D. Santillan, J. Fraile-Ardanuy, M. Toledo (2013). Dam seepage analysis
based on artificial neural networks: The hysteresis phenomenon. In
Neural Networks (IJCNN), The 2013 International Joint Conference
on, pages 1–8. IEEE.

[67] P. Cortez, M. J. Embrechts (2011). Opening black box data mining
models using sensitivity analysis. In Computational Intelligence and
Data Mining (CIDM), 2011 IEEE Symposium on, pages 341–348. IEEE.

[68] M. Gevrey, I. Dimopoulos, S. Lek (2003). Review and comparison of
methods to study the contribution of variables in artificial neural net-
work models. Ecological Modelling, 160(3):249–264.

[69] J. D. Olden, D. A. Jackson (2002). Illuminating the black box: a ran-
domization approach for understanding variable contributions in artifi-
cial neural networks. Ecological modelling, 154(1):135–150.

[70] S. Arlot, A. Celisse, et al. (2010). A survey of cross-validation procedures
for model selection. Statistics surveys, 4:40–79.

[71] D. R. Legates, G. J. McCabe (1999). Evaluating the use of goodness-of-
fit measures in gic and hydroclimatic model validation. Water resources
research, 35(1):233–241.

39


