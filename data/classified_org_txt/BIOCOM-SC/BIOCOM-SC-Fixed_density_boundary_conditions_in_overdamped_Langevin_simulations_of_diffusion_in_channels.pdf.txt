
































Fixed-density boundary conditions in overdamped Langevin simulations
of diffusion in channels

L. Ramı́rez–Piscina
Departament de F́ısica, Universitat Politècnica de Catalunya,

Avinguda Doctor Marañón 44, 08028 Barcelona, Spain
(Dated: June 12, 2018)

We consider the numerical integration of Langevin equations for particles in a channel, in the
presence of boundary conditions fixing the concentration values at the ends. This kind of boundary
condition appears for instance when considering the diffusion of ions in molecular channels, between
the different concentrations at both sides of the cellular membrane. For this application the over-
damped limit of Brownian motion (leading to a first order Langevin equation) is most convenient,
but in previous works some difficulties associated with this limit were found for the implementation
of the boundary conditions. We derive here an algorithm that, unlike previous attempts, does not
require the simulation of particle reservoirs or the consideration of velocity variables or adjustable
parameters. Simulations of Brownian particles in simple cases show that results agree perfectly with
theory, both for the local concentration values and for the resulting particle flux in nonequilibrium
situations. The algorithm is appropriate for the modeling of more complex ionic channels and, in
general, for the treatment of analogous boundary conditions in other physical models using first
order Langevin equations.

Keywords: Stochastic Differential Equations; Numerical Simulations; Brownian Motion; Boundary Condi-
tions; Ion channels

1. INTRODUCTION

Ionic channels are protein structures at the nanometric scale that permit the crossing of specific ions through
the cell membrane, leading to important physiological functions [1]. Ion flow through the channel is driven by the
concentration difference between the extracellular and intracellular media, and by the action of electrostatic forces
due to the membrane potential. Experiments performed on single channels show the presence of strong fluctuations,
both in the ionic flux and in the gating dynamics of the channel [2]. For the modeling of this problem it is often
convenient to consider the diffusive motion of ions inside the channel, in combination of some specific dynamics for
the gates [1, 3]. In some semimicroscopic approaches this is achieved by means of stochastic differential equations, or
Langevin equations, for ion positions and other variables [4–7]. Langevin equations are employed for modeling a large
variety of systems in which fluctuations are relevant for their dynamics [8, 9]. In such equations, the dynamic variable
obeys a stochastic differential equation in which most microscopic degrees of freedom are substituted by stochastic
terms or noises.

We consider here the Langevin dynamics of a population of Brownian particles, representing the individual ions,
moving in a molecular channel between two particle reservoirs with fixed concentrations, corresponding to those of
both sides of the membrane. The low Reynolds number values associated with such small scales imply that inertia is
negligible and one can safely take the overdamped limit of the Langevin equation, which means that the problem can
be formulated as a set of first order stochastic differential equations for the particle positions.

Whereas other boundary conditions on Brownian particles are standard and somewhat trivial in simulations (e.g.
absorbing or reflecting boundary conditions [8]), fixed concentration conditions have turned out to be more difficult
to implement efficiently in the overdamped case [10, 11]. Previous attempts involved for instance the simulation of
particles in the reservoirs [12, 13], the consideration of random walks as discrete-time Brownian dynamics [14], the
employing of velocity variables [15, 16], or some shooting method to empirically finding simulation parameters [17].
Here we make explicit the derivation and procedure of a satisfactory method for these boundary conditions, without
such shortcomings, recently implemented in ionic channel simulations [7, 18, 19]. For simplicity, we will illustrate
the method by the simulation of very simple cases, consisting of non-interacting particles in one-dimensional static
channels devoid of any biological complexity. The treatment of the boundary conditions would be applicable to more
complex and realistic situations.

The outline of this article is the following. In the next section we state the problem and show some known theoretical
results, which will be useful for interpreting simulations. In Sec. 3 we derive the algorithm for the boundary conditions
with fixed concentration values. In Sec. 4 we perform numerical simulations in order to check the method. In view of
the obtained results we also discuss some assumptions that are implicit in this kind of boundary conditions. We end
with some conclusions.



2

2. LANGEVIN EQUATION WITH FIXED CONCENTRATIONS BOUNDARY CONDITIONS

We consider the temporal evolution of an ensemble of independent Brownian particles, moving in the overdamped
limit in an external potential V (x) through a channel of length L. For simplicity we consider here the one dimensional
dynamics in the x-direction of the particles. The extension of the method to a three-dimensional system in contact
with a surface with fixed concentration is immediate. The Langevin equation for the position x ∈ (0, L) of each of
the particles is then

γẋ = −
dV (x)

dx
+ ξ(t), (1)

where γ is a friction coefficient and ξ(t) is a gaussian white noise with zero mean and correlation given by

⟨ξ(t)ξ(t′)⟩ = 2γkBTδ(t− t′). (2)

Noises acting on different particles are independent (uncorrelated). These equations have been constructed verifying
the fluctuation-dissipation theorem, and then lead to the correct equilibrium solutions. Here we will put the system
in a nonequilibrium situation by considering the channel connecting two reservoirs with fixed values of particle
concentration placed at both ends of the channel, and adding an external field acting on the particles.

Let ρ1, ρ2 be the particle concentration (i.e. number of particles per unit length in the channel) at x = 0, L
respectively. In the case of a very narrow channel connecting two large volumes, the values of ρ1, ρ2 are related to
the three-dimensional concentrations ci (particles per unit volume at the reservoirs) by ρi = Aci, with A being the
transversal section of the channel. Note that for a very narrow channel and large and well mixed reservoirs the flow
of ions will have a negligible effect on the values of the concentrations at the reservoirs, which permits us to consider
constant values for the boundary conditions. In order to have a theoretical reference for the simulation results it is
convenient to consider the Fokker-Planck equation for the concentration ρ(x, t) [8]:

∂ρ(x, t)

∂t
= −

∂

∂x
f(x)ρ(x, t) +D

∂2

∂x2
ρ(x, t), (3)

with the drift velocity f(x) and the diffusion coefficient D given by

f(x) = −
1

γ

dV

dx
, D =

kBT

γ
(4)

The steady solution of Eq. (3) with these boundary conditions can be written as

ρ(x) = e−V (x)/kBT
(
ρ1e

V (0)/kBT − J
γ

kBT

∫ x
0

eV (x
′)/kBT dx′

)
, (5)

with J being the steady current of particles, which is given by

J =
kBT

γ

ρ1e
V (0)/kBT − ρ2eV (L)/kBT∫ L

0
eV (x

′)/kBT dx′
. (6)

In the particular case of particles moving under the action of a constant drift (for instance charges q inside a planar
capacitor with voltage ϕ, which constitutes a model for a membrane channel), we can write V (x) = qϕ(x − x1)/L.
Then the current is

J = −
qϕ

γL

ρ1 − ρ2 exp(qϕ/kBT )
1− exp(qϕ/kBT )

. (7)

For large voltages the current is controlled by the rate at which particles can enter into the channel, which translates
into a dependence on one of the boundary concentrations, depending on the sign of the voltage. That is, for qϕ/kBT ≫
1 we have J ≃ −qϕρ2/γL, whereas for qϕ/kBT ≪ −1 we have J ≃ −qϕρ1/γL. Between these two limiting regimes the
system presents a crossover in which the current is regulated both by the different concentrations at both boundaries
and by the value of the voltage. When checking numerical results it will be appropriate to consider cases from each
of these three regimes.



3

3. NUMERICAL ALGORITHM

3.1. Time-discretized Langevin dynamics

Let us consider a temporal step ∆t. An explicit Euler algorithm for the evolution of the position variable of the
Brownian particle of Eq. (1) calculates the new x(t+∆t) by using the values at the old position x(t):

x(t+∆t) = x(t) + f(x(t))∆t+
√
2D∆t χ, (8)

where χ is a Gaussian random number of zero mean and unit variance. For later use we can also write an equivalent
formulation by means of the conditional probability density

p(x, x′) =
1

√
4πD∆t

exp−
(x− x′ − f(x′)∆t)2

4D∆t
, (9)

where p(x, x′)dx is the probability of a particle being at a position in the interval (x, x + dx) at the end of the time
step (at time t+∆t) if it was at position x′ at the beginning (at time t).
This last expression corresponds, for a constant drift (x-independent f), to the result that can be directly obtained

from the diffusive motion of the original Langevin [Eq. (1)]. Therefore Eq. (9) is exact for any ∆t in such constant
drift case.

3.2. Boundary conditions

The boundary conditions will be implemented in the following way. The particles in the system evolve according to
Eq. (1) until at the end of any time step any of the particles escape from the limits of the system. In this moment the
particle disappears from the simulation and it is never re-used. At the same time there exists a certain probability
for new particles entering into the system through each boundary at each time step.

These new particles, inserted with a given probability, start their dynamics at some initial position (which has also
to be determined), and evolve together with the rest of the particles until at some time step they could also exit from
the system. The objective here is to calculate this insertion probability and to determine the distribution of initial
positions.

3.2.1. Rate of new particles

Let us consider the left boundary at x = 0. The other boundary at x = L can be treated in an equivalent way. We
consider the semi-infinite domain (−∞, 0) (the particle reservoir) where there is supposed to exist an infinite number
of virtual particles with a homogeneous concentration (particles per unit length) ρ1, all evolving with the dynamics
of Eq. (1) but with a constant value of the drift equal to that of the boundary, i.e. f = f(0). Some of these virtual
particles can enter into the system and have a position x > 0 at the end of the time step ∆t. Let ρin(x) be the local
density inside the system of these new particles that in the previous step were outside the system. It can be calculated
by using Eq. (9) as

ρin(x) =

∫ 0
−∞

dx′ρ1p(x, x
′) =

ρ1
2

erfc

(
x− f∆t
√
4D∆t

)
. (10)

The mean number of particles entering through this boundary during the time step ∆t can be calculated by integrating
this density. After some manipulations, and by using known recurrence relations for the integrals of the error function
[see for instance Eq. (7.2.5) in Ref. [20]], we get

⟨N⟩ =
∫ ∞
0

dxρin(x) = ρ1
√
D∆t q(a), (11)

where a and the function q(x) are given by

a = −f
√

∆t

4D
(12)

q(x) = −x erfc(x) +
1
√
π
exp−x2. (13)



4

Since the particle arrivals are independent events, the number of particles that enter into the system at each time step
should be chosen from a Poisson distribution with the mean number ⟨N⟩ calculated in Eq. (11). This can be done by
using standard techniques [21]. However, for small ∆t and not very large densities, one has ⟨N⟩ ≪ 1 and the generation
of the Poisson random number can be avoided. Note that for small a Eq. (11) reduces to ⟨N⟩ ≃ ρ1

√
D∆t/π+ 1

2
ρ1f∆t

so this condition impose two conditions on ∆t, namely ∆t ≪ (ρ21D)−1 and ∆t ≪ (ρ1f)−1. In such case one can
neglect the possibility of two o more particles appearing during the same time step through the same boundary and
identify the obtained mean value with the probability of appearing one single particle, i.e. p(1) ≃ ⟨N⟩. The algorithm
then reduces to the generation at each time step of an uniform random value χ ∈ (0, 1), and its comparison with p(1).
If χ ≤ p(1) one particle enters by the boundary, and otherwise no particle enters.

3.2.2. Position of entering particles

Once the number of particles entering into the system during the temporal step is decided, their initial position has
to be determined. They cannot be placed at exactly the boundary, since they would leave the system by diffusion
almost immediately. Basically the initial position of new particles follows the probability (10), once normalized by
Eq. (11). That is, the new positions of the entering particles have the probability density p(x) given by

p(x) =
1

2 q(a)
√
D∆t

erfc

(
x− f∆t
√
4D∆t

)
. (14)

In order to sample the probability density, the standard method involves the inversion of the associated distribution
function [21]. This distribution function is obtained by integration of the probability. The result for p(x) is

F (x) =

∫ x
0

p(x) dx = 1−
q
(

x−f∆t√
4D∆t

)
q(a)

. (15)

Then, for each new particle entering into the system one should obtain a uniform random number χ ∈ (0, 1), and the
desired initial position is given by

x = F−1(χ). (16)

The actual inversion of F (x) can be done numerically, for instance by saving in a table a series of values of F (x) at
the beginning of the simulation, and performing afterwards interpolations for the desired values of F (x). For large x
(i.e. F (x) very close to 1) one can use the approximation

x ≃ f∆t+
√

−4γkBT∆t ln(2
√
πq(a)(1− χ) (17)

In our simulations we have employed Newton’s method by using an approximate guess and by using the fact that
the derivative of F (x) is the function p(x). In this way we can obtain the solucion of Eq. (16) by the iteration

yi+1 =
1

erfc yi

(
1
√
π
e−y

2
i − (1− χ)q(a)

)
(18)

until the desired convergence is achieved. The initial position of the new particle is then obtained as

x = f∆t+
√
4γkBT∆t y (19)

4. SIMULATION RESULTS AND DISCUSSION

4.1. Checking the algorithm

We have performed simulations of Brownian particles following the dynamics of Eq. (1) in a channel of length
L = 4. The chosen temperature has been kBT = 25 and the friction parameter γ = 1000. The temporal step has
been taken as ∆t = 10−4. In a system of units based on length 1 nm, time 0.1 µs and energy 1 meV these values
enter into the appropriate order of magnitude for ionic molecular channels. As a check of the algorithm we study the
particle concentration along the channel and the resulting particle flux in different cases. Particle densities have been
calculated by using n = 1000 spatial bins of width ∆x = L/n, and by counting the number of particles inside each
bin at each step.



5

0 1 2 3 4
x

0
2
4
6
8

10

ρ(
x) 8

10
12

8
10
12

Figure 1: Particle concentration vs. position in the steady state for different values of the external potential ϕ and boundary
conditions ρ1, ρ2. Red (gray) lines: average over 10000 independent realizations of the system; black lines: average on a single
realization over a temporal window Tmeas = 10

6. Top: qϕ = 0, ρ1 = ρ2 = 10; middle: qϕ = 8kBT , ρ1 = ρ2 = 10; bottom:
qϕ = 0, ρ1 = 1, ρ2 = 10.

In a first run of tests we have considered a constant deterministic drift f(x) = f , whose value has been varied. For
convenience we write f = −qϕ/γL, where qϕ is the potential energy difference between both ends of the channel.
Then q and ϕ could be understood as the electric charge of the particle and the external electric voltage respectively.
For this situation we have considered different values of concentration as boundary conditions at both ends of the
channel.

We first simulate cases with the same value of concentration at both ends of the system, ρ1 = ρ2 = 10. In this
case the steady particle distribution is a constant, equaling the value at the boundaries, for any value of the drift.
Measured densities, however, are expected to present large fluctuations (since the particles are non-interacting, the
number of them in each bin follows a Poisson distribution, from which it can be seen that values of local density
should have a dispersion of order σρ(∆x) =

√
ρ/∆x). It is hence most convenient averaging either by running many

independent realizations of the system (reducing dispersion by 1/
√
N) or by performing time averages in the steady

state. This is shown in Fig. 1. At the top we present an equilibrium situation with no external field applied (i.e.
qϕ = 0). The red (gray in the printed version) line is the average of 10000 independent realizations, taken once
reached the steady state. The result presents the correct steady solution, with a dispersion of values σi = 0.512 very
close to the expected fluctuations σρ(∆x)/

√
N = 0.5. The black line is a long temporal average of a single realization

in the steady state during a window Tmeas = 10
6. Here dispersion is strongly reduced, and it can be seen that results

converge perfectly to the expected solution ρ(x) = 10.
By imposing an external field (qϕ = 8kBT ) and maintaining the same boundary conditions we get the results

shown in the middle of Fig. 1. We also show averages over 10000 independent realizations [red (gray) line] and a long
temporal average during a window Tmeas = 10

6 (black line). We are no longer in an equilibrium situation, but the
results agree as well with the steady state solution ρ = constant. The dispersion of values σi = 0.507 is also very close
to the expected value 0.5.

This agreement is remarkable since the concentration value at the boundaries is imposed in the simulation by the
mean rate at which new particles enter into the system only, which is calculated by using the boundary condition
and the local value of the drift, but not using the expected flux or any other aspect of the solution of the problem.
The dynamics of the particles (and their eventual exit from the system) is given exclusively by the trajectories of the
Langevin equation (1), without using the value of the prescribed concentration or any other data. It is also worth



6

0 1 2 3 4
x

0

1

2

3

4

5

6

7

8

9

10

11
ρ(

x)

Figure 2: Particle concentration vs. position in simulations with an constant external field qϕ = 8kBT . Colored (gray) lines
are simulation results averaged for 10000 independent realizations; black lines are theoretical predictions from Eq. (5). Blue
(dark gray) line: ρ1 = 1, ρ2 = 10; red (light gray) line: ρ1 = 10, ρ2 = 1.

noting that there no boundary layer is visible near the ends, as could occur in some other approaches.
Note that by comparing the resulting particle densities in the cases without and with external field (top and middle

plots in Fig. 1), they are completely indistinguishable. They both present fluctuations that are uncorrelated in space,
and of the same magnitude. Their local mean values are given by the solution of the Fokker-Planck equation (3), and
for this equation the presence of a constant drift is equivalent to the switching to a moving reference frame. Therefore
in this situation with homogeneous mean density the invariance of the results when changing the field was expected.

We also test the steady solution reached by the system between boundaries with very different concentration values.
For qϕ = 0 and ρ1 = 1, ρ2 = 10 simulation results for local concentration are presented with the same statistics as the
other cases at the bottom of Fig. 1. In this case the steady solution between both values has a constant slope. Again
results converge to the theoretical solution by means of a long temporal averaging. It is observed that fluctuations
are larger in the higher concentration side, as expected, and reduced at the other boundary.

Simulation results and theoretical predictions are compared in Fig. 2 for a large external field qϕ = 8kBT and
boundary conditions with very different concentration values. Simulation results (fluctuating colored lines, gray in
the printed version) are averages for 10000 realizations. Black lines correspond to the theoretical prediction of Eq. (5).
In one case (blue, dark gray, line) both external field and concentration gradient drive the flow in the same direction,
towards the left side, whereas in the other case both mechanisms act towards oposite directions. As can be seen in
both cases the agreement is very good. Long temporal averages for both cases have also been obtained (not shown),
the results being virtually indistinguishable from the theoretical lines.

Next we have tested the prediction for the particle flux, Eq. (7). For this test we have considered the situation
with very different concentration values at both ends of the channel, ρ1 = 10 and ρ2 = 1, and performed simulations
for different values of the drift, in order to span very different regimes. We have averaged the results over a time
Tmeas = 10

6. In Fig. 3 we show theoretical predictions and simulation results for particle flux through the channel
We see that the agreement is virtually perfect in all regimes: namely for flux controlled by the concentration of a
single end (i.e. very large voltages, either positive or negative) in which current is proportional to voltage, and for the



7

-10 -5 0 5 10 15 20
qφ/k

B
T

-0.2

-0.1

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7
J(

qφ
)

Figure 3: Particle flux (particles crossing the channel per unit time, averaged for a total time Tmeas = 10
6) vs. potential energy,

with boundary conditions ρ1 = 10 and ρ2 = 1. Line: theoretical prediction of Eq. (7); symbols: simulation results. Observed
differences in J values between theory and simulations were in all cases smaller than 10−3.

crossover regime in which the flux is controlled by the concentration of both ends. In fact, by analyzing the obtained
values, the differences with theoretical results are of the order of magnitude of the expected statistical uncertainties
(since the crossing of individual particles forms independent events, the total number of them in a temporal span
Tmeas is a Poisson process, which implies that the variance in the measured mean flux should be σ

2
J = J/Tmeas).

We finally simulate the case of a channel with a potential barrier in the middle. This could be representative of an
ionic channel with a more complex potential landscape, or with the presence of a gate. Following the shape of the
gates used in Refs. [7, 18, 19] we add a Gaussian barrier to the constant drift, with which the total potential reads

V (x) = qϕ(x− x1)/L+ Vb exp−
(x− xb)2

2l2
, (20)

where Vb is the height, l is the width, and xb is the center position of the barrier. We have taken the values Vb = 8KBT ,
l = L/16, xb = L/2, and the potential energy difference qϕ = −8kBT . In this case the constant force term pushes
the particles towards the right side, but they are trapped due to the barrier and the resulting flow is reduced. As a
result one observes a slow transient during which a large number of particles are being accumulated until the system
reaches the steady state. We have followed this transient and compared it with the direct numerical integration of
the Fokker-Planck equation (3). Results are presented in Fig.4. We see in this figure that the agreement is very good
during the entire transient. It is remarkable that the rate at which particles are accumulating depends critically on
the balance of entering and exiting particles, and hence on the boundary conditions.

4.2. Boundary conditions revisited

The proposed algorithm for the fixed concentration boundary conditions belongs to the class of methods that assign
probabilistic rules for the appearance of new particles at the boundaries [15–17]. An important difference of this type



8

0 1 2 3 4
x

0

20

40

60

80

100

120
ρ(

x,
t)

t=0.0
t=0.5
t=1.0
t=2.0
t=10

0 1 2 3 4
-8

-6

-4

-2

0

2

4

6

8

10

12

14

V
(x

)/
kT

Figure 4: Particle concentration vs. position during the transient (t = 0, 0.5, 1, 2) and in the steady state (t = 10). Simulations
are performed with an external potential qϕ = −8kBT and a potential barrier as specified in Eq. (20), also represented. Colored
(gray) lines: simulation results averaged for 10000 independent realizations; black lines: numerical integration of Eq. (3); dashed
line: applied potential acting on the particles.

of algorithms from others using buffer zones or particle reservoirs is that in the latter methods the dynamics at the
boundary outside the system is simulated with buffer particles, which implies that some assumptions on this dynamics
(for instance the size of the buffer zone, or the criteria for maintaining constant concentration) have to be established.
The validity of these assumptions should be discussed in terms of the real physics of the system at hand.

In fact, also in the present algorithm (and in other algorithms assuming the probabilistic appearance of particles
at the boundary) an important assumption has been implicitly assumed: the probability of new particles entering
into the system does not depend on past exit events, and as a consequence the boundary loses memory of any exiting
particle instantaneously. This is equivalent to saying that the particle reservoirs (which are not explicitly simulated)
are assumed to be mixed at each time step. An immediate effect is an implicit loss of temporal correlations near
the boundaries. We will illustrate the consequences of this assumption by returning to the simple simulations of the
channel without a barrier and with the same values of prescribed concentrations at both ends of the channel.

We show again in Fig. 5 (top) results for the equilibrium situation with no external field applied (qϕ = 0) as in Fig. 1
(top). Here we show several temporal averages calculated in shorter windows Tmeas = 10

3. We clearly see here that
when performing temporal averages the appearance of the fluctuations is radically different from when performing
averages over independent realizations. Namely the concentration values in different positions are correlated when
they are calculated by temporal averages, due to the contribution of the same particles moving diffusively across the
system, which results in the shape of the fluctuations appearing in the figure. Short length fluctuations are short lived
(their associated diffusion times have smaller diffusion times ∼ λ2/D) and they are averaged out. This is so because
the effective number of independent observations of a statistical quantity with correlation time Tcorr in a temporal
window Tmeas is of the order of Tmeas/2Tcorr, and the resulting dispersion is reduced as the square root of this effective
number (see, for instance, Ref. [22]). However long length fluctuations are slower and do not disappear in not very
long temporal averages. This is manifested in the large dispersion of results that can be seen at the center of the
channel.

This dispersion of results is strongly reduced at the boundaries, as can also be seen in Fig. 5 (top). Since the loss
of temporal correlations is produced at the boundaries, fluctuations there will have shorter correlation times than
in the middle of the system. As a result statistical dispersion after temporal averaging will also be shorter near the



9

0 1 2 3 4
x

8

10

12

ρ(
x)

8

10

12

Figure 5: Particle concentration vs. position for temporal averages Tmeas = 10
3 in the steady state. Top: qϕ = 0; bottom

qϕ = 8kBT .

boundaries, and the averaged concentration values will better converge to the prescribed values of boundary conditions
there. When performing even shorter temporal averages (not shown) dispersions are seen to be larger in the middle
of the system but they are also reduced at both ends, in such a way that the prescribed concentration values are also
verified.

In Fig. 5 (bottom) we present the case with the same concentration at the boundaries, but with an applied field
qϕ = 8kBT . Differently from what is observed in Fig. 1, temporal averages are no longer invariant when changing
the field. Dispersion at the ends are also reduced and the boundary conditions are well verified, but dispersion in
the middle of the channel is smaller than in the equilibrium case. This is due to the deterministic drift given by the
external field. Particles in average remain in the system a ballistic time of the order of L/qϕ, smaller than the diffusion
time, and therefore there is a shorter time to develop density fluctuations. The lifetimes of the largest fluctuations
are shorter than in the equilibrium case and, as a consequence, the same simulation times permit a better average
and the observed dispersion is smaller.

These observations constitute an indication that in Langevin simulations of diffusing particles, constant concentra-
tion boundary conditions imply more assumptions that the mere specification of the mean concentration values at the
boundaries. To illustrate this point let us consider the case of solving the simplest case of a small piece or segment
of length L of a very large (or infinite) channel with a mean density ρ of free particles in equilibrium. At the level of
the Fokker-Planck equation for the mean density the appropriate boundary condition will be the fixing of the value
of the concentration at both ends of the segment of length L, i.e. the same as what has been considered here. But at
the level of the Langevin dynamics of the particles, one should expect in this case the presence of density fluctuations
of large scale (much larger than the piece size L), which will decay very slowly, at times of the order of its diffusion
time. Then, in a finite time averaging the piece of length L should almost always be in a large fluctuation, and the
concentration values of the boundary conditions would almost never be observed.

On the contrary, the way in which we have implemented the boundary conditions in this work (corresponding to
the same Fokker-Planck equation and with the same solution for the mean density) does not correspond to a piece
of a such much larger homogeneous system, but instead to a system of length L between two boundaries separating



10

the system from reservoirs that are perfectly mixed. It is precisely the loss of correlations at the boundaries which
permits the prescribed concentration values to be observable in temporal averages.

5. CONCLUDING REMARKS

We have derived an algorithm for the integration of first order additive Langevin equations in the presence of fixed
concentration boundary conditions. The method consists of letting disappear any particle that exit from the system
through the boundary, and the appearance of new particles near the boundaries according to the prescribed condition.
For this we have calculated the appearance probability and the distribution of initial positions for the new particles.
This method implies that particle memory is lost when crossing the boundary, which is equivalent to resetting the
positions of the reservoir particles at each time step. This permits us to eliminate fluctuations larger than the system
size, which would hinder the verifying of the boundary condition in finite simulations.

In situations in which there is not a perfect mixing in the reservoirs, the method would also be appropriate for
modeling separately the microscopic dynamics of the individual particles in the system (i.e. the channel) and the
concentration dynamics outside the system (for instance by means of more mesoscopic or hydrodynamic models). The
resolution of the latter dynamics would then be used as the boundary condition for the former. The only requirement
in this case would be that the resulting flux across system had a negligible effect over the reservoirs. This is the
important case of a very thin channel joining two large cavities.

This algorithm for the boundary conditions is closely related to what employed in other works [15–17], where the
simulation of the particle reservoirs was also avoided by considering the stochastic appearance of new particles through
the boundary. In particular in Ref. [17] it was already remarked that some prescription was necessary for the initial
position of the new particles in order to avoid the appearance of spurious depletion boundary layers at the boundary,
and a specific distribution of new positions was derived provided the flux was known. This fact limited the procedure
to analytically resolvable problems or to resorting to a shooting method to adjust a simulation parameter. On the
contrary for our algorithm we have directly calculated both appearance and new position probabilities, depending
only on the desired boundary condition and on the local drift at the boundary. As a result we obtain in all cases the
correct results without the use of any adjustable parameter.

We have checked simulation results in conditions appropriate for modeling molecular ionic channels at the cellular
membrane, that is for the Brownian dynamics in the overdamped limit of ions with a constant deterministic drift
corresponding to the value of the membrane potential. Results agree perfectly with theoretical predictions, both for
(steady and transient) density distribution and for resulting mean flux. Moreover the magnitude of fluctuations agree
with the expected values.

As already pointed out, the method has no adjustable parameter, and does not involve the explicit simulation of
particles in the reservoirs or the consideration of velocity variables that should be irrelevant in the low Reynolds limit.
The results do not show any trace of residual boundary layers. It can be applied to any model formulated in terms of
trajectories of Brownian particles following first order additive Langevin equations of the type of Eq. (1). Therefore it
is specially appropriate in Langevin approaches for the study of molecular channels and the modeling of the interaction
between gates and individual ions and the action of the membrane potential, as used in Refs. [7, 18, 19].

Acknowledgments

This work was performed in the context of an extensive collaboration with Prof. J.M. Sancho in the area of
molecular channel dynamics, and many and very fruitful discussions with him are gratefully acknowledged. This work
was supported by the Ministerio de Economia y Competividad (Spain) and FEDER (European Union), under project
FIS2015-66503-C3-2-P.

[1] B. Hille, Ion Channels of Excitable Membranes (Sinauer, Sunderland, 2001), 3rd ed.
[2] C. Hammond, Cellular and Molecular Neurophysiology (Academic Press, Amsterdam, 2015), 4th ed.
[3] D. G. Levitt, Annual review of biophysics and biophysical chemistry 15, 29 (1986).
[4] K. Cooper, E. Jakobsson, and P. Wolynes, Progress in biophysics and molecular biology 46, 51 (1985).
[5] D. G. Levitt, The Journal of general physiology 113, 789 (1999).
[6] K. Lee and W. Sung, Physica A: Statistical Mechanics and its Applications 315, 79 (2002), ISSN 0378-4371, slow

Dynamical Processes in Nature, URL http://www.sciencedirect.com/science/article/pii/S0378437102012475.
[7] L. Ramı́rez-Piscina and J. M. Sancho, EPL (Europhysics Letters) 108, 50008 (2014).



11

[8] C. W. Gardiner, Handbook of stochastic methods for physics, chemistry and the natural sciences, vol. 13 of Springer Series
in Synergetics (Springer-Verlag, Berlin, 2004), 3rd ed., ISBN 3-540-20882-8.

[9] J. Garćıa-Ojalvo and J. M. Sancho, Noise in Spatially Extended Systems (Springer, New York, 1999).
[10] V. Barcilon, D. Chen, R. S. Eisenberg, and M. A. Ratner, The Journal of Chemical Physics 98, 1193 (1993),

https://doi.org/10.1063/1.464342, URL https://doi.org/10.1063/1.464342.
[11] A. Singer, Z. Schuss, B. Nadler, and R. S. Eisenberg, Phys. Rev. E 70, 061106 (2004), URL https://link.aps.org/doi/

10.1103/PhysRevE.70.061106.
[12] B. Corry, M. Hoyles, T. W. Allen, M. Walker, S. Kuyucak, and S.-H. Chung, Biophysical journal 82, 1975 (2002).
[13] A. Gomez-Marin and J. M. Sancho, Phys. Rev. E 77, 031108 (2008), URL https://link.aps.org/doi/10.1103/PhysRevE.

77.031108.
[14] M. F. Schumaker, The Journal of chemical physics 117, 2469 (2002).
[15] R. S. Eisenberg, M. M. Klosek, and Z. Schuss, The Journal of Chemical Physics 102, 1767 (1995),

https://doi.org/10.1063/1.468704, URL https://doi.org/10.1063/1.468704.
[16] B. Nadler, Z. Schuss, and A. Singer, Phys. Rev. Lett. 94, 218101 (2005), URL https://link.aps.org/doi/10.1103/

PhysRevLett.94.218101.
[17] A. Singer and Z. Schuss, Phys. Rev. E 71, 026115 (2005), URL https://link.aps.org/doi/10.1103/PhysRevE.71.026115.
[18] L. Ramı́rez-Piscina and J. M. Sancho, European Physical Journal B 91, 10 (2018), URL http://dx.doi.org/10.1140/

epjb/e2017-80569-5.
[19] L. Ramı́rez-Piscina and J. Sancho, Physica A: Statistical Mechanics and its Applications 505, 345 (2018), ISSN 0378-4371,

URL http://www.sciencedirect.com/science/article/pii/S0378437118303935.
[20] M. Abramowitz, Handbook of Mathematical Functions, With Formulas, Graphs, and Mathematical Tables, (Dover Publi-

cations, Inc., New York, 1974), ISBN 0486612724.
[21] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery, Numerical Recipes 3rd Edition: The Art of Scientific

Computing (Cambridge University Press, New York, NY, USA, 2007), 3rd ed., ISBN 0521880688, 9780521880688.
[22] D. W. Heermann, Computer-Simulation Methods (Springer-Verlag, 1990), pp. 8–12.


