











































DeepVoice: Tecnoloǵıas de Aprendizaje Profundo aplicadas al
Procesado de Voz y Audio

Deep Learning Technologies for Speech and Audio Processing

Marta R. Costa-jussà y José A. R. Fonollosa
TALP Research Center - Universitat Politècnica de Catalunya, Barcelona

{marta.ruiz,jose.fonollosa}@upc.edu

Resumen: Este proyecto propone el desarrollo de nuevas arquitecturas para el pro-
cesado de la voz y el audio mediante métodos de aprendizaje profundo, explorando
también nuevas aplicaciones y dando continuidad al trabajo inicial del equipo de
investigadores solicitante y de toda la comunidad internacional. Las lineas de in-
vestigación incluyen: reconocimiento de voz, reconocimiento de eventos acústicos,
śıntesis de voz y traducción automática.
Palabras clave: Tecnoloǵıas del habla, Aprendizaje profundo, Reconocimiento del
habla, Conversión de texto a voz, Redes neuronales profundas

Abstract: This project proposes the development of new deep learning methods for
speech and audio processing, exploring new applications and continuing the initial
work of the research team and the international community. Research lines include:
automatic speech recognition, acoustic event detection, speech synthesis and machine
translation.
Keywords: Speech technology, Deep learning, Speech recognition, Text to speech,
Deep neural networks

1 Participantes del proyecto

El grupo de investigación que participa en el
proyecto es el grupo de Voz del Departamen-
to de Teoŕıa de Señal y Comunicaciones de
la Universidad Politécnica de Cataluña. Los
investigadores principales son los mismos au-
tores de este art́ıculo.

2 Entidad financiadora

El proyecto está financiado por el Ministerio
de Economı́a y Competitividad y el Fondo
Europeo de Desarrollo Regional y el codigo
del proyecto es TEC2015-69266-P. DeepVoice
comenzó el 1 de enero de 2016 y tiene una
duración de cuatro años.

3 Contexto y motivación

Las tecnoloǵıas de aprendizaje profundo ha-
cen referencia a los métodos y sistemas de
aprendizaje automático compuestos de varias
capas de procesamiento o niveles de abstrac-
ción. Esta familia de algoritmos suele caracte-
rizarse además por tener una estructura sen-
cilla de describir y versátil. En concreto, este

aprendizaje profundo suele utilizar alguna va-
riante de las redes neuronales artificiales de
múltiples capas o profundas para aprender
un determinado modelo. En este modelado
es tan importante la arquitectura de la red
neuronal como el algoritmo de entrenamien-
to o aprendizaje de los parámetros de esta
red.

En los últimos años, el modelado median-
te redes neuronales ha resurgido con mucha
fuerza gracias a ese énfasis en el aprendizaje y
en el número de capas. Otros factores impor-
tantes han sido la disponibilidad de mayor ca-
pacidad de cálculo y de grandes bases de da-
tos. La grandes bases de datos permiten en-
trenar mejor estructuras multicapa con gran
número de parámetros y los recursos compu-
tacionales permiten realizar este proceso en
tiempos razonables.

A pesar de que su uso no se ha generali-
zado hasta hace unos pocos años y de la difi-
cultad de analizar el comportamiento de los
algoritmos de aprendizaje profundo, su im-
pacto ha sido ya espectacular en mucho ámbi-



tos como el procesado de imagen, voz y texto
tanto a nivel de investigación como comer-
cial. En reconocimiento de voz, por ejemplo,
se ha pasado de un avance anual muy len-
to basado en sistemas de gran complejidad a
estructuras sencillas de aprendizaje profundo
que suponen toda una revolución en cuanto
a arquitectura y salto en prestaciones.

Este proyecto propone el desarrollo de
nuevas arquitecturas para el procesado de la
voz y el audio mediante métodos de apren-
dizaje profundo, explorando también nuevas
aplicaciones.

El proyecto incluye un paquete de traba-
jo general dedicado al aprendizaje profundo
y otros cuatro paquetes de trabajo dedicados
al reconocimiento del habla y del locutor, de-
tección de eventos acústicos, śıntesis de voz
y traducción de voz. En el primer paquete de
trabajo se exploran nuevas arquitecturas y al-
goritmos de aprendizaje, teniendo en cuenta
el coste computacional y la escalabilidad a
grandes bases de datos, mientras que los si-
guientes exploran su aplicación en procesado
de la voz y del audio. En la siguiente sec-
ción mencionamos con algo más de detalle
qué aportaciones se harán en cada una de las
tareas.

En estas tareas o en la difusión de los re-
sultados está previsto continuar colaborando
con otros grupos de investigación a nivel na-
cional e internacional y con las empresas in-
teresadas en la temática del proyecto y sus re-
sultados. En concreto, se incluye en el plan de
trabajo la colaboración con el hospital Sant
Joan de Déu de Barcelona en la detección
y mejora de las condiciones acústicas de las
unidades de cuidados intensivos de neonatos.
También se pone énfasis en la evaluación de
los resultados. Se comenta esta colaboración
en la sección 5 de este art́ıculo.

4 Proyecto DeepVoice

El proyecto integra diferentes áreas de las
tecnoloǵıas del habla y prentende contribuir
en cada una de ellas incorporando modelos
de aprendizaje profundo. A continuación des-
cribimos brevemente los objetivos de cada
uno de los paquetes de trabajo del proyecto
que además del paquete de arquitecturas de
aprendizaje profundo incluye las areas de: re-
conocimiento de voz, reconocimiento de even-
tos acústicos, śıntesis de voz y traducción au-
tomática.

4.1 Arquitecturas de aprendizaje
profundo

Las arquitecturas profundas construidas a
partir de redes neuronales artificiales tienen
una larga historia, pero su reciente renaci-
miento está relacionado con la disponibili-
dad de algoritmos de entrenamiento efica-
ces, bases de datos grandes y hardware de
computación potente (Hinton, Osindero, y
Teh, 2006; Bengio, 2009).

El proyecto dedicará recursos a investigar
nuevas arquitecturas de aprendizaje profun-
do que puedan ser útiles en aplicaciones de
voz. Se pretende desarrollar medidas de op-
timización nuevas para entrenar redes recu-
rrentes con datos no segmentados. Asimis-
mo, desarrollar nuevos algoritmos de entre-
namiento o modificar los ya existentes para
que sean paralelizables.

4.2 Reconocimiento de voz

El impacto del aprendizaje profundo en re-
conocimiento de voz ha sido revolucionario y
abarcan las tres ĺıneas de investigavión que
vamos a seguir en este proyecto.

En primer lugar, en robustez del sistema
de reconocimiento, algunos trabajos recien-
tes proponen usar redes neuronales profun-
das (Xia y Bao, 2014) para reducir el ruido
de la señal, por poner un ejemplo. En esta di-
rección, se contribuirá mediante el desarrollo
de técnicas basadas en aprendizaje profundo
que permitan añadir ruido al sistema sin que
la calidad se vea afectada.

En segundo lugar, se pretende desarrollar
arquitecturas end-to-end de reconocimiento
de voz, viendo la viabilidad de las mismas
en ejemplos anteriores (Hannun et al., 2014).
Para ello, se debe hacer un estudio exhaustivo
de las caracteŕısticas perceptuales en mode-
lado acústico y su modelización con modelos
neuronales profundos. Asimismo, se pretende
usar redes neuronales recurrentes y entrena-
mientos conjuntos para los modelos acústico
y de lenguaje.

Finalmente, en reconocimiento de locutor
trabajos anteriores como (Richardson, Rey-
nolds, y Dehak, 2015) usan las redes neuro-
nales para extracción automática de carac-
teŕısticas. En este proyecto se pretende ir más
allá y usar la entrada de señal sin modificar
para mejorar el rendimiento de los algoritmos
de aprendizaje profundo.



4.3 Reconocimiento de eventos
acústicos

El contexto de esta tarea se encuentra en la
unidad de curas intensivas de neonatos (NI-
CU). En este contexto, hay muchos ruidos
que se tienen que filtrar para estudiar los pa-
trones relevantes. Se pretende grabar y eti-
quetar datos recogidos de micrófonos instala-
dos en las incubadoras de las NICU. La base
de datos incluirá información sobre las varia-
bles fisiológicas relevantes y los patrones de
sueño.

4.4 Śıntesis de voz

El aprendizaje profundo se ha integrado en
śıntesis de voz principalmente aplicado a la
modelización paramétrica (Ling et al., 2015)

La tarea de śıntesis de voz es básicamen-
te una tarea de regresión. Con tal de produ-
cir voz natural y continua se pueden utilizar
técnicas de generación paramétrica. En esta
area, proponemos investigar representaciones
de la voz que permitan usar redes neurona-
les. También pretendemos proponer y evaluar
técnicas de aprendizaje profundo para redu-
cir el ruido de la voz generada e incluir ex-
presividad en la voz final.

4.5 Traducción automática

En este caso, el aprendizaje profundo se ha
usado para mejorar los sistemas estad́ısticos
ya existentes y también ha permitido desarro-
llar un nuevo paradigma de traducción usan-
do un modelado de secuencia a secuencia. Co-
mo en las otras areas, la lista de trabajos es
muy extensa (Costa-jussà et al., 2017).

La traducción automática se puede apli-
car a la voz o al texto. El objetivo al final de
este proyecto es construir un sistema de tra-
ducción de voz a texto, ya sea concatenando
técnicas de reconocimiento de voz y traduc-
ción de texto o planteando un sistema directo
de voz a texto traducido. En el primer caso,
se integrarán las mejoras del paquete de re-
conocimiento de voz y las mejoras que aporta
un paradigma de traducción automática ba-
sado en redes neuronales. En el segundo caso,
se diseñará una nueva arquitectura neuronal
para afrontar el reto.

5 Impacto del proyecto

Las tecnoloǵıas de voz pueden facilitar el ac-
ceso a la información (comunicación hombre-
máquina) y la comunicación humana. Los dis-
positivos electrónicos se están convirtiendo

en imprescindibles. El uso de la voz en es-
tos dispositivos es cada vez más esencial y
también puede abrir una nueva gama de po-
sibilidades. Estas tecnoloǵıas también pueden
aplicarse a múltiples campos espećıficos, co-
mo mejorar la comunicación y la comprensión
de los seres humanos, ayudar a las personas
discapacitadas y ancianas, mejorar los servi-
cios ofrecidos en los medios de comunicación,
etc. El empleo de dispositivos de voz con vo-
ces inadecuadas (género, edad, acento, dia-
lecto, tono) o sistemas de reconocimiento de
voz que no funcionan en condiciones ruidosas
pueden desalentar a los usuarios. El desarro-
llo que estamos proponiendo de la tecnoloǵıa
de voz será la clave para aplicaciones robus-
tas de alta calidad. Asimismo, la traducción
es un aspecto importante para reducir las ba-
rreras internacionales y lograr el pleno en-
tendimiento entre las personas, preservando
al mismo tiempo las sociedades multilingües.
Esperamos realizar traducciones de voz en
tiempo real y de alta calidad con concate-
nación e integración de reconocimiento pro-
fundo de voz y tecnoloǵıas de traducción au-
tomática. Esto representaŕıa un progreso cla-
ro en los negocios y las relaciones poĺıticas,
aśı como en las áreas de ocio y educación.

Nuestra propuesta de investigación sobre
detección de eventos acústicos también inclu-
ye su aplicación espećıfica en unidades de cui-
dados intensivos neonatales (NICU). En este
caso, se diferenciarán los factores de ruido mi-
croambiental y los signos fisiológicos y aśı los
cĺınicos podrán proponer mejores protocolos
NICU.

6 Página web

En la página web del proyecto
http://www.tsc.upc.edu/deepvoice/
se puede consultar el equipo de investiga-

ción. En la misma página también se harán
públicos los principales resultados alcanzados
con el progreso de DeepVoice.

Bibliograf́ıa

Bengio, Y. 2009. Learning deep architectu-
res for ai. Found. Trends Mach. Learn.,
2(1):1–127, Enero.

Costa-jussà, M. R., A. Allauzen, L. Barrault,
K. Cho, y H. Schwenk. 2017. Introduc-
tion to the Special Issue on Deep Learning
Approaches for Machine Translation. Ac-
cepted for publication in Computer Speech



and Language, Special Issue in Deep lear-
ning for Machine Translation.

Hannun, A. Y., C. Case, J. Casper, B. Ca-
tanzaro, G. Diamos, E. Elsen, R. Pren-
ger, S. Satheesh, S. Sengupta, A. Coates,
y A. Y. Ng. 2014. Deep speech: Scaling
up end-to-end speech recognition. CoRR,
abs/1412.5567.

Hinton, G. E., S. Osindero, y Y. Teh. 2006.
A fast learning algorithm for deep belief
nets. Neural Comput., 18(7):1527–1554,
Julio.

Ling, Z., S. Kang, H. Zen, A. W. Senior,
M. Schuster, X. Qian, H. M. Meng, y

L. Deng. 2015. Deep learning for acoustic
modeling in parametric speech generation:
A systematic review of existing techniques
and future trends. IEEE Signal Process.
Mag., 32(3):35–52.

Richardson, F., D. A. Reynolds, y N. Dehak.
2015. A unified deep neural network for
speaker and language recognition. CoRR,
abs/1504.00923.

Xia, B. y C. Bao. 2014. Wiener filtering
based speech enhancement with weighted
denoising auto-encoder and noise classifi-
cation. Speech Communication, 60:13–29.


