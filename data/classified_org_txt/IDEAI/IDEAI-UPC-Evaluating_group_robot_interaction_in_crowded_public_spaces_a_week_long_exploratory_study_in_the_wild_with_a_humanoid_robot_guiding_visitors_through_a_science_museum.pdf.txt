







































2013_IJHR_DiazetalV3_CameraReady 02.dvi


April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

International Journal of Humanoid Robotics
c© World Scientific Publishing Company

EVALUATING GROUP-ROBOT INTERACTION IN CROWDED

PUBLIC SPACES: A WEEK-LONG EXPLORATORY STUDY IN

THE WILD WITH A HUMANOID ROBOT GUIDING VISITORS

THROUGH A SCIENCE MUSEUM

MARTA DÍAZ, DENNYS PAILLACHO∗, CECILIO ANGULO

Technical University of Catalonia, Vı́ctor Balaguer 1

08800 Vilanova i la Geltrú, Spain

{marta.diaz, dennys.paillacho, cecilio.angulo}@upc.edu

∗Escuela Superior Politécnica del Litoral, Km 30.5 v́ıa Perimetral

09015863 Guayaquil, Ecuador

dpaillac@espol.edu.ec

ORIOL TORRES, JONATHAN GONZÁLEZ

PAL Robotics, Pujades 77-79

08005 Barcelona, Spain

{oriol.torres, jon.gonzalez}@pal-robotics.com

JORDI ALBO-CANALS

La Salle BCN – Ramon Llull University, Quatre Camins 30

08022 Barcelona, Spain

jalbo@salle.url.edu

This paper describes an exploratory study on group interaction with a robot-guide
in an open large-scale busy environment. For an entire week a humanoid robot was
deployed in the popular Cosmocaixa Science Museum in Barcelona and guided hundreds
of people through the museum facilities. The main goal of this experience is to study in
the wild the episodes of the robot guiding visitors to a requested destination focusing
on the group behavior during displacement. The walking behavior follow-me and the

face to face communication in a populated environment are analyzed in terms of guide-
visitors interaction, grouping patterns and spatial formations. Results from observational
data show that the space configurations spontaneously formed by the robot guide and
visitors walking together did not always meet the robot communicative and navigational
requirements for successful guidance. Therefore additional verbal and nonverbal prompts
must be considered to regulate effectively the walking together and follow-me behaviors.
Finally, we discuss lessons learned and recommendations for robot’s spatial behavior in
dense crowded scenarios.

Keywords: Group-robot interaction; robotic-guide; social navigation; space management;
spatial formations; group walking behavior; crowd behavior.

1



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

2 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

1. Introduction

Service robots are increasingly taking part of people daily life activities interacting

socially and sharing spaces with individual and groups in close proximity. For social

robots featured with walk around functionality, key questions to be addressed for

effective performance are how to move (i.e. speed, kind of movement, trajectories),

where to perform (i.e. proximity management) and how to place (i.e. distance,

position, stance and orientation) to be unobtrusive, effective and socially congruent.

Promising attempts to optimize social robots spatial management in different

scenarios (e.g. assistive telepresence at home) have been developed applying models

and knowledge from social psychology (i.e. proxemics, space formations, group walk-

ing patterns and crowd dynamics). Guidance is one of the most useful services of

robots in public spaces as museums, exhibitions, malls, and tourist sites. Assuming

the role of guide the robot not only provides people with appropriate information

to make the visit a more enjoyable experience but help them to reach intended

destinations. The main difference between an informer or recommender robot and a

robotic guide is that guidance in public spaces implies social navigation in a highly

dynamic scenario; i.e., that the social robot navigation design must consider the

actions of people around them.

Socially compliant navigation1 implies planning and performing robot’s trajec-

tories and motion behavior taking into account the communicative function and

social rules of space management in a shared location. Smart spatial behavior (e.g.

interpersonal distance, orientation) according to social norms would not only en-

hance collocated user’s safety and acceptance but also provide mobile robots with

an intuitive rich nonverbal channel to communicate intentions (e.g. shift direction,

initiate displacement) and to express emotional content2.

To explore guide robot-visitors performance in open large-scale dense environ-

ments PAL Robotics’ REEM robot was deployed during a week in the CosmoCaixa

Science Museum informing, motivating, giving directions and walking groups of

visitors to requested locations. The whole experience was video-recorded by two

external general-view cameras and one on-board camera for observational data

analyses. Our approach is to put the focus on the group spatial behavior rather

than on individuals taken as independent agents. Therefore, in this paper visitors’

group behavior while walking (i.e. spatial arrangement) will be described and ana-

lyzed –based on the knowledge on group walking and crowd dynamics–, as well as

communicative behavior towards the robot. Lessons learned from this long lasting

experiment in the wild could also be considered for designing spatial behavior of

mobile service robots in other contexts as receptions, leisure parks or hospitals.

In the next section findings from previous work on guide-robots in open large-

scale environments and related knowledge from the fields of proxemics and group

walk are reviewed. In Section 3, the experience at CosmoCaixa Science Museum

Barcelona is described. Next, analysis of recorded human-robot social interaction

data is detailed with special focus on the follow-me episodes. A discussion and



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 3

recommendations for improved experience design follow in Section 6. Finally, some

conclusions are provided and further research is pointed out.

2. Related Work

Mobile service robots may deploy their activity in close proximity to people either

in closed (e.g. home3, school4, office, nursing home5) and open environments (e.g.

exhibitions6, museums7,8,9, malls). In closed environments the occupants are known,

and often belong to few homogeneous profiles (e.g. ages, familiarity to technology).

On the other hand, in open public spaces occupants are unknown, diverse, variable

and dynamic, often including heterogeneous profiles (i.e. teenagers, staff, elderly).

A frequent situation in large-scale open public environments is the configuration

of dense crowds that the robot is supposed to travel through fulfilling safety (the

primary requirement of a robot operating in a public space), reliability and social

requirements at a time.

Moreover, robots with the “walk around” functionality get involved in spatial

relationships with people3,10. Spatial relationships are a combination of distance,

relative position and orientation that occur naturally whenever two or more people

engage in an interaction11 and convey significant and relevant social information

(e.g. how each of them is involved) and also define an interpersonal space for devel-

oping activity.

Empirical studies in telepresence applications have identified the management

of spatial relationships between people and robot as a main issue in order to im-

prove the quality of interaction taking into account that interpersonal distances

convey significant and relevant social information10. Based on Kendon’s model12,

the authors identify space formations or spatial patterns (e.g. vis-a-vis, side-by-side,

L-shape, follow or ahead) related to the roles adopted by the robot, the activities

and the spatial constrains, as well as individual variables such as familiarity with

the agent. As a conclusion, when physical constraints (e.g., narrow passages) along

with navigational requirements prevents the robot to maintain the convenient spa-

tial behavior, it can compensate this situation with other interactive behaviors (e.g.

verbally apologizing for an inappropriate distance or reducing the eye-contact) to

maintain an overall degree of desired intimacy.

An open public scenario where autonomous mobile robots have been deployed

are museums. Three aspects make the robot navigation in a museum specially dif-

ficult: the robot has to guide visitors through dense even crowded spaces, some

elements of the physical space could be “invisible” to the robot (e.g. glass walls)

and the configuration of the environment change frequently (e.g. pieces of furni-

ture, fences). The robot guide in a museum faces two primary challenges: navi-

gating safely, reliably and socially through crowds, and interact with people in a

compelling and intuitive way7.

Guidance is a demanding collaborative task that requires communicating

intentions13 (i.e. robot offers the service, visitors select a destination and request



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

4 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

the “Bring me there” function, the robot heads towards the destination) and social

navigation (i.e. walk together to the target location). Walking along following the

leader implies complex space regulations (i.e. distancing, spatial configurations) to

allow guide and visitors group up and walk together effectively. These space rela-

tionships during guidance must be at a time socially meaningful and compatible

with the robot’s navigation specifications (i.e. collision avoidance performance14).

To model the navigation through crowds of dynamic agents with uncertain tra-

jectories some attempts has been done drawing inspiration from the pedestrians

behaviors in dense environments, where people usually engage in “joint collision

avoidance” (called the social forces model) and adapt their trajectories to each other

to make room for navigation15. This model is proposed to overcome shortcomings of

models based on anticipate trajectories taking each individual as independent agents

that often lead when tested in the wild to ineffective overcautions robot behaviors

and even to “freezing the robot” when people attracted by the robot surround it and

once the environment surpasses a certain level of complexity, the planner decides

that all forward paths are unsafe and freezes in place to avoid collisions. In the case

of the “freezing problem”, the focus on group collaborative behavior rationales can

be more fruitful to design robot’s ability to elicit the natural cooperative behavior

of making room to create feasibly trajectories. Verbal and nonverbal cues as look

at the intended direction or asking for permission could be enough to make room

for safe navigation.

Communication between robot and users in this scenario is complex. According

to its role, naturally the guide communicates with dynamic groups of different sizes,

densities and composition often walking around in busy environments . Thus, the

simpler models of one-to-one and face to face human-robot interaction are largely

surpassed in this context. Moreover, in the social situation of visiting a museum

(as an entertainment venue) people are likely to be curious, active and attracted by

new appealing things as the robot itself. Exploration of the robot and of its limits16

is a natural behavior that sometimes lead to malfunction (e.g. push the emergeny

stop button) and even to damage the robot seriously. In addition to unintentional

damage, malicious behaviors towards service robots are also been reported, making

robots’ robustness or even resilience a key specification in public spaces.8. Several

robotic museum guides as Minerva17, Robovie5, RoboX6, Rhino7, Chips, Sweetlips,

Joe And Adam40-808 do quite well in addressing people and keeping their attention,

however interaction between robots and humans is still limited due to the highly

challenging environment. As far as we know, research on robotic guides has mainly

focused on verbal and non-verbal communicative behaviors (i.e. dialog) to improve

the visitor experience in static situations rather than on the spatial arrangements

during guidance.

On the other hand, although there are several studies that evaluate the HRI

by spatial relationships, these are framed only in the individual and in closed and

non-natural environments3,10,18,19,20,21. An interesting approach related to spatial



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 5

relationships, buy in crowds of pedestrians, was conducted by Bandini et.al.22. In

this work, Bandini analyzes the behavior of groups such as the characteristics of the

groups and their group spatial arrangement while walking in dynamic environments.

From an empirical research, different patterns of group spatial arrangement (e.g.

line- abreast, v-pattern and river-like) and its significance in relation to the social

cohesion of the group were analyzed.

The present study focus on the description of follow-me group behavior from

observational data gathered in a naturalistic trial in the wild, applying models from

group spatial management (i.e. proxemics, group walking23 and crowd dynamics22.

3. The Experience at Cosmocaixa Museum

This section discusses general issues related to the design and development of the

experience at CosmoCaixa Science Museum Barcelona: our main objective, the em-

ployed service robot, the scenario, and the task.

3.1. Design

During 6 days the REEM robot was deployed in a restricted area in the CosmoCaixa

Museum navigating autonomously around the facility. The robot played the role of

a museum guide offering information and guidance to visitors when requested.

The presence of researchers and technical staff was reduced to a discrete and per-

manent remote surveillance of the robot’s performance. The intervention of technical

staff was aimed at recovering the robot for eventual breakdowns and discouraging

misuse to enhance people safety and to prevent robot’s damage.

No briefing or instruction was given to visitors and no adaptation of the physical

environment was implemented except from the two cameras placed in the walls in

an effort to maximize the study ecological validity preserving the natural every-day

conditions and routines in the Museum activity (i.e. density and flows of visitors).

3.2. Objective

The main goal is to investigate in the wild visitors-robot guide interaction while

walking (i.e. space formations) and in face-to-face communication (i.e. natural and

computer-based interactive behavior).

A first set of research questions are related to robot effectiveness according to

its role: Under which conditions and to what extend does the robot attract and

entertain visitors, engage people in satisfactory face-to-face interaction, help peo-

ple to find their way? A second set of research questions are about group spatial

management during guidance: Can patterns of spatial group behavior during group

walking be identified? Are they similar to those modeled for human groups? Are all

of them equally suitable for effective guiding? Do visitors’ individual variables influ-

ence the group walking performance? Do group size and/or composition influence

the space arrangements?



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

6 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

The ultimate purpose is to guide the redesign of robot’s interactive behavior and

–as far as possible in an exploratory study– to draw new knowledge about spatiality

and interactive behavior in group-robot interaction.

3.3. The robot

REEM is a 1,65m high humanoid robot with 22 degrees of freedom. The upper part

of the robot comprises of a torso with a touchscreen, two motorized arms, which

give it a high degree of expression, and a head, which is also motorized (Figure 1).

The robot features a rear small platform which can be used to transport objects

(e.g. a trolley). The mobile base contains a lithium battery that provides up to

eight hours of autonomous operation. A complete range of sensors (i.e. cameras,

ultrasonic, lasers) support dynamic distancing and collision avoidance for a safe

navigationa.

Fig. 1: REEM robot from PAL Robotics.

As a sophisticated anthropomorphic robot, REEM features diverse elements

and devices to support verbal and non-verbal communication. Some of them are

recognizable mechanic versions of natural-like elements as eyes –that are just two

holes in the face without lids, eyelids or pupils– framed under the shape of brows.

The monochromatic white face presents as well the shape of a nose but no mouth

is represented. At both sides of the head are placed two elements evoking vaguely

the position and shape of ears that are enlightened when the robot is activated.

The head can move up and down and turn right and left and so does the torso. The

articulated arms and hands may support social and utilitarian behavior (i.e. shake

aVisit http://pal-robotics.com/en/products/reem/ for more details.



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 7

hands, point, wave, grasp). In addition users can interact with REEM through

the friendly-use 12 inch touchscreen interface on the robot’s torso where ad hoc

interactive multimedia applications can be run.

Therefore, according to REEM appearance and features enriched intuitive

human-like non-verbal communication can be implemented through head and body

movement (i.e. gaze behavior), posture (i.e. orientation) and smart navigation (i.e.

social distancing) (see Table 1).

Table 1: REEM’s potential interactive behavior.

Dimensions Variables Categories Subcategories

Verbal Spoken Unidirectional non conversational

Non Verbal Gaze behavior Eye contact

Look at

Gestures Head movements

Arms motion

Hands motion

Body stance

Displacement Social navigation Direction

Velocity

Follow

Guide

Obstacle Avoidance

Distancing

For safety and feasibility issues the use of some REEM’s interactive resources

was deliberately constrained during the autonomous operation. Consequently the

robot’s potentiality for verbal and non-verbal communication was reduced to not-

facial/not-verbal behavior2,24. Specifically, arms and hands were blocked and stuck

to the body for safety issues. Not conversational communication is implemented

but the information displayed on the screen was as well spoken out by the robot

as redundant feedback during face-to-face interaction. Therefore, in our study we

investigate to which extend REEM is capable to carry out the main role-dependent

functions of smart guiding based only on head movements, motion and interface-

based interaction.

3.4. Scenario and setup

CosmoCaixa is a science museum located in Barcelona, Spain. The museum hosts a

very popular planetarium and a wide range of permanent and temporary exhibitions

and attractions where visitors, mainly children and their families, are encouraged



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

8 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

to experience and interact actively with the environment. Up to 800,000 people

visited the Museum in 201225. In 2006 CosmoCaixa Barcelona was awarded by the

‘European Museum of the Year Award’ –institution sponsored by the European

Council– as the best science museum in Europe.

The field study was carried out from Tuesday November 27th to Sunday Decem-

ber 2nd, 2012 on the occasion of the European Robotics Week. This 6 days schedule

includes a free entrance day (Sunday) when the number of visitors increases con-

siderably.

The robot was deployed in the floor −2 in a restricted area of about 5 meters

wide and 40 meters long in a centric corridor leading to the more popular facilities

(see Figure 2 and Figure 3). Three locations (A, B and C in Figure 2) were defined

as the three possible destinations. Visitors going to “Planetarium” and “Flooded

Forest” were walked to A, visitors going to “Flash” and “Touch-Touch!” to B and

visitors to the activity “Clik” to C. Point D is the initial location of the robot close

to one of the main entrances and besides an information desk.

Fig. 2: Map for the robot placement at CosmoCaixa Science Museum Barcelona

3.5. Task

According to its role the general function of REEM is to enrich visitors’ experience

by exhibiting itself as an attraction, providing entertainment and information and

eventually bringing visitors to requested destinations. The robot role is deployed in

three activities: offering services, face-to-face interaction and guidance (Figure 4).

The purpose of offering services is to attract people to engage in interaction.

This phase starts as soon as the robot is activated, the ears’ lights turn on and the

home page is displayed on the touchscreen at the robot’s chest. According to the

programmed mode, the robot either deploy a proactive behavior moving around

among visitors or remain stationary by the information desk until someone even-

tually approach. This phase ends when the screen is touched and the interactive



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 9

(a) (b)

Fig. 3: External camera shots: (a) from recording camera 1 (RC1); and, (b) from

recording camera 2 (RC2).

Fig. 4: Flow of robot’s guide role.

multimedia application is launched. During face-to-face interaction the communica-

tion is mediated by the graphic interface. The textual information displayed on the

screen is spoken aloud redundantly by the robot to enhance robot’s social presence.

A tree of the easy-to-use application architecture is shown in Figure 5. If the visitor

selects the option Bring me there! the robot initiates the guidance navigating to the

target location associated to the requested destination. Once the target location is

reached or the mission definitive aborted (e.g. the robot is blocked by a crowd) the

robot stops and restarts the activity from the first phase (i.e. offering services).



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

10 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

Fig. 5: Architecture of the multimedia GUI interface.

3.5.1. Data collection

To register continuously visitors and robot activity two commercial surveillance

cameras (RC1 and RC2 in Figure 2) were set in the center of the corridor fixed to

the building pillars at a height of approximately 3m to have an aerial overview of

the experimental area (Figure 3). In addition, the robot’s on-board camera (RC3)

placed behind the robot’s eyes was used to obtain a close-up view of visitors from

the robot’s perspective to study face-to-face interaction. The three video sources

were downloaded and stored daily for further processing and analysis.

4. Analyses

4.1. Observational data processing

According to the study’s aim the spatial arrangements performed during guidance

and visitors’ face-to-face communicative behavior with the robot were analyzed. In

Table 2 the dimensions for group characterization and the coding scheme for group

walking behavior and interactive face-to-face behavior are summarized.



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 11

The coding was carried out manually by two of the experimenters working to-

gether.

Table 2: Group characterization and Visitor’s behaviors.

Dimensions Variables Categories Subcategories

Group characterization Size
Single
Couple
Triple
Larger

Composition All-children
All-young
All-adults
Mixed

Visitor’s behavior Walking Groups Side by side
Spatial Arrangements “>” formation

“<” formation
Leader-follower

Face-to-Face Gaze behavior Eye-contact
Interaction Look at the robot

Look at the screen
Physical contact Screen

Other
Facial Expression Smile

Grimaces
Gestures Wave

Head Motion

4.1.1. Follow-me episodes

To improve the row data from the panoramic cameras and to select the relevant

episodes of guidance a preliminary preprocessing of the videos was done as follows:

• Up to 4828 minutes of recordings from external cameras (RC1 and RC2 in

Figure 2) were labeled and stored.

• Recordings without any kind of movement were eliminated using computer

vision techniques resulting in a total duration of 3966 minutes.

• The sequences where the robot appeared simultaneously with at least one

person (i.e. visitors or museum staff) were selected. As a result, a total of

283 scenes with approximately 825 minutes of total duration were selected.

• Every episode of guidance were selected resulting in 91 clips with approxi-

mately 96 minutes of total time.

4.1.2. Face-to-face sequences

83 minutes of video were registered by the on-board camera (RC3 in Figure 2) to

analyse people’s face-toface behavior interacting with the robot. 14 episodes were

pre-selected for a total duration of 47 min. In order to obtain quantitative data,



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

12 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

the 14 episodes were sampled considering 10 seconds every minute obtaining a set

of 47 sequences with a total time of 8 minutes approximately.

4.1.3. Groups

Visitors’ groups in the 91 episodes of guidance are characterized by composition

(i.e. age of the members) and size. A walking group in guidance is composed by the

robot and the visitors that move along with it regardless the relative distance and

position between them. Visitors that join the group on the fly –and that probably

are not aware where are the robot heading to– are also considered members of the

group.

In face-to-face interaction, social context is defined by all the people that are in

camera and within the social space at any moment during the sequence regardless

the distance, position, orientation or behavior. Co-present individuals beyond the

social distance are only considered when they look at the robot at least once during

the sequence.

4.1.4. Group spatiality during guidance

In this study a guidance episode is the sequence of walking together behavior de-

ployed by the robot and a group of visitors starting when the “Bring me there”

option is selected on the screen and ending when the robot stops and comes back

to offering services state. Guidance ends either when the robot reach the requested

destination or when the robot’s trajectory is definitely aborted (e.g. robot blocked

by a crowd of visitors, robot stuck in a corner, emergency shutdown). Temporary

stops during the displacement due to navigational constraints (i.e. mobile obstacles

avoidance) do not end the guidance sequence provided the trajectory is resumed

by the robot. Any displacement of visitors along with the robot is considered a

guidance episode regardless to the particular relative position they adopt (i.e. robot

ahead, robot side-by side).

The size categories in guidance sequences are single individuals, couples, triples

and larger groups (Table 2). Group composition is referred to the age of the group

members defining four types of group: all-children, all-young, all-adults and mixed

groups.

An ad hoc coding scheme was built-up to investigate the space distribution pat-

terns –relative position and distance between agents including the robot. 4 spatial

patterns were described to classify the group spatial layout while walking with the

robot: side-by-side, v-shape and leader-follower (Table 2).

4.2. Visitors-robot face to face interaction

According to the task description, face-to-face interaction may happen any time

the robot is activated and not engaged in guiding a group. In this situation when



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 13

typically the robot is stationary the touch screen-based interaction is available and

REEM’s social behavior is based on head motion and speech.

The 47 face-to-face sequences are described according to participant individual

variables (genre, age), presence of other co-located visitors (group size and composi-

tion), the distance from the robot, the robot behavior (displacement, head motion)

and visitor social behavior: gaze (eye contact, look at the robot, look at the screen),

physical contact on robot (on the screen, other) facial expression (smile, grimaces)

and gestures (wave, head motion) (See Table 3).

5. Results

5.1. REEM’s performance

During the 6 day trial the robot completed 48 hours of autonomous operation

walking through the museum defined space during regular public attendance at a

maximum displacement speed of 4km/h. To the best of our knowledge during this

time REEM robot operated without remarkable pauses (i.e. more than one hour)

and suffered a total of 5 shutdown incidences caused by visitors’ misuse pressing

deliberately the salient red emergency stop button placed at the robot’s back.

5.2. Group description

The whole 96 minutes of the 91 follow-me episodes were analyzed (11.64% of the

total video-recordings where people and robot were detected together in the scene)

to investigate the group walking behavior.

Concerning the group composition, 1.10% of groups that interact with the robot

were all-children, 8.79% were all-youth, 52.75% were all-adults and 37.36% were

mixed groups. From the mixed groups, 50% were formed by children and adults,

29.41% were formed by youth and adults, and 20.59% were formed by children,

youth and adults.

Concerning the group size, 3.30% of the people walked alone with the robot,

while the 96.70% arrived in groups: 10.99% of groups were couples, 14.29% triples

and 71.43% larger groups.

Visitors who walked alone with the robot were 33.33% youth and 66.67% adults;

couples were 10% youth, 80% adults and 10% children and adults; triples were

formed by 15.38% youth, 61.54% adults, 7.69% children and adults, and 15.38%

youth and adults. Larger groups were composed of 1.54% children, 6.15% youth,

46.15% adults, 23.08% children and adults, 12.31% youth and adults, and 10.77%

children, youth and adults.

5.3. Group spatial arrangement

Results about group spatial arrangement with people walking together with robot

in the follow-me behavior showed that:



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

14 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

• 100% of guide-visitor couples (i.e. one person-one robot) was characterized

by a leader (robot) - follower spatial arrangement (as shown in Figure 6a);

• 90% of guide-visitors triples was characterized by the robot heading the

group and followed by a dyad in an inverted V-like pattern (Figure 6b),

and 10% by V-like pattern (Figure 6c);

• 100% of four-agents groups (i.e. three people-one robot) was characterized

by the robot followed by a triad (Figure 6d).

We can show that 96.15% of the formations that were analyzed have a robot

leader - person follower structure, indicating a weak social cohesion between the

robot and people in almost all spatial arrangements.

(a) (b)

(c) (d)

Fig. 6: Group spatial arrangements: (a) guide-visitor couple with leader-follower

formation; (b) guide-visitors triple in a leader-follower spatial arrangement with

robot heading the group followed by a dyad; (c) guide-visitors triple with V-like

pattern; and, (d) four-agents with robot leader followed by a triad.



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 15

5.4. Interactive behavior

As mentioned before, a subset of 47 10-seconds sequences of face-to-face interaction

were randomly selected from the on-board recordings. The description correspond-

ing to 42 different visitors is summarized in Table 3 in the Appendix.

In the 47 sequences the 60% of the 43 participants were males and the 30%

females. 45% were adults, 17% young people and 30% children.

In 29 of the 47 sequences (62%) the visitor established eye contact with the

robot at least once (Figure 7a) with a total of 50 smiles registered. In 9 occurrences

the visitor kept staring at the robot’s face during the whole sequence.

In 23 sequences (62%) the visitor smile at least once with a total of 31 smiles

registered. In 9 occurrences the visitor kept smiling during the whole sequence

(Figure 7b).

With respect to the interface mediated communication, in 10 sequences (21%)

the visitor touched the screen at least once and in 18 (38%) the user looked at the

screen. Male visitors seem more prone to interact through the graphic screen: the

50% of the male visitors looked at the screen and the 29% touched the screen, in

front of a 22% of female visitors that looked at the interface and only the 11% of

females touched it.

In the 8 sequences showing people interacting alone with the robot (Figures 7b–

(d)) in 7 the visitor established eye contact and in 5 sequences they smile. There are

relevant instances because the social behavior cannot be attributed to be addressed

or provoked by human-human interaction (Figures 7e–(f)).

It is noteworthy that the analyzed behaviors are not mutually exclusive. Even

though in the descriptive analyses are quantified as independent behaviors, facial

expressions (e.g. smile) and gestures (e.g. wave) may be presented simultaneously

and actually usually are in non-verbal interpersonal communication (e.g. 100% of

observed wave behaviors appeared with smile).

6. Discussion

6.1. Robot Guide’s performance

The robot succeeded in developing the role of a museum guide -attracting people,

providing information and guidance- fulfilling up to 91 follow-me missions operat-

ing autonomously. Registered face to face episodes show visitors spontaneous social

behavior addressed to the robot including eye contact, smiles, and greetings. Al-

though visitors’ face-to-face behavior is described qualitatively and no conclusive

results can be drawn from the data some of the observed behaviors seem to account

clearly for enjoyment and engagement.

However same shortcomings and difficulties were met mostly related to the chal-

lenging social context that is extremely complex, dynamic (i.e. changeable in vis-

itors density and distribution) and sometimes crowds of visitors with uncertain

trajectories. Attendance is formed by a wide range of visitors’ profiles and group



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

16 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

(a) (b)

(c) (d)

(e) (f)

Fig. 7: Interactive behaviors: (a) visual contact; (b) smiling; (c)–(d) waving; (e)–(f)

mimic head movement.

configurations with a high rate of children that increases the uncertainty. The phys-

ical scenario is not stable either due to temporary exhibitions, eventual events and

maintenance tasks7.

In addition, a science museum as an experimental bed test for HRI studies has



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 17

some peculiarities that may be outlined. The robot is an attraction itself as a piece

of smart technology and an object of visitors’ interest and curiosity in a context

where visitors are encouraged to explore and try9. Far to become transparent in this

situation the technology becomes the target and visitors do not miss the opportunity

to explore and interact with the robot manipulating it (e.g. pushing the emergency

button), defying its capabilities (e.g. climbing to the rear platform) and putting it

in challenging situations to see what happens (e.g. activating on purpose the face

tracker moving the head up and down). In our trial we have observed that eventually

these visitors’ active behaviors result in shutdown or the impossibility to fulfill the

task.

The robot guide attracted untrained näıve people and engaged visitors 91 times

in follow-me behavior without any other cue but the robot appearance and behavior,

especially when it moved around, moved the head searching and tracking faces

and initiated motion. The success in attracting people led the guide robot to face

the “freezing robot” problem: once the environment surpasses a certain level of

complexity all alternatives are unsafe and stuck in place15.

Therefore, the context of service is a challenging combination of a complex

space and the willingness of people -sometimes crowds- to approach and interact

with the robot. In this situation a conservative navigation for safety issues and

a focus on robot’s robustness is required even if it implies a sacrifice on robot’s

interactivity and attractiveness (e. g. discarding the communicative use of its arms).

From this experience, we agree with Willeke8 that resilience for recovering from

visitors’ misuse -even abuse- and awkward situations (i.e. approaching a wall too

closely or being crowded by people) is a crucial issue to ensure the continuity of the

service.

To overcome these constrains, we consider that it would be interesting to em-

power the robot with some kind of authority that would be consistent with the

role of guide to regulate visitors’ behavior (i.e. showing people clearly what is not

allowed) and to give the robot more social presence that maybe could prevent from

same rough manipulations. In addition, closer but unobtrusive supervision might be

provided by conductors or staff to discourage deliberate or not deliberate misuse.

6.2. Contributions to HRI studies

We consider that the study has a remarkable ecological validity provided that nei-

ther changes of the regular schedule of the museum nor modifications of the natural

scenario was implemented -except for the set of the 2 cameras- to deploy the robot

during the 6-day trial.

The literature on social space management, crowd behavior and spatiality in

walking groups are revised and applied to the evaluation of hybrid groups formed

by the robot and a number of näıve participants. This approach focus on groups

rather than on individuals and extend the scope of HRI proxemics -mostly oriented

to one-to-one interaction10- with the consideration of dynamic spatial arrangements



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

18 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

during displacement that are critical for robot’s performance in public spaces.

The detailed description of the HRI episodes offers empirical based insights that

can be of interest to improve the evaluation and design of HRI in public and dense

environments and to focus on relevant variables like the social situation, the role

the robot’s takes, its social affordances, the actual robot’s behavior and the physical

constrains.

Furthermore, this study has outlined the feasibility and convenience of auto-

matic processing techniques (e.g. computer vision) to study spatial HRI through

systematic observation even though their use still represents great challenges of

reliability and robustness in the wild.

6.3. Limitations and Future work

6.3.1. Camera coverage

The two cameras do not cover in detail all the relevant interactive behaviors be-

tween robot and visitors in the experimental space. In particular, even though the

perspective provided was enough for group arrangements classification, face-to-face

interaction at the end of the guidance episodes are missed being the destination

points too far away from the cameras. Adding another on-board omnidirectional

camera could provide a view of all the social space around the robot and facilitate

the use of automatic spatial behavior analyses.

6.3.2. Face-to-face interaction data

Due to technical constraints it was not possible to videotape continuously face-to-

face interaction from the on-board subjective-perspective camera so the analyses has

been done on a sample of sequences from the 83 minutes of available recordings. No

systematic or representative conclusions can be drawn from data. Nevertheless the

observational data analyses provide a sound base for an empirical-based contextual

coding scheme for further research.

6.3.3. Measures of density

One very relevant variable that influences group walking behavior is the space den-

sity, which has not been measured accurately in our study. Further studies must

provide density measures preferably automatically obtained from vision processing.

6.3.4. Logging of Robot behavior and interaction on GUI

To triangulate human-robot interaction evaluation it would be very interesting to

analyse the logs of robot behavior and of the interface-based interaction. Data are

in principle available from robot’s log but it must be faced the issues of processing

and storage.



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 19

6.3.5. Visitors’ experience

The evaluation of the guide robot performance would benefit from a complementary

assessment of visitors experience from short questionnaires after interacting with

the robot. This self-report data could be of great interest to interpret or contrast

the observational data.

6.3.6. Factors influencing behavior

While the aim of this study is to provide descriptive analyses and evidence-based

insight with high ecological validity, systematic exploration of factors influencing the

observed behavior should be carried out in future works to better understand the

interactive behavior in this context. Systematic quantitative studies on individual

variables (i.e. gender, age), social context, robot personality (i.e. body language),

and group features (i.e. composition, density, dispersion and velocity) could be of

the greatest interest in social HRI research.

7. Conclusions

An exploratory study on group-robot interaction was carried out during a week in

an open and natural environment to observe visitors’ spatial behavior and commu-

nication with the guide robot REEM in a popular science museum.

The robot succeeded in developing the role of a museum guide -attracting people,

providing information and guidance- fulfilling up to 91 follow-me missions operat-

ing autonomously. Registered face to face episodes show untrained visitors social

behavior addressed to the robot including eye contact, smiles, and greetings.

Differently from previous works on mobile service robots that evaluate naviga-

tion and HRI as separate functions we address spatial behavior analyses focusing

on its social meaning, not only as a prerequisite for effective communication (i.e.

orientation, positioning) but as potential communicative acts (i.e. express intent

and emotions).

The analysis is focused on visitors’ groups rather than individual. Groups were

described according to their composition, size, spatial formations and interactive be-

havior with the robot during guidance. Observational methods applied to evaluate

group-robot interaction provide fruitful insight to understand the relationship be-

tween robot positioning and effcient communication (i.e. walking side-by-side) and

between robot motion cues (e.g. gaze behavior, body orientation) and collaborative

walking together behavior through populated environments.

Acknowledgements

This research was supported in part by the PATRICIA Research Project (TIN2012-

38416-C03-01,03), funded by the Spanish Ministry of Economy and Competitive-

ness. The authors would like to express their very great appreciation to CosmoCaixa



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

20 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

Science Museum Barcelona and Fundació “La Caixa” for providing the research

facilities used in this study. They are particularly grateful for the encouraging sup-

port of Ms. Cristina Smandia from the Communication and Audiences Department,

Fundació “La Caixa”. Assistance provided by Mr. Jordi-Ysard Puigbò, Ms. Judit

Casacuberta (Technical University of Catalonia), Ms. Isaura Almar, and Mr. Miguel

Kaouk (La Salle Engineering) is greatly appreciated. Finally, special thanks are ex-

tended to Dr. Ricardo Téllez and the technical staff of PAL Robotics company.

References

1. M. Kuderer, H. Kretzschmar and W. Burgard, Teaching mobile robots to cooperatively
navigate in populated environments, in IEEE/RSJ Int. Conf. Intelligent Robots and
Systems (IROS) (IEEE Press, Tokyo, Japan, 2013), pp. 3138–3143.

2. C.L. Bethel and R.R. Robin, Affective expression in appearance constrained robots, in
ACM/IEEE Int. Conf. Human-Robot Interaction (HRI) (ACM Press, Salt Lake City,
Utah, 2006), pp. 327–328.

3. H. Huettenrauch, K. Severinson Eklundh, A. Green and E.A. Topp, Investigating spa-
tial relationships in human-robot interaction, in Int. Conf. Intelligent Robots and Sys-
tems (IROS) (IEEE Press, Beijing, China, 2006), pp. 5052–5059.

4. T. Kanda, T. Hirano, D. Eaton and H. Ishiguro, Interactive robots as social partners
and peer tutors for children: a field trial, Human-Computer Interaction 19(1) (2004)
61–84.

5. M. Montemerlo, J. Pineau, N. Roy, S. Thrun and V. Verma, Experiences with a mobile
robotic guide for the elderly, in Nat. Conf. Artificial Intelligence (AAAI) (AAAI Press,
Edmonton, Alberta, Canada, 2002), pp. 587–592.

6. R. Siegwart, K.O. Arras, S. Bouabdallah, D. Burnier, G. Froidevaux, X. Greppin,
B. Jensen, A. Lorotte, L. Mayor, M. Meisser, R. Philippsen, R. Piguet, G. Ramel,
G. Terrien and N. Tomatis, Robox at Expo.02: a large-scale installation of personal
robots, Robotics and Autonomous Systems 42(3) (2003) 203–222.

7. W. Burgard, A.B. Cremers, D. Fox, D. Hähnel, G. Lakemeyer, D. Schulz, W. Steiner and
S. Thrun, The interactive museum tour-guide robot, in Nat. Conf. Artificial Intelligence
(AAAI) (AAAI Press, Madison, Wisconsin, 1998), pp. 11–18.

8. T. Willeke, C. Kunz and I.R. Nourbakhsh, The history of the mobot museum robot
series: an evolutionary study, in Florida Artif. Intell. Res. Soc. Conf. (FLAIRS) (Key
West, Florida, 2001), pp. 514–518.

9. M. Shiomi, T. Kanda, H. Ishiguro and N. Hagita, Interactive humanoid robots for a
science museum, IEEE Intelligent Systems 22(2) (2007) 25–32.

10. A. Kristoffersson, K. Severinson Eklundh and A. Loutfi, Measuring the quality of
interaction in mobile robotic telepresence: a pilots perspective, International Journal
of Social Robotics 5(1) (2012) 89–101.

11. P. Marshall, Y. Rogers and N. Pantidi, Using F-formations to analyse spatial pat-
terns of interaction in physical environments, in ACM Conf. Comp. Supp. Coop. Work
(CSCW) (ACM Press, Hangzhou, China, 2011), pp. 445–454.

12. A. Kendon, Spacing and orientation in co-present interaction, in Development of Mul-
timodal Interfaces: Active Listening and Synchrony, Series in Lecture Notes in Com-
puter Science, Vol. 5967 (Springer Berlin Heidelberg, 2010), pp. 1–15.

13. A. Bauer, D. Wollherr and M. Buss, Human-robot collaboration: A survey, Interna-
tional Journal of Humanoid Robotics 5(1) (2008).

14. P. Ratsamee, Y. Mae, K. Ohara, T. Takubo and T. Arai, Human–robot collision



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 21

avoidance using a modified social force model with body pose and face orientation,
International Journal of Humanoid Robotics 10(1) (2013) 1–24.

15. P. Trautman and A. Krause, Unfreezing the robot: navigation in dense, interacting
crowds, in IEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS) (IEEE Press,
Taipei, Taiwan, 2010), pp. 797–803.

16. D. Karreman, L. Utama, M. Joosse, M. Lohse, B. van Dijk and V. Evers, Robot
etiquette: how to approach a pair of people?, in ACM/IEEE Int. Conf. Human-Robot
Interaction (HRI) (ACM Press, Bielefeld, Germany, 2014), pp. 196–197.

17. S. Thrun, M. Bennewitz, W. Burgard, A.B. Cremers, F. Dellaert, D. Fox, D. Hahnel,
C. Rosenberg, N. Roy, J. Schulte and D. Schulz, MINERVA: a second-generation mu-
seum tour-guide robot, in IEEE Int. Conf. Robotics and Automation (ICRA) (IEEE
Press, Detroit, Michigan, 1999), pp. 1999–2005.

18. D.J. Feil-Seifer and M.J. Matarić, Distance-based computational models for facilitat-
ing robot interaction with children, Journal of Human-Robot Interaction 1(1) (2012)
55–77.

19. E. Torta, R. Cuijpers, H. Raymond, J.F. Juola and D. Van Der Pol, Modeling and
testing proxemic behavior for humanoid robots, International Journal of Humanoid
Robotics 9(4) (2012).

20. H. Kuzuoka, Y. Suzuki, J. Yamashita and K. Yamazaki, Reconfiguring spatial forma-
tion arrangement by robot body orientation, in ACM/IEEE Int. Conf. Human-Robot
Interaction (HRI) (ACM Press, Osaka, Japan, 2010), pp. 285–292.

21. A. Garrell and A. Sanfeliu, Cooperative social robots to accompany groups of people,
International Journal of Robotics Research 31(13) (2012) 1675–1701.

22. S. Bandini, A. Gorrini and G. Vizzari, Towards an integrated approach to crowd
analysis and crowd synthesis: a case study and first results, Pattern Recognition Letters
44(July) (2014) 16–29.

23. M. Costa, Interpersonal distances in group walking, Journal of Nonverbal Behavior
34(1) (2010) 15–26.

24. A. Beck, L. Cañamero, A. Hiolle, L. Damiano, P. Cosi, F. Tesser and G. Sommavilla,
Interpretation of emotional body language displayed by a humanoid robot: a case study
with children, International Journal of Social Robotics 5(3) (2013) 325–334.

25. CosmoCaixa, General information about CosmoCaixa Barcelona,
http://obrasocial.lacaixa.es/laCaixaFoundation/home en.html [accessed on 16 March
2015].

Marta D́ıaz-Boladeras received her B.Sc/M.Sc degree in

Psychology from the University of Barcelona (UB) (1984),

the Ph.D. in Business Administration from the Depart-

ment of Management at the Universitat Politècnica de

Catalunya - BarcelonaTech (UPC) (1997) and the Ms.Sc

degree in Occupational Risk Prevention / Ergonomics and

Applied Psycho-Sociology from the UPC (2000). She is

currently engaged in the Doctoral Program on Primatology and Ethology at the

Faculty of Psychology (UB). In 1990 joined the Department of Management at the

UPC and became full professor in 1997. Director of the IBuX-Lab at the Technical

Research Centre for Dependency Care and Autonomous Living (UPC). Her research

interests are social human-robot interaction and ICT systems design for health and

well-being. Her current research focuses on the application of social psychology and



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

22 M. Dı́az, D. Paillacho, C. Angulo, O. Torres, J. González, and J. Albo-Canals

ethology models and methods to long-term human-robot interaction optimisation.

Dennys Paillacho received his B.S. degree in Com-

puter Science from the Escuela Superior Politécnica del

Litoral in 2003 and his M.S. degree in Automatic Control

and Robotics from Universitat Politècnica de Catalunya -

BarcelonaTech in 2010. From 2001 to 2004 Mr. Paillacho

was a software engineer with Sonda Technology Group in

Ecuador. From 2004 he was as Associate Professor and Re-

search Assistant at Escuela Superior Politécnica del Litoral.

Currently, Mr. Paillacho is a Ph.D. candidate with the Department of Automatic

Control (ESAII) at Universitat Politècnica de Catalunya in Barcelona. His interests

include social robotics, human-robot spatial interaction and educational robotics.

Cecilio Angulo received his M.S. degree in Mathematics

from the University of Barcelona, Spain, and his Ph.D. de-

gree in Sciences from the Universitat Politècnica de Catalunya -

BarcelonaTech, Spain, in 1993 and 2001, respectively. From 1999

to 2007, he was at the Universitat Politècnica de Catalunya,

as Assistant Professor. He is nowadays an Associate Profes-

sor in the Department of Automatic Control, in the same

university. From 2011 he also served as Director of the Master’s degree

in Automatic Control and Robotics. He’s currently the Director of the

Knowledge Engineering Research Group where he is responsible for research

projects in the area of social cognitive robotics.

Cecilio Angulo is the author of over 250 technical publications. His research

interests include cognitive robotics, machine learning algorithms and social robotics

applications.

Oriol Torres received his M.S. degree in Electronic En-

gineering from the Universitat Politècnica de Catalunya -

BarcelonaTech, Spain, in 1999. From 2000 to 2001, he worked

in Xilinx, Inc., the worldwide FPGA-leader company. From

2001 to 2004, he was at the Universitat Politècnica de

Catalunya as Research Assistant. In 2004, he started the

company PAL Robotics, where he occupied different posi-

tions such as Electronics Manager and Project Manager.

In 2010, he also completed a Master in Project Management. He is currently Busi-

ness Strategy Manager from PAL Robotics. His research interests include robotic



April 29, 2015 8:28 WSPC/INSTRUCTION FILE
”2013˙IJHR˙DiazetalV3˙CameraReady 02”

Evaluating Group-Robot Interaction in Crowded Public Spaces 23

topics and human machine interaction.

Jonathan González-Diéguez received his M.Sc., degree in

Telecommunications Engineering, specialized on Communica-

tion Systems, from the Universitat Politècnica de Catalunya

- BarcelonaTech, Spain, in 2012. Since then, he joined PAL

Robotics managing different areas of the company. He is re-

sponsible for REEM robot in real environment conditions.

Jordi Albo-Canals received his B.Sc, M.Sc., and PhD de-

gree in Telecommunications Engineering from the Engineering

School of La Salle - Ramon Llull University of Barcelona, Spain,

in 2000, 2003, and 2012, respectively. Currently, he is an As-

sociate Professor in the Electrical Engineering Department of

La Salle - Ramon Llull University (Spain), the Robotics Direc-

tor of La Salle Almere (Netherlands), and a Visiting Professor

in the Mechanical Engineering Department at Tufts University (US). His research

interests include theoretical and applied aspects of human factors in robot design

and cloud robotics.



A
p
ri
l

2
9
,

2
0
1
5

8
:2
8

W
S
P
C
/
IN

S
T
R
U
C
T
IO

N
F
IL
E

”
2
0
1
3
˙I
J
H
R
˙D

ia
ze
ta
lV

3
˙C
a
m
er
a
R
ea
d
y
0
2
”

2
4

M
.
D
ı́a
z
,
D
.
P
a
il
la
c
h
o
,
C
.
A
n
g
u
lo
,
O
.
T
o
r
re
s
,
J
.
G
o
n
z
á
le
z
,
a
n
d
J
.
A
lb
o
-C

a
n
a
ls

T
a
b
le

3
:
F
a
ce
-t
o
-f
a
ce

in
te
ra
ct
iv
e
se
q
u
en
ce
s
d
es
cr
ip
ti
o
n
.

Gaze B Contact Facial Gestures
Sample Subject EPISODE Age Genre Size Comp HM DIS Eye C Look at Screen Screen Oth Smile Grimace Wave M RHM
S02 V 01 B Young F 10 y Y 1 3 0 0 0
S03 V 02 B CH M 10 y Y 3 2 3 1 0 0
S04 V 03 B Young M 10 Y Y 1 0 0 0
S05 V 04 C A M 1 A Y 1 0 0 0
S06 V 05 D A F 2 A N 0 1 0 0
S07 V 06 D A M 3 A Y 0 1 1 1 0 0
S08 V 06 D A M 3 A Y 1 1 1 0 0 0
S09 V 07 D A F 3 A Y 2 1 1 0 0 0
S10 V 08 E A M 2 A N 1 0 0 0
S12 V 04 F A M 1 A N 0 1 0 0 0
S13 V 09 G CH M 30 Ch/Mx Y 5 1 1 0
S14 V 10 G CH F 30 Ch/Mx Y 3 1 2 3 0
S15 V 11 G CH M 30 Ch/Mx Y 3 1 1 1 0
S16 V 12 G CH F 30 Ch/Mx Y 5 1 1 0
S17 V 13 G CH F 15 Ch/Y Y 3 2 1 0
S18 V 14 H A M 1 A Y 1 1 1 0
S19 0 0 0 0
S20 V 15 H A M 1 A Y 1 1 0 0
S21 V 16 I Young M 5 Y Y y 0 1 1 0 0 0
S22 V 17 J A F 1 A N 1 1 0 0
S23 V-18 J CH M 6 CH/A Y 1 1 0 0
S24 V 19 J Young M 3 Y/A Y 0 1 1 0 0 0
S25 V 20 J A F 3 A N 1 0 0 0
S26 V 17 J A F 6 mx y 1 0 0 0
S27 V 21 K A F 1 A y Y 1 0 0 0
S28 V 22 J A M 1 A Y 1 1 0 1
S29 V 23 J Young M 4 Y Y 1 1 0 1
S30 V 24 J A M 7 MX Y 1 1 1 1 0 0
S31 V 25 J CH M 6 MX Y 2 1 0 0 1
S32 V 26 J Young M 7 MX Y 1 1 0 1
S33 V 27 J Young M 7 MX Y 1 1 1 0 1
S34 V 28 J Young M 11 MX Y 0 1 1 0 0 0
S35 V 29 L CH M 5 MX Y Y 0 1 0 0 0
S36 V 30 J CH f 8 mx y 2 2 0 1
S37 V 31 J CH F 13 MX Y 0 9 1 0 0
S38 V 32 J A M 6 MX Y 0 1 5 1 0 0
S39 V 33 M CH M 6 MX N 0 10 0 0 0
S40 V 34 M A F 6 mx Y 0 8 2 0 0
S41 V 35 J A F 10 MX Y 0 7 0 0 0
S42 V 36 J A F 8 MX Y 0 8 0 0 0
S43 V 37 J A F 11 MX Y 0 7 0 0 0
S44 V 38 J A m 3 Mx Y 1 1 1 0 0 0
S45 V 21 J A F 6 Mx Y 0 1 1 0 0 0
S46 V 39 N A M 1 2 4 A Mx mx Y 2 0 0 0
S47 V 40 N CH F 5 Mx Y 0 1 0 0 0
S48 V 41 J CH M 2 3 4 ch/ch/Mx Y 0 1 1 0 0 0
S49 V 42 O A F 1 A Y 2 1 0 0


