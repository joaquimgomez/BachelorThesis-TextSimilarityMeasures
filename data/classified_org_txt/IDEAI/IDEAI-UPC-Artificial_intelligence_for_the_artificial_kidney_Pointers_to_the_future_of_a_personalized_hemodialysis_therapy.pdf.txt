










































Microsoft Word - AI&ML in dialysis_submit


1 

Artificial Intelligence for the artificial kidney: pointers to the future of a personalized 
hemodialysis therapy 

Running Head. Artificial Intelligence and Machine Learning for dialysis 

Miguel Hueso1* (mhueso@idibell.cat), Alfredo Vellido2* (avellido@cs.upc.edu), Nuria Montero1 
(nuriamonteroperez@gmail.com), Carlo Barbieri3 (Carlo.Barbieri@fmc-ag.com), Rosa Ramos3 
(Rosa.Ramos@fmc-ag.com), Manuel Angoso4 (magvalencia@gmail.com), Josep M Cruzado1 

(jmcruzado@bellvitgehospital.cat), Anders Jonsson5  (anders.jonsson@upf.edu). 

1-Department of Nephrology. Hospital Universitari Bellvitge, and Bellvitge Research Institute 
(IDIBELL). L’Hospitalet de Llobregat. Spain 
2-Intelligent Data Science and Artificial Intelligence (IDEAI) Research Center. Universitat 
Politècnica de Catalunya (UPC). Spain 
3-Fresenius Medical Care, Bad Homburg, Germany 
4-Dialysis Unit. Clínica Virgen del Consuelo. Valencia. Spain 
5-Artificial Intelligence and Machine Learning Research Group. Universitat Pompeu Fabra (UPF). 
Spain 

*Corresponding authors:
Miguel Hueso MD.  
Department of Nephrology. Hospital Universitari Bellvitge and Bellvitge Research Institute 
(IDIBELL) 
C/ Feixa llarga, s/n; L’Hospitalet de Llobregat, 08907 Barcelona, Spain.  
Fax number:+34932607603, Telephone number:+34932607602 
Email: mhueso@idibell.cat 

Alfredo Vellido PhD 
Intelligent Data Science and Artificial Intelligence (IDEAI) Research Center. Universitat 
Politècnica de Catalunya (UPC) 
C/ Jordi Girona, 1-3, 08034, Barcelona, Spain. 
Telephone number: +34934137787 
Email: avellido@cs.upc.edu 

WORD COUNT OF THE TEXT: 4008 

NUMBER OF TABLES AND FIGURES: 1 figure 

This is the peer-reviewed but unedited manuscript version of the following article: 
Hueso, M., Vellido, A., Montero, N., Barbieri, C., Ramos, R., Angoso, M., Cruzado, J. M., Jonsson, A. 
Artificial intelligence for the artificial kidney: Pointers to the future of a personalized hemodialysis 
therapy. "Kidney diseases", Febrer 2018, vol. 4, núm. 1, p. 1-9. (DOI: 10.1159/000486394). 
The final, published version is available at http://www.karger.com/?doi=10.1159/000486394



 

2 

 

Abstract  

Background: Current dialysis devices are not able to react when unexpected changes occur 
during dialysis treatment, or to learn about experience for therapy personalization. 
Furthermore, great efforts are dedicated to develop miniaturized artificial kidneys to achieve a 
continuous and personalized dialysis therapy, in order to improve patient’s quality of life. These 
innovative dialysis devices will require a real-time monitoring of equipment alarms, dialysis 
parameters and patient-related data to ensure patient safety and to allow instantaneous 
changes of the dialysis prescription for assessment of their adequacy. The analysis and 
evaluation of the resulting large-scale data sets enters the realm of Big Data and will require 
real-time predictive models. These may come from the fields of Machine Learning and 
Computational Intelligence, both included in Artificial Intelligence, a branch of engineering 
involved with the creation of devices that simulate intelligent behavior. The incorporation of 
Artificial Intelligence should provide a fully new approach to data analysis, enabling future 
advances in personalized dialysis therapies. With the purpose to learn about the present and 
potential future impact on medicine from experts in Artificial Intelligence and Machine Learning, 
a scientific meeting was organized in the Hospital of Bellvitge (Barcelona, Spain). As an outcome 
of that meeting, the aim of this review is to investigate Artificial Intelligence experiences on 
dialysis, with a focus on potential barriers, challenges and prospects for future applications of 
these technologies.  

Summary and Key Messages: 

Artificial Intelligence research on dialysis is still in an early stage and the main challenge relies 
on interpretability and/or comprehensibly of data models when applied to decision making. 

Artificial Neural Networks (ANN) and Medical Decision Support Systems (MDSS) have been used 
to make predictions about anemia, total body water or intradialysis hypotension and are 
promising approaches for prescription and monitoring of hemodialysis therapy. 

Current dialysis machines are continuously improving due to innovative technological 
developments, but patient safety is still a key challenge.  

Real-time monitoring systems, coupled with automatic instantaneous bio-feedback, will allow 
changing dialysis prescriptions continuously.  

The integration of vital signs monitoring with dialysis parameters will produce large data sets 
that will require the use of data analysis techniques, possibly from the area of Machine Learning, 
in order to make better decisions and increase the safety of patients. 

KEY WORDS: Artificial Intelligence, Machine Learning, Hemodialysis. 

LIST OF ABBREVIATIONS:  
 
ACM: Anemia Control Model 

AI: Artificial Intelligence 



 

3 

 

ANN: Artificial Neural Networks 

DL: Deep Learning 

EHR: Electronic Health Records  

ESA: Erythropoiesis Stimulating Agents 

ESRD: End Stages Renal Diseases  

FS: Feature Selection 

HD: Hemodialysis 

IDH: IntraDialytic Hypotension 

GDPR: General Data Protection Regulation 

GPU: Graphical Processing Units 

MDSS: Medical Decision Support Systems  

ML: Machine Learning 

RBV: Relative Blood Volume  

SVM: Support Vector Machines  

UF: Ultrafiltration 

WAK: Wearable Artificial Kidney 

 

 

 

 

 

 

 

 

 

 

 



 

4 

 

 

BODY (4000 words) 

Background 

Renal transplantation is the best option for End Stages Renal Diseases (ESRD) in terms of 
patient’s life expectancy and quality of life, but the shortage of organ donors and clinical  
contraindications make dialysis the only real option for many patients 1 (Saran R, 2017). 
Complications in dialysis occur during the treatment, but current dialysis software is not able to 
make real-time changes when unexpected events happen, or to learn from experience to 
improve therapy and personalize treatments. Great efforts have been made to pre-set 
ultrafiltration (UF) and dialysate sodium profiles to counterbalance the negative effects of 
uncontrolled water or solute removal 2 (Fisheux, 2017). However, this approach has failed, since 
predetermined ultrafiltration and sodium profiles do not allow adaptations during treatment if 
the designed profile was inadequate 3 (Ronco C, 1999). Thus, we need real-time data monitoring 
using multiple biosensors to detect the most important chemical/physical signals from patients 
and achieve an automatic, immediate and adequate change of dialysis parameters to reduce 
patients morbidity 4(Locatelli F, 2005). 

Data analytics, delivered by Artificial Intelligence (AI) and Machine Learning (ML) is likely to play 
an important role in patient monitoring of dialysis efficacy and safety. AI is already having an 
impact on healthcare in areas such as medical image analysis, smart robotics in surgery and 
voice-enabled assistants 5-6 (Senders JT, 2017; Feng R, 2017). Can this success be exported to 
dialysis? Is it possible to design and develop smart dialysis devices? A first scientific meeting to 
discuss the present and future of AI in dialysis was organized at the Hospital of Bellvitge 
(Barcelona, Spain) with the aim to answer these questions and discuss the state-of-the-art in the 
field. As a result from that meeting, this study reviews AI experiences in dialysis and discusses 
barriers, challenges and future applications in the field. 

Present of Artificial Intelligence in medicine: Challenges for the application of machine 
learning in this area and the importance of model interpretability.  

Current research in the life sciences relies heavily on data acquisition and analysis 7 [Leonelli, 2016]. 
The drive towards data-based science is especially strong in the –omics fields, where fast 
technological advances in data acquisition have shifted part of the research challenges to the 
computer science domain. These challenges maybe only relatively less pressing in healthcare or 
biomedicine, but, even here, the complexity and heterogeneity of medical information means 
that “it is not yet possible to create a comprehensive model capable of considering all the 
aspects of health care systems” 8 [SM Reza, 2016]. 

The widespread adoption of computers and networked digital systems is creating a fast-evolving 
medical information ecosystem. This situation of data abundance, only bound to increase, may 
be seen as the perfect opportunity for data analytics, be it in the form of statistics, ML, or 
combinations of both under the umbrella of AI. Data analytics is at the heart of medical decision 
support systems (MDSS), which are often based on AI methods such as ML. MDSS, although still 



 

5 

 

far from the mainstream of medical practice, have made substantial advances in specific 
domains 9-11 [Safdar, S., 2017// Pombo, N. 2014// Vellido, A., in press].  

This opportunity seems like a win-win scenario but, in fact, the implementation of AI methods 
in healthcare and biomedicine is riddled with non-trivial challenges. We argue here that, unless 
those challenges are appropriately addressed, this type of methods is unlikely to be adopted in 
practice beyond a limited number of niche applications. Some of these pressing challenges have 
their origin in societal issues. Let us illustrate this with two examples. One of the currently most 
fruitful applications of ML in medicine is Electronic Health Records (EHR) text mining. It has been 
argued, though, that this application might lead to a reduction of skills among medical experts. 
This negative consequence of the use of ML methods in medicine has been described as ML 
methods’ undue “focus on text and the demise of context” 12 [Cabitza, F., 2017]. The second 
example involves the implementation of a European Union directive for General Data Protection 
Regulation (GDPR) that will be enforced in 2018 and mandates a right to explanation of all 
decisions made by automated or AI algorithmic systems 13 [Goodman, B. 2017]. Note that this 
regulation should be a warning for any AI-based MDSS for which the required explanation is 
unfeasible. 

Let us now turn to a challenge that is directly derived from the characteristics of many AI 
methods: the potential lack of interpretability and/or comprehensibility of the data models they 
generate. Interpretability has become a central issue in ML research over the last years 14 [Vellido, 
A., 2012]. Such surge of interest is at least partly caused by the resurgence of connectionist ML in 
the form of Deep Learning (DL), a family of successful methods that have also found their way 
into biomedicine and healthcare 15 [Jackups, R. 2017]. 

Three main challenges for the application of ML in medicine have been recently listed 12 [Cabitza, 
F., 2017] and one of them is precisely interpretability, expressed as “the need to open the machine 
learning black box”. Not that this is a new challenge for ML, because the black box syndrome 
was already on the table decades ago 16 [Tu, J V.1996]. The problem can also be expressed as the 
impossibility to describe in clear terms the relationship between the observed data and the 
resulting outcomes due to its complexity. This has obvious implications in the medical context: 
if an MDSS churns out decisions that cannot easily be described in comprehensible terms, a 
potentially insurmountable barrier is raised between the MDSS and the human users. For 
instance, the medical expert could not trust to implement a decision that cannot be explained, 
while the patient might not trust an expert that bases her or his judgement on unexplainable 
algorithmic outcomes. Also, and on the basis of legal safeguards such as the GDPR, a healthcare 
system might not be willing to implement an opaque MDSS in clinical practice. 

It has been argued that the role of ML in healthcare should be acting “as a tool to aid and refine 
specific tasks performed by human professionals” 17 [MJ Reid, 2017]. Note that this means that 
interpretability cannot be dissociated from the human interpreter. Some formal framework for 
machine-human interaction in the pursuit of interpretability is required. One such framework is 
outlined in Figure 1. 

A similar augmented framework was recently proposed for ML interpretability through 
visualization 18 [Sacha, Dominik, 2017], emphasizing interactivity between human and algorithm. 



 

6 

 

Visualization can be seen as a powerful tool for exploratory data analysis and it has also been 
mentioned to play a central role in interpretability for medicine in recent research 19 [Bhanot, G., 
2017]. 

This is the context in which we need to appraise the present of the application of AI and ML in 
Nephrology and, specifically, dialysis. Research in this area is still somehow disconnected and 
tentative. For instance, AI and ML have addressed problems concerning anemia and other issues 
in HD patients 20  [Brier, M. E., 2016], 21  [Fernández, E.A., 2013] . Artificial Neural Networks (ANN) were 
used for predicting total body water in HD patients 22 [Chiu, J. S., 2005], and the target range of 
plasma intact parathyroid hormone concentration 23 [Wang, Y.F., 2006]. Support Vector Machines 
(SVM) and Reinforcement Learning have been proposed for erythropoietin dosage prediction 
and personalization 24 [J.D. Martin-Guerrero, 2009]. Full ML-based MDSS have also been proposed, like 
a tool for anemia management in renal disease patients undergoing dialysis 25 [Barbieri, C., 2016.].  

In continuous ambulatory peritoneal dialysis for monitoring patients with severe kidney failure, 
ML has been used as the basis for an MDSS for blood tests analysis to ascertain their stroke risk 
levels 26 [Rodrigues, M., 2017]. A completely different use of ML is the application of Classification 
Trees and Naïve Bayes to the prediction of the quality of life in HD patients 27 [Saadat, 2017]. Data 
feature selection can help the interpretation of a given problem by providing guidance about 
the relative impact of input features on the outcome. An example of such approach is the 
analysis of the relative relevance of genetic and phenotypic data features associated with the 
inflammatory status of patients on dialysis 28 [Bobrowski L, 2014].  

As with the application of AI and ML techniques to medicine in general, a word of caution about 
the existence of non-trivial challenges must be included here also for the case of dialysis. Ricci 
and colleagues 29[Ricci, Z., 2017] have recently described an scenario where “often the 
dialysis/Continuous Renal Replacement machine is seen as a black box where nothing can be 
modified from the scheduled functionality and the machine is automatically selecting the best 
operational mode to achieve therapeutic targets”. Authors warn that this scenario might lead to 
the progressive deskilling of clinicians. It is also a context in which lack of model transparency 
can only be overcome by achieving a synergy between machine and human experts in which 
both tap into each other’s expertise to increase their own. 

Clinical experiences of AI and ML techniques to HD: Anemia Therapy control and Hemocontrol 
TM.  

Anemia Therapy control, or how algorithms make systems smart. 

Although dialysis partially restores kidney blood filtration function, it is unable to replace its role 
in regulating metabolism and in endocrine function, producing common dialysis complications 
such as anemia 30 [Lankhorst, 2010.]. The availability of exogenous Erythropoiesis Stimulating 
Agents (ESA) have improved the treatment of anemia but a high intra- and inter-individual 
response variability has been detected 31 [Foley,2011]. Thus, with the aim to support the 
nephrologist in ESA and iron dosing, an AI tool has been developed. The Anemia Control Model 
(ACM) consists of two components: (1) an ANN model that uses updated patients’ clinical data 
to predict future hemoglobin concentration; (2) an algorithm that suggests the optimal ESA and 



 

7 

 

iron dosage to achieve the hemoglobin target. It is important to stress that ACM only provides 
therapy recommendations and that has to be validated.  
The neural network was trained to predict the change in hemoglobin value occurring over a 
month, based on the current patient condition (lab tests, baseline characteristics, and dialysis 
treatment parameters) and the administered ESA and iron doses. This predictive model is used 
to assess how hemoglobin is expected to change as a function of different ESA dosages, and is 
used in the next dose selection step 32,33 [Martínez-Martínez JM, 2014; Barbieri C 2015]. In 
summary, based on model simulation, the algorithm looks for the drug dosage that would move 
hemoglobin to the target interval, while avoiding excessive hemoglobin drops or jumps 34 
[Escandell-Montero P, 2014]. Patients’ updated clinical information is fed to the ACM by means 
of an automatic interface module with the clinical system, which ensures continuous recording 
of clinical and laboratory data.  
The clinical introduction of ACM has allowed an increase of number of patients in target (70.6% 
to 83.2%), a decrease in hemoglobin variability (from 0.95 g/dL to 0.83 g/dL), a significant 
reduction of hemoglobin> 12g/dL (18.06% to 7.5%) and a reduction of ESA and iron consumption 
25 [Barbieri C, 2016]. 

Hemocontrol TM and Machine Learning Systems  

Intradialytic hypotension (IDH) occurs in 20% of patients and increases cardiovascular mortality 
and morbidity 35 (Stefansson. 2014;). IDH are caused by an imbalance between the 
prescribed weight loss, the plasma refilling capacity, and the cardiovascular system 
compensatory mechanism. To prevent IDH, an innovative, multi-input multi-output  controller 
named HemocontrolTM  has been developed 36 (Santoro, 1994). HemocontrolTM  assesses three 
variables (blood volume, total weight loss and average dialysate sodium level) and controls two 
dialysis parameters: UF and dialysate sodium level. Relative blood volume (RBV) changes are 
monitored by an optical absorption biosensor (HemoscanTM) that estimates haemoglobin 
concentration using spectrophotometry. The estimated RBV used on the hemocontrol 
prescription is based on the patient’s ratio of total UF and final BV changes (BV/UF volume). 
Hemocontrol TM modifies sodium concentration of dialysate and regulates the UF rate through 
a biofeedback mechanism to adjust it to the predetermined RBV trajectory. The changes in UF 
rate and in sodium concentration are carried out within a defined limit to avoid sodium overload 
and to achieve the prescribed weight loss. Biofeedback systems that only adjust UF without 
changing dialysate sodium concentration will not reduce the rate of IDH compared to 
conventional therapy 37 (Leung, 2017). The dialysis team will be able to follow up the patient’s 
response adjusting the UF goal and change on RBV as required by the patient’s clinical condition. 
Biofeedback systems like Hemocontrol TM have shown to significantly reduce the incidence of 
IDH by a 39%  38 (Nesrallah, 2013 ) and myocardial stunning 39(Selby,2006),  while achieving 
higher UF volumes  per treatment 40 (Roland E. 2011) compared to conventional 
HD.  Hemocontrol TM initial rise in the dialysate sodium concentration has shown to increase the 
plasma levels of vasopressin that might contribute to a decrease in the number IDH episodes at 
the end of the treatment 41 (Ettema, 2012). It has also shown to reduce the number of 
antihypertensive medications in the long term, improving the patients haemodialysis experience 
by decreasing   post-haemodialysis fatigue, increasing the number  of event-free sessions 



 

8 

 

and  reducing the  number of  dialysis sessions that require nursing interventions 42 (Doria, 
2014).  

 
The future in medical devices that will revolutionize the treatment of dialysis patients. 

Miniaturization, portability, flexibility, “water use” efficiency, and wearable technology are goals 
subject to intense research that will contribute to the metamorphosis of current dialysis 
machines. Achieving these goals will require innovative technological developments in the field 
of membranes (smart biocompatible nanotechnology-produced membranes or composite 
membranes containing specific sorbents) 43 (Tijink MS, 2013); dialysis fluids regeneration with 
cation-exchange sorbent systems and enzyme technology 44 (Agar 2010); highly efficient 
pumping system both for blood and dialysis fluids; anticoagulation and non-thrombogenic 
surfaces for clotting avoidance; and a safe vascular access for a therapy that should operate 
continuously 45 (Armignacco P, 2015). Developments in bioelectronics and semiconductor 
technologies have made possible to design circuits that can be integrated into a single chip and 
consume less power. Smaller but powerful batteries with longer backup time will further allow 
miniaturization, enhancing portability. This technology has allowed the development of 
Wearable Artificial Kidney (WAK) based on dialysate-regenerating sorbent technology 46 (Gura 
V, 2016). Another development in miniature dialysis devices, still in the preclinical studies stage, 
is the implantable bioartificial kidney based on silicon nanotechnology to create membranes 
mimicking glomerular filtration in combination with renal tubular cells 47 (Roy S, 2011).  

Wireless technology will also enhance clinical workflow for EHR or remote monitoring. However, 
electrical leakage in wearable devices is a matter of concern given that patient safety is a key 
challenge for the development of future dialysis devices, where stringent regulatory and 
compliance requirements catalyze innovation.  To improve patients’ security, a system of alarms 
is required for air detection, blood leaks, transmembrane pressure, and proper blood pump 
functioning. In addition, miniaturized sensor technology in dialysate affluent and effluent are 
also important for adequate monitoring of electrolytes and acid-base disturbances. On-line 
monitoring systems with automatic instantaneous bio-feedback based on real-time and 
repeated measurement of chemical and physical signals from the patient, such as blood-volume 
changes, dialysate conductivity, urea kinetics and thermal energy balance, followed by the 
analysis and evaluation of the data, will allow more personalized treatments 4 (Locatelli F2005). 
Treatment parameters will change continuously through a dialysis delivery system that 
incorporates adaptive and logic controls. Integrating monitoring vital signs with parameters of 
dialysis will produce large data sets that will require predictive models with complex calculations 
and, possibly, ML methods to deliver better decisions and increase patients’ safety 48,49 
(Nadkami GN, 2016; Ketchersid T. 2013). 

 

 

Is AI the future for therapy and decision problem solving in medicine or it is science fiction?. 
A vision of potential applications of AI in medicine. 



 

9 

 

To discuss the future potential of AI in medicine, it is necessary to assess its current standing, as 
described in previous sections. AI is the field of computer science that studies the automatic 
generation of intelligent behavior from a computational point of view. The term "intelligent 
behavior" is usually defined in terms of how difficult it would be for a human to perform a given 
task 50 (Russell, 2009). Computational problems that are historically considered part of AI 
include reasoning, knowledge discovery, planning, learning, natural language processing, 
perception and the ability to move and manipulate objects. 

ML, a subfield of AI, has experienced an unprecedented boom in the 2010's, particularly in the 
form of DL 51 (Goodfellow, I2016). This progress is intimately tied to the increased 
computational power of processing units. Many of the algorithms popularized during this period 
were developed decades earlier, but their full potential was not realized until the advent of 
commercially available graphical processing units (GPUs) that made it possible to efficiently 
parallelize computation. Automatically generating intelligent behavior that is comparable to 
that of humans has been a long-standing goal of AI. There are many recent publications that 
claim to achieve or surpass human-level performance in various areas of AI, such as image 
segmentation 52 (Zeng, T., 2017), concept learning 53 (Lake, B.M., 2015), and speech 
recognition 54 (Xiong 2016). With respect to medicine, achieving human-level performance is 
not only of academic interest, but effectively determines when an AI algorithm may perform its 
task better than a human would. Several studies indicate that AI algorithms may already surpass 
humans in clinical tasks such as predicting lung cancer 55 (Yu 2016), skin cancer 56 (Esteva 2017), 
and the risk of heart attacks 57 (Weng 2017). This trend is bound to continue in the future, with 
some clinical tasks performed more efficiently and accurately using AI. 

With this background in mind, it is evident that AI holds a great potential for clinical tasks in 
medicine. However, much research on AI for medicine has been carried out in academic settings. 
For AI systems to have an impact on the diagnosis and treatment of the general population, it 
would be necessary to implement and integrate such systems in the public healthcare domain. 
As we discuss below, such a large-scale implementation of AI systems in medicine is far from 
straightforward. The problem of interpretability has already been discussed, but there is also a 
host of other issues that we describe below. 

A prerequisite for the implementation of AI systems in medicine is to ensure that the 
appropriate infrastructure is in place. Specifically, patient data should be properly collected, 
labelled and organized, and measurements performed by digital tools that are directly 
connected to the network, such that patient records are automatically updated and maintained. 
Such a digital reform is under way in many countries 58 (The Economist, 2017), but there is still 
plenty of work to be done. An important limitation of ML algorithms is that they need access to 
large amounts of high-quality data. Although open access to data is becoming more common in 
academics, there are many incentives in medicine for keeping data private: companies want to 
maintain an edge over their competition; hospitals may not want to compromise the privacy of 
its patients, etc. Most likely, it would be necessary to propose and implement new regulations 
regarding how medical data is created, maintained and shared. A related problem is to ensure 
that sensitive patient information is not divulged in data records used to train ML algorithms. 
Patient records are usually anonymized to leave out sensitive information in order to guarantee 



 

10 

 

the privacy of patients. However, as ML algorithms become increasingly powerful, they can also 
be used to predict the missing information in patient records. Hence, anonymization may not be 
sufficient on its own, and additional techniques are necessary to ensure that anonymized patient 
information cannot be reconstructed. 

If AI algorithms are used to make clinical decisions, this raises both ethical and legal questions. 
Who is liable in case something goes wrong, the developer of the AI system or the hospital? 
What should an AI algorithm do in case it is faced with two unattractive options? Ethical 
dilemmas of this type are frequently discussed in the context of self-driving cars 59 (Bonnefon, 
J., 2015), e.g. what should an autonomous car do if it is faced with the decision of hitting a 
pedestrian or hurting its own passengers? The Ethics Commission at the German Ministry of 
Transport and Digital Infrastructure recently published the world's first ethical guidelines for 
autonomous driving 60 (BMVI. 2017), and similar initiatives would be needed for medicine. 

If discriminatory bias is present in historical data records, then ML algorithms simply learn to 
reproduce this discriminatory bias. There are several examples in the news of ML algorithms 
that discriminate: an algorithm implemented by Google to display job ads presented men with 
higher-paying job offers than women 61 Independent, 2015), and an algorithm for predicting 
crime rates in the U.S. unfairly associated a higher risk with African-Americans than with other 
ethnical groups 62 (Business Insider, 2016). It is easy to imagine clinical situations in which 
decisions may be considered discriminatory, so this is another aspect of AI that has to be taken 
into account. 

Another problem is that implementing AI systems in healthcare can be viewed by doctors as 
trespass on their domain of expertise, and perhaps even as a threat to their job security. Given 
the current state-of-the-art in AI, most doctors should be safe: AI algorithms excel at specialized 
tasks for which they have been trained, but they lack the ability to draw conclusions, integrate 
information and perform high-level reasoning. In addition, doctors can provide patients with a 
sense of comfort and human empathy that would be very difficult to reproduce in an artificial 
system. However, there are specialist doctors such as radiologists whose job mainly consists in 
analyzing images to diagnose patients. These specialists would directly compete with AI 
algorithms that perform the same task. Even in these cases, however, there is a danger in relying 
too much on AI algorithms, since the human knowledge might eventually become lost, an effect 
known as "automation bias". 

In the short term, we believe that the proper way to integrate AI in medicine is to view AI 
algorithms as tools that doctors can use to make more informed decisions. In this sense, it is 
important to develop applications that present the outcome of AI algorithms in an explanatory 
way that doctors can understand and interpret. On the one hand, doctors would have to accept 
that there are certain tasks that AI algorithms perform better. On the other hand, doctors would 
be ultimately responsible for the final decisions taken regarding diagnosis and treatment. 

It is difficult to speculate in how AI will transform medicine in the long term. One area of AI called 
life-long learning studies the problem of AI systems that evolve over time and adapt to new 
challenges and tasks that they were not originally designed for. Such a system would more 
closely resemble a human's ability to switch between tasks and draw on previous experience to 



 

11 

 

solve new tasks more efficiently. This research is still in an early stage, and it will likely be many 
years before such systems are ready to be implemented in real-world applications. One can 
imagine deploying a team of autonomous nanobots in a human body that automatically learn 
to perform new tasks over time, with the aim of ensuring the well-being of the patient. 

CONCLUSIONS AND FUTURE TRENDS. 

ESRD patients depend on technology for living. The evolution of dialysis therapy has been 
characterized by the search for safer devices with more efficient and clinically tolerable 
treatments.  

Data analytics, delivered by AI and ML is likely to play an important role in medical decision 
making for patient monitoring of dialysis efficacy and safety. However, MDSS are still far from 
the mainstream of medical practice.  

One challenge for AI methods is the potential lack of interpretability and/or comprehensibility 
of the data models they generate due to the impossibility to describe the relationship between 
the observed data and the resulting outcomes due to its complexity. This problem can only be 
overcome by achieving a synergy between machine and human experts in which both tap into 
each other’s expertise to increase their own. 

 

 

ACKNOWLEDGMENTS. This report comes from the 1st Science for Dialysis: Artificial Intelligence 
which took place in Bellvitge Universitary Hospital in 22th September, MH and NM wrote the 
background and future in medical devices. As chairmen they oversaw the consistency of the 
manuscript edition. Other section were written by the following participants: AV wrote present 
of AI in medicine, CB and RR wrote Anemia Therapy control, MA wrote Hemocontrol, JC wrote 
future in medical devices and AJ wrote AI the future for therapy and decision problem solving in 
medicine. Conclusions were written by all participants. We thank Estanislao Navarro for the 
critical reading of the manuscript. 

 

CONFLICT OF INTEREST: None declared. 

 

REFERENCES (50) 

1. Saran R, Robinson B, Abbott KC, Agodoa LYC, Ayanian J, Bragg-Gresham J, et al. US Renal 
Data System 2016 Annual Data Report: Epidemiology of Kidney Disease in the United 
States. Am J Kidney Dis, 2017;69(3):A7–8.  

2. Ficheux A, Gayrard N, Duranton F, Guzman C, Szwarc I, Vetromile F, Brunet P, Servel 
MF,Argilés A: A reliable method to assess the water permeability of a dialysis system: 
the global ultrafiltration coefficient. Nephrol Dial Transplant 2017;32:364–370. 



 

12 

 

3. Ronco C, Ghezzi PM, La Greca G. The role of technology in hemodialysis. J Nephrol, 1999: 
Suppl 2: S68-81.   

4. Locatelli F, Buoncristiani U, Canaud B, Köhler H, Petitclerc T, Zuchelli P: Hemodyalisis 
with on-line monitoring equipment: tools or toys?. Nephrol Dial Transplant, 2005: 20: 
22-33.5.  

5. Senders JT, Arnaout O, Karhade AV, Desenbrock HH, Gormley WB, Broekman ML, Smith 
TR: Natural and Artificial Intelligence in Neurosurgery: A Systematic Review. 
Neurosurgery, 2017: doi: 10.1093/neuros/nyx384. 

6. Feng R, Badgeley M, Mocco J, Oermann EK: Deep Learning guided stroke management: 
a review of clinical applications. J Neurointerv Surg, 2017: doi: 10.1136/neurintsurg-
2017-013355. 

7. Leonelli S: Data-Centric Biology: a Philosophical Study. University of Chicago Press, 2016. 

8. Reza SM: Transforming big data into computational models for personalized medicine 
and health care, Dialogues in Clinical Neuroscience, 2016; 18(3): 339-343.9.  

9. Safdar S, Zafar S, Zafar N, Khan NF: Machine learning based decision support systems 
(DSS) for heart disease diagnosis: a review. Artificial Intelligence Review, 2017;1-27.  

10. Pombo N, Araújo P, Viana J:  Knowledge discovery in clinical decision support systems 
for pain management: A systematic review. Artificial Intelligence in Medicine, 
2014;60(1), 1-11. 

11. Vellido A, Ribas V, Morales C, Ruiz-Santamaría A, Ruiz-Rodríguez J: Machine Learning for 
critical care: state-of-the-art and a sepsis case study, Biomedical Engineering OnLine, in 
press. 

12. Cabitza F, Rasoini R, Gensini G F:  Unintended consequences of machine learning in 
medicine. JAMA, 2017; 318(6), 517-518.      

13. Goodman B, Flaxman S:  European Union Regulations on Algorithmic Decision Making 
and a" Right to Explanation". AI Magazine, 2017; 38(3). 

14. Vellido A, Martín-Guerrero JD, Lisboa PJG: Making machine learning models 
interpretable. In M. Verleysen (Ed.), Proceedings of the 20th European Symposium on 
Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 
2012), Bruges, Belgium, 163-172 

15. Jackups R: Deep Learning makes its way to the clinical laboratory, Clinical Chemistry, 
2017; 63(12). 

16. Tu JV:  Advantages and disadvantages of using artificial neural networks versus logistic 
regression for predicting medical outcomes. Journal of Clinical Epidemiology, 1996; 
49(11), 1225-1231. 



 

13 

 

17. Reid MJ:  Black-box Machine Learning: implications for healthcare, Polygeia, April 6, 
2017. 

18. Dominik S, Sedlmair M, Zhang L, Lee JA, Peltonen J, Weiskopf D, North SC, Keim DA: 
What you see is what you can change: Human-centered machine learning by interactive 
visualization. Neurocomputing, 2017; 268, 164-175.  

19. Bhanot G, Biehl M, VillmannT, Zühlke D: Biomedical data analysis in translational 
research: Integration of expert knowledge and interpretable models. In M. Verleysen 
(Ed.), 25th European Symposium on Artificial Neural Networks, Computational 
Intelligence and Machine Learning, ESANN 2017, 177-186. 

20. Brier ME, Gaweda AE: Artificial intelligence for optimal anemia management in end-
stage renal disease. Kidney International, 2016; 90(2), 259-261.  

21. Fernández EA, Valtuille R,Balzarini M: Artificial Neural Networks Applications in Dialysis. 
In Modeling and Control of Dialysis Systems; in Studies in Computational Intelligence, 
vol.405, Springer: Biofeedback Systems and Soft Computing Techniques of Dialysis, 
2013, vol 2, pp. 1145-1179.  

22. Chiu JS, Chong CF, Lin YF, Wu CC, Wang YF, Li YC:  Applying an artificial neural network 
to predict total body water in hemodialysis patients. Am J Nephrol, 2005; 25(5), 507-
513. 

23. Wang YF, Hu TM, Wu CC, Yu FC, Fu CM, Lin SH, Huang WH, Chiu JS:  Prediction of target 
range of intact parathyroid hormone in hemodialysis patients with artificial neural 
network. Computer Methods and Programs in Biomedicine, 2006; 83(2), 111-119. 

24. Martin-Guerrero JD, Gómez F, Soria-Olivas E, Schmidhuber J, Climente-Marti M, 
Jiménez-Torres NV: A reinforcement learning approach for individualizing 
erythropoietin dosages in hemodialysis patients, Expert Syst. Appl, 2009;  36(6), 9737–
9742. 

25. Barbieri C, Molina M, Ponce P, Tothova M, Cattinelli I, Titapiccolo JI, Mari F, Amato C, 
Leipold F, Wehmeyer W, Stuard S: An international observational study suggests that 
artificial intelligence for clinical decision support optimizes anemia management in 
hemodialysis patients. Kidney International, 2016; 90(2), 422-429. 

26. Rodrigues M, Peixoto H, Esteves M, Machado J: Understanding stroke in dialysis and 
chronic kidney disease. Procedia Computer Science, 2017; 113, 591-596. 

27. Saadat S, Aziz A, Ahmad H, Imtiaz H, Zara SS,  Kazmi A, Aslam S, Naqvi N, Saadat S: 
Predicting quality of life changes in hemodialysis patients using machine learning: 
generation of an early warning system." Cureus, 2017, 9(9): e1713.  

28. Bobrowski L, Łukaszuk T, Lindholm B, Stenvinkel P, Heimburger O, Axelsson J, Bárány P, 
Carrero JJ, Qureshi AR, Luttropp K, Debowska M, Nordfors L, Schalling M, Waniewski J: 
Selection of genetic and phenotypic features associated with inflammatory status of 



 

14 

 

patients on dialysis using relaxed linear separability method. PLoS ONE, 2014; 9(1): 
e86630. 

29. Ricci Z, Romagnoli S, Ronco C:  Automatic dialysis and continuous renal replacement 
therapy: keeping the primacy of human consciousness and fighting the dark side of 
technology. Blood Purification, 2017; 44(4), 271-275.  

30. Lankhorst CE, Wish JB: Anemia in renal disease: diagnosis and management. Blood 
Reviews, 2010; 24: 39-47.  

31. Foley RN: Treatment of anemia in chronic kidney disease: known, unknown, and both. 
Journal of Blood Medicine, 2011; 2: 103-12.   

32. Martínez-Martínez JM, Escandell-Montero P, Babieri C, Soria-Olivas E, Mari F, Martinez 
Sober M, Amato C, Serrano Lopez A, Bassi M, Magdalena Benedito R, Stopper A, Gatti E: 
Prediction of the hemoglobin level in hemodialysis patients using machine learning 
techniques. Computer Methods and Programs in Biomedicine, 2014; 117 (2): 208-217. 

33. Barbieri C, Mari F, Stopper A, Gatti E, Escandell-Montero P, Martínez-Martínez JM, 
Martín-Guerrero JD: A new machine learning approach for predicting the response to 
anemia treatment in a large cohort of End Stage Renal Disease patients undergoing 
dialysis. Computers in Biology and Medicine, 2015; 61:56-61. 

34. Escandell-Montero P, Chermisi M, Martínez-Martínez JM, Gomez Sanchis J, Babieri C, 
Soria Olivas E, Mari F, Vila Frances J, Stopper A, Gatti E, Martin Guerrero JD:  
Optimization of anemia treatment in hemodialysis patients via reinforcement learning. 
Artif Intel Med, 2014; 62 (1): 47-60. 

35. Stefánsson BV, Brunelli SM, Cabrera C, Rosenbaum D, Anum E, Ramakrishnam K, Jensen 
DE, Stalhammar NO: Intradialytic hypotension and risk of cardiovascular disease. Clin J 
Am Soc Nephrol, 2014; 9(12), 2124-2132. 

36. Santoro A, Mancini E, Paolini F, Spongano M, Zucchelli P: Automatic control of blood 
volume trends during hemodialysis. ASAIO J, 1994; 40(3): M419-422. 

37. Leung KCW, Quinn RR, Ravani P, Duff H, MacRae JM: Randomized crossover trial of blood 
volume monitoring-guided ultrafiltration biofeedback to reduce intradialytic 
hypotensive episodes with hemodialysis. Clin J Am Soc Nephrol, 2017; 12(11): 1831-
1840.41.  

38. Nesrallah GE, Suri RS, Thiessen-Philbrook H, Heidenheim P, Lindsay RM: Can 
extracellular fluid volume expansion in hemodialysis patients be safely reduced using 
the hemocontrol biofeedback algorithm? A randomized trial. ASAIO J, 2008; 54(3): 270-
274. 

39. Selby NM, Lambie SH, Camici PG, Baker CS, McIntyre CW: Ocurrence of regional 
ventricular dysfuction in patients undergoing standard and biofeedback dialysis. Am J 
Kidney Dis, 2006; 47:830-41. 



 

15 

 

40. Winkler RE, Grandi F, Santoro A: Blood Volume Regulation,; in Maria Goretti Penido (ed): 
Technical problems in patients on hemodialysis, InTech, 2011, chapter 15 DOI: 
10.5772/21598. 

41. Ettema EM, Kuipers J, Groen H, Kema IP, Westerhuis R, de Jong PE, Franssen CFM: 
Vasopressin release is enhanced by the Hemocontrol biofeedback system and could 
contribute to better haemodynamic stability during haemodialysis. Nephrol Dial 
Transplant, 2012; 27(8): 3263-3270. 

42. Doria M, Genovesi S, Biagi F, Steckiph D, Mancini E, Stella A, Santoro A: The dialysis staff 
workload and the blood volume tracking system during the hemodialysis sessions of 
hypotension-prone patients. Int J Artif Organs, 2014; 37(4): 292-298. 

43. Tijink MS, Wester M, Glorieux G, Gerritsen KG, Sun J, Swart PC, Borneman Z, Wessling 
M, Vanholder R, Joles JA, Stamatialis: Mixed matrix hollow fiber membranes for removal 
of protein-bound toxins from human plasma. Biomaterials, 2013; 34:7819-28. 

44. Agar J: Review: Understanding sorbent dialysis systems. Nephrology, 2010; 15:406-
4011.  

45. Armignacco P, Garzotto F, Neri M, Lorenzin A, Ronco C: WAK engineering Evolution. 
Blood Purif, 2015; 39:1-3. 

46. Gura V, Macy AS, Beizai M, Ezon C, Golper TA: Technical breakthroughs in the Wearable 
Artificial Kidney (WAK). CJASN, 2009; 4: 1441-1448. 

47. Roy S, Goldman K, Marchant R, Zydney A, Brown D, Fleischman A, Conlisk A, Desai T, 
Duffy S, Humes H, Fissell W: Implanted renal replacement for end-stage renal disease.  
Panminerva Med, 2011; 53:155-66. 

48. Nadkarni GN, Coca SG, Wyatt CM: Big data in nephrology: promises and pitfalls. Kidney 
Int, 2016; 90: 240-241.  

49. Ketchersid T: Big data in nephrology: friend or foe?. Blood Purif, 2013; 36: 160-4. 

50. Russell SJ, Norvig P: Artificial Intelligence: A Modern Approach., in Rusell SJ, Norving P 
(eds): Prentice Hall series in Artificial Intelligence. 3rd edition, New Jersey, Pearson 
Education, Inc, 2009. 

51. Goodfellow I, Bengio, Y, Courville A: Deep Learning, MIT Press, 2016. 

52. Zeng T, Wu B, Ji S: DeepEM3D: approaching human-level performance on 3D anisotropic 
EM image segmentation. Bioinformatics, 2017; 33:2555-2562.  

53. Lake BM, Salakhutdinov R, Tenenbaum JB: Human-level concept learning through 
probabilistic program induction. Science, 2015; 350: 1332-1338.  

54. Xiong W, Droppo J, Huang X, Seide F, Seltzer M, Stolcke A, Yu D, Zweig G: Achieving 
human parity in conversational speech recognition. arXiv, 2016; arXiv:1610.05256v2. 



 

16 

 

55. Yu KH, Zhang Ce, Berry GJ, Altman RB, Ré C, Rubin DL, Snyder M: Predicting non-small 
cell lung cancer prognosis by fully automated microscopic pathology image features. 
Nature Communication, 2016; 7:12474 

56. Esteva A, Kuprel B, Novoa RA, Ko, J, Swetter SM, Blau HM, ThrunS: Dermatologist-level 
classification of skin cancer with deep neural networks., Nature, 2017; 542:115-118.   

57. Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N: Can machine-learning improve 
cardiovascular risk prediction using routine clinical data?. PLoS ONE, 2017; 12:0174944. 

58. How hospitals could be rebuilt, better than before, The Economist, April 2017. 

59. Bonnefon JF, Shariff A, Rahwan I: The social dilemma of autonomous vehicles. Science, 
2016; 352:1573-1576.  

60. Luetge C: The German Ethics Code for automated and Connected Driving. Philosophy & 
Technology, 2017; 30: 547-558.  

61. Carpenter J: Google's algorithm shows prestigious job ads to men, but not to women, 
Independent, July 2015. 

62. Smith J: Crime prediction tool may be reinforcing discriminatory policing. Business 
Insider, October 2016. 

 

 

 

FIGURE LEGENDS 

Figure 1: Interpretability cycle, considering a number of actors, including: the data and/or 
corresponding models and the ML interpretation tools, on one side (the machine side), and the 
cognitive processing based on a model of the reality to be interpreted, on the other side (the 
human side). The cycle allows for data and model adaptation according to human interpretation 
(Adapted from 14 [Vellido, A., 2012]). 

 

 

 

 


