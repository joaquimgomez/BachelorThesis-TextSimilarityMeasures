coverag charact base neural machin translat tecnica de cobertura caracter integrado en la traduccion automatica basada en aprendizaj profundo m.bashir kazimi marta r. costa-jussa talp research center universitat politecnica de catalunya , barcelona mohammad.bashir.kazimi @ est.fib.upc.edu marta.ruiz @ upc.edu abstract : recent year , neural machin translat ( nmt ) achiev state- of-th art perform translat languag ; sourc languag , anoth ; target languag .
howev , mani propos method use word embed techniqu repres sentenc sourc target languag .
charact em- bed techniqu task suggest repres word sentenc better .
moreov , recent nmt model use attent mechan relev word sourc sentenc use generat target word .
problem approach word translat multipl time , word translat .
address problem , coverag model integr nmt keep track already-transl word focus untransl one .
research , present new architectur use charact embed repres sourc target languag , also use coverag model make certain word translat .
experi perform compar model coverag charact model result show model perform better two model .
keyword : machin learn , deep learn , natur languag process , neu- ral machin translat resumen : en los ultimo ano , la traduccion automatica basada en el aprendizaj profundo ha conseguido resultado estado del art .
sin embargo , mucho de los metodo propuesto utilizan espacio de palabra embebido para representar una oracion en el idioma de origen destino esto genera mucho problema nivel de cobertura de vocabulario .
avanc recient en la traduccion automatica basada en aprendizaj profundo incluyen la utilizacion de caracter que permit reducir las palabra fuera de vocabulario .
por otro lado , la mayora de algoritmo de traduccion automatica basada en aprendizaj profundo usan mecanismo de atencion dond las palabra mas relevant en de la oracion fuent se utilizan para generar la traduccion destino .
el problema con est enfoqu es que mientra alguna palabra se traducen varia vece , alguna otra palabra se traducen .
para abordar est problema , usamo el modelo de cobertura que realiza un seguimiento de las palabra ya tra- ducida se centra en las traducida .
en est trabajo , presentamo una nueva arquitectura en la que utilizamo la incorporacion de caracter para representar el lenguaj origen , tambien usamo el modelo de cobertura para asegurarno que la frase origen se traduc en su totalidad .
presentamo experimento para comparar nuestro modelo que integra el modelo de cobertura modelo de caracter .
los resultado muestran que nuestro modelo se comporta mejor que los otro dos mod- elo .
palabra clave : aprendizaj automatico , aprendizaj profundo , procesado del lenguaj natur , traduccion automatica 1 introduct machin translat ( mt ) task us- ing softwar translat text one languag anoth .
mani natur languag world quit complex due fact word could differ mean base context use , could also use differ gram- matic categori ( e.g .
match noun verb ) .
therefor , main challeng mt fact correct translat word , requir mani differ factor consid ; grammat struc- ture , context , preced succeed- ing word .
year , research devel- ope differ method order reduc amount manual work human in- tervent , increas amount auto- matic work , machin depend transla- tion .
one main method mt sta- tistic machin translat ( smt ) data-driven approach produc trans- lation base probabl sourc target languag .
goal maxim condit probabl p ( y|x ) target sentenc given equival sourc sentenc x base set pre- design featur ( koehn , 2009 ) .
nmt recent approach ma- chine translat pure base larg neural network train learn translat text sourc tar- get languag .
unlik smt , re- quir pre-design featur function train fulli base train data ( lu- ong man , 2015 ) .
nmt attract attent mani research re- cent year .
use neural network translat baidu ( zhongjun , 2015 ) , attent googl  nmt system ( wu et al. , 2016 ) , facebook  automat text trans- lation , mani industri given urg research nmt push .
research , studi state art nmt , propos novel approach combin two recent model nmt ; coverag ( tu et al. , 2016 ) charac- ter model ( costa-jussa fonollosa , 2016 ) , hope achiev state art result .
rest paper organ follow .
section 2 studi relat work nmt , section 3 explain propos model studi point contribut research , section 4 explain exper- iment perform result obtain , final section 5 summar thesi point possibl futur research .
2 relat work nmt achiev state art result mt , first nmt model use re- current neural network ( rnn ) encod de- coder architectur ( sutskev , vinyal , le , 2014 ; cho et al. , 2014 ) .
ap- proach , input sentenc encod encod fixed-length vector ht use recurr neural network ( rnn ) , fixed-length vector decod decod ; anoth rnn , generat output sen- tenc .
word-embed ( mandelbaum shalev , 2016 ) use representa- tion sourc target word .
one main issu simpl rnn encod decod model encod vector fix length , repres long sentenc complet .
address issu , attent model introduc simpl rnn encod decod model ( bahdanau , cho , bengio , 2014 ) .
at- tention model use bi-direct recurr neural network store inform memori cell instead fixed-length vector .
small neural network call attent mechan use input inform memori cell inform pre- viousli translat word decod or- der focus relev input word translat specif output word .
model mention , word em- bed use word representa- tion .
perform well , limit nmt model fixed-s vocabulari .
sinc model train use larg set vocabulari , vocabulari alway lim- ite , model face problem rare out-of-vocabulari ( oov ) word ( yang et al. , 2016 ; lee , cho , hofmann , 2016 ) .
mani word could various morphologi- cal form , could affix , word- embed model would abl dis- tinguish word train affix ad differ morphologi- cal form word use ( chung , cho , bengio , 2016 ) .
address problem , propos use charact embed- ding rather word embed , result fulli character-level nmt system ( lee , cho , hofmann , 2016 ) , charact base nmt model use charact embed sourc languag ( costa-jussa fonollosa , 2016 ; kim et al. , 2015 ) , character-level decod use charact embed target languag ( chung , cho , bengio , 2016 ) .
two addit ad- vantag charact embed nmt usabl multilingu translat , result abil identifi share morpholog structur among lan- guag , also fact oppos word embed model , text segmenta- tion requir , enabl system learn map sequenc charac- ter overal mean represent au- tomat ( lee , cho , hofmann , 2016 ) .
prove charact nmt mod- el produc improv perform attent model ( costa-jussa fonollosa , 2016 ; yang et al. , 2016 ; lee , cho , hof- mann , 2016 ; chung , cho , bengio , 2016 ) .
anoth issu model mention earlier ; specif case atten- tion model , track translat histori henc , word translat mani time word translat translat fals .
address problem , differ model coverag propos track translat histori , avoid translat word multipl time focus word yet translat ( tu et al. , 2016 ; mi et al. , 2016 ) .
author claim achiev better result compar attent base model .
3 coverag charact base neural machin translat 3.1 contribut research base model rnn encod decod ( sutskev , vinyal , le , 2014 ; cho et al. , 2014 ) attent model ( bahdanau , cho , bengio , 2014 ) , produc charact model ( costa-jussa fonollosa , 2016 ; yang et al. , 2016 ; kim et al. , 2015 ; lee , cho , hof- mann , 2016 ) coverag model ( tu et al. , 2016 ; mi et al. , 2016 ) achiev state art result , model address one two issu earlier model sep- arat .
charact model address problem rare , oov word , word various morpholog structur , use charact embed rather word em- bed , coverag model address problem word trans- late multipl time rest never fals translat .
research , propos joint address two im- portant problem tradit nmt model introduc coverag charact model achiev state art result nmt .
charact embed use sourc word , target word still use word embed .
3.2 architectur propos nmt model backbon propos architectur still attent model propos bahdanau et al .
( bahdanau , cho , ben- gio , 2014 ) word embed input languag replac charact embed propos costa-jussa fonollosa ( costa-jussa fonollosa , 2016 ) .
thus , first , encod comput input sentenc summari ht = [  h ;  h ] concaten  h  h = 1 , 2 , ... . , .
 h  h hidden state forward backward rnn encod read inform input sen- tenc forward revers order , re- spectiv .
hidden state calcul follow .
 h =  f ( xt ,  h t1 ) ( 1 )  h =  f ( xt ,  h t1 ) ( 2 )  h t1  h t1 denot previous hidden state forward backward rnn ,  f  f recurr activ function , xt embed represen- tation t-th input word .
atten- tion model , xt simpl word embed represent word sourc lan- guag , case , xt charact embed calcul propos costa- jussa fonollosa ( costa-jussa fonol- losa , 2016 ) explain follow .
first , sourc word k repre- sent matrix ck sequenc vector repres charact embed- ding charact sourc word k. , n convolut filter h length w , w rang 1 7 , appli ck order obtain featur map fk sourc word k follow .
fk [ ] = tanh ( ck [  , : i+w1 ] , h+b ) ( 3 ) b bias i-th element featur map .
convolut filter h , output maximum valu select max pool layer order captur import featur .
ykh = max fk [ ] ( 4 ) concaten output valu n convolut filter h ; yk = [ ykh1 , k h2 , ... . , k hn ] , represent sourc word k. addit two highway network layer prove give bet- ter represent sourc word ( kim et al. , 2015 ) .
layer highway network perform follow .
xt = t g ( whyk + bh ) + ( 1 )  yk ( 5 ) g nonlinear function , =  ( wti k + bt ) transform gate , ( 1 - ) carri gate , xt charact em- bed use equat 1 2 .
decod generat summari zt of target sentenc follow .
zt = f ( zt1 , yt1 , st ) ( 6 ) st represent sourc word calcul follow .
st = t t=1 ttht ( 7 ) ht calcul encod ex- plain earlier , tt comput fol- low .
tt = exp ( ett ) t k=1 exp ( etk ) ( 8 ) ett = ( zt1 , ht , ct1t ) ( 9 ) call attent mechan align model score relev input word posit output word posit t , ct1t previous cov- erag coverag model propos tu et al .
( tu et al. , 2016 ) calcul follow .
ctt = f ( ct1t , tt , ht , zt1 ) ( 10 ) , output sentenc generat comput condit distribut possibl translat .
log p ( y|x ) =  p ( yt |y < t , x ) ( 11 ) x output input sen- tenc , respect , yt -th word sentenc .
condit proba- biliti term p ( yt |y < t , x ) comput use feed forward neural network follow .
p ( yt |y < t , x ) = softmax ( g ( yt1 , zt , st ) ) ( 12 ) g nonlinear function , zt de- code state equat 6 , st context vector equat 7 overal architectur propos model illustr figur 1 , 2 , 3 .
figur 1 illustr charact base word embed- ding model take input embed- ding charact sourc word xt , output final word level represent .
output fed encod ; depict figur 2 output context vector st base attent mechan coverag model .
context vector st fed decod illustr figur 3 generat target translat .
highway network highway network e c h xt charact embed multipl convolut differ length max pool layer select maximum output filter two layer highway network figur 1 : charact base word embed echt dick kist charact base word embed system x1 x2 x3 h1 h2 h3 + c1 c2 c3 attent layer t = 1 st  coverag bidirect rnn figur 2 : encod coverag & align 4 experi order evalu perform model , experi data set z2z1 echt dick kist charact base word embed system x1 x2 x3 encod + attent layer s1 s2 awesom y1 sauc y2 figur 3 : decod perform use charact model costa-jussa fonollosa ( costa-jussa fonollosa , 2016 ) , coverag model tu et al .
( tu et al. , 2016 ) , final pro- pose model studi ; coverag char- acter model .
section divid two subsect .
subsect 4.1 explain data set use preprocess per- form data , subsect 4.2 elab- orat evalu method re- sult obtain .
4.1 data data set use experi kind provid costa-jussa ( costa-jussa , 2017 ) includ subset larger data set includ set paper edit 10 year bilingu catalan news- paper , el periodico , addit cor- pus medic domain provid universal- doctor project1 .
preprocess task , data set token dic- tionari 10 thousand frequent word prepar train system .
detail inform data set list tabl 1 languag set # sentenc # word # vocab ca train dev test 83.5k 1k 1k 2.9m 27.7k 27k 83.5k 6.9k 6.7k es train dev test 100k 1k 1k 2.7m 25k 24.9k 90k 7k 7k tabl 1 : spanish-catalan dataset statist 1http : //www.universaldoctor.com/ model bleu score charact 53.30 coverag 53.76 character+coverag 54.87 tabl 2 : bleu score nmt model 4.2 evalu result evalu model , bleu ( bilingu evalu understudi ) evalu method propos papineni et al .
( papineni et al. , 2002 ) use .
main idea behind evalu method closer human translat machin translat , better model perform .
result experi perform data set mention section 4.1 list tabl 2 .
observ tabl 2 , propos model outperform model achiev state art perform .
main motiv studi tri ad- dress two main issu attent model .
first , attent model use word embed- ding languag represent , thus suffer rare , oov word problem , problem identifi differ mor- pheme ad word .
second issu even though attent model fo- cuse relev part input sen- tenc order translat generat output sentenc , keep track already-transl word , lead mul- tipl translat word rest never fals translat .
two is- sue individu tackl charac- ter model ( costa-jussa fonollosa , 2016 ; yang et al. , 2016 ; lee , cho , hofmann , 2016 ; kim et al. , 2015 ) , coverag mod- el ( tu et al. , 2016 ; mi et al. , 2016 ) , respec- tive .
research , tri improv state art introduc coverag charact model nmt .
experi perform data set shown tabl 1 clear show model outperform earlier model , shown tabl 2 .
under- stand contribut propos model see combin charact coverag model compliment two model sometim perform better model , list tabl 3 manual analysi sampl translat mod- el test .
martaruiz highlight martaruiz cross-out martaruiz insert text use subset larg corpus extract paper edit bilingu catalan newspap , el peridico ( costa-juss ` et al. , 2014 ) .
spanish-catalan corpus partial avail via elda ( evalu languag resourc distribut agenc ) catalog number elra-w0053 .
refer : marta r. costa-juss ` , march poch , jose a.r .
fonollosa , mireia farrus , jose b. marino .
2014 .
larg spanish-catalan parallel corpus releas machin translat .
comput informat journal , 33 martaruiz cross-out martaruiz sticki note repeat surnam two time ... `` tu et al .
( 2016 ) '' previous ... sever refer paper !
martaruiz cross-out martaruiz insert text word martaruiz cross-out martaruiz insert text martaruiz cross-out martaruiz cross-out martaruiz insert text martaruiz sticki note need list refer ... go relat work , enough !
martaruiz sticki note exampl show model capabl keep best translat character-bas ( exampl x ) coverage-bas ( exampl ) baselin system add new improv ( exempl xxx ) ( may write better ; - ) , idea ... martaruiz cross-out martaruiz cross-out 1 src tgt ch cov ch+cov dos regidor es presenten al comici .
dos concejal se pre-sentan alo comicio .
dos edil se presentan en los comicio .
dos concejal sepresentan los comicio .
dos concejal se presentan los comicio .
2 src tgt ch cov ch+cov la falta de public l  ha condemnat mort en una zona clau de l  oci barcelon que , pel que es veu , te mes poder de convocatoria .
la falta de publico lo ha condenado muert en una zona clave del ocio barcelon que , por lo que se , tien mas poder de convocatoria .
palma alguna de publico le ha condenado muert en una zona clave del ocio barcelon que , por lo que se , tien mas poder de convocatoria .
falta de publico al ha condenado muert en una zona clave del ocio barcelon que , por lo que se , tien mejor de convocatoria .
la falta de publico le ha condenado muert en una zona clave del ocio barcelon que , por el que se , tien adema poder de convocatoria.a .
3 src tgt ch cov ch+cov una firma austraca va voler vendr sang amb sida l  asia.. una firma austriaca quiso vender sangr con sida en asia .
una firma unk quiso vender sangr con sida en asia .
una seguidor unk quiso vender sangr con sida en asia .
unafirma unk quiso vender sangr consida en asia 4 src tgt ch cov ch+cov com consequencia de la progressiva reduccio del marg .
como consecuencia de la progresiva reduccion de los margen .
consecuencia de la unk reduccion de los margen .
consecuencia de la unk reduccion de los margen .
como consecuencia de la progresiva reduccion de los margen .
5 src tgt ch cov ch+cov ... requereix un esforc que involucri  departa de turism , joventut educacio , tamb de coordinacio en l  ambit europeu  ... ... requier un esfuerzo que involucr  departamento de turismo , juventud educacion , tambien de coordinacion nivel europeo ... ... requier un esfuerzo que unk  departamento de turismo , joventut educacion , que tien que unk en el ambito europeo ... ... requier un esfuerzo que unk  departamento de turismo , joventut educacion , que tien que unk en el ambito europeo ... ... requier un esfuerzo que unk  departamento de turismo , juventud educacion , tambien de coordinacion en el ambito europeo  ... tabl 3 : manual analysi .
src tgt repres sourc target sentenc , ch , cov , ch+cov repres translat charact , coverag , propos moedl , respect .
exampl 1 2 , propos model behav like coverag model , exampl 3 , behav like charact model , exampl 4 5 , perform better model .
5 summari recent model ; attent , propos bahdanau et al .
( bahdanau , cho , ben- gio , 2014 ) tackl problem fixed- length encod vector rnn en- coder decod model use sutskev et al .
( sutskev , vinyal , le , 2014 ) cho et al .
( cho et al. , 2014 ) .
give nmt abil abl translat sentenc length .
face two main problem ; rare , oov word problem along problem differ possibl morphem singl word , problem over- translat under-transl .
char- acter model use charact embed ( costa-jussa fonollosa , 2016 ; kim et al. , 2015 ; yang et al. , 2016 ; lee , cho , hof- mann , 2016 ) coverag model , keep track translat histori ( tu et al. , 2016 ; mi et al. , 2016 ) individu ad- dress issu , respect .
research , coverag intro- duce charact model aim address main issu mention earlier al- togeth , improv state art nmt .
corpus shown tabl 1 martaruiz cross-out martaruiz insert text model martaruiz cross-out martaruiz insert text una firma martaruiz sticki note mark bold correct translat martaruiz sticki note encoder-decod martaruiz sticki note ital ?
?
martaruiz sticki note pleas , add list refer ! ! !
martaruiz cross-out martaruiz cross-out martaruiz sticki note ital ?
experi result list tabl 2 .
clear observ model studi outperform pre- vious model achiev state art perform nmt .
case charact model , charact embed use sourc languag , target languag still limit word embed .
re- search requir order studi char- acter embed ad target lan- guag impact perform model , left investig factor af- fect perform nmt system .
acknowledg work support ministerio de economa competitividad fondo eu- ropeo de desarrollo region , con- tract tec2015-69266-p ( mineco/fed , ue ) postdoctor senior grant ramon cajal .
refer bahdanau , d. , k. cho , y. bengio .
2014 .
neural machin translat joint learn align translat .
corr , abs/1409.0473 .
cho , k. , b .
van merrienbo , c. gulcehr , d. bahdanau , f. bougar , h. schwenk , y. bengio .
2014 .
learn phrase represent use rnn encoder-decod statist machin translat .
arxiv preprint arxiv:1406.1078 .
chung , j. , k. cho , y. bengio .
2016 .
character-level decod without explicit segment neural machin transla- tion .
corr , abs/1603.06147 .
costa-jussa , m. r. 2017 .
catalan- spanish neural machin translat ?
anal- ysis , comparison combin standard rule phrase-bas technolo- gie .
: workshop nlp similar languag , varieti dialect .
 pro- ceed fourth workshop nlp similar languag , varieti di- alect ( vardial )  , page 5562 .
costa-jussa , m. r. j .
a. r. fonollosa .
2016 .
character-bas neural machin translat .
corr , abs/1603.00810 .
kim , y. , y. jernit , d. sontag , a. m. rush .
2015 .
character-awar neu- ral languag model .
arxiv preprint arxiv:1508.06615 .
koehn , p. 2009 .
statist machin transla- tion .
cambridg univers press .
lee , j. , k. cho , t. hofmann .
2016 .
fulli character-level neural machin translat without explicit segment .
corr , abs/1610.03017 .
luong , m.-t. c. d. man .
2015 .
stanford neural machin translat sys- tem spoken languag domain .
mandelbaum , a. a. shalev .
2016 .
word embed use sentenc clas- sific task .
corr , abs/1610.08229 .
mi , h. , b. sankaran , z. wang , a. it- tycheriah .
2016 .
coverag embed- ding model neural machin translat .
corr , abs/1605.03148 .
papineni , k. , s. rouko , t. ward , w.- j. zhu .
2002 .
bleu : method auto- matic evalu machin translat .
proceed 40th annual meet associ comput linguis- tic , page 311318 .
associ com- putat linguist .
sutskev , i. , o. vinyal , q. v. le .
2014 .
sequenc sequenc learn neural network .
advanc neural informa- tion process system , page 31043112 .
tu , z. , z. lu , y. liu , x. liu , h. li .
2016 .
coverage-bas neural machin transla- tion .
corr , abs/1601.04811 .
wu , y. , m. schuster , z. chen , q. v. le , m. norouzi , w. macherey , m. krikun , y. cao , q. gao , k. macherey , et al .
2016 .
googl  neural machin translat sys- tem : bridg gap human machin translat .
arxiv preprint arxiv:1609.08144 .
yang , z. , w. chen , f. wang , b. xu .
2016 .
character-awar encod neu- ral machin translat .
cole .
zhongjun , h. 2015 .
baidu translat : re- search product .
acl-ijcnlp 2015 , page 61 .
