automat speech recognit deep neural network impair speech cristina espana-bonet1,2 jose a. r. fonollosa1 1 talp research center , universitat politecnica de catalunya , barcelona , spain 2 universitat des saarland , saarbrucken , germani cristina @ cs.upc.edu , jose.fonollosa @ upc.edu abstract .
automat speech recognit reach almost human perform control scenario .
howev , recognit im- pair speech difficult task two main reason : data ( ) scarc ( ii ) heterogen .
work train differ architectur databas dysarthr speech .
comparison architectur show , even small databas , hybrid dnn-hmm model out- perform classic gmm-hmm accord word error rate measur .
dnn abl improv recognit word error rate 13 % sub- ject dysarthria respect best classic architectur .
improv higher one given deep neural network cnns , tdnns lstms .
experi done kaldi toolkit speech recognit adapt sever recip deal dysarthr speech work torgo databas .
recip public avail .
keyword : speech recognit , speaker adapt , deep learn , neu- ral network , dysarthria , kaldi 1 introduct automat speech recognit ( asr ) consist automat transcrib voic text .
easi task : one deal nois , differ among speaker spontan speech phenomena among other .
control scenario one minimis effect phenomena , asr approach exceed accuraci human sever benchmark [ 2 , 19 ] .
despit good perform recent propos end-to-end neural speech recogn [ 2 ] , hidden markov model ( hmm ) still backbon competit speech recognit system [ 19 ] .
hmms model speech signal sequenc state associ probabl distribut everi observ vector .
probabl repres use differ approach gaussian mixtur model ( gmm ) artifici neural network ( ann ) .
0 a. abad et al .
( ed .
) : iberspeech 2016 , lnai 10077 , pp .
111 , 2016 .
doi : 10.1007/978-3-319-49169-1 10 work , refer former system classic architectur latter one neural network architectur .
although infanc ann abl deal long time-sequ speech signal , hybrid system ann-hmm alreadi show state-of-the-art begin 90s [ 24 ] .
ann solv least two problem respect gmms [ 3 ] : ( ) assumpt shape statist distribut input featur requir ( ii ) train data use train state ( align state ) .
opposit , need larger comput capabl especi larg vocabulari .
current , due exist huge comput capabl , hybrid deep neural network architectur dnn-hmm abl improv signif- icant asr respect gmm-hmm system larg vocabulari task [ 21 , 4 , 8 ] .
increas number neuron hidden layer network improv word error rate ( wer ) recognit .
howev , spars data small data set amount paramet proper fit perform diminish [ 10 ] .
deal impair speech , one must face problem data sparsiti .
sinc gather data even difficult case , databas exist , one exist small .
besid , differ among speaker larger databas tend heterogen .
pose problem ann , also gmms sensit differ train test data .
, studi perform classic neural network ar- chitectur train small databas speaker dysanthria , torgo databas [ 9 ] .
discuss differ classic neural system , also suitabl use speaker adapt techniqu case .
system train use kaldi speech recognit toolkit [ 15 ] .
adapt sever recip order prepar data , ex- tract featur train systems3 .
remain paper organ follow .
first , section 2 describ databas use experi .
next , section 3 introduc main architectur asr specif techniqu resourc use .
sec- tion 4 make emphasi acoust model modul present differ recognit system evalu task .
final , discuss result draw conclus section 5 6 respect .
2 torgo databas server speech disord alter correct utter sound .
speaker dysarthria show difficulti articul phonem due lesion nervous system .
may caus chang voic qualiti , slow rate speech abnorm pitch rhythm .
3 recip public avail https : //github.com/cristinae/asrdi tabl 1 .
figur 15 speaker torgo databas rank accord degre disord speaker f01 m01 m02 m04 m05 f03 f04 m03 degre sever sever sever sever sev-mid mid mild mild # audio 228 739 772 659 610 1097 675 806 speaker fc01 fc02 fc03 mc01 mc02 mc03 mc04 degre none none none none none none none # audio 296 2183 1924 2141 1112 1661 1614 torgo databas [ 9 ] contain speech 15 subject , 6 femal 9 male .
total , databas contain 3 hour per speaker record speech , one third correspond impair speech .
four speaker se- vere dysanthria , one moderately-to-sever dysanthr one moder dysanthr .
two subject mild dysanthria remain 7 subject control speaker without disord .
tabl 1 describ 15 sub- ject includ number audio avail databas .
utter use , audio obtain head-mount microphon one obtain direct microphon .
use two microphon , 5586 utter speaker dysan- thria ( mean 698 per speaker ) 10931 utter control speaker ( mean 1562 ) .
utter singl word sentenc , mean word per utter 3.5 .
3 system  architectur system describ follow section share common main archi- tectur four modul : ( ) featur extract , ( ii ) acoust model , ( iii ) lan- guag model ( iv ) pronunci lexicon .
featur extract acoust model differ among system .
3.1 featur extract basic acoust featur use 13 mel-frequ cepstral coeffici ( mfccs ) .
featur generat 25 ms window shift 10 ms control speaker 15 ms dysanthr speech .
configur dysanthr speaker shown adequ ref .
[ 9 ] .
explain section 2 , disord make speaker talk slower widen shift consec- utiv frame help homogenis differ patient control speaker .
convolut neural network ( cnn ) , use 40 dimension fil- terbank featur order account correl signal , estim window interv .
besid , order obtain evolv speaker independ ( si ) featur , appli linear discrimin analysi transform ( lda ) project sequenc frame 40 dimens , afterward , maximum likelihood linear transform ( mllt ) diagonalis matrix gather cor- relat among vector [ 6 ] .
speaker depend featur ( sd ) , appli feature-spac maximum likelihood linear regress ( fmllr ) [ 16 ] .
case , also add 100-dimension ivector gather specif inform everi speaker environ [ 5 , 20 ] .
3.2 acoust model work use monophon model sever standard three-stat con- text depend triphon model differ featur use , train methodolog probabl associ hmm state calcu- late .
section 4 describ main characterist acoust model use .
3.3 languag model pronunci lexicon srilm toolkit [ 22 ] use build standard 3-gram languag model interpol kneser-ney discount train data transcript .
lexicon , choos carnegi mellon univers pronounc dictionary4 north american english .
contain 134,000 word pronunci arpabet phonem set 39 phonem .
4 acoust model two type model distinguish follow subsect : classic architectur gmm-hmm hybrid neural network architectur dnn-hmm .
4.1 classic architectur studi differ variat natur featur kind train use standard gmm-hmm architectur .
, list system analys work main characterist .
easi comparison , also show everi system parenthes nomenclatur use kaldi .
adapt kaldi  recip fit data , train 7 classic system 1800 hmm state total 9000 gaussian : mono monophon model mfcc featur ( mono ) tri basic triphon model featur mfcc++ ( tri2a ) tri-si triphon model speaker-independ transform appli mfcc+lda+mllt ( tri2b ) 4 http : //www.speech.cs.cmu.edu/cgi-bin/cmudict tri-sd triphon model speaker-depend transform ad mfcc+lda+mllt+fmllr ( tri3b ) tri-sddi triphon model tri-sd discrimin maximum mutual inform ( mmi ) feature-spac mmi train ( fmmi ) , tri-sd+mmi+fmmi .
use learn rate 0.001 ( tri3b fmmi ) sever discrimin train done fit hmm paramet .
done experi mmi train , boost mmi , minimum phone er- ror ( mpe ) , direct indirect feature-spac discrimin mmi train ( fmmi ) sever learn rate .
model tri-sddi best perform one dysarthr speaker , therefor , one includ analysi .
final , also consid subspac gaussian mixtur model [ 14 ] 8000 state 19000 substat : sgmm subspac gmm top sd featur mfcc+lda+mllt+fmllr ( sgmm2 4a ) sgmm2 subspac gmm addit speaker adapt transform fm- llr ( sgmm2 4a fmllr ) 4.2 neural network architectur hybrid system , ann train estim probabl hmm state .
differ network configur use purpos : dnnce deep neural network train align obtain mfcc+ +lda+mllt+fmllr featur use cross-entropi .
dnn 6 hidden layer , 1024 neuron 1800 output unit .
net initialis stack restrict boltzmann machin ( rbms ) ( dnn4b pretrain-dbn dnn ) dnnsmbr introduc sequenc discrimin train minimis error state label sentenc .
depart dnnce , 6 itera- tion state-level minimum bay risk ( smbr ) appli ( dnn4b pretrain- dbn dnn smbr ) notic sever kind sequence-discrimin train use .
refer [ 25 ] present experi mmi , mpe , smbr boost mmi .
although train set larger ( 300h 110h ) small differ found among object function , slight better smbr , one use follow section .
cnnba cnn convolut along frequenc axi .
use 40-dim filter- bank featur , two convolut layer learn rate 0.008 ( cnn4c ) cnnsmbr dnnsmbr built top cnnba .
first , cnn train build rbms top , train 6-layer dnn cross-entropi af- terward 6 iter discrimin train ( cnn4c pretrain-dbn dnn smbr ) final , select two kind neural network especi devot deal time sequenc : time delay neural network recurr neural network .
tabl 2 .
wer score 8 speaker dysarthria set select system .
f01 m01 m02 m04 m05 f03 f04 m03 mono 70.86 80.10 76.55 88.62 77.71 57.02 29.10 43.32 tr1 70.68 91.18 81.09 88.62 84.59 41.80 18.62 26.01 tri-si 76.80 79.12 83.67 88.68 96.71 53.08 18.97 32.59 tri-sd 47.30 78.91 68.49 81.16 97.16 42.88 13.29 17.06 tri-sddi 45.68 74.74 66.49 79.29 70.46 39.87 12.82 11.57 sgmm 43.71 77.83 64.01 71.46 98.43 37.26 11.42 10.19 sgmm2 43.53 78.37 63.33 71.34 97.31 37.22 11.24 9.74 dnnce 39.57 62.20 42.89 69.05 62.60 39.30 13.06 17.71 dnnsmbr 35.61 62.30 47.95 69.30 62.53 37.01 10.95 12.76 cnnba 53.24 66.04 77.66 83.62 65.67 46.78 15.81 37.88 cnnsmbr 53.06 66.74 50.47 81.40 65.74 33.89 11.24 10.44 tdnn 66.19 69.50 62.28 73.51 88.18 47.46 14.34 28.04 tdnniv 94.96 95.62 84.14 92.59 93.94 91.98 39.29 70.97 lstm 59.71 71.61 67.33 72.97 84.73 48.28 12.00 27.50 lstmiv 71.04 75.01 76.13 77.30 72.85 69.33 19.61 32.20 tdnn multi-splic time delay neural network train align ob- tain mfcc+lda+mllt+fmllr featur .
use high-resolut mfcc featur .
network 3 hidden layer p-norm input dimen- sion 2000 output dimens 250 .
learn rate evolv 0.01 0.007 ( nnet tdnn noivec ) tdnniv characterist previous network add 100-dim ivector 40-dim high-resolut mfcc input featur speaker adapt ( nnet tdnn ) lstm long-term short-term memori network 3 hidden layer 1024 neuron .
network train 10 epoch learn rate evolv 0.0012 0.00036 , momentum 0.5 ( lstm noivec ) lstmiv characterist previous network add 100-dim ivector 40-dim mfcc input ( lstm ivec ) 5 result discuss use 14 speaker train paramet acoust model test system 15th .
, train , distinct speaker without dysarthria besid differ shift frame defi- nition extract featur .
sinc data especi dysarthr speaker , train done impair speech improv re- sult .
similar , languag model use test estim 14 speaker , includ addit corpora differ domain train languag model improv result either .
cross-valid neu- ral network train , alway use data come speaker mild tabl 3 .
wer score 7 control speaker .
fc01 fc02 fc03 mc01 mc02 mc03 mc04 mono 22.40 30.27 29.88 39.52 42.99 33.59 51.19 tr1 13.06 24.06 23.38 36.73 30.66 30.10 42.07 tri-si 13.20 24.73 26.30 38.30 32.98 33.28 42.48 tri-sd 8.01 21.96 16.71 16.96 19.46 27.47 36.27 tri-sddi 7.42 21.72 15.43 17.49 18.23 26.51 37.40 sgmm 7.86 20.87 13.57 15.12 16.16 24.89 28.82 sgmm2 7.57 20.93 13.55 14.90 16.12 24.96 28.38 dnnce 6.53 19.62 11.01 15.32 14.72 22.11 27.06 dnnsmbr 6.38 19.24 10.41 12.03 13.38 20.37 23.76 cnnba 15.58 22.38 14.63 25.01 38.25 33.25 44.66 cnnsmbr 9.64 18.28 12.35 11.65 15.91 23.79 38.16 tdnn 10.98 18.97 12.90 35.67 58.69 32.90 31.90 tdnniv 16.32 24.51 21.48 51.31 62.00 49.92 62.99 lstm 8.46 19.30 13.21 24.06 41.80 25.53 21.78 lstmiv 6.38 19.93 13.91 21.47 37.20 27.25 29.92 dysarthria regardless natur test speaker we use subject f03 , f04 case test subject f03 .
tabl 2 show result speaker dysarthria .
measur qual- iti system mean wer .
notic sever dysarthr speaker , triphon model abl improv monophon model .
fact , speaker , signific improv wer score appear speaker depend transform appli .
happen control speaker ( tabl 3 ) case base triphon system alway better monophon system .
general , intrins differ among 15 speaker make necessari speaker adapt techniqu .
subspac gaussian mixtur model best perform classic model .
case recognit extrem difficult ( m01 m05 ) tri-sddi system outperform sgmm famili .
remark hard task : wherea mean error rate control speaker 18 % , mean six patient sever diseas reach 65 % .
patient mild patholog wer lower equival control speaker .
best perform network result dnn train gmm-hmm align .
dnn-hmm system show lowest wer 11 15 test speaker , 6 8 speaker dysarthria .
consid neural network architectur compar classic one , figur increas 14 15 7 8 respect .
subject sever diseas , differ dnn train minimis cross-entropi ( dnnce ) includ subsequ sequenc discrimin train ( dnnsmbr ) , mean error rate vari 52.6 52.5 .
control speaker , wer diminish 16.6 15.1 ad discrimin train .
sever work report improv use cnns , tdnns lstms respect dnns , especi larg vocabulari [ 17 , 1 , 13 , 18 , 7 , 11 ] .
find behaviour task .
reason twofold : torgo databas small data heterogen .
comparison small databas , author ref .
[ 13 ] train tdnn resourc manag databas , 3 hour record speech .
studi , standard dnn perform slight better , although larger amount data tdnn got better result .
hand , cnns outperfom dnns 50-hour english broadcast news task [ 17 ] 18-hour microsoft-intern voic search task [ 1 ] .
neural network architectur present appli speaker adapt , least fmllr featur seed classic model and/or train network .
tdnns lstms , also studi consequ includ ivector .
although studi larger databas inclus ivector improv baselin without [ 12 , 23 ] , task clear damag perform .
tdnns system ivector tdnniv increment wer 24 point dysarthr speaker 12 point control speaker .
result negat lstms still prefer base lstm : dysarthr speaker inclus ivector caus increment 6 point wer control speaker system even .
work one devot build asr dysarthr speak- er .
creator torgo databas train asr ref .
[ 9 ] .
analysi , , simpl triphon model abl improv signific monophon model .
, instead experi new architectur built triphon model , approach base adapt speaker acoust mod- el incorpor specif lexicon speaker .
lexicon includ pro- nunciat sever word follow guidelin pronunci detect patient dysarthria .
adapt acoust model dysarthr speaker , author report relat improv wer 23 % av- erag 6 speaker sever dysarthria 3 % addit lexicon .
creation lexicon difficult general automat sinc de- pend analysi error commit new speaker .
within approach , hope deep neural network learn behaviour speaker similar problem .
speaker adapt model tri-sd sgmm2 similar [ 9 ] .
still , 6 speaker , get minor improv adapt : sgmm2 model achiev improv wer 10 % respect baselin , much smaller 23 % .
differ given main subject m05 , best model [ 9 ] reach 15 % wer , model surpass 70 % wer speaker .
differ explain differ data .
best architectur neural network , dnnsmbr , achiev 23 % improv wer compar baselin , similar ref .
[ 9 ] without build resourc manual .
6 conclus recognis dysarthr speech difficult task .
train asr speaker without dysarthria use torgo databas , databas dysarthr articul .
three hour record speech per 15 subject , moder word error rate score obtain even control speaker .
mean wer 15 % obtain case , rise 52 % six test patient sever dysarthria .
hybrid dnn-hmm system best perform .
dnns out- perfom best classic system 14 15 test speaker : wer score improv 3 % control speaker 13 % subject dysarthria respect best classic architectur , subspac gmm model ad- dition speaker adapt transform fmllr .
classic neural architectur , speaker adapt techniqu import improv recognit .
classic system , fmllr transform make qualit leap respect speaker independ transform mllt .
neural network use tri-sd model train .
howev , task , ivector carac- teris speaker environ negat impact qualiti final system .
current result obtain use databas combin impair normal speech .
remain seen whether includ addit data normal speech abl improv recognit .
acknowledg work support spanish ministerio de economa competi- tividad european region develop fund , contract innpacto ipt-2012-0914-300000 tec2015-69266-p ( mineco/fed , ue ) .
refer 1 .
abdel-hamid , o. , deng , l. , yu , d. : explor convolut neural network struc- ture optim techniqu speech recognit .
: interspeech 2013 , lyon , franc , august 25-29 , 2013. pp .
33663370 ( 2013 ) 2 .
amodei , d. , anubhai , r. , battenberg , e. , case , c. , casper , j. , catanzaro , b.c. , chen , j. , chrzanowski , m. , coat , a. , diamo , g. , elsen , e. , engel , j. , fan , l. , fougner , c. , han , t. , hannun , a.y. , jun , b. , legresley , p. , lin , l. , narang , s. , ng , a.y. , ozair , s. , prenger , r. , raiman , j. , satheesh , s. , seetapun , d. , sengupta , s. , wang , y. , wang , z. , wang , c. , xiao , b. , yogatama , d. , zhan , j. , zhu , z. : deep speech 2 : end-to-end speech recognit english mandarin .
corr abs/1512.02595 ( 2015 ) 3 .
bourlard , h.a. , morgan , n. : connectionist speech recognit : hybrid ap- proach .
kluwer academ publish , norwel , , usa ( 1993 ) 4 .
dahl , g. , yu , d. , deng , l. , acero , a. : context-depend pre-train deep neural network larg vocabulari speech recognit .
ieee transact audio , speech , languag process 20 ( 1 ) , 3042 ( januari 2012 ) 5 .
dehak , n. , dehak , r. , kenni , p. , brummer , n. , ouellet , p. , dumouchel , p. : sup- port vector machin versus fast score low-dimension total variabl space speaker verif .
: interspeech 2009 , 10th annual confer intern speech communic associ , brighton , unit kingdom , septemb 6-10 , 2009. pp .
15591562 ( 2009 ) 6 .
gopinath , r.a. : maximum likelihood model gaussian distribut classif .
: proceed 1998 ieee intern confer acous- tic , speech signal process , icassp  98 , seattl , washington , usa , may 12-15 , 1998. pp .
661664 ( 1998 ) 7 .
li , x. , wu , x. : construct long short-term memori base deep recurr neural network larg vocabulari speech recognit .
: 2015 ieee intern con- ferenc acoust , speech signal process , icassp 2015 , south brisban , queensland , australia , april 19-24 , 2015. pp .
45204524 ( 2015 ) 8 .
maa , a.l. , hannun , a.y. , lengerich , c.t. , qi , p. , jurafski , d. , ng , a.i .
: increas- ing deep neural network acoust model size larg vocabulari continu speech recognit .
corr abs/1406.7806 ( 2014 ) 9 .
mengistu , k.t. , rudzicz , f. : adapt acoust lexic model dysarthr speech .
: proceed ieee intern confer acoust , speech , signal process ( icassp11 ) .
pp .
49244927 .
ieee ( 2011 ) 10 .
miao , y. , metz , f. : improv low-resourc cd-dnn-hmm use dropout multilingu dnn train .
: bimbot , f. , cerisara , c. , fougeron , c. , gravier , g. , lamel , l. , pellegrino , f. , perrier ( ed . )
interspeech .
pp .
22372241 .
isca ( 2013 ) 11 .
miao , y. , metz , f. : speaker adapt long short-term memori recurr neural network .
: interspeech 2015 , 16th annual confer inter- nation speech communic associ , dresden , germani , septemb 6-10 , 2015. pp .
11011105 ( 2015 ) 12 .
peddinti , v. , chen , g. , povey , d. , khudanpur , s. : reverber robust acoust model use i-vector time delay neural network .
: interspeech 2015 , dresden , germani , septemb 6-10 , 2015. pp .
24402444 ( 2015 ) 13 .
peddinti , v. , povey , d. , khudanpur , s. : time delay neural network architectur effici model long tempor context .
: interspeech 2015 , dresden , germani , septemb 6-10 , 2015. pp .
32143218 ( 2015 ) 14 .
povey , d. , burget , l. , agarw , m. , akyazi , p. , kai , f. , ghoshal , a. , glembek , o. , goel , n. , karafiat , m. , rastrow , a. , rose , r.c. , schwarz , p. , thoma , s. : subspac gaussian mixtur model-a structur model speech recognit .
comput .
speech lang .
25 ( 2 ) , 404439 ( apr 2011 ) 15 .
povey , d. , ghoshal , a. , bouliann , g. , goel , n. , hannemann , m. , qian , y. , schwarz , p. , stemmer , g. : kaldi speech recognit toolkit .
: ieee 2011 workshop automat speech recognit understand .
ieee signal pro- cess societi ( 2011 ) 16 .
povey , d. , saon , g. : featur model space speaker adapt full covari- anc gaussian .
: interspeech 2006 - icslp , ninth intern confer spoken languag process , pittsburgh , pa , usa , septemb 17-21 , 2006 .
isca ( 2006 ) 17 .
sainath , t.n. , moham , a. , kingsburi , b. , ramabhadran , b. : deep convolu- tional neural network lvcsr .
: ieee intern confer acous- tic , speech signal process , icassp 2013 , vancouv , bc , canada , may 26-31 , 2013. pp .
86148618 ( 2013 ) 18 .
sak , h. , senior , a.w. , beaufay , f. : long short-term memori recurr neural network architectur larg scale acoust model .
: interspeech 2014 , sin- gapor , septemb 14-18 , 2014. pp .
338342 ( 2014 ) 19 .
saon , g. , sercu , t. , renni , s.j. , kuo , h.j .
: ibm 2016 english convers telephon speech recognit system .
corr abs/1604.08242 ( 2016 ) 20 .
saon , g. , soltau , h. , nahamoo , d. , picheni , m. : speaker adapt neural network acoust model use i-vector .
: asru .
pp .
5559 .
ieee ( 2013 ) 21 .
seid , f. , li , g. , yu , d. : convers speech transcript use context- depend deep neural network .
: interspeech 2011 , 12th annual confer intern speech communic associ , florenc , itali , august 27-31 , 2011. pp .
437440 ( 2011 ) 22 .
stolck , a. : srilm - extens languag model toolkit .
: proceed- ing seventh intern confer spoken languag process ( ic- slp2002 ) .
pp .
901904 .
denver , colorado , usa ( 2002 ) 23 .
tan , t. , qian , y. , yu , d. , kundu , s. , lu , l. , sim , k.c. , xiao , x. , zhang , y. : speaker-awar train lstm-rnns acoust model .
: 2016 ieee intern confer acoust , speech signal process , icassp 2016 , shanghai , china , march 20-25 , 2016. pp .
52805284 ( 2016 ) 24 .
trentin , e. , gori , m. : survey hybrid ann/hmm model automat speech recognit .
neurocomput 37 ( 14 ) , 91126 ( 2001 ) 25 .
vese , k. , ghoshal , a. , burget , l. , povey , d. : sequence-discrimin train deep neural network .
: interspeech 2013 , lyon , franc , august 25-29 , 2013. pp .
23452349 ( 2013 )
