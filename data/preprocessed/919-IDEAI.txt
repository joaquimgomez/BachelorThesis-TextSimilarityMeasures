intellig servic robot manuscript no. (will insert editor) closed-loop approach track humanoid robot particl filter depth data *pablo a. martnez *xiao lin mario castelan josep casa gustavo arechavaleta received: date / accepted: date abstract humanoid robot introduc instabl bipe march complic process estim posit orient time. track humanoid ro- bot us typic applic navigation, task requir benchmark mul- tipl process involv regist measur perform humanoid walking. small robot repres addit challeng size me- chanic limit gener unstabl swing walking. paper present strategi activ local humanoid robot environ monitor extern devices. problem face particl filter method depth imag captur rgb-d sensor order effect track posit orient robot march. track stage coupl locomot control step- ping robot given orient target. present integr commun framework track *the author contribut equally. p.-a. martnez(b) m. castelan g. arechavaleta robot advanc manufactur group, centro investigacion y estudio avanzado del ipn, saltillo, coahuila, 25900, mexico. e-mail: m. castelan e-mail: g. arechavaleta e-mail: xiao lin josep casa imag process group, depart signal theori communications, universitat politecnica catalunya, barcelona, 08034, spain. e-mail: josep casa e-mail: locomot control robot base robot oper (ros), capabl achiev real time locomot task nao humanoid robot. keyword humanoid robot track rgb-d sensor particl filter ro 1 introduct local classic studi problem ro- botics. wide rang sensor devic methodolog face problem order accur estim robot pose. local robot crucial step applic robot interact environment, i.e. task navigation, grasp obstacl avoidance. challeng instanc prob- lem humanoid robot local displac gener by-product complex kinemat structur make contact ground surface. well-known locomot behavior impli inaccur odome- try estim import drift short distances. sense, necessari close pose estim mo- tion execut loop incorpor estim process control scheme. moreover, humanoid robot design perform human-lik tasks, bipe locomot human in- teract man-mad environments. regard, robot predict behavior human per- form self-localization. predict human mo- tion intent major axi research ro- botic neurosci communities. particular prob- lem goal-direct locomot human consist studi underli motion pattern shape human trajectori recovered. [3], databas hu- man walk trajectori studi and, result, control model human locomot suggest base optim 2 pablo a. martnez et al. control tools. also, invers optim control formula- tion introduc [32] [30]. [4], sta- tistic model human walk reported. common concern work predict human walk- ing path accord spatial goal plane term posit orient coordinates. requir estim humanoid robot posi- tion orient arriv meet point pre- cise bodi orientation. exist work human- humanoid interact point import social accept robot motion [37]. sense, robot orien- tation meet point maxim safeti vis- ibil criteria. object improv human comfort posit robot human field view. context, robot consid servic assistant, autonom machine. thus, social rule proto- col consid robot move [38]. commonly, intellig room equip sensor perceiv move agents, e.g. human ro- bots. work, advantag percept ca- pabil avail scenario cope hu- manoid local problem. particularly, explor idea extern rgb-d sensor, estim po- sition orient walk humanoid robot per- form locomot tasks. sensor cheap pop- ular incorpor close space rela- tive easi manner. focu studi provid robot local capabilities, coupl strategi requir effici accur hu- manoid track tool. worth mention track humanoid trivial task, state art invest effort landmark robot scenario, gather previou knowledg world 3d map constrain motion robot upper articulations, problem local mainli caus robot walking. consid accuraci level centimet achiev task perform reduc space. motiv reasons, paper us rgb- d sensor estim posit orient hu- manoid robot. sensor locat ceil top-down field view. estim process base particl filter natur coupl humanoid loco- motion control accur reach meet point given predefin posit orient plane. main contribut articl are: depth-bas tracker abl accur follow locomot behavior humanoid robot. control scheme consid reach target posi- tion orient updat linear angular veloc accord current local humanoid robot. ro commun framework link depth tracker humanoid locomotion. paper organ follows: section 2 present review relat work; section 3 describ prob- lem track local humanoid robot depth data rgb-d sensor particl filter imple- mentat face problem; section 4 describ control scheme incorpor estim robot pose activ local approach develop ro integra- tion framework; experiment result provid section 5; final conclud remark futur work present section 6. 2 relat work section divid parts. present work relat humanoid robot localization, emphas applic intern extern sensor track locomot robot. second describ relev work relat track human context smart rooms. 2.1 humanoid robot local walk process leg humanoid robot gener produc noisi motion effect bipe loco- motion. example, situat joint backlash foot slip floor gener inaccur execut motion tasks. consequence, import robot local environment. order face problem, visual sensor main sourc input data track systems. track mo- tion robot, sensor mount insid hu- manoid. reason us built-in camera rang sensor weight constraint relat limit pay- load humanoid robot. alternatively, sensor adapt humanoid extern sourc order extend sens capabl integr system needed. 2.1.1 built-in sensor problem estim humanoid robot pose vi- sual data face appli differ approaches. extend kalman filter (ekf), allow integr multipl sensors. [40] ekf pro- pose data propriocept sensor walk- ing pattern gener fuse vision or- der obtain robot motion estimation. method successfulli appli human-s hrp-2 robot slam methodolog abl build map spars 3d closed-loop approach track humanoid robot particl filter depth data 3 point local robot indoor environ [9]. ekf methodolog test small- size humanoid robot. example, [29], ekf predic- tion step perform relat torso joint veloci- ti nao robot differenti kinematics. end, visual data process parallel track map (ptam) approach [19] emul 3d visual sensor. ekf correct step [29] consid fuse provid camera pose data iner- tial unit measur mount chest robot. recently, novel visual-bas local approach bundl adjust [42] hrp-2 humanoid robot present [2]. later, monocular local framework [1] propos predict visibl 3d point previous built spars 3d map stereo visual slam. common featur approach includ inform local robot order perform locomot tasks, i.e., instantan posit orient robot consid control modul reach specif goal. filter-bas approach allow integr multipl sensors, visual inform (features, cues, etc.) core method accur odometri required. sense, filter base approach reli ro- bust visual-bas local order maintain success track humanoid robot. currently, ptam prove reliabl visual-bas lo- caliz cue available. integr activ local method con- trol locomot humanoid robot [21,22]. thereby, possibl guid trajectori robot surround- ing object order estim geometri monocular video sequenc acquir robot walk [22]. furthermore, method control march robot direct favor visual base local present [21]. here, set sta- tistic criteria analysi 3d map reproject 2d point target robot direc- tion rich visual information. unfortunately, ptam work accurately, requir initi step sensit physic distanc imag captur monocular camera. monte-carlo techniqu test nao platform fuse data laser scanner, iner- tial measur unit joint encod order esti- mate robot pose [18]. approach later im- prove includ new observ model base visual data monocular camera [28]. depth sensor considered, instance, [20] rgb-d sensor mount head humanoid robot order solv 6d torso pose. here, observ model abl integr depth data. propos ap- proach test extens real-world environment, includ climb stairs, monocular-bas observ model appli order increas localiza- tion accuracy. work inspir octre repre- sentat [43], allow success construct dynam map real-tim collision-fre path plan tasks. however, requir accur initi static world and, consequence, previou process dens 3d scan model navig space be- come essential. recent filter modal successfulli in- tegrat depth data reduc drift humanoid local process [11] enlarg region robot abl local [6]. techniqu focus object-cent local obstacl avoidance. example, [5], laser scanner mount hip robot order construct height map represent environment. represent provid grid help fit plane identifi obstacl height infor- mation contain cell grid. also, [24], gpu implement model-bas approach propos track 6d pose object order local cam- era mount head hrp-2 robot. end, dimens object need known order successfulli local robot perform requir tasks. 2.1.2 extern sensor navig extern sensor track small size humanoid robot pose present [15]. here, 3d featur virtual visual servo (vvs) [8] suc- cessfulli integrated. rgb-d sensor exter- nal devic depth featur combin imag featur render cad model robot. pose estim process base differ render real imag features. approach appli varieti robot platforms, method struggl accur estim posit orient robot rang outsid 10 cm 10 re- spectively. [25], calibr arrang retro-reflect marker place head hrp-2 robot or- der facilit problem multi-camera tracking. aim approach continu solv ex- trinsic paramet camera robot order gener reconstruct environment. recon- struction divid floor obstacles. plane floor increment updat walk robot obstacl segment base color. path planner oper level foot- step autonom navig task. later, retro-reflect marker incorpor track- ing object scene. method name naviga- 4 pablo a. martnez et al. tion movabl obstacl (namo) [41]. app- roach provid accur methodolog recov pose robot real time cost carefulli calibrat- ing retro-reflect landmark robot scene. 2.2 track human smart room visual-bas human track state process de- tect track human bodi sequenc im- ages. process challeng larg variat human appear motion, chang camera viewpoints. estim bodi pose time considered, problem scale track human motion analysis. taxonomi human motion present [31], main approach introduced: model-bas model-free. model base approach us predefin human bodi model pose estim [35]. here, pro- cess consist model (construct likelihood func- tion) estim (find like pose given likelihood surface). second approach establish di- rect relat imag observ pose, priori human bodi model available. human motion analysi consid spe- cific applic real time object tracking. [45] suit- abl categor track method present describ step build object tracker. visual human track approach classifi categori accord differ type data used: color, depth fusion both. color base track method commonli follow framework. foreground appear model color textur information, foreground model match success frame order correspon- denc them. example, [7] object localiza- tion formul gradient optim problem color histogram regular spatial mask isotrop kernel, [27] adapt color-bas parti- cle filter used. model reliabl situat like sudden illumin chang unex- pect occlusions, usual happen real time track- ing. advantag rgb-d consum depth sensor microsoft kinect asu xtion provid afford wai acquir depth inform good resolut low cost. foster present depth depth color-bas real time track method years. intuit wai exploit depth inform perform track directli depth images, take ad- vantag shape cue given depth value. example, histogram orient depth (hod) success- fulli appli human track [39], perform his- togram orient gradient (hog)-lik method depth data. hod local encod direct depth chang shape featur make model robust illumi- nation issues. background model approach depth data available. hansen et al. [16] propos build background model joint distri- bution depth intens information, accommo- date chang domains. then, cluster pixel sig- nificantli differ background model track expect maxim (em) algorithm. [44], depth data human tracking. here, mean chamfer distance, binari head-shap templat match edg map extract depth array. head located, bodi contour extract separ background track achiev motion person. wai deal depth data reconstruct 3d scene perform track 3d. work scope usual focu complic problem skeleton track [12,13]. advantag 3d track data measur real world met- rics, facilit paramet set track systems. unfortunately, higher complex deal 3d data, method requir gpu implemen- tation order run real time. track human depth sensor bird-ey view present [34] [26]. approach pre- sent [34] reli background model foreground/background segmentation, base featur descriptor maxim detect discrimi- nativ train head-should classifier. moreover, ap- proach propos [26] us particl filter implement depth data human tracking. main applic analyz behavior costum (the human walking) bui activ shelves, simul instal depth sensor ceil supermarket. therefore, propos model con- sider upper bodi (head, shoulder arms) separ two: 2d model, repres head shoulders, estim person local 3d model determin arm motion fit geometr primit (cylind arm fore- arms, ellipt cylind torso rectangular plane hands). 3 rgb-d tracking-loc command humanoid robot reach target point lead inaccuracies. usual occur fact control know possibl drift actual step robot. order address prob- lem, propos scheme robot navig closed-loop approach track humanoid robot particl filter depth data 5 fig. 1: exampl appli propos rgb-d tracking- local approach. point cloud extract robot model project point xy-plan ellips fitting. extern depth sensor obtain data track it. rgb-d sensor provid depth map real world dis- tanc visibl humanoid surfac sensor pixel image, make possibl par- tialli reconstruct 3d point cloud scene, en- rich inform exploit track- ing process. benefici estim orientation, sharper object boundari provid depth map comparison color images. main task tracker estim posit orient robot analyz point cloud frame, publish real time commu- nicat [33], control subscrib information, adjust movement robot accord- ingli reach target higher accuracy. 3.1 particl filter implement track method paper base particl filtering. zenith rgb-d sensor captur depth data track robot view scene. section, propos robot track de- scribed. initi posit orient provid user help graphic interfac choos data current rgb imag ob- serv scenario. therefore, particl filter manual ini- tializ origin posit orient robot. then, tracker run particl filter process or- der estim posit robot. posit obtained, region robot separ background estim posit depth image. finally, orient estim base ex- tract region ellips fit shown figur 1. 3.1.1 posit like particl filter algorithms, recurs approx- imat posterior probabl densiti function p(xt |yt) current state model xt evalu likelihood z th s h o ld x y z fig. 2: robot model. robot model design combi- nation cuboid cylinder. observ yt accord set weight parti- cle { xit ,w t } . xit stand sampl point state space i-th particl time t wit associ weight. particl repres random sampl propag prior probabl densiti ap- proxim time t 1 dynam model. process basic consist steps. resampling: n particl { xit ,w t } p(xt |yt) iter time t resampl base resam- pling strategi order sure resampl par- ticl { xit ,1/n } distribut reason way. resampl strategi method sampl import resampl [14] (sir), mean particl select accord weight. parti- cle larg weight duplicated, low weight particl probabl delet keep total number particl unchanged. propagation: resampl particl propag gener new set particl { xit+1,w t+1 } p(xt+1|yt) base dynam model p(xt+1|xt), describ chang time. method, gaussian function used. weighting: order approxim true posterior distribut discret particles, need weight likelihood function repres correspond model new obser- vation. weight normal sum equal 1. approach, defin ob- servat number point it, count t degre rotat robot model center posit particl 3d space, t esti- mate orient iteration. robot model design combin cuboid cylind figur 2. figur 1 show point cloud robot captur view, head, hand shoulder visibl parts. geometr model (figur 2) em- ploi match point cloud shape 3d space. therefore, observation, point 6 pablo a. martnez et al. z-coordin higher z-threshold fit cylind model, repres point cloud robot head. point z- coordin lower z-threshold fit cuboid area, repres point cloud shoulder hands. weight observ comput count number point cor- rectli fit geometr model. model robot give cue shape robot, make robust perspect chang robot moves. likelihood function defin equat (1), yt denot observ qi proba- biliti mass associ i-th particl qi = p(yt |xit ) n i=1 p(yt |x t ) , (1) weight particl equal likelihood: wit+1 = q (2) estimation: estim result obtain perform weight averag particles{ xit+1,w t+1 } p(xt+1|yt+1): xt+1 = n i=1 wit+1 x t+1 (3) 3.1.2 orient orient robot design estim sep- arat previou step purpos reduc dimens state space increas compu- tation speed track system. speed chang orient small estim directli target region extract ellips fit process strongli affect overal track accuracy. weight summat locat parti- cle show estim posit xt+1 obtain previ- ou step. larger window compar observ window (the geometr model) locat estima- tion process chosen extract point cloud robot center estim position. extract point cloud project xy-plane, roughli repres shape robot view. princip compon analysi (pca) emploi estim direct largest data variat project 2d points. direct treat major axi ellips minor axi ellips perpendicular major axi indic estim orientation. besides, assum orient robot chang continu time mean estim orient t time t data: local xre fcom current time k, orient fc current time k, target posit xt , target orient t . result: refer linear veloc xre fcom time k+1, refer angular veloc fc time k+1. xre fcom outsid stop region xre fcom =x(x f comxt) f c = ( f c t) appli wpg given (xre fcom , f c ) gener locomot invers kinemat end algorithm 1: robot perform locomot task reach target posit orientation. interv [t1h,t1 +h] h repres threshold maxim orient chang time slot. worth mention fit ellips ex- plore track posit head walk hu- man multipl sensor environment, camera laser rang finder combined. work, present [23] benefit particl filter track motion humans. far filter kalman concerned, linear gaussian noise, kalman filter op- timal. nonlinear, kalman filter state estimation, particl filter better result price addit comput effort. non-gaussian noise, kalman filter optim linear filter, particl filter perform better [36]. situation, nois track process non-gaussian, mainli come biped walking, reason follow par- ticl filter framework standard kalman filter. 4 locomot control local robot comput rgb-d tracker, task reach target posit specif orient formul locomot framework. task, propos locomot control direct posit orient robot lie path minim distanc current local given target term posit orientation. let xre fcom = [xw,yw] t refer posit center mass (com) xy-plan fc orien- tation angle, provid tracker describ sec- tion 3. current state robot defin pair (xre fcom, f c ) given target state defin (xt ,t). refer linear veloc com, xre fcom com- pute consid proport control base dis- tanc current estim robot com po- closed-loop approach track humanoid robot particl filter depth data 7 local , target , locomotiontrack fig. 3: ro framework. follow ro program paradigm, tracker locomot control code node (elipses) common topic share local target (rectangles). sition comput target position. likewise, refer angular velocity, fc , differ current target orient used. therefore, error ex = x f comxt e = f c t regul impos exponenti converg ex =xex e = e , x constant proport gains. pro- cedur perform robot reach end trajectori formal describ algorithm 1. input walk pattern gener (wpg) given xre fcom output consid dynam sta- ble trajectori com, posit foot contact footstep placement. wpg solv quadrat program predefin time horizon propos [17]. case, refer orient fc express inequ constraint defin admis- sibl region place footstep. comput joint trajectori robot wpg outcom base real-tim invers kinemat method suggest [10]. 4.1 ro integr framework order provid integr experiment framework, previous explain tracker locomot approach integr robot oper [33]. platform conveni commun differ system required. case, rgb-d cam- era serv main sensor tracker system, physic actuat humanoid robot directli af- fect locomot control system. ro platform fig. 4: ground truth marking. point label color imag black point p1(x1,y1) repres posi- tion robot, vector p3-p2 stand orient image. thought program tool help in- tegrat sensor actuat work separ re- quir commun protocol interact function in- tegrally. achiev requir communication, ro orga- nize protocol us nodes, messag topics. figur 3 depict messag strategi design com- munic tracker locomot system ex- periment application. figure, tracker loco- motion system shown elips repres nodes. purpos node carri main process system, i.e. tracker node estim posit orient robot current time locomot node determin immedi linear angular veloc need appli control robot order closer target state. far topic concerned, depict rectangl refer lo- caliz target topics. function topic regard receiv messag publish differ node system. local topic receiv current state robot publish tracker node target topic receiv target local current task. note how, target state remain fix singl experiment, tracker node publish valu manual select graphic inter- face application. finally, arrow appear figur 3 repres messag pass node topics. regard, worth mention tracker node aim publish messag local target topics, locomot node subscrib topics, i.e. read messag publish topic tracker node. 8 pablo a. martnez et al. 2.6 2.8 3 3.2 3.4 1.6 1.7 1.8 1.9 2 2.1 2.2 2.3 2.4 rout 1 (depth based) 3 4 1 5 2 2.6 2.8 3 3.2 3.4 3.6 1.7 1.8 1.9 2 2.1 2.2 2.3 2.4 2.5 2.6 rout 2 (depth based) 3 4 1 5 2 2 2.2 2.4 2.6 2.8 3 3.2 2 2.2 2.4 2.6 2.8 rout 3 (depth based) 3 4 1 5 2 2.6 2.8 3 3.2 3.4 1.6 1.7 1.8 1.9 2 2.1 2.2 2.3 2.4 rout 1 (color based) 3 4 1 5 2 2.6 2.8 3 3.2 3.4 3.6 1.7 1.8 1.9 2 2.1 2.2 2.3 2.4 2.5 2.6 rout 2 (color based) 1 23 4 5 2 2.2 2.4 2.6 2.8 3 3.2 2 2.2 2.4 2.6 2.8 rout 3 (color based) 3 4 1 5 2 fig. 5: track results. rout shown column-wise. rout perform twice, consid depth (top) color (bottom) information. ground truth appear black line track trajectori appear gray. number diagram indic locat robot visit, start locat 1 stop locat 5. control consid experiment, robot reach desir place accuracy. 5 result section present experiment evalu ap- proach appli navig task perform humanoid robot. experi relat track motion humanoid robot, i.e., close loop consid here. main idea underli ex- periment assess perform particl filter depth color chosen drive filter. princip conclus experi depth inform greatli outperform color. reason, second experi includ evalu propos control scheme consid depth-bas particl fil- ter. 5.1 record ground-truth label ground truth posit orient robot trajectori purpos quantita- tive verif accuraci tracker navi- gation system. experi perform real time, color depth imag mark ground truth captur specif number frame track process, order avoid potenti interfer realtim track control system. specifically, figur 4 shows, point label color imag black point p1(x1,y1) repres po- sition robot, vector p3-p2 stand orien- tation image. point label color images, depth valu obtain correspond depth image. data transform world coordi- nate accord camera calibr parameters, re- sult actual posit orient robot world refer frame. note that, experi minim separ frame video sequenc keep mark task manageable. respect second experi minim separ frame used. track control approxim respons publish messag (local- ization) second. also, imag record process take time affect rate, reason imag saved. 5.2 experi 1: track aim experi explor benefit us- ing depth inform color inform particl filter. end, compar similar rout robot command visit differ locations. note close loop consid experiment, correct error-to-target observ dur- ing march robot. figur 5 present graphic result tracking, ground truth depict black result track trajectori shown light gray. visual inspect figur reveal closed-loop approach track humanoid robot particl filter depth data 9 0 0.05 0.1 0.15 0.2 p os iti e rr (m et er s) 1 2 3 4 5 6 depth color rout 1 rout 3 rout 3 rout 2 rout 1 rout 2 fig. 6: posit error. figur show error posit rout experi 1. note depth inform significantli outperform color information. depth inform suitabl success par- ticl filter tracking. explan gener particl color-bas tracker weight compar color histogram observ particl sourc color histogram target obtain frame. color histogram contain geometr infor- mation robot, make robust per- spectiv chang geometr model exploit depth-bas tracker. instance, color base tracker prefer track visibl robot, coincid correct location. besides, parti- cle weight method depth-bas tracker con- sist simpli count number point fit model, mean lower complex comput color histogram particl color-bas method. result support quantit result shown figur 6. statist analysi obtain data present box plots. box, cen- tral mark median, edg box 25th 75th percentiles, whisker extend ex- treme data point consid outliers, outlier plot individually. figur show depth-bas case perform better term minim error (smaller 0.05 m) repeat results. far error orient concerned, great differ exhibit depth color base trials.th mean error 4.6 standard deviat 3.8, mean big major robot state track accuraci 10 orientation. 5.3 experi 2: track control experi test effect depth-bas tracker propos control scheme. experi divid main navig task relat final posit reach robot, i.e., sens robot march fig. 7: experiment set (posit orientation). initi posit final posit robot shown top. target posit 1 m awai initi position. forward, diag- onal horizont sens observ experiment. differ orient final posit robot reach experi shown bottom, rang 90 90. perform forward, horizont diagon mode w.r.t. initi position. figur 7 depict posit set- tings. direct path follow label p1, p2 p3, respect forward, horizont diagon paths. experiments, distanc initi final posit 1 m. provid accur posit robot lo- comot relev featur robust tracker. current orient need estim order provid locomot control inform command robot challeng tasks. sense, set final orient incorpor target posit describ above, total experi (3 final posit 5 final orienta- tions). import note initi orient experi 0, i.e., robot start posit face forward direction, shown figur 7 (top). figur 7 (bottom), differ orien- tation requir target statu shown, rang 90 90. test kinect rbg- d sensor nao humanoid robot. process ran local network form server instal smart room (2.8ghz, 4gb ram), laptop (2.53ghz, 4gb ram) aldebaran r nao v4 robot (1.6ghz, 1gb ram)) approxim respons 4 publish messag second. 10 pablo a. martnez et al. 1.8 2 2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 1.6 1.8 2 2.2 2.4 2.6 2.8 3 3.2 xaxi (meters) y ax (m et er s) (a) target orient 90. 1.8 2 2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 1.6 1.8 2 2.2 2.4 2.6 2.8 3 3.2 xaxi (meters) y ax (m et er s) (b) target orient 45. 1.8 2 2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 1.6 1.8 2 2.2 2.4 2.6 2.8 3 3.2 xaxi (meters) y ax (m et er s) (c) target orient 0. 1.8 2 2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 1.6 1.8 2 2.2 2.4 2.6 2.8 3 3.2 xaxi (meters) y ax (m et er s) (d) target orient 45. 1.8 2 2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 1.6 1.8 2 2.2 2.4 2.6 2.8 3 3.2 xaxi (meters) y ax (m et er s) (e) target orient 90. fig. 8: qualit result (position). perform approach term posit shown figure. blue line depict orient estim tracker red line repres polynomi curv fit ground truth posit (mark black circles). black-edg rectangl repres initi final posit robot, green-edg rectangl depict target positions. small black arrow respect orient (measur w.r.t. x-axis) 5.3.1 stop criterion order stop march robot target reached, consid euclidean distanc stop con- dition 5 cm target. criterion base overlap area bound box robot ideal bound box robot center target. note how, robot reach tar- closed-loop approach track humanoid robot particl filter depth data 11 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (a) p1 - tgt. or. 90. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (b) p1 - tgt. or. 45. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (c) p1 - tgt. or. 0. 50 100 150 200 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (d) p1 - tgt. or. 45. 50 100 150 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (e) p1 - tgt. or. 90. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (f) p2 - tgt. or. 90. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (g) p2 - tgt. or. 45. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (h) p2 - tgt. or. 0. 20 40 60 80 100 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (i) p2 - tgt. or. 45. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (j) p2 - tgt. or. 90. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (k) p3 - tgt. or. 90. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (l) p3 - tgt. or. 45. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (m) p3 - tgt. or. 0. 20 40 60 80 100 120 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (n) p3 - tgt. or. 45. 50 100 150 200 250 90 45 0 45 90 frame number o r e n t t o n ( d e g ) (o) p3 - tgt. or. 90. fig. 9: qualit result (orientation). perform approach term orient shown. blue line depict orient estim tracker red line repres polynomi curv fit ground truth posit (mark black circles). get, appli veloc neglig produc walking-in-plac motion. consequence, nois in- duce sensor lectur tracker node. reason, stop orient criterion 10 chosen base suppos result drift 10 cm, caus propag posit error diverg orientation, i.e, control correct er- ror. 5.4 qualit result start discuss result accuraci tracker estim posit robot. end, figur 8 depict plot show aerial view differ experi perform robot. figur divid diagrams. diagram present main paths: forward, diagon horizontal, fol- low robot order reach target position. diagram show result relat singl target orienta- tion, i.e., diagram (b) main path 12 pablo a. martnez et al. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 90 45 0 45 90 final orient (deg) p os iti e rr (m et er s) (a) posit error p1. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 90 45 0 45 90 final orient (deg) p os iti e rr (m et er s) (b) posit error p2. 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 90 45 0 45 90 final orient (deg) p os iti e rr (m et er s) (c) posit error p3. fig. 10: statist analysi posit errors. statist analysi posit data shown image. diagram show posit error meter relat singl target posit (p1 (a), p2 (b) p3 (c)) combin final orientation. final orient 45 presented, diagram (d) depict relat final orient 45. diagrams, trajectori follow humanoid robot estim tracker color blue. com- parison, ground truth posit (depict black cir- cles) fit polynomi curv (in red). initi final posit depict black-edg rectangl target posit shown green. respect orient associ rectangl (measur w.r.t. x-axis) repres black arrows. decid us interpol method order relax manual ground- truth mark frame videos. sake obtain error calcul includ video frame correspond sampl ground- truth indexes, linear interpolation. strategi necessarili accur repres departur track state gener tendenc mark ground-truth. featur note figur 8. firstly, experiments, final track posit appear close target, consid 5 cm stop condition. comparison estim trajectori ground truth (blue red line respectively) ac- curaci tracker system. import notic trajectori natur swing motion small size humanoid robot fulli recovered. rele- vant featur note figur effect final orient shape track trajectory, exam- ple, visual analysi horizont path reveal im- portant differ step requir achiev final orientation, sens direct humanoid incorpor march final goal. follow discussion, estim robot ori- entat shown, experiments, figur 9. figur organ row columns, corre- spond target posit final ori- entations, respectively. diagram, blue line rep- resent robot orient estim tracker ground truth mark black circles. red line repres polynomi curv fit ground truth observations. notic experi perform term node i.e. tracker humanoid robot control interact coherently. appreci gradual chang ini- tial orient desir orient reached. note experi number frame requir reach posit orient target be- tween 110 120. nonetheless, (d), (f) (o) took 150 frames. explain consequ proport gain relat control- ling posit robot. i.e., 5 cm stop condi- tion easili reach proport gain consider decreas consequ proxim error target position. methodology, however, coupl control paradigm consid sophist convergence. worth comment path p2 (g), 45 challeng final orientation. lo- comot control caus robot close target posit struggl reach target orient ful- fill stop criteria quickly. reason, greater number frame (near target position) robot appear walk place (minim displac small linear velocity), caus tracker perform accur cases. 5.5 quantit result order measur quantit perform pro- pose approach, comput euclidean error valu estim tracker polynomi curv fit ground truth observations. data correspond- closed-loop approach track humanoid robot particl filter depth data 13 0 2 4 6 8 10 12 14 16 18 20 p1 p2 p3 o rie nt io n er ro r ( g) (a) orient error 90. 0 2 4 6 8 10 12 14 16 18 20 p1 p2 p3 o rie nt io n er ro r ( g) (b) orient error 45. 0 2 4 6 8 10 12 14 16 18 20 p1 p2 p3 o rie nt io n er ro r ( g) (c) orient error 0. 0 2 4 6 8 10 12 14 16 18 20 p1 p2 p3 o rie nt io n er ro r ( g) (d) orient error 45. 0 2 4 6 8 10 12 14 16 18 20 p1 p2 p3 o rie nt io n er ro r ( g) (e) orient error 90. fig. 11: statist analysi orient errors. statist analysi posit data shown image. diagram show orient error degre relat singl final orient (90 (a), 45 (b), 0 (c), 45 (d), 90 (e)) combin final positions. ing error posit shown box plot figur 10 quantit error orient depict fig- ur 11. figur 10 organ diagrams, show posit error (in meters) relat singl target posit combin final orientations, i.e. diagram (a) show final orient relat forward path (p1). similar way, figur 11 depict diagram repres orient combin final posit and, case, orient er- ror shown degrees. let start discuss figur 10, observ posit error trajectori follow robot. except outliers, record error 6 cm experiments, support accuraci track respect position. note presenc outlier gener compromis accur perform system, greater 10 cm. far figur 11 concerned, orient error 10 experiments, exclud outliers. import notic track orient small size humanoid robot challeng problem, compar instanc wheel robot consid sys- tem configuration, i.e. view camera-sensor. explain outcom swing motion gen- erat biped walk small humanoids, produc great nois data acquir sensor. 5.6 discuss result present section correspond track reli fit geometr primit order determine, real time, posit orient walk humanoid robot. mean fit model pro- pose section 3 accord physic dimens robot. sense, fit ellipse, method- ologi humanoid robot present elong distribut shoulders. case humanoids, robot atla boston dynamics, carri batteri box back, depart ellipt elongation, requir fit differ geometr primitive. depth-bas track approach propos pa- emploi simpl gener geometr model particl filter process track humanoid object scene. compar target model cad models, simpl geometr model strongli reduc comput complex weight particl gen- erat frame intuit count number 14 pablo a. martnez et al. point fit model. also, perform keep modul gener track humanoid ob- ject differ size appear multi- object track task. reason choos zenith depth camera extern camera track occlus perspect chang involv view. geometr model approach exploit shape humanoid object view track process suitabl improv robust partial occlusions. orient estim sen- sitiv occlus ellips fit method highli reli complet point cloud data. never- theless, address introduc tempor con- sistenc orient estim process. particularly, implement smooth estim orient time target orient chang greatli consecut frames. far track method concerned, de- cide focu sole approach natur track problem approach state art, i.e., track walk complet viabl method follow constraints: (a) emphasi track joint articul static robot, (b) evid failur departur initi ref- erenc orient occur, (c) reli numer land- mark humanoid body, head sce- nario, (d) previous acquir 3d model world, (e) failur poor textur scenario (such wooden mo- saic floors), (f) extern sensor. worth comment aspect relat approach. includ robot scene, propos depth-bas track abil cope humanoid object scene, gener geometr model emploi approach consid- er gener shape humanoid object point cloud view. however, direct vision camera robot interrupt partli interrupted, track perform affected. case, smaller gener high weight observ (par- ticles), target data provid frame miss- ing. worst case tracker take wrong data observation, i.e. take occlud target, common problem color-bas track approa- ches. however, propos depth-bas particl filter robust occlus extend. approach, depth inform geometr model help distinguish occlud tar- observ depth-bas tracker co- incid real situat observ in- correct data. manner, particl distribut target occlud better protect occlud frames. finally, author believ low cost rgb- d sensor methodolog appropri instal monitor humanoid close spaces, human-robot interact hous environ needed. also, combin capabl extern sensor base track intern sensor camera humanoid robot increas local ca- pabil robot depend requir task, i.e., walk target perform ex- ternal sensor grasping, manipul target achiev intern mount sensor. 6 conclus framework face activ local track humanoid robot presented. particl filter depth inform obtain rgb-d sensor humanoid robot pose (posit orientation) esti- mated. activ featur local carri incorpor pose robot locomot con- trol. integr commun achiev ros, facilit appli propos frame- work navig tasks. approach test kinect nao humanoid robot promis results. geometr model approach exploit shape humanoid object view track process suitabl improv robust partial occlusions. orient estim sen- sitiv occlus ellips fit method highli reli complet point cloud data. never- theless, address introduc tempor con- sistenc orient estim process. particularly, implement smooth estim orient time target orient chang greatli consecut frames. worth comment impact framework field human-robot interaction, i.e., term ac- curat local robot take decis real time navig room human ap- proach. first, track method complement ap- plicabl plan algorithm human obsta- cle appear. second, scheme easili incorpo- rate human track approach order increas rang possibl interact robot hu- man. idea consid extens scope describ paper. acknowledg work partial develop framework project tec2013-43935-r, financ span- ish ministerio economa y competitividad european re- gional develop fund (erdf). also, author like thank mexican council scienc technolog (conacyt) phd studentship pablo a. martnez financi support sabbat leav mario castelan. closed-loop approach track humanoid robot particl filter depth data 15 refer 1. alcantarilla, p., ni, k., bergasa, l., dellaert, f.: visibl learn largescal urban environment. in: ieee intern confer- enc robot automation. shanghai, china (2011) 2. alcantarilla, p.f., stasse, o., druon, s., bergasa, l.m., dellaert, f.: local humanoid singl camera? autonom robot 38(1-2), 4771 (2013) 3. arechavaleta, g., laumond, j.p., hicheur, h., berthoz, a.: op- timal principl govern human walking. ieee transact robot 24(1) (2008) 4. castelan, m., arechavaleta, g.: approxim reachabl space human walk paths: low dimension linear approach. in: ieee intern confer humanoid robots, pp. 81 86. paris, franc (2009) 5. chestnutt, j., takaoka, y., suga, k., nishiwaki, k., kuffner, j., kagami, s.: bipe navig rough environ on- board sensing. in: ieee intern confer intellig robot systems. st. louis, mo, usa (2009) 6. clark, r., wang, s., wen, h., trigoni, n., markham, a.: increas- ing effici 6-dof visual local multi-mod sensori data. in: humanoid robot (humanoids), 2016 ieee- ra 16th intern confer on, pp. 973980. ieee (2016) 7. comaniciu, d., ramesh, v., meer, p.: kernel-bas object track- ing. ieee transact pattern analysi machin intelli- genc 25(5), 564577 (2003) 8. comport, a.i., marchand, e., pressigout, m., chaumette, f.: real- time markerless track augment reality: virtual vi- sual servo framework. ieee transact visual graphic 12(4), 615628 (2006) 9. davison, a., reid, i.d., molton, n.d., stasse, o.: monoslam: real-tim singl camera slam. ieee transact pattern anal- ysi machin intellig 29(6), 10521067 (2007) 10. escande, a., mansard, n., wieber, p.b.: hierarch quadrat programming: fat onlin humanoid-robot motion generation. in- ternat journal robot research 33(7), 10061028 (2014) 11. fallon, m.f., antone, m., roy, n., teller, s.: drift-fre humanoid state estim fuse kinematic, inerti lidar sensing. in: humanoid robot (humanoids), 2014 14th ieee-ra interna- tional confer on, pp. 112119. ieee (2014) 12. ganapathi, v., plagemann, c., koller, d., thrun, s.: real time mo- tion captur singl time-of-flight camera. in: ieee con- ferenc vision pattern recognition, cvpr, pp. 755762 (2010) 13. ganapathi, v., plagemann, c., koller, d., thrun, s.: real-tim hu- man pose track rang data. in: vision eccv 2012, pp. 738751. springer (2012) 14. gordon, n.j., salmond, d.j., smith, a.f.: novel approach nonlinear/non-gaussian bayesian state estimation. in: iee pro- ceed f (radar signal processing), vol. 140, pp. 107113. iet (1993) 15. gratal, x., smith, c., bjorkman, m., kragic, d.: integr 3d featur virtual visual servo hand-ey humanoid robot pose estimation. in: ieee/ra intern confer humanoid robots, pp. 240245 (2013) 16. hansen, d.w., hansen, m.s., kirschmeyer, m., larsen, r., sil- vestre, d.: cluster track time-of-flight cameras. in: ieee societi confer vision pattern recognit workshops, cvprw08, pp. 16 (2008) 17. herdt, a., diedam, h., wieber, p.b., dimitrov, d., mombaur, k., diehl, m.: onlin walk motion gener automat foot- step placement. advanc robot 24(5-6), 719737 (2010) 18. hornung, a., wurm, k., bennewitz, m.: humanoid robot localiza- tion complex indoor environments. in: ieee/rsj intern confer intellig robot systems, pp. 16901695. taipei, taiwan (2010) 19. klein, g., murray, d.: parallel track map small ar workspaces. in: proc. sixth ieee acm intern sympo- sium mix augment realiti (ismar07). nara, japan (2007) 20. maier, d., hornung, a., bennewitz, m.: real-tim navig 3d environ base depth camera data. in: ieee inter- nation confer humanoid robots, pp. 692697. osaka, japan (2012) 21. martnez, p.a., castelan, m., arechavaleta, g.: vision base per- sistent local humanoid robot locomot tasks. in- ternat journal appli mathemat sci- enc 26(3), 669 (2016) 22. martnez, p.a., varas, d., castelan, m., camacho, m., marques, f., arechavaleta, g.: 3d shape reconstruct humanoid gener video sequence. in: humanoid robot (humanoids), 2014 14th ieee-ra intern confer on, pp. 699706. ieee (2014) 23. matsumoto, y., wada, t., nishio, s., miyashita, t., hagita, n.: scalabl robust multi-peopl head track combin dis- tribut multipl sensors. journal intellig servic robot 3(1), 2936 (2010) 24. michel, p., chestnutt, j., kagami, s., nishiwaki, k., kuffner, j., kagami, s.: gpu-acceler real-tim 3d trake humanoid locomot stair climbing. in: ieee intern confer intellig robot systems. san diego, usa (2007) 25. michel, p., chestnutt, j., kagami, s., nishiwaki, k., kuffner, j., kanade, t.: onlin environ reconstruct bipe naviga- tion. in: ieee intern confer robot automa- tion. orlando, fl, usa (2006) 26. migniot, c., ababsa, f.: 3d human track view depth inform record xtion pro-liv camera. in: ad- vanc visual computing, pp. 603612. springer (2013) 27. nummiaro, k., koller-meier, e., van gool, l.: adapt color- base particl filter. imag vision comput 21(1), 99110 (2002) 28. obwald, s., hornung, a., bennewitz, m.: improv propos highli accur local rang vision data. in: ieee/rsj intern confer intellig robot sys- tem. vilamoura, portug (2012) 29. oriolo, g., paolillo, a., rosa, l., venditelli, m.: humanoid odo- metric local integr kinematic, inerti visual infor- mation. autonom robot pp. 113 (2015) 30. papadopoulos, a.v., bascetta, l., ferretti, g.: gener hu- man walk paths. in: ieee/rsj intern confer intellig robot systems, pp. 16761681. tokyo, japan (2013) 31. poppe, r.: vision-bas human motion analysis: overview. vision imag understand 108(1), 418 (2007) 32. puydupin-jamin, a.s., johnson, m., bretl, t.: convex approach invers optim control applic model human locomotion. in: ieee intern confer robot automation, pp. 531536. minnesota, usa (2012) 33. quigley, m., conley, k., gerkey, b.p., faust, j., foote, t., leibs, j., wheeler, r., ng, a.y.: ros: open-sourc robot oper system. in: icra workshop open sourc softwar (2009) 34. rauter, m.: reliabl human detect track top-view depth images. in: ieee confer vision pat- tern recognit workshops, cvprw, pp. 529534 (2013) 35. siddiqui, m., liao, w., medioni, g.g.: vision-bas short rang interact person servic robot user. intellig servic robot 2(3), 113130 (2009) 36. simon, d.: optim state estimation: kalman, h infinity, nonlinear approaches. wiley-intersci (2006) 37. sisbot, e.a., marin-urias, l.f., alami, r., simeon, t.: human awar mobil robot motion planner. ieee transact robot- ic 23(5), 874883 (2007) 16 pablo a. martnez et al. 38. sisbot, e.a., marin-urias, l.f., broquere, x., sidobre, d., alami, r.: synthes robot motion adapt human presence. inter- nation journal social robot 2(3), 329343 (2010) 39. spinello, l., arras, k.o.: peopl detect rgb-d data. in: ieee/rsj intern confer intellig robot sys- tems, pp. 38383843 (2011) 40. stasse, o., davison, a., sellaouti, r., yokoi, k.: real-tim 3d slam humanoid robot consid pattern gener infor- mation. in: ieee/rsj intern confer intellig ro- bot systems, pp. 348355. beijing, china (2006) 41. stilman, m., nishiwaki, k., kagami, s., kuffner, j.: plan execut navig movabl obstacles. in: ieee inter- nation confer intellig robot systems. beijin, china (2006) 42. triggs, b., mclauchlan, p., hartley, r., fitzgibbon, a.: bundl adjust modern synthesis. vision algorithms: theori practic (1999) 43. wurm, k.m., hornung, a., bennewitz, m., stachniss, c., bur- gard, w.: octomap: probabilistic, flexible, compact 3d map represent robot systems. in: ieee intern confer- enc robot automation, workshop best practic 3d percept model mobil manipulation. anchor- age, alaska (2010) 44. xia, l., chen, c.c., aggarwal, j.: human detect depth inform kinect. in: ieee societi confer vision pattern recognit workshops, cvprw, pp. 1522 (2011) 45. yilmaz, a., javed, o., shah, m.: object tracking: survey. acm comput survei (csur) 38(4), 13 (2006)