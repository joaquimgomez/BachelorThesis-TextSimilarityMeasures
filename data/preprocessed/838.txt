robot reason group behavior museum visitors: leader detect group track karla trejo a,, cecilio angulo a, shinichi satoh b mayumi bono b esaii automat control department, universitat politcnica catalunya - upc, barcelona, spain b digit content media scienc research division, nation institut informat - nii, tokyo, japan abstract. field human-robot interact (hri) broad commun encompass robotics, artifici intellig (ai), human-comput interact (hci), psycholog social science. hri social robot explor import issu design robot work peopl daili life environments, capabl interact with, modeling, learn humans. robot system improv capabl understand human convei intent actions. present work demonstr behaviour achiev field studi conduct scienc museum. articl introduc vision algorithm abl detect track leader group peopl scienc communicator, particular case distinguish group member non-group member well, mean cognit logic behaviour analysi interact scene. leader direct comput attent refer approach. vision supervis peopl group follow guid prevent accid miss persons. work repres wide rang possibl applic futur scenario group interact kei aspect robot understand effect particip social environments. keywords: human-robot interaction, human motion analysis, leader detection, group categorization, group track 1. introduct activ research topic com- puter vision, visual analysi human motion attempt detect, track recogn people, gener- ally, understand human behavior im- ag sequenc involv human [1,2,3]. strong driven wide spectrum promis ap- plicat area content-bas im- ag storag retrieval, video conferencing, smart surveil [4], perceptu interfaces, virtual realiti robot [5], few. track group peopl import skill surveil system robot oper pop- *correspond author: karla andrea trejo ramrez, grec knowledg engin research group, upc - barcelonatech, build u - offic 543. pau gargallo 14. 08028 barcelona, spain; ulat environments. research 70% pedestrian walk group [9]. peopl so- cial be form groups, interact other, merg larger group separ them. group dynam wide discuss earlier work [10,11,12]. harvest power knowledg groups, position, size, motion state social behavior, enabl system gain deeper understand human environ pro- vide better servic users. make assemblag peopl group highli complex question gener involv difficult-to-measur social relat subjects. concept relat topic proxem theori in- troduc hall [13]. seri psycholog experi social relat peopl reliabl correl physic distanc interaction. correl allow infer group affili mean avail bodi space infor- mation, approach wide deploi work. aim research track reason social group highli defin role sim- plistic cognit process, learn pri- ori social relations. cognit develop detect subject hold leader role group and, subsequently, assign rest correspond role either, group member non-group members. as- signment base behavior analysi group refer select leader, motion spac- ing interactions. museum hri friendli environ- ment strong leader-group role relev valuabl maintain peopl organ safe, schoolchildren walking, therapi group guid tour industri commerci facilities. larg group peopl requir heighten attent leader guid them. robot com- panion, act autonom independ be- ing interact crowd assist group leader process cohes information, allevi workload. reli smartphon tablet platform provid data, activ easili distract leader break concentr possibl ways. experi work attempt prove feasibl propos approach. intent later demonstr robot endow vision capabl track group museum visitor follow lead scienc com- municator. hence, implement robot hri area similar behaviour setup help supervis task ad new tech- nolog support. paper organ follows: brief dis- cussion relat work section 2, methodolog- ical formul project propos earli stage describ section 3. main stage propos formulation, group categor leader tracking, introduc sec- tions. conduct experi framework case studi defin illustr section 6. section 7 conclud paper goe detail futur work. 2. relat work abil robot endow camera track peopl surround major is- sue. track individu peopl highli stud- i problem target tracking, vision robotics, problem track group peopl bare explor [6]. however, number re- late work recent increas activ- iti visual surveil social comput commun [7,8]. arra et al. [14,15] constantli work recurs multi-model hypothesi theori track group people. approach seek re- flect group format process gain effici sit- uation maintain state individu peo- ple intractable. theori reli heavili learn group model cohes probabili- ties. state-of-the-art group track area undoubt- edli includ works, outstand- ing track perform achiev real-tim us- ing rgb-d data [16]. nonetheless, research group observ peopl detect whole, accur categor mean indi- vidual role assign non-exist author knowledge. open novel research line featur- ing valuabl in-depth inform social re- lationship interact track group. 1990 research explor possibl implement companion robot robot mu- seum guid [17,18]. studi focus human-robot interact address robot abil creat short-term interact visitor museum, robot abil navig populated, dynam unpredict place museum environ [19]. studi look creat believ social robots, ex- plore robot abil creat emot contact museum visitor ey contact engag dialogu robot audienc museum tour [20,21,22]. studi mainli con- duct focu technolog abil robot quest optim robot function- aliti guide. question pose robot assist human museum guide. provid support empower- ing human expert task act replac [23]. task prevent visitor hive group inevit lost. recur- rent incident, special kids, reason miss person major concern crowd environ museum. moreover, robot assist visitor safe awar restrict area museum sourc accid well. import support matter, scienc commun deal larg group visitors. 3. methodolog approach detect person hold leadership posit group peopl easi task human being. us, take second witness- ing interact group, identifi member recogn leader them. thus, formul approach problem convei natur cognit capac discern machine. 3.1. analyz behavior select track leader distinct piec cloth, color equipment, leader attitude. dis- tinctiv trait infer rapidli spot person charge. bodi language: lead- er tend gesticul group, express idea give direc- tion members. indicator, sure obviou one, lead translations, like person ahead group fol- low members, guid way. featur reflect vi- sion algorithm mean high variat po- sition bound box obtain peo- ple detector. major gesticul lead variat size (width height) bound box, quick displac import translat x y directions. assert repres signific chang bound box posit mem- ber group certainli displai through- frame given scene. nevertheless, bound box approach scarc effective. peopl detector algorithm lose sta- biliti come precis posit recall. person remain place pose frame another, peopl de- tector like retriev bound box dif- ferent posit size time, despit true positive. section 4.1 describ premis reinforc motion detect strategi result robust group categor algorithm. accord featur selected, strongli reli build artifici cognit base human motion behavior analysis, gener methodolog group-lead track ex- posed. figur 1 show structur group- leader tracker algorithm, detect leader group observ peopl and, consequently, classifi subject scene either, group not. 3.2. detect correspond filter initi step detect individu imag scene opencv peopl detector algo- rithm [24] fine tune parameters. achiev best possibl perform detector, 30 train test carri differ paramet set ex- periment phase. unfortunately, peopl detect preserv appear order analyz frames. match detect make sure relat human detect current frame correspond detect previou frame. stage, coor- dinat detect box current frame compar coordin detect previou frame. minimum distanc coordin assum detect frames. detect match peopl scene, area differ bound box x,y quantifi store cumul sum. accumul differ stage appli thresh- old filter prevent outrag valu sum- up, origin possibl group error false- posit detect peopl detector, gener- fig. 1. gener scheme group-lead tracker algorithm. alli valu disturb algorithm affect perform upcom stages. 4. motion detect group categor order categor peopl video stream, motion gestur detect algorithm em- ploi fast accur form. detect motion, tag assign peopl present scene accord role group. 4.1. motion detect major improv bound box ba- sic treatment motion detect mention section 3.1 achiev implement dif- ferenti subtract algorithm collin et al. [25]. techniqu allow eras ghost phe- nomenon gener bound box el- ement imag humans. moreover, combin method optim c- dric verstraeten [26] standard deviat ne- glect fals posit offer prospect better results. robust motion algorithm far tackl out- door environ problem ease. present data collect indoors, necessari compromis cpu power task. simpl trick eras fals posit assum motion occur sequenc imag larger one. interest paramet neglect fals posit standard deviation. stan- dard deviat describ distribut motion. motion specif singl point, like human move far awai camera, mo- tion mainli concentr singl point pixel, standard deviat near zero. hand, lot motion detect distribut entir image, standard deviat high. huge distribut indic real motion, e.g. indic aggress wind abrupt changes. notic scenarios, public places, high distribut usual assumpt fails. instead work rectangl shape bound box, concav hull defined. again, case problem, keep thing simpl preferable. accordingly, process motion detect base imag video stream, call previous, current next. step perform subtract previou im- ag (see exampl figur 2d) imag current (figur 2e). logic oper place result final result threshold accur larger chang (figur 2f). threshold result place window current imag look motion changes, pixel valu equal 255 indic mo- tion. motion detect min max valu evaluated, comput bound rect- angl contain chang pixel scene. motion detected, yellow rectangl drawn result imag (figur 3). method hold simpl fast, obtain high performance. select thresh- old valu kei point accur motion detec- tion. algorithm suggest pick dynam adapt threshold. nevertheless, featur delai overal procedur complet avoid fals positives, considered. 4.2. group categor pursu categor peopl detect scene group not, definit group fig. 2. motion detect example: a) previous, b) current c) imag frames. absolut differ a) c) shown d), absolut differ b) c) depict e). final result f) obtain perform bitwis oper d) e) threshold outcome. fig. 3. yellow bound box comput contain result white pixel (valu equal 255) figur 2f, repres area signific motion given scene: scienc commun gestur hand. established. group stand set peopl hav- ing leader his/her current followers. assum leader act entir video sequenc follow conform group remain number start finish. words, new leadership aris group new member allow join. despit hard constraint definition, typ- ical appli guid tour museums. hence, re- quir focu monitor track group museum visitor establish restrictions, highli relat actual environment, spe- cific circumst case studi work. depend condit meet transitori stationari state, peopl detect scene earn perman transient (modifiable, overwritable) tag identifi assign cor- respond role individu (see tabl 1). transitori state initi consid video stream start depict leader move follow place (figur 4), stationari state encount video stream start leader settl scene surround follow (figur 5). sense, leader transitori state prone initi movement screen, guid- ing group. stationari state leader tend gesticul else, excessively, clearli justifi scienc com- munic museum. gestur action start displai notion movement scene. logic assumpt subsequ effect reflect tabl 1, evalu main interact motion rectangl bound- ing box peopl detections. leader suscept incorrectli detect stationari state, detect motion gestur discrete, take longer period time categor transitori coun- terpart. hence, relev movement take place frame imag sequenc number detect occurring, imag experienc soft case. case abl detect person frame scene, imag go hard case. soft case easier overcom hard one, matter time leader signific gestur activ motion detect algorithm (figur 6). hard case, contrast, deal difficulti work peopl de- tector failur complex view angl occlu- sion individu (figur 7). fig. 4. exampl video sequenc undergo transitori state. top: frame 1 training2 video. bottom: frame 100 training2 video. tabl 1 logic peopl detect categor tag type role transitori state stationari state 1 perman group member detect box overlap motion box group member box potenti group member select leader 2 perman non-group member detect box overlap motion box group member box detect box tag poten- tial group member 3 perman group leader peopl detect box overlap motion box potenti group member overlap motion box 4 transient potenti group member na detect box significantli close fig. 5. exampl video sequenc undergo stationari state. top: frame 1 training4 video. bottom: frame 100 training4 video. group member tendenc close to- gether maintain certain distanc leader figure. consequence, exist high probabl leader person occlud successfulli identifi peopl detector hard case. however, possibl reli entir previou assumpt assign role base ex- clusiv this. fig. 6. training3 video exemplifi soft case. top: frame 1, peopl detector output human detect scene. bottom: frame 35, algorithm abl rapidli categor detec- tion group leader identified. hence, properli handl ambigu role situ- ation, conjunct permanent-typ tags, special transient-typ tag associ potenti group member role created. video stream start motion de- tect yet, algorithm search peopl detec- tion box closer design fig. 7. training1 video exemplifi hard case. top: frame 1, peopl detector output human detection. middle: frame 6, leader categor group member despit ex- istenc human scene. bottom: frame 97, group member detect automat categor algorithm. detect member potenti group transient tag. leader spotted, tag be- come perman role automat assigned. cognit develop trigger process perceiv individu group beginning, monitor behaviour ana- lyze scene. form, gener solut categor stationari state achiev with- isol hard soft cases. evidently, transient tag affect tran- sitori state motion detect show fast. nevertheless, true member algorithm inter- nalli serv filter assign tag transitori state. descript tabl 1 refer set action trigger role select sequenc final transform role assignments. true member algorithm respons second level analysi behavior action ensur possibl definit role assignment. true mem- ber evalu box overlap role-assign box or, fail that, close box term pixel distance. point, clear distinct group leader group member. cameraman? cameraman consid- er group member not? technically, cameraman treat pas- sive group member follow group keep track start finish short distance. nevertheless, given natur research, choic line reason cameraman consid group member mu- seum visitor, strictli speaking. cameraman false-posit catego- rize non-members, detect peo- ple wander scene. 25 frame rate sampl appli detect elimin possibl fals positives, min- imiz error upcom frames. fals posit origin peopl detector phase, stage overal procedure, algorithm maintain fast, mayb inaccurate, real- time process purpose. peopl bound box categori label assigned, comput- ing time avail evalu regist detec- tion activ not. detect activ procedur appli base set features. detect attribut ar- ea differ bound box x,y, co- ordin bound box x, y assign categor tag. x,y coordin provid lo- cation upper-left corner detect bound box. featur chang 25 frame detect consid true activ one; else, presenc detect attribut changes, consid fals posi- tive probabl detect assign object human extrem high. emphas fil- tere appli detect obtain far time evaluation, free role assign consideration. 5. leader tracker direct estim categor phase complet frame video stream role assign stationari state, time algorithm continu track select group leader. 5.1. leader tracker dlibs1 implement win algorithm 2014 visual object track challeng select handl stage. robust scale estima- tion challeng problem visual object tracking. exist method fail handl larg scale vari- ation complex imag sequences. propos ap- proach danelljan et al. [27] work learn dis- crimin correl filter base scale pyramid representation. learn separ filter transla- tion scale estimation, demonstr improv perform compar exhaust scale search. scale estim approach gener incorpor track method inher scale estimation. method shown out- perform best exist tracker 16.6% median distanc precision, oper real-time. centr coordin leader bound box, obtain frame leader detected, inform fed algorithm, capabl predict posit bound box upcom frame high accuracy. 25 frame rate sampl section 4.2 emploi comput averag optic flow determin group leader direction. mat- ter thoroughli discuss section pa- per, relev stage algorithm bring conclus overal methodolog project. 1 5.2. leader direct constrain optic flow simpl optic flow algorithm current avail opencv, tao [28] lucas-kanad method [29] combin shi-tomasi [30] algorithm select points, dens flow implement weinzaepfel [31] farnebck [32]. tao wein- zaepfel approach state-of-the-art procedures, farnebck long-establish algorithm tri first. tao algorithm work high- resolut video case leav weinzaepfel unquestion candid fu- ture upgrades. therefore, order determin indic direct leader face given scene, opencv implement farnebck optic flow chosen. main idea constrain optic flow calcul bound box area group leader defin roi (region inter- est), run algorithm scene. option proposed: (a) comput leader direct averag direct bodi manifesting; (b) calcul averag di- rection pixel compos central axi bound box; (c) obtain averag direct bodi centroid pixel. averag approach consid stabil flow behavior wai displai it, expos relev improv visual term perfor- manc well. time being, option (c) selected, simpl straightforward strategy. make sens retriev centroid pixel direct comput op- tical flow: person torso stabl bodi in- evit describ motion realiti individual. words, person turn head certain direct necessarili impli she/h plan direction, explain look momentarili catch person attent location. action move torso de- termin person direct intention, can- torso conduct self, state genuin focus, torso stand primari attention. therefore, torso reliabl bodi featur resolv direct human face also, complic posit retriev confront challeng inter-individu variance. 6. case studi experiment nation institut informat (nii) tokyo, japan, perform experi nation mu- seum emerg scienc innov (miraikan), place kinect v1 sensor differ spot rooms. experi consist gather color, depth skeleton inform pro- vide rgb-d sensor stream februari march 2014 sessions. collect scene contain visitor interact sci- enc commun museum. retriev data meant replic offlin analysi 3d research lines. unfortunately, posterior data process take time expect essenti inform missing. imag frame scene differ angl and, hence, differ camera pose estim case scenario. calibr paramet available, camera re-sect 3d-2d map color- skeleton stream futile. depth-color map ap- proach considered, yet, collect depth frame major drawbacks: background subtract timestamp frame. hand- workaround actual performed, huge work result virtual low precis rate. present, comput 3d-2d map opti- mize result unreason condi- tions. however, genuin interest exploit 2d possibl valuabl inform will- ing offer, robot platform system run basic hardwar resourc short budget effici purposes. which, case, make high- end, fast easy-to-us technolog afford ev- eryon need it. consequently, decid color data form pictur video current used. leav aside, moment, rest data 3d upgrad near future. 6.1. goal experi object us inform leader detection: detect track leader group peopl particular case, sci- enc commun determin direct leader facing. second object group tracking: identifi leader follow scene, i.e, member compos group guid scienc commu- nicator. addit acknowledg peopl group, classifi role reason- ing group behavior interactions. understand scene individu compris kei element eventu robot social interact environ activ particip it. role interpret remark- abli accurate, robot recog- nize entir group track fulli su- pervis museum visitors, work task scienc communicator. 6.2. testb video compris 3000 frame total select train, supervis fashion, propos group-lead tracker algorithm. video share background obtain kinect device, although, record prior fix devic tripod base gain stability. hence, color data video reflect angl differ relat illu- minat changes. videos, differ on training, contain total 2405 frame sub- mit test respect ground truth. video 1 video 6 share background, slightli differ view angles, de- vice appar slid bit sessions. remain video share similar fate record room, however, video 2 video 3 angl view, differ view angl video 4 video 5. contrast background condit re- sult tabl 2 safe relat good outcom certain background, wai around. 6.3. result ground truth accuraci formul quantit evalu propos method- ologi imper measur actual perfor- mance. ground truth object wai obtain real accuraci algorithm. creat annot ground truth data time consum process absenc avail dataset employ. new problem, impli manual la- bell score come matter. percentag accuraci test video depict tabl 2. accuraci measur base number correct categor to- tal number detect boxes, appli sampl frame video. column tabl 2 displai test video, follow total number frame compos video sampl rate applied. test video, sampl taken x frames, call valu sampl frame rate. reason, number sampl frame obtain result divid number total frame sampl frame rate. detect box column state total number detect box encount sampl frames, column determin detect correctli incorrectli catego- rize algorithm, classifi leader member detections. accuraci comput sum correct categor leader correct member correct detect box valu 100% goal. better understand formul take, in- stance, example. figur 8 present anno- tate ground truth versu test result sampl frame number 38 video 2, detect categor correctly: group leader, group member cameraman classifi non-member. false-posit encountered, algorithm categor non-memb filter abl elimin them. mean fals posit case incorrectli cat- egor group member. hence, accuraci test result sampl frame number 38 video 2 alloc tabl 2 as: correct categor leader (leader correct +1), correct categor group member cameraman (member correct + 3) incorrect categor fals posit (member incorrect + 1). accuraci categor promis number algorithm intro- duce work obtain tabl 2. averag accuraci video lead gen- eral averag accuraci 75%, actual aver- ag accuraci algorithm 71% com- pute total detect box give import video differ length. video 2, 4 5 reveal astonish result present figur 9, video 6 lag 70% accuraci rate. result fig. 8. sampl frame 38 video 2. top: ground truth annotation. bottom: test result. blue box repres group leader, green box group member red box suggest non group members. yellow box describ motion detect area, larg scene undergo transitori state. merit in-depth analysi video 1 video 3 demand poor performance, activ seek feedback order improve. test intend provid relev inform issue, thoroughli examin section 6.4. leader direct perform constrain optic flow approach mani- fest except results. example, figur 10 de- pict transitori state video 5 scienc commun guid museum visitor exhibit room. notic direc- tion arrow sampl frame 5 (top) small com- pare arrow shown sampl frame 15 (bottom). frame taken video sequence, portrai displac leader group room, observ magnitud motion calculated. tabl 2 categor - accuraci test test total frame sampl frame rate sampl frame detect box leader correct leader incorrect member correct member incorrect accuraci (%) video 1 910 10 91 139 3 33 47 56 36 video 2 450 10 45 100 41 0 57 2 98 video 3 200 10 20 35 0 13 17 5 46 video 4 500 10 50 65 50 0 15 0 100 video 5 230 10 23 48 20 0 27 1 98 video 6 115 5 23 20 3 6 11 0 70 fig. 9. video 2 98% accuracy. scienc commun dis- plai group leader blue bound box, museum visitor recogn green-color box member group. pixel coordin upper-left corner box. length arrow reflect magnitud averag optic flow point space, proport magnitud motion scene. scienc commun sampl frame 5 re- centli start move appoint direction, arrow magnitud smaller seen sampl frame 15, scienc commun reach final destination. mag- nitud reveal speed displacement. hence, larg direct arrow easili encount tran- sitori state videos, short arrow common stationari state scienc commun posit explain exhibit (see figur 11). leader direct inform alert robot as- sistant larg quick displac sci- enc communicator. all, museum visitor circumst like split group accidentally, distracted. miss person situat prevent monitor particular attent reference. fig. 10. video 5 98% accuracy. top: sampl frame 5. blue arrow leader torso origin estim direction. bottom: sampl frame 15. leader direct arrow indic direct movement displai proport magnitude. 6.4. issu distanc camera certain distanc camera necessari peopl detector work properly. occlus be- tween individu close camera view make difficult algorithm detect group member scene, recurr issu (see figur 11). fact, quickli escal major peopl detector partial de- tect member group despit circum- stances, video 1. failur relat peopl detector video 1 hold lowest perform tests, own 36% accuracy. caus frame leader bound box collid motion box, exact moment peopl detector detect leader. motion box final make appear result scienc commun gestur- ing, peopl detector detect scene. unfortunately, detect corre- spond scienc commun museum visitor instead. algorithm immedi perform role assign visitor over-s de- tection box overlap motion rectangl (see figur 12). outcom hard case scenario wrong leader selection, error propag entir video sequence. effect false-posit false-posit consid non- group member algorithm logic pe- riodic filter function set elimin them, consider object-trigg false-posit drawn peopl detector. fig. 11. video 4 100% accuracy. stationari state scenario hard detect museum visitor assist scienc communicator. so, cameraman successfulli clas- sifi non-group member red color box. fig. 12. video 1 36% accuracy. top: frame 1, scienc com- munic detected, role assign yet. middle: frame 4, scienc commun gestur motion box overlap detect obtained, select museum visitor group leader. bottom: frame 6, scienc commun detect leader role given, appoint group member. lose track unusu problem encount test videos: leader tracker got lost. tracker algorithm extrem robust normal mani- fest error come peopl detector weaknesses. hence, rare face issu occur train sequenc before. figur 13 show algorithm perform suffici video 6 tracker loos scienc commun location. track inform missing, algorithm categor task remain force. cameraman controversi cameraman case difficult overcome, oppos opinion exist question cameraman consid group member not, human beings. then, expect reason machine? fig. 13. video 6 70% accuracy. top: scienc commun track leader. fals posit object detect clas- sifi non-group member algorithm abl elimin it. bottom: leader track lost point frame 35. yet, algorithm consid leader group. cameraman close group move fast catch them, like cameraman confus group member. situat exist cameraman address group leader start move earlier leader faster, try avoid possibl collis group. keep pace leader yet, fals categor leader role oc- cur certain cours events. video 3 portrai imag sequenc deal transitori state video start depict scienc communica- tor guid museum visitor exhibition. scene move time fast scienc commun lead way, creat larg motion rectangl overlap detect box (see figur 14). unveil critic predica algo- rithm logic far. detect box overlap motion rectangle, choos group leader box de- tect analyz peopl detector, random. 6.5. discuss mention previou section, is- sue come peopl detector perform true case come certain complexity, better peopl detector imple- ment mitig issu possible. error aris self occlus individ- ual difficult view angl like dis- sipat instal robot assis- tant. experi present work contain imag sequenc fix camera kinect de- vice record upper differ rooms. contrast, robot better point view scene gener flexibl one. purpos extend averag accuraci boost algorithm perform level, exponenti motion algorithm carefulli design implementation. human cognit knowledg role observ group peopl base exponenti interact behavior attitud time. mean- ing that, difficult human be fig. 14. video 3 46% accuracy. top: individu detected, role assign yet. bottom: cameraman address group leader, scienc communi- cator detect frame. larg motion rectangl displai contain detect scene. immedi categor group classifi role group extrem homogen priori. member behav equal adopt attitud other, regardless there visual distinct subject not. consequ complexity, need observ interact longer mem- ber develop self-identities, defin group role (conscious not). satisfi develop look natur deliber determin leader followers. arriv con- clusion impli observ seri interac- tion evolving, leader attitud grew expo- nential certain time period. convei human-lik wai reason machin miss piec puzzle. quantifi motion interact time detections, ex- ponenti fashion, reinforc algorithm im- prove significantli overal structure. 6.6. exponenti motion algorithm implement version exponenti motion approach develop subsequ test videos. exponenti analysi 50 frames, target role detec- tion definit categorization. 50 frames, role comput reset zero start again, elimin initi hard constraint deliv rel dynam role at- tribution. tabl 3 refer accuraci test result obtain implement exponenti motion algorithm. contrast tabl 2, gener averag accuraci actual averag accuraci drop 2%, 75% 73% 71% 69%, respec- tively. follow comparison specific, video 1 video 6 shown fair result error effect diminish (see figur 15 16). however, accuraci video 1 increas 12% exponenti motion implementation, ac- curaci video 6 decreas 7%. hand, video 3 rose accuraci 12% well, improv correct leader de- tection (see tabl 3 ), member categoriza- tion video 3 leav desir (figur 17). problem affect rest video on de- pict best accuraci previou set-up much. notic accuraci video 2, video 4 video 5 fell 9% respect origin algo- rithm. caus fluctuat ob- serv tabl 3, visibl gener trade-off leader member categorization: improve- ment correct identif leader af- fect membership neg way. dynam role assign interfer proxem origin algorithm, factor consid second version ex- ponenti motion implementation. note, peopl detect issu back- ing algorithm performance, despit ef- fort creat arrai histor record detect attempt maintain track control detect box avoid duplica- tion sub-detect (identifi detect smaller bound box). tabl 3 categor exponenti motion - accuraci test test total frame sampl frame rate sampl frame detect box leader correct leader incorrect member correct member incorrect accuraci (%) video 1 910 10 91 178 36 46 51 45 48 video 2 450 10 45 100 39 0 50 11 89 video 3 200 10 20 36 8 3 13 12 58 video 4 500 10 50 55 45 0 5 5 91 video 5 230 10 23 57 16 1 35 5 89 video 6 115 5 23 24 9 0 6 9 63 fig. 15. video 1 result exponenti motion implementation. top: frame 51, group member correctli categor wrongli address group leader, true leader detected. bottom: frame 419, frame analysi detect correctli categor scene. 7. conclus futur work paper, new problem address group track research area. detect leader group categor member attract great deal studi group interac- tion social environments. role assign be- fig. 16. video 6 result exponenti motion implementation. top: frame 51, fals categor group mem- ber leader track work properly. bottom: frame 70, incorrect categor group member remains, tracker keep follow leader exit scene. haviour analysi mean cognit approach base motion logic proxem theori novel methodolog appar naiv simplic- iti proven successful. promin result work consid relev wide scope possibl applica- tions, special robot assist similar en- fig. 17. video 3 result exponenti motion implementation. top: frame 51, peopl scene move significantli group leader does, leader correctli cat- egor cameraman group mem- bers. bottom: frame 102, detect wrongli categorized. purpl box refer previou detections. vironments. order achiev suffici accu- raci algorithm later impact com- plex environments, number improv re- quired, on mention section 6.5 6.6, exhaust analysi experiment results. hence, depth data relat color imag obtain kinect rgb-d sensor cre- at refin detect subjects, despit challeng restor faulti information. im- provement refer locat peopl bound boxes, region correspond depth arrays, combin threshold distances, background subtract algo- rithm deep learn segment method, provid better results. import fulli exploit collect 3d data field sake futur experi research line. however, natur explor so- lution immedi upgrades. kinect v2 us time-of flight sensor complet dark room lit room. kinect accomplish featur structur light reconstruct depth data approxim pixel pro- ject points. still, kinect v2 far superior perfor- manc pixel uniqu depth value. method stable, precis prone interferences. face recognit motion track greater accuraci newest kinect model. kinect v2 1080 imag resolut (hd), 60% wider field vision, detect track 20 joint 6 peopl bodi includ thumbs. comparison, kinect v1 track 20 joint 2 people. rgb-d state-of-th art technolog certainli power complex embed gener kinect. signific improve- ment come real-time, process 2 giga- byte data second faster broadband data transfer. therewith, on-lin implementa- tion background subtract coordin map- ping result peopl detector higher ac- curaci virtual zero false-positives. acknowledg like thank dr. mamoru mohri miraikan staff data collection. work partli support sokendai interdisciplinari research program (fy 2013-2016), propos interdisciplinari research coordin sok- endai (the graduat univers advanc stud- ies, japan). karla trejo acknowledg financi aid provid conacyt grant nii interna- tional internship program. refer [1] t. moeslund, a. hilton v. kruger, survei advanc vision-bas human motion captur analysis, vision imag understanding, 2006, 104(2), pp. 90-126. [2] x. perez-sala, s. escalera, c. angulo j. gonzlez, survei model base approach 2d 3d visual human pose recovery, sensors, 2014, 14(3), pp. 4189-4210. [3] s. escalera, human behavior analysi depth maps, in: articul motion deform object (2012), pp. 282- 292. [4] d. gowsikhaa, s. abirami r. baskaran, autom human behavior analysi surveil videos: survey. artifici intelleng review, 2014, 42(4), pp. 747-765. [5] c. angulo, s. pfeiffer, r. tellez g. aleny, evalu us robot enlarg aal services, journal ambient intel- ligenc smart environments, 2015, 7(3), pp. 301-313. [6] a. garrell-zulueta a. sanfeliu, cooper social robot accompani group people, intern journal robot research, 2012, 31(13), pp. 1675-1701. [7] m. daz, d. paillacho, c. angulo, o. torres, j. gonzlez j. albo-canals, evalu group-robot interact crowd public spaces: week-long exploratori studi wild humanoid robot guid visitor scienc museum, intern journal humanoid robotics, 2015, 12(4). [8] d. paillacho, c. angulo m. daz, exploratori studi group-robot social interact cultur center, in: ieee/rsj intern confer intellig robot systems. iro 2015 workshop design evalu social robot public settings, 2015, pp. 44-48. [9] m. moussad, n. perozo, s. garnier, d. helb g. ther- aulaz, walk behaviour pedestrian social group impact crowd dynamics, plo one, 2010, 5(4). [10] s.j. mckenna, s. jabri, z. duric, a. rosenfeld h. wech- sler, track group people, vision imag understanding, 2000, 80(1), pp. 42-56. [11] f. cupillard, f. brmond m. thonnat, track group peopl video surveillance, univers kingston (london), 2001. [12] s. saxena, f. brmond, m. thonnat r. ma. crowd be- havior recognit video surveillance, in: proceed 10th intern confer advanc concept in- tellig vision system (aciv 08), springer-verlag, berlin, heidelberg, pp. 970-981, 2008. [13] e. hall, handbook proxem research, societi an- thropolog visual communications, 1974. [14] b. lau, k. o. arra w. burgard, track group peo- ple multi-model hypothesi tracker, in: proceed 2009 ieee intern confer robot automa- tion (icra09), 2009, pp. 3487-3492. [15] b. lau, k. o. arra w. burgard, multi-model hypothesi group track group size estimation, intern journal social robotics, 2010, 2(1), pp. 19-30. [16] t. linder k. o. arras, multi-model hypothesi track group peopl rgb-d data, ieee intern confer- enc inform fusion (fusion14), salamanca, spain, 2014. [17] w. burgard, a. b. cremers, d. fox, d. hhnel, g. lakemeyer, d. schulz, w. steiner s. thrun, interact museum tour-guid robot, in: proceed fifteenth national/tenth confer artifici intelligence/innov applic artifici intellig (aaai 98/iaai 98), 1998. [18] w. burgard, a. b. cremers, d. fox, d. hhnel, g. lakemeyer, d. schulz, w. steiner s. thrun, experi inter- activ museum tour-guid robot, artifici intelligence, 114, 1-2 (octob 1999), 3-55. [19] s. thrun, m. beetz, m. bennewitz, w. burgard, a. b. cremers, f. dellaert, et al. probabilist algorithm interact museum tour-guid robot minerva. intern journal robot research, 2000, 19(11), pp. 972as999. [20] m. ghosh h. kuzuoka, ethnomethodolog studi museum guid robot attempt engag disen- gagement, journal robotics, 2014. [21] y. kuno, h. sekiguchi, t. tsubota, s. moriyama, k. yamazaki a. yamazaki, museum guid robot commun head motion, in: 15th ieee intern symposium robot human interact communication, 2006. roman 2006. [22] y. kuno, k. sadazuka, m. kawashima, k. yamazaki, a. ya- mazaki h. kuzuoka, museum guid robot base soci- olog interact analysis, in: proceed sigchi confer human factor comput system (chi 07), 2007. [23] f. mart carrillo, j. butchart, s. knight, a. scheinberg, l. wise, l. sterling, c. mccarthy, help help you: human-assist social robot pediatr rehabilitation, in: proceed annual meet australian special group human interaction. acm, 2016. [24] n. dalal b. triggs, histogram orient gradient human detection, in: proceed 2005 ieee societi confer vision pattern recogni- tion (cvpr05), 2005, pp. 886-893. [25] r.t. collins, a.j. lipton, t. kanade, h. fujiyoshi, d. duggins, y. tsin, d. tolliver, n. enomoto, o. hasegawa, p. burt l. wixson, video surveil monitoring: vsam final report, robot institute, carnegi mellon university, pittsburgh pa, 2000. [26] c. verstraeten, opencv simpl motion detection, kerberos.io: open sourc video surveil motion detection, 2014. [27] m. danelljan, g. hger, f. s. khan m. felsberg, accur scale estim robust visual tracking, in: proceed british machin vision conference, bmva press, septem- ber 2014. [28] m. tao, j. bai, p. kohli, s. paris, simpleflow: non- iterative, sublinear optic flow algorithm, graph- ic forum (eurograph 2012), 2012, 31(2). [29] b.d. lucas, t. kanade, imag registr techniqu applic stereo vision, in: proceed imag un- derstand workshop, 1981, pp. 121-130. [30] j. shi c. tomasi, good featur track, 1994 ieee confer vision pattern recognit (cvpr94), 1994, pp. 593-600. [31] p. weinzaepfel, j. revaud, z. harchaoui, c. schmid, deep- flow: larg displac optic flow deep match- ing, 2013 ieee inten confer vision (iccv13), 2013, pp. 1385-1392. [32] g. farnebck, two-fram motion estim base polyno- mial expansion, in: proceed 13th scandinavian con- ferenc imag analysi (scia03), josef bigun toma gustavsson (eds.), springer-verlag, berlin, heidelberg, 2003, pp. 363-370.