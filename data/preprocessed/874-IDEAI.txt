audiovisu head orient estim particl filter multisensor scenario hindawi publish corpor eurasip journal advanc signal process volum 2008, articl id 276846, 12 page doi:10.1155/2008/276846 research articl audiovisu head orient estim particl filter multisensor scenario cristian canton-ferrer,1 carlo segura,2 josep r. casas,1 monts pardas,1 javier hernando2 1 imag process group, universitat politecnica catalunya, 08034 barcelona, spain 2 talp research center, universitat politecnica catalunya, 08034 barcelona, spain correspond address cristian canton-ferrer, receiv 1 februari 2007; accept 7 june 2007 recommend eni ahmet cetin articl present multimod approach head pose estim individu environ equip multipl camera microphones, smartroom automat video conferencing. determin individu head orient basi form sophist interact human technic devic automat sensor select (camera, microphone) commun video surveil systems. us particl filter unifi framework estim head orient monomod multimod case proposed. video, estim head orient color inform exploit spatial redund cameras. audio inform process estim direct voic produc speaker make us direct characterist head radiat pattern. furthermore, differ particl filter multimod inform fusion scheme combin audio video stream analyz term accuraci robustness. one, fusion perform decis level combin monomod head pose estimation, second us joint estim combin inform data level. experiment result conduct clear 2006 evalu databas report comparison propos multimod head pose estim algorithm refer monomod approach prove effect propos approach. copyright 2008 cristian canton-ferr et al. open access articl distribut creativ common attribut license, permit unrestrict use, distribution, reproduct medium, provid origin work properli cited. 1. introduct estim human head orient wide rang applications, includ varieti servic human- interfaces, teleconferencing, virtual reality, 3d audio rendering. recent years, signific research effort devot develop human-comput interfac intellig environ aim support human task situations. exampl intellig environ includ digit offic [1], in- tellig house, intellig classroom, smart confer- enc room [2, 3]. head orient person pro- vide import clue order construct percept capa- biliti scenarios. knowledg allow better un- derstand user refer to. further- more, accur head pose estim allow comput perform face identif improv automat speech recognit select subset sensor (camera mi- crophones) adequ locat task. focu attent directli relat head orientation, person inform users, in- stance, monitor beamer displai text im- ag directli target focu attention. synthesis, determin individu head orient basi form sophist interact hu- man technic devices. automat video conferenc- ing, set computer-control camera captur im- ag individu adjust orient range, compens sourc motion [4]. context, head orient estim crucial sourc inform decid camera microphon suit captur scene. video surveil appli- cations, determin head orient individ- ual camera selection. applic includ control avatar virtual environ input cross-talk cancel 3d audio rendering. 2 eurasip journal advanc signal process previou approach estim head pose video technologies. techniqu pro- pose head orient estim reli facial featur detection. facial featur extract compar face model determin head orient [5, 6]. approach usual requir high-resolut imag commonli avail aforement scenarios. global techniqu us entir imag face es- timat head orient suitabl sce- narios. global techniqu produc classifica- tion head orient base number previous learn class neural network [710]. analysis- by-synthesi approach propos [11]. estim head orient base audio new chal- leng task. earli work speaker orient base acoust energi defin [12], larg microphon arrai consist hundr sensor surround environment. orient global coher- enc field (ogcf) method propos recent work [13], variat gcf acoust local algorithm. scenario audio video available, smart room automat video conferencing, multimod approach achiev accur robust results. audio inform avail person speaking, person usual center at- tention system. reason, audio inform improv precis head orient speak person correct error produc video analysi estim unavail- abil video data (when person move awai camera field view). recent [14], author present multi- modal algorithm aim estim head pose au- diovisu information. propos architectur combin result author base video [15] novel method exclus acoust sig- nal small set microphones. monomod video system, estim perform fit 3d re- construct head combin view cali- brate set cameras. audio head orient base fact radiat pattern human head frequenc dependent. context, propos method es- timat orient activ speaker ra- tio energi differ band frequency. fusion data level decis level mean decentr kalman filter appli sequenc video audio orient estim [16]. particl filter prove us techniqu track estim task variabl involv hold gaussian uncertainti model linear dy- namic [17]. successfulli video ob- ject track audio sourc localization. inform audio video sourc effect combin emploi pf strategi activ speaker track [18] audiovisu multiperson track [19]. article, propos us particl filter uni- fi framework estim head orient monomod multimod case. particl filter multimod fusion, differ strategi com- bine audio video data proposed. one, inform perform decis level combin monomod head pose estimation, second us joint estim combin inform data level. remaind paper organ follows. section 2, present gener architectur propose, introduc particl filter basi estim techniqu develop follow sections. section 3, monomod video head estim techniqu introduced, section 4, present audio singl modal speaker ori- entat estimation. section 5, propos method fuse audio video modal combin estima- tion provid data decis levels. section 6, perform obtain dis- cussed, conclud paper section 7. 2. analysi framework nowadai decreas cost audio visual sensor acquisit hardwar make deploy multisensor system distribut audio visual observ common- place. intellig scenario requir design flexibl reconfigur percept network feed data per- ceptual analysi end [20]. design multicamera configur continu room video monitor con- sist calibr cameras, connect dedic computers, field view aim cover complet scene interest, usual certain over- lap allow triangul 3d data captur vi- sual tracking, face localization, object detection, person iden- tification, gestur classification, overal scene analysis. multimicrophon aural room analysi deploi flexibl microphon network compris microphon ar- rays, microphon clusters, tabl microphones, close- talk microphones, target detect multipl acoust events, voic activ detection, asr speaker lo- cation tracking. acoust sensors, calibr step defined, accord purpos have jointli consist descript audio-video sensor geometry, timestamp ad acquir data tem- poral synchronization. perceptu analysi end intellig envi- ronment consist collect perceptu compon detect classifi low-level featur later interpret higher semant level. perceptu com- ponent analyz audio-visu data head orient detect contribut low-level featur yield fundamen- tal clue drive interact strategy. angl estim purpos multisensor scenario chosen orient head xy plane. angl provid semant inform peopl look scene analysi track attent meet [21]. subsection, particl cristian canton-ferr et al. 3 filter introduc technolog base system describ article. 2.1. particl filter estim pan angl t head person given time t given set observ 1:t written context state space estim problem [22] driven follow state process equation: t = f ( t1, vt ) , (1) observ equation: t = h ( t, nt ) , (2) f() function describ evolut model h() observ function model relat be- tween hidden variabl t measur magnitud t. nois components, vt nt, assum inde- pendent stochast process given distribution. bayesian perspective, pan angl estim track problem recurs estim certain de- gree belief state variabl t time t, given data 1:t time t. thus, requir calcul pdf p(t | 1:t), recurs steps, namely, predict update. predict step us process equat (1) obtain prior pdf mean chapman-kolmogorov integr p ( t | 1:t1 ) = p ( t | t1 ) p ( t1 | 1:t1 ) dt1 (3) p(t1 | 1:t1) known previou iter p(t | t1) determin (1). measur t be- come available, updat prior pdf bay rule: p ( t | 1:t ) = p ( t | t ) p ( t | 1:t1 ) p ( t | t ) p ( t | 1:t1 ) dt , (4) p(t | t) likelihood statist deriv (2). however, posterior pdf p(t | 1:t) (4) comput analyt linear-gaussian model adopted, case kalman filter provid optim solution. particl filter (pf) [23] algorithm sequenti mont carlo method base point mass (or particle) represent probabl densities. techniqu emploi tackl estim track problem variabl involv hold gaussian uncertainti model linear dynamics. case, pf approxim posterior densiti p(t | 1:t) sum ns dirac function center { jt }, 0 < j ns p ( t | 1:t ) ns j=1 w j t ( t jt ) , (5) w j t weight associ particl fulfil ns j=1 w j t = 1. type estim track prob- lems, common approach emploi sampl im- portanc resampl (sir) strategi drive particl time [24]. assumpt lead recurs updat weight w j t w j t1 p ( t | jt ) . (6) sir pf circumv particl degeneraci problem resampl replac time step [23], is, dismiss particl lower weight proportion- alli replic higher weights. case, weight set w j t1 = n1 j, therefore, w j t p ( t | jt ) . (7) hence, weight proport likelihood func- tion comput incom data t. resampl step deriv particl depend weight previou step, new particl re- ceiv start weight equal n1 updat likelihood evaluation. best state time t, t, deriv base dis- crete approxim (5). common solut mont carlo approxim expect t = e [ t | 1:t ] ns j=1 w j t j t . (8) finally, propag model adopt add drift angl j t resampl particl order progres- sive sampl state space follow iter [23]. complex pf problem involv high-dimension state space articul human bodi track task [25], underli motion pattern emploi order effi- cientli sampl state space reduc number particl required. singl dimens head pose estim task, gaussian drift emploi motion model assumed. pf successfulli appli number task audio video object track task clutter background [17] speech enhanc [26]. in- format audio video sourc effect combin emploi pf strategi activ speaker track- ing [18] audiovisu multiperson track [19]. 2.2. pf appli multimod head pose estim pf techniqu appli problem studi take account common criteria design implement pf audio video modal- ities. common design criterion allow natur mul- timod inform fusion strategi decis data level describ section 5. input observ t written set t = [ v t ] , (9) v t refer audio video observations, respectively. sources, happen set depend audio video infor- mation avail not. typically, = subject 4 eurasip journal advanc signal process studi speak vt = project head person camera. data perspective, analysi possibl de- vised: audio, video, audiovisu processing. main factor taken account employ- ing pf construct likelihood evalu func- tion measur similar input data set t given pan angl j t . function assign weight particl state (7). finally, note person present scene, pf estim head orient assign them. 3. video head pose estim method head pose estim video signal pro- pose literatur classifi featur base appear base [27]. featur base method [5, 6, 28] us gener approach involv estim posit specif facial featur imag (typic eyes, nostril mouth) fit data head model. practice, method requir manual ini- tializ particularli sensit select featur points. moreover, near-front view assum high-qual imag required. applic ad- dress work, condit usual difficult satisfy. specif facial featur typic clearli visi- ble light condit wide angl camera views. entir unavail face ori- ent cameras. method reli detail featur analysi follow head model fit fail circumstances. furthermore, ap- proach base monocular analysi imag address multiocular case face head anal- ysi [15, 28, 29]. contrary, appearance-bas meth- od [8, 30] tend achiev satisfactori result low- resolut images. however, techniques, head ori- entat estim pose classif problem neural networks, produc output angl resolut limit discret set. example, [7] angl estima- tion restrict step 25 [31] step 45 employed. perform multimod fusion, informa- tive video output desired, prefer data analysi method provid real-valu angl output. section present new approach multicamera head pose estim low-resolut imag base pf. spatial color analysi input imag per- form redund camera exploit pro- duce synthet reconstruct head person. inform construct likelihood function weight particl pf base vi- sual information. estim head orient comput expect pan angle, describ section 2, produc real-valu output increas precis compar classi- ficat approach pave wai multimod integration. 3.1. spatial analysi head local task perform head orient estim process. object address literatur refer person local track [32, 33] face local [34]. here, head lo- caliz algorithm base previou research [35] reviewed. prior imag analysis, analyz scene character term space disposit con- figur foreground volumes, is, peopl candi- dates, order select potenti 3d region head person present. imag obtain multipl view camera allow exploit spatial redun- danci order detect 3d region [36]. given frame video sequence, set ncam im- ag obtain ncam cameras. camera model pinhol camera model base perspec- tive projection. accur calibr inform available. foreground region input imag obtain segment algorithm base stauffer-grimson back- ground learn substract techniqu [37]. as- sume move object human people. origin segment imag input inform rest imag analysi modul describ here. foreground region extract set ncam origin imag time t, set m 3d point xk, 0 k < m, correspond 3d detect vol- um room obtain appli robust bayesian correspond algorithm describ [35]. inform come track loop speed process narrow- ing search space correspond time t + 1 allow reject fals head detections. inform given establish correspon- denc allow defin bound box bk, center 3d xk averag size adequ contain human head candid (see exampl output figur 1(a)). afterwards, voxel reconstruct [38] com- pute bound box bk, obtain set vox- el vk defin kth 3d foreground volum candid head. order refin verifi set vk belong ellipsoid geometr shape, templat match- ing evalu [38] performed. 3.2. color analysi region provid bound box head provid 2d mask origin imag skin color pixel sought. order extract skin color-lik pix- els, probabilist classif comput rgb in- format [39], color distribut skin esti- mate offlin hand-select sampl skin pixels. finally, color inform combin spatial infor- mation obtain analysi step. pixel classifi skin, pnskin, view n, 0 n < ncam, check pnskin pn ( vk ) , 0 k < m, (10) cristian canton-ferr et al. 5 (a) h0 195 199 203 207 211 215 x 280 288 296 304 312 320 y 140 145 150 155 160 165 z (b) figur 1: exampl output spatial analysi model fit modules. (a), multiview correspond head correctli established. project bound box b0 contain head depict white. (b), voxel reconstruct appli b0 obtain voxel belong head (green cubes). model fit modul result depict red. pn() perspect project oper 3d 2d coordin view n [36]. way, pnskin identifi project voxel set vk correctli handl establish orient multipl head face later modules. let denot skn skin pixel nth view classifi belong kth voxel set. recal set skn occlus under-perform skin detect technique. however, track inform re- dundanc view allow overcom prob- lem. 3.3. head model fit order achiev good fit performance, geometr 3d configur human head considered. research work, ellipsoid model human head shape adopted. spite fairli simpl approxim compar complex geometri head shape [11], head fit achiev accuraci purpos (see figur 1(b), e.g.). let h k = {ck, rk, sk} set paramet defin ellipsoid model kth detect human head candi- date ck center, rk rotat axi center ck sk length axis. obtain- ing set voxel vk belong kth candid head h k, ellipsoid shell model fit voxels. statist moment analysi emploi estim paramet ellipsoid center mark voxel ob- tain 3d spatial mean v k covari matrix cvk . covari diagon eigenvalu decom- posit cvk = , orthonorm diagonal. identif defin paramet estim ellipsoid h k moment analysi paramet straightforward: ck = vk, rk = , sk = diag(). (11) 3.4. 3d head appear gener combin color space inform requir order perform high-semant level classif estim head orientation. inform aggreg procedur take input inform gener low-level imag analysi person: ellipsoid estima- tion h k head set skin patch view belong head {skn}, 0 n < ncam. output techniqu fusion color space inform set denot k. procedur inform aggreg defin base assumpt skin patch {skn} pro- jection region surfac estim ellipsoid defin head person. hence, color space infor- mation combin produc synthet reconstruc- tion head face appear 3d. fusion pro- cess perform head separ start back- project skin pixel skn ncam view kth 3d ellipsoid model. formally, pixel pkn skn , comput ( pkn ) p1n ( pkn ) = + v, r+, (12) obtain back-project rai world coordin frame pass pkn imag plane origin camera center director vector v. order obtain back-project pkn surfac ellipsoid model kth head, (12) substitut equat 6 eurasip journal advanc signal process o0 o1 s0 h (p 0) (p 1 ) 1 0 0 s0 s1 s1 z y x (a) 15 10 5 0 5 10 15 z 10 5 0 5 10x 15 10 5 0 51015 y (b) (c) figur 2: (a), color spatial inform fusion process scheme. pixel set skn back-project surfac ellipsoid defin h k , gener set skn weight term k n. (b), result inform fusion obtain synthet reconstruct face appear imag (c) skin patch plot red ellipsoid fit white. ellipsoid defin set paramet h k [36]. give quadrat : a2 + b + c = 0. (13) case (13) real roots. mean rai intersect ellipsoid twice case solut smaller valu chosen reason visibl consistency. scheme process figur 2(a). process appli pixel given patch skn obtain set skn contain 3d point inter- section back-project skin pixel view n kth ellipsoid surface. order perform joint analysi set {skn}, set associ weight factor take account real surfac ellipsoid repres singl pixel view n. is, quan- tize effect differ distanc center object camera. weight factor kn es- timat project sphere radiu r = max(sk) camera plane, comput ratio appear area sphere number project pixels. precise, kn estim element skn but, far-field condit max ( sk ) ck 2, n, (14) fulfilled, kn consid constant intersect skn . schemat represent fusion procedur depict figur 2(a). finally, appli process skin patches, obtain fusion color spatial infor- mation set k = {skn ,kn, h k}, 0 n < ncam, head scene. result process shown figur 2(b). 3.5. head pose video likelihood evalu order implement pf take account visual inform solely, visual likelihood evalu function defined. sake simplic notation, let assum person present scene, k . observ vt construct inform provid set . set sn contain- ing 3d euclidean coordin ray-ellipsoid inter- section transform plane , ellipt coor- dinat origin c, describ surfac h . intersect associ weight factor n set transform intersect quantiz 2d quan- tizat step size . process produc visual observ vt (n ,n) understood face map provid planar represent appear head person. exampl represent depict figur 3. groundtruth inform train databas emploi comput averag normal templat face map center = 0, namely, v(n ,n), is, ap- pearanc head person distort factor (bad perform skin detector, camera see face person, etc.). inform emploi defin likelihood func- tion. comput templat face map shown figur 4. cost function defin sum-squar differ function v(,v(n ,n)) comput v ( ,v ( n ,n )) = n k=0 n k=0 ( 1 ( v ( k , k ) v ( k , k ))2) , n = 2 , n = , (15) circular shift operator. function pro- duce small valu valu pan angl hypothesi match angl head produc visual ob- servat v(n ,n). finally, weight particl defin w j t ( j t , v ( n ,n )) = exp ( v v ( j t , v ( n ,n ))) . (16) invers exponenti function pf applic order reflect assumpt measur error cristian canton-ferr et al. 7 (a) (b) 0 (c) 0 (d) figur 3: exampl vt set contain visual inform fed video pf. set differ configur depend appear head person study. experiments, quantiz step = 0.02 0.02 rad employed. imag courtesi univers karlsruhe. 0 figur 4: templat face map obtain annot train databas 10 differ subjects. gaussian [17]. advantag weak hy- pothes finit probabl preserved, desir case spars samples. valu v noncruci valu allow faster converg track > 1 [25]. empir fix v = 50. 4. multimicrophon head pose estim section, present new monomod approach estim head orient acoust signals, make us frequenc depend head radia- tion pattern. propos method effici term comput load simplic requir larg apertur microphon arrai previou work [12]. result describ work deriv set t-shape 4-channel microphon clusters. however, necessari microphon cluster specif geometri locat predefin position. acoust speaker orient approach present work consist essenti find candid sourc locat classifi speech nonspeech, comput high/low band ratio describ follow section microphone, final comput likelihood eval- uation function order implement pf. aim work determin head orientation, assum activ speaker locat known video. robust speaker lo- caliz multimicrophon scenario base srp-phat algorithm address previou research [40]. 4.1. head radiat human speaker radiat speech uniformli direc- tions. general, sound sourc (e.g., loudspeaker) radiat pattern determin size shape frequenc distribut emit sound. like acous- tic radiator, speaker direct increas fre- quenci mouth aperture. infact, radiat pattern time-vari normal speech production, de- pendent lip configuration. work try simul human radiat pattern [41] work accur measur human radiat pattern, show- ing differ male femal speaker dif- ferent languag [42]. figur 5(a) show a-weight typic radiat pat- tern human speaker horizont plane pass mouth. radiat pattern show attenu 2 db speaker (90 270) 6 db back. similarly, vertic radiat pattern uni- 8 eurasip journal advanc signal process 0 2 4 6 8 6 4 2 0 r el iv e le ve l (d b ) speech 90 120 150 180 210 240 270 300 330 0 30 60 horizont plane (a) 14 12 10 8 6 4 2 0 2 h l b r (d b ) 0 20 40 60 80 100 120 140 160 180 angl () (b) figur 5: (a), a-weight head radiat diagram horizont plane. (b), hlbr head radiat pattern. form, example, 3 db attenu speaker head. knowledg human radiat pattern estim head orient activ speaker simpli comput energi receiv microphon search angl best fit radiat pattern energi measures. however, simpl approach problem microphon perfectli calibr differ attenu microphon propag account for, requir us sound propag models. approach, propos comput simplic acoust energi nor- maliz solv aforement problems. energi radiat 200 hz activ speaker low directional. however, frequenc 4 khz radi- ation pattern highli direct [42]. base fact, defin high/low band ratio (hlbr) radiat pattern ratio high low band frequenc radiat pattern observ figur 5(b). instead comput absolut energi receiv microphone, propos comput hlbr acoust energy. valu directli compar microphon since, normalization, effect bad calibr propag loss cancelled. 4.2. high/low band ratio estim video case, assum activ speaker lo- cation known determin c vector ri speaker microphon mi calcu- lated. project vector ri xy plane form angl x-axis. let valu hlbr acoust energi microphon mi. valu normal softmax function [43], wide neural networks, output unit neural network interpret posterior probabilities. softmax normal hlbr valu given = eki n k=1 e kk , (17) k design factor. experiments, k set 20. definit softmax function ensur lie 0 1 sum equal 1. 4.3. speaker orient likelihood evalu work, hlbr head radiat pattern (see figur 5(b)) likelihood evalu func- tion pf. valu i, comput contin- uou approxim hlbr head radiat pat- tern w() = nmic i=0 exp ( ( c )2) , (18) constant c interpol function (18) measur confid estimation. work, c chosen c = , (19) likelihood srp-phat acoust localiza- tion algorithm, threshold depend num- ber microphon [40]. order maintain parallel video coun- terpart, cost function defin follows, audio observ w(): ( ,a ) = 1w(). (20) cristian canton-ferr et al. 9 finally, weight particl defin vi- sual likelihood evalu function: w j t ( j t , ) = exp ( aa ( ,a )) . (21) = 100 provid satisfactori results. 5. multimod integr multimod head orient track base audio video technolog describ previou sections. framework, expect far observ video modal audio modal person smartroom visibl camera dur- ing video frames. moreover, audio estim person head orient she/h speaking. hence, present approach reli primarili video audio inform incorpor correspond video estim multimod fusion process. achiev synchron audio video estim fuse sourc information. combin audio video inform particl filter address past speaker track applications. [19, 44] multipl peopl track- ing base integr audio visual state observ likelihood components. thus, combin probabl audio video data obtain multiply- ing correspond probabl audio video source, assum independ estim comple- mentari modalities. differ context, [25], approach combin differ data articul bodi tracking. [45] multipl speaker track set independ pfs, person. pf mixtur propos distribution, mixtur com- ponent deriv output single-cu trackers. [18] joint audio visual probabl speaker track comput weight averag singl modal probabilities. paper, report advantag modal fusion data level compar deci- sion level fusion. decis level fusion consid base independ pf audio video modalities. thus, estim angl com- pute linear combin audio video estima- tions. second strategi consid independ particl filters, estim angl comput joint expect audio video particles. simpl strategi compar data level fu- sion approach comput combin proba- biliti audio video data [19, 44]. 5.1. decis level fusion strategi present perform inform fu- sion decis level. 0 40 80 120 160 d es 0 100 200 300 400 500 600 700 800 900 1000 frame estim error particl varianc figur 6: pan angl estim error correl disper- sion particl allow construct multimod estimators. (i) linear combin monomod angl estim pan angl estim provid audio video particl filters, v t , respectively, linearli com- bine produc av1t accord formula av1 t = 1 1/at 2 + 1/vt 2 ( 1 2 t + 1 vt 2 v t ) , (22) 2 vt 2 refer varianc audio video estim normal process. moreover, varianc figur (relat dispers parti- cles) understood magnitud relat es- timat error. effect depict figur 6 shown correl pan angl estim error variance. (ii) particl combin decis level fusion perform expec- tation taken monomod pf (see (8)). indeed, par- ticl gener monomod pf contain inform sampl audio video pdf s: p(t | a1:t) p(t | v1:t). joint expect comput particl come audio video pf av2 t = e [ t | a1:t,v1:t ] ns j=1 ( w a, j t a, j t +w v, j t v, j t ) , (23) enforc ns j=1 w a, j t + ns j=1 w v, j t = 1. (24) 10 eurasip journal advanc signal process (a) (b) figur 7: imag experiment cases. (a), speaker bow head laptop video-bas head orient esti- mation produc accur result (red vector) audio estim (green vector) gener accur output. estim reliabl proport vector length. (b), exampl estim output correct result. 5.2. data level fusion video pf estim head orient angl take ac- count frontal face defin orienta- tion. hand, audio pf estim angl ex- ploit fact maximum hlbr function head radiat pattern correspond mouth region. multimod inform fusion data level take account speech produc frontal head. correl modal model work defin joint likelihood func- tion p(t | a1:t,v1:t) exploit depend audio video sources. article, multimod weight defin w mm, j t ( j t , t , v t ) = exp ( mm ( ( j t , t ) + v v ( j t , v t ))) , (25) v empir estim weight param- eter control influenc modality. com- pare perform monomod estim (see section 6), paramet b set exper- iment = 0.6, v = 0.4 provid satisfactori results. converg paramet set mm = 100. 6. result order evalu perform propos algo- rithms, emploi clear 2006 head pose databas [31] contain set scene indoor scenario person give talk, approxim 15 minutes. order provid meaning compar result mono- multimod approaches, subject studi evalu databas speaking, is, audio video inform available. analysi sequenc record 4 fulli calibr camera resolut 720 576 pixel 25 fp 4 microphon cluster arrai sampl frequenc 44 khz. au- dio video sensor synchronized. head local assum avail aim research estim orientation. nevertheless, result head lo- caliz specif report author tabl 1: quantit result present system show multimod approach outperform monomod ap- proaches. method pmae () pcc (%) pccr (%) video 59.52 24.68 64.21 audio 47.84 31.84 71.90 mm featur fusion type 1 49.09 28.21 73.29 mm featur fusion type 2 44.04 34.54 75.27 mm data fusion 30.61 48.99 83.69 [15, 46]. complet databas devised, exist databas design task author knowledge. metric propos [31] head pose evalu adopted: pan mean averag error (pmae), measur precis head orient angl term degrees; pan correct classif (pcc), show abil correctli classifi head posi- tion 8 class span 45 each; pan correct classif rang pcc, show perfor- manc classifi head pose 8 class allow classif error 1 adjac class. experi conduct article, fix number particl set pf, ns = 100. experiment result prove emploi particl report better perform system. system present paper (video, audio, multimod fusion decis data level) evalu 3 measur comput order com- pare performance. tabl 1 summar obtain result multimod approach out- perform monomod techniqu expected. improv achiev multimod approach twofold. first, error estim angl (pmae) decreas combin estim and, secondly, classif per- formanc score (pcc pcc) increas failur modal compens other. compar result provid clear 2006 evalu [31], rank 2nd posit 5 partic- ipants. visual result provid figur 7 show cristian canton-ferr et al. 11 multimod approach allow enhanc result modal fails. 7. conclus futur work us particl filter prove us unifi framework estim head orien- tation monomod multimod case term accuraci robust clear 2006 evalu database. monomod head pose estimation, good result obtain video estim base 3d reconstruct head and, especially, novel au- dio estim base direct characterist head radiat pattern. multimod head pose estimation, slightli better result obtain linear combi- nation monomod estim better re- sult reach particl combin decis level. however, current scenario, us joint par- ticl filter fusion video audio stream data level yield best results, achiev rel 42% reduc- tion classif error rate best monomod estimation. futur research line aim design adapt modal- iti weight algorithm multimod data level fusion estim automat set valu b. analysi produc data track attent multipl peopl meet understand behavior individ- ual study. acknowledg author like express gratitud andrei temko fruit discussions. refer [1] m. black, f. berard, a. jepson, et al., digit office: over- view, proceed aaai spring symposium intel- ligent environments, pp. 98102, palo alto, calif, usa, march 1998. [2] p. chiu, a. kapuskar, s. reitmeier, l. wilcox, room rear view: meet captur multimedia confer room, ieee multimedia, vol. 7, no. 4, pp. 4854, 2000. [3] chil-comput human interact loop, chil.server.de/. [4] c. wang, s. griebel, m. brandstein, robust automat video-conferenc multipl camera microphones, proceed ieee intern confer multi- media expo (icm 00), vol. 3, pp. 15851588, new york, ny, usa, july-august 2000. [5] p. ballard g. c. stockman, control facial aspect, ieee transact systems, man, cyber- netics, vol. 25, no. 4, pp. 669677, 1995. [6] t. horprasert, y. yacoob, l. s. davis, comput 3-d head orient monocular imag sequence, pro- ceed 2nd intern confer automat face gestur recognition, pp. 242247, killington, vt, usa, oc- tober 1996. [7] r. rae h. j. ritter, recognit human head orienta- tion base artifici neural networks, ieee transact neural networks, vol. 9, no. 2, pp. 257265, 1998. [8] m. voit, k. nickel, r. stiefelhagen, neural network- base head pose estim multi-view fusion, pro- ceed 1st intern clear evalu workshop (clear 06), vol. 4122 lectur note science, pp. 291299, southampton, uk, april 2006. [9] n. gourier, j. maisonnasse, d. hall, j. l. crowley, head pose estim low resolut images, pro- ceed 1st intern clear evalu workshop (clear 06), vol. 4122 lectur note science, pp. 270280, southampton, uk, april 2006. [10] l. zhao, g. pingali, i. carlbom, real-tim head orienta- tion estim neural networks, proceed ieee intern confer imag process (icip 02), vol. 1, pp. 297300, rochester, ny, usa, septemb 2002. [11] x. l. c. brolly, c. stratelos, j. b. mulligan, model- base head pose estim air-traff controllers, pro- ceed ieee intern confer imag process (icip 03), vol. 2, pp. 113116, barcelona, spain, septemb 2003. [12] j. m. sachar h. f. silverman, baselin algorithm es- timat talker orient acoust data large- apertur microphon array, proceed ieee interna- tional confer acoustics, speech, signal process (icassp 04), vol. 4, pp. 6568, montreal, canada, 2004. [13] a. brutti, m. omologo, p. svaizer, orient global coher- enc field estim head orient smart room equip distribut microphon arrays, pro- ceed 9th european confer speech communica- tion technolog (interspeech 05), pp. 23372340, lisbon, spain, septemb 2005. [14] c. segura, c. canton-ferrer, a. abad, j. r. casas, j. hernando, multimod head orient attent track smart rooms, proceed ieee interna- tional confer acoustics, speech, signal process (icassp 07), vol. 2, pp. 681684, honolulu, hawaii, usa, april 2007. [15] c. canton-ferrer, j. r. casas, m. pardas, fusion multi- ple viewpoint inform 3d face robust orient detection, proceed ieee intern confer imag process (icip 05), vol. 2, pp. 366369, genova, italy, septemb 2005. [16] h. r. hashemipour, s. roy, a. j. laub, decentr structur parallel kalman filtering, ieee transact automat control, vol. 33, no. 1, pp. 8894, 1988. [17] m. isard a. blake, condensationcondit den- siti propag visual tracking, intern journal vision, vol. 29, no. 1, pp. 528, 1998. [18] k. nickel, t. gehrig, r. stiefelhagen, j. mcdonough, joint particl filter audio-visu speaker tracking, pro- ceed 7th intern confer multimod in- terfac (icmi 05), pp. 6168, torento, italy, octob 2005. [19] d. gatica-perez, g. lathoud, j.-m. odobez, i. mccowan, audiovisu probabilist track multipl speaker meetings, ieee transact audio, speech languag processing, vol. 15, no. 2, pp. 601616, 2007. [20] j. r. casas, r. stiefelhagen, k. bernardin, et al., multicam- era/multi-microphon design continu room monitoring, deliver chil-wp4-d4.1-v2.1-2004-07-08- co, chilip506909comput human interact loop, juli 2004. [21] r. stiefelhagen, track focu attent meetings, proceed 4th ieee intern confer multi- modal interfac (icmi 02), pp. 273280, pittsburgh, pa, usa, octob 2002. 12 eurasip journal advanc signal process [22] m. west j. harrison, bayesian forecast dynam models, springer, new york, ny, usa, 2nd edition, 1997. [23] m. s. arulampalam, s. maskell, n. gordon, t. clapp, tutori particl filter onlin nonlinear/non-gaussian bayesian tracking, ieee transact signal processing, vol. 50, no. 2, pp. 174188, 2002. [24] n. j. gordon, d. j. salmond, a. f. m. smith, novel ap- proach nonlinear/non-gaussian bayesian state estimation, iee proceed fradar signal processing, vol. 140, no. 2, pp. 107113, 1993. [25] j. deutscher i. reid, articul bodi motion captur stochast search, intern journal vision, vol. 61, no. 2, pp. 185205, 2005. [26] j. vermaak, c. andrieu, a. doucet, s. j. godsill, particl method bayesian model enhanc speech signals, ieee transact speech audio processing, vol. 10, no. 3, pp. 173185, 2002. [27] c. wang m. brandstein, robust head pose estim machin learning, proceed ieee intern confer- enc imag process (icip 00), vol. 3, pp. 210213, van- couver, bc, canada, septemb 2000. [28] y. matsumoto a. zelinsky, algorithm real-tim stereo vision implement head pose gaze direc- tion measurement, proceed 4th ieee interna- tional confer automat face gestur recognition, pp. 499504, grenoble, france, march 2000. [29] m.-y. chen a. hauptmann, robust face recog- nition multipl views, proceed ieee interna- tional confer multimedia expo (icm 04), vol. 2, pp. 11911194, taipei, taiwan, june 2004. [30] z. zhang, y. hu, m. liu, t. huang, head pose estima- tion seminar room multi view face detectors, pro- ceed 1st intern clear evalu workshop (clear 06), vol. 4122 lectur note science, pp. 299304, southampton, uk, april 2006. [31] clear evalu campaign, 2006, uation.org/. [32] o. lanz, approxim bayesian multibodi tracking, ieee transact pattern analysi machin intelligence, vol. 28, no. 9, pp. 14361449, 2006. [33] b. wu, v. k. singh, r. nevatia, c.-w. chu, speaker track seminar human bodi detection, pro- ceed 1st intern clear evalu workshop (clear 06), vol. 4122 lectur note science, pp. 119126, southampton, uk, april 2006. [34] a. pnevmatikaki l. polymenakos, 2d person track kalman filter adapt background learn feedback loop, proceed 1st intern clear evalu workshop (clear 06), vol. 4122 lectur note science, pp. 151160, southampton, uk, april 2006. [35] c. canton-ferrer, j. r. casas, m. pardas, bayesian approach robust find correspond mul- tipl view geometri environments, proceed 5th intern confer comput scienc (icc 05), vol. 3515 lectur note science, pp. 281289, atlanta, ga, usa, 2005. [36] r. i. hartlei a. zisserman, multipl view geometri vision, cambridg univers press, cambridge, uk, 2004. [37] c. stauffer w. e. l. grimson, adapt background mix- ture model real-tim tracking, proceed ieee societi confer vision pattern recognit (cvpr 99), vol. 2, pp. 252258, fort collins, colo, usa, june 1999. [38] i. mikic, m. trivedi, e. hunter, p. cosman, articul bodi postur estim multi-camera voxel data, proceed ieee societi confer vision pattern recognit (cvpr 01), vol. 1, pp. 455460, kauai, hawaii, usa, decemb 2001. [39] m. j. jone j. m. rehg, statist color model ap- plicat skin detection, intern journal vision, vol. 46, no. 1, pp. 8196, 2002. [40] a. abad, c. segura, d. macho, j. hernando, c. nadeu, audio person track smart-room environment, proceed 9th european confer speech com- munic technolog (interspeech 05), lisboa, portugal, septemb 2005. [41] p. c. meus h. f. silverman, character talker radiat pattern microphon array, proceed ieee intern confer acoustics, speech, sig- nal process (icassp 94), vol. 2, pp. 257260, adelaide, sa, australia, april 1994. [42] w. t. chu a. c. warnock, detail direct sound field human talkers, tech. rep., institut research construction, ontario, canada, 2002. [43] a. tuerk s. j. young, polynomi softmax function pattern classification, 2001. [44] n. checka, k. w. wilson, m. r. siracusa, t. darrell, mul- tipl person speaker activ track particl filter, proceed ieee intern confer acoustics, speech, signal process (icassp 04), vol. 5, pp. 881884, montreal, canada, 2004. [45] y. chen y. rui, real-tim speaker track particl filter sensor fusion, proceed ieee, vol. 92, no. 3, pp. 485494, 2004. [46] a. lopez, c. canton-ferrer, j. r. casas, multi-person 3d track particl filter voxels, proceed ieee intern confer acoustics, speech, sig- nal process (icassp 07), honolulu, hawaii, usa, april 2007. introduct analysi framework particl filter pf appli multimod head pose estim video head pose estim spatial analysi color analysi head model fit 3d head appear gener head pose video likelihood evalu multimicrophon head pose estim head radiat high/low band ratio estim speaker orient likelihood evalu multimod integr decis level fusion (i) linear combin monomod angl estim (ii) particl combin data level fusion result conclus futur work acknowledg refer