coi32404.dvi n-gram-bas machin translat jose b. marino rafael e. banch josep m. crego adria gispert patrik lambert jose a. r. fonollosa marta r. costa-jussa universitat politecnica catalunya articl describ n-gram approach statist machin translation. ap- proach consist log-linear combin translat model base n-gram bilingu units, refer tuples, specif featur functions. translat performance, happen state art, demonstr spanish-to-english english-to-spanish translat european parliament plenari session (epps). 1. introduct begin statist machin translat (smt) trace earli fifties, close relat idea inform theori aros (shannon weaver 1949) inspir work cryptographi (shannon 1949, 1951) worldwar ii. accord view, machin translat conceiv problem find sentenc decod given encrypt version (weaver 1955). idea feasible, enthusiasm fade shortli afterward comput limit time (hutchin 1986). finally, nineties, factor possibl smt actual practic technology: first, signific increment comput power storag capac computers, second, avail larg volum bilingu data. smt systemswer develop earli nineti (brown et al. 1990, 1993). system base so-cal noisi channel approach, model probabl target languag sentenc t given sourc languag sentenc s product translation-model probabl p(s|t), account adequaci trans- lation contents, time target languag probabl p(t), account fluenci target constructions. smt systems, translation-model probabl sentenc level approxim word-bas translat model train bilingu corpora (brown et al. 1993). case target languag probabilities, gener train monolingu data n-grams. present smt system evolv origin on wai mainli differ respects: first, word-bas translat model depart signal theori communications, campu nord, barcelona 08034, spain. submiss received: 9 august 2005; revis submiss received: 26 april 2006; accept publication: 5 juli 2006 2006 associ comput linguist comput linguist volum 32, number 4 replac phrase-bas translat model (zens, och, nei 2002; koehn, och, andmarcu 2003) directli estim align bilingu corpora consid- er rel frequencies, second, noisi channel approach expand gener maximum entropi approach log-linear combin multipl featur function implement (och nei 2002). extens machin translat problem, technolog advanc field automat speech recognit (asr) text speech synthesi (tts) possibl envis challeng spoken languag translat (slt) (kay, gawron, norvig 1992). accord this, smt approach finite-st point view natur wai integr asr smt (riccardi, pieraccini, bocchieri 1996; vidal 1997; knight al-onaizan 1998; bangalor riccardi 2000). smt approach, translat model implement mean finite- state transduc transit probabl learn bilingu data. oppos phrase-bas translat models, consid probabl target sourc unit refer phrases, finite-st translat model reli probabl sequenc bilingu units, defin transit transducer. translat describ articl implement translat model deriv finite-st perspectivemor specifically, work casacuberta (2001) casacuberta vidal (2004). however, earlier work translat model implement finite-st transducer, sys- tem present translat model implement n-grams. way, propos translat advantag smooth consist- enci provid standard back-off n-gram models. translat model present actual constitut languag model sort bilanguag compos bilin- gual units, refer tupl (de gispert andmarino 2002). alterna- tive approach, reli bilingual-unit unigram probabilities, develop tillmann xia (2003); contrast, approach present consid bilingual- unit n-gram probabilities. addit tupl n-gram translat model, translat present implement specif featur function log-linearli combin translat model perform decod (marino et al. 2005). articl intend provid detail descript n-gram-bas translat system, demonstr perform wide- domain, large-vocabulari translat task. articl structur follows. first, section 2 present complet descript n-gram-bas translat model. then, section 3 describ addit featur function that, trans- lation model, compos n-gram-bas smt implemented. section 4 describ european parliament plenari session (epps) data, relev detail translat task considered. section 5 present discuss translat experi results. finally, section 6 present conclus intend work. 2. tupl n-grammodel section describ tupl n-gram translat model, constitut core model implement n-gram-bas smt system. first, bilingu unit definit model comput present section 2.1. then, import refin basic translat model provid discuss section 2.2. finally, section 2.3 discuss issu relat n-gram-bas decoding. 528 marino et al. n-gram-bas machin translat 2.1 tupl extract model comput mentioned, translat model implement describ smt sys- tem base bilingu n-grams. model actual constitut languag model particular bilanguag compos bilingu unit refer tuples. way, translat model probabl sentenc level approxim n-gram tuples, describ follow equation: p(t,s) k k=1 p((t, s)k|(t, s)k1, (t, s)k2, . . . , (t, s)kn+1) (1) t refer target, s source, (t, s)k kth tupl given bilingu sentenc pair. import note languag link tuples, context inform provid translat model bilingual. tupl extract word-to-word align corpu wai uniqu segment bilingu corpu achieved. principl viterbi align allow tupl extraction, result tupl vocabulari depend highli particular align set considered, impact trans- lation results. accord experience, best perform achiev union source-to-target target-to-sourc align set (ibm models; brown et al. [1993]) tupl extract (some experiment result issu present section 4.2.2). additionally, us union justifi theoret point view consid union set typic exhibit higher recal valu align set intersect source-to-target. way, oppos implementations, one-to-on (bangalor riccardi 2000) one-to-mani (casacuberta vidal 2004) align used, tupl extract many-to-mani alignments. implement produc monoton segment bilingu sentenc pairs, allow simulta- neousli captur contextu reorder inform bilingu translat unit structures. segment allow estim n-gram probabil- iti appear (1). order guarante uniqu segment corpus, tupl extract perform accord follow constraint (crego, marino, gispert 2004): monoton segment bilingu sentenc pair produced, word insid tupl align word outsid tuple, smaller tupl extract violat previou constraints. notic that, accord this, tupl formal defin set shortest phrase provid monoton segment bilingu corpus. figur 1 present simpl exampl illustr uniqu tupl segment given pair sentences, complet phrase set. import observ figur 1 relat possibl occurr tupl contain unalign element target side. case tupl 1. tupl kind handl altern wai abl provid appropri translat unalign elements. problem 529 comput linguist volum 32, number 4 figur 1 exampl tupl extraction. tupl extract viterbi align wai set shortest bilingu unit provid monoton segment bilingu sentenc pair achieved. handl kind situation, refer involv source-nul tuples, discuss section 2.2.2. also, observ figur 1, total number tupl significantli lower total number phrases, and, cases, longer phrase construct consid tupl n-grams, case phrase 2, 6, 7, 9, 10, 11. however, phrase 4 5 gener tuples. general, tupl represent abl provid translat individu word appear ti word occur tuple. problem, refer embed words, discuss section 2.2.1. import observ figur 1 tupl length implicitli defin word link alignment. oppos phrase-extract proce- dures, maximum phrase length defin avoid vocabulari explosion, tupl extract procedur control tupl lengths. accord this, tupl approach strongli benefit structur similar languag consideration. then, close languag pairs, tupl expect successfulli handl short reorder pattern includ tupl structure, case traduccion perfecta : perfect translat present figur 1. hand, case distant pair languages, larg number long tupl expect occur, approach easili fail provid good translat model tupl sparseness. 2.2 translat model refin basic n-gram translat model, defin previou section, exhibit import limit easili overcom incorpor specif chang 530 marino et al. n-gram-bas machin translat tupl vocabulari n-grammodel. section describ limit provid detail descript implement refinements. 2.2.1 embeddedwords. issu n-gram translationmodel relat mention problem embed words, refer fact tupl represent abl provid translat individu word time. embed word drawback occur rel signific number tupl vocabulary. consid exampl word translat figur 1. seen figure, word appear embed tupl traduccion perfecta : perfect translations. similar situat encount occurr word train corpus, translat probabl independ occurr word exist. relev exampl case embed word perfect adject move rel noun modifying. case, provid translat word-to-word translat probabl per- fecta : perfect guarante decod translat option isol occurr word guarante word order. so, certainly, adjectivenoun combin includ word perfect, seen train stage, translat wrong order. accordingly, problem result embed word partial solv incorpor bilingu dictionari abl provid word-to-word translat requir translat system. complet treatment problem consid implement word-reord strategi propos smt approach (a discuss section 6, constitut main concern research). n-gram-bas smt implementation, follow strategi handl em- bed word considered. first, one-word tupl detect embed word extract train data correspond word-to-word translat probabl comput rel frequencies. then, tupl n-gram model enhanc includ embedded-word tupl unigram model. high-precis align set desir extract one-word tupl estim probabilities, intersect alignments, sourc target target-to-source, instead union. particular case epp task consid work, embed word constitut real problem great train materi reduc size test data set (see section 4.1 detail descript epp data set). contrary, translat task avail train material, embedded-word handl strategi describ us (de gispert, marino, crego 2004). 2.2.2 tupl sourc sides. second import issu n-gram translat model relat tupl sourc sides, hereinaft refer source-nul tuples. tupl n-gram model implementation, fre- quentli happen target word link null end produc tupl null sourc sides. consider, example, tupl exampl present figur 1. example, null : source-nul tupl spanish consid sourc language. notic tupl kind allow null expect occur translat input. classic solut problem finite-st transduc framework inclus epsilon arc (knight al-onaizan 1998; bangalor riccardi 531 comput linguist volum 32, number 4 2000). however, epsilon arc significantli increas decod complexity. n-gram implementation, problem easili solv preprocess union set align extract tuples, wai target word link null attach preced word follow word. way, target word remain link null, source-nul tupl occur tupl extraction. differ strategi handl target word align null considered. simplest strategy, whichwil refer attach-to-right strat- egy, target word align null attach follow word. simpl strategi happen provid better results, english-to-spanish spanish- to-english translations, opposit (attach previou word), better sophist strategi consid bigram probabl decid given word attach follow pre- viou one. notic particular case spanish english, attach-to-right strat- egi justifi heuristically. indeed, translat spanish english, source-nul tupl result omit verbal subjects, common situat spanish. case tupl figur 1. suppose, instance, attach-to-right strategi figur 1; case, tupl quisieramo : like replac new tupl quisieramo : like, actual make better translat unit, grammat point view. similarly, common situat identifi translat english-to-spanish direction, omit determin (e.g., want inform european countri : quiero informacion sobr lo pase europeos). again, attach-to-right strategi unalign spanish determin lo best one. experiment result compar attach-to-right strategi addit strat- egi base statist translat lexicon provid section 5.1.3. 2.2.3 tupl vocabulari pruning. issu n-gram transla- tion model relat comput cost result tupl vocabulari size decoding. idea refin reduc comput time storag requir degrad translat performance. n-gram- base smt implementation, tupl vocabulari prune histogram counts. prune perform keep thenmost frequent tupl common sourc sides. notic pruning, perform comput tupl n-gram probabilities, direct impact translat model probabl overal performance. reason, prune paramet n critic effici usag translat system. low valu n significantli decreas translat quality, hand, larg valu n provid translat qualiti adequ n, signific increment comput costs. optim valu paramet depend data adjust empir consid translat task. 2.3 n-gram-bas decod decod n-gram-bas translat model slightli differ phrase- base decoding. reason, specif decod tool implemented. 532 marino et al. n-gram-bas machin translat section briefli describ marie, n-gram base search engin develop smt (crego, marino, gispert 2005a). mari implement beam-search strategi base dynam programming. decod perform monoton guid source. decoding, partial-transl hypothes arrang differ stack accord total number sourc word cover. way, given hypothesi compet hypothes provid source-word coverage. translat step, stack prune decod tractable. mari allow differ prune methods: threshold pruning: partial-transl hypothes score predetermin threshold valu eliminated. histogram pruning: maximum number partial-transl hypothes consid limit k-best rank ones. additionally, mari allow hypothesi recombination, provid effici search. implement algorithm, partial-transl hypothes re- combin coincid exactli present tupl tupl trigram history. mari allow consid addit featur function decoding. model taken account simultaneously, n-gram trans- lation model. smt implementation, addit featur function considered. function describ section 3.2. 3. featur function n-gram-bas smt section describ featur function implement n-gram translat model complet translat system. first, subsect 3.1, log-linear combin framework implement optim proce- dure discussed. then, specif featur function constitut smt detail section 3.2. 3.1 log-linear combin framework mention introduction, recent translat system noisi channel ap- proach replac gener approach, found princi- ple maximum entropi (berger, della pietra, della pietra 1996). approach, correspond translat given sourc languag sentenc s defin target languag sentenc maxim log-linear combin multipl featur function hi(s,t) (och nei 2002), describ follow equation: argmax t m mhm(s,t) (2) m repres coeffici mth featur function hm(s,t), ac- tualli correspond log-scal version mth-model probabilities. optim valu m coeffici estim optim procedur develop data set. 533 comput linguist volum 32, number 4 3.2 translat featur addit tupl n-gram translat model, n-gram-bas smt implement featur functions: target-languag model, word-bonu model, lexicon models. featur describ next. 3.2.1 target-languag model. featur provid inform target lan- guag structur fluency. favor partial-transl hypothes like constitut correctli structur target sentenc not. model implement word n-gram model target language, comput accord follow expression: htl(t,s) = htl(t) = log k k=1 p(wk|wk1,wk2, . . . ,wkn+1) (3) wk refer kth word consid partial-transl hypothesis. notic model depend target data, fact train includ addit inform avail monolingu corpora. 3.2.2 word-bonu model. featur introduc bonu depend partial- translat hypothesi length. compens prefer short translat larg ones. model implement bonu factor directli depend total number word contain partial-transl hypothesis, comput follows: hwp(t,s) = hwp(t) = m (4) wherem number word contain partial-transl hypothesis. 3.2.3 source-to-target lexicon model. featur actual constitut complemen- tari translat model. model provides, given tuple, translat probabl estim sourc target sides. featur implement ibm-1 lexic paramet (brown et al. 1993; och et al. 2004). accordingly, source- to-target lexicon probabl comput tupl accord follow equation: hlf(t,s) = log 1 (i + 1)j j j=1 i=0 q(tnj |s n ) (5) sni t n j ith jth word sourc target side tupl (t, s)n, j correspond total number word side. equation, q(.) refer ibm-1 lexic parameters, estim align comput source-to-target direction. 3.2.4 target-to-sourc lexicon model. similar previou feature, featur function constitut complementari translat model too. comput ex- 534 marino et al. n-gram-bas machin translat actli wai previou model is, differ ibm-1 lexic paramet estim align comput target-to-sourc direct instead. 4. epp translat task section describ relev issu translat task con- sidered. section 4.1 describ epp data set used, section 4.2 present overal implement detail regard preprocessing, training, optimization. 4.1 corpu descript epp data set compos offici plenari session transcript eu- ropean parliament, current avail differ languag (koehn 2002). however, case result present here, spanish english version epp data prepar rwthaachen univers context european project tc-star. training, development, test data includ session transcript april 1996 septemb 2004, octob 21 octob 28, 2004, novemb 15 novemb 18, 2004, respectively. tabl 1 present basic statist training, development, test data set consid language. specifically, statist shown tabl 1 number sentences, number words, vocabulari size (or number distinct words), averag sentenc length number words, number avail translat references. seen tabl 1, total number word train set similar languages, vocabulari size substanti different. indeed, spanish vocabulari approxim 60% larger english vocabulary. explain inflect natur spanish, particularli evid case nouns, adjectives, verbs, differ form de- pend gender, number, tense, mode. seen result present section 5, differ vocabulari size import consequ translat qualiti english-to-spanish direction. develop data set, 1, 008 sentenc considered. notic tabl 1 case, spanish vocabulari 20% larger english tabl 1 basic statist training, development, test data set (m k stand million thousands, respectively; lmean refer averag sentenc length number words, ref. number avail translat references). set languag sentenc word vocabulari lmean ref. train english 1.22 m 33.4 m 105 k 23.7 1 spanish 1.22 m 34.8 m 169 k 28.4 1 dev. english 1008 26.0 k 3.2 k 25.8 3 spanish 1008 25.7 k 3.9 k 25.5 3 test english 1094 26.8 k 3.9 k 24.5 2 spanish 840 22.7 k 4.0 k 27.0 2 535 comput linguist volum 32, number 4 vocabulary. import issu develop data set number unseen words, is, word present develop data present train data. case, 35 word (0.13%) total number word english develop set occur train data. 35 words, 30 correspond differ words. similarly, 61 word (0.24%) total number word spanish develop set train data. case, 57 differ word occurred. notic tabl 1 differ test set translat direction, differ number sentenc consid case, vocabulari size equivalent. unseenwords, case, 112 word (0.42%) total number word english test set occur train data. 112 words, 81 correspond differ words. similarly, 46 word (0.20%) total number word spanish test train data. case, 40 differ word occurred. 4.2 preprocessing, training, optim section present overal implement detail regard preprocessing, training, optim translat system. languages, english span- ish, translat direct consid differ configurations. 4.2.1 preprocess alignment. train data preprocess stan- dard tool token filtering. filter stage, sentenc pair remov train data allow better perform align tool. sentenc pair remov accord follow criteria: fertil filtering: remov sentenc pair word ratio larger predefin threshold value. length filtering: remov sentenc pair sentenc 100 word length. help maintain bound align comput times. preprocessing, word-to-word align perform directions, source-to-target target-to-source. implementation, giza++ (och nei 2000) comput alignments. total iter model ibm-1 hmm, iter model ibm-3 ibm-4, performed. then, obtain align set comput intersect union align tupl embedded-word tupl extracted, respectively. 4.2.2 tupl extract pruning. tupl set translat direct ex- tract union set align avoid source-nul tupl procedur describ section 2.2.2. then, result tupl vocabulari prune accord procedur describ section 2.2.3. case epp data consideration, prune paramet valu n = 20 n = 30 spanish-to-english english-to-spanish, respectively. order better justifi align set prune paramet selections, tabl 2 3 present model size translat accuraci tupl n-grammodel 536 marino et al. n-gram-bas machin translat tabl 2 tupl vocabulari size correspond number n-gram (in millions), translat accuraci tupl extract differ align sets. notic bleu measur tabl correspond translat comput tupl n-gram model alone. direct align set tupl voc. bigram trigram bleu es en source-to-target 1.920 6.426 2.353 0.4424 union 2.040 6.009 1.798 0.4745 refin 2.111 6.851 2.398 0.4594 en es source-to-target 1.813 6.263 2.268 0.4152 union 2.023 6.092 1.747 0.4276 refin 2.081 6.920 2.323 0.4193 tupl extract differ align set differ prune paramet used, respectively. translat accuraci measur term bleu score (papineni et al. 2002), comput translat gener tupl n-gram model alone, case tabl 2, tupl n-gram model addit featur function describ section 3.2, case tabl 3. translat directions, spanish english (e en) english spanish (en es), consid table. case tabl 2, model size translat accuraci evalu type align set extract tuples. differ align set considered: source-to-target, union source-to-target target-to-source, refin align method describ och andnei (2003). result present tabl 2, prune paramet valu n = 20 spanish-to-english direction, valu n = 30 english-to-spanish direction. clearli seen tabl 2, union align set happen favor extract tupl translat direct provid significantli better translat accuracy, term bleu score, align set considered. notic tabl 2 union set provid smallest model size accord number bigram trigrams. explain improv observ translat accuracy, respect cases, term model sparseness. tabl 3 tupl vocabulari size correspond number n-gram (in millions), translat accuraci differ prune valu translat directions. notic bleu measur tabl correspond translat comput tupl n-gram model addit featur function describ section 3.2. direct prune tupl voc. bigram trigram bleu es en n = 30 2.109 6.233 1.805 0.5440 n = 20 2.040 6.009 1.798 0.5434 n = 10 1.921 5.567 1.759 0.5399 en es n = 30 2.023 6.092 1.747 0.4688 n = 20 1.956 5.840 1.733 0.4671 n = 10 1.843 5.342 1.677 0.4595 537 comput linguist volum 32, number 4 case tabl 3, model size translat accuraci compar differ prune conditions:n = 30,n = 20, andn = 10. case present table, tupl extract union set alignments. notic tabl 3 translat accuraci clearli affect pruning. case spanish english, valu n = 20 n = 10, provid tupl vo- cabulari reduct 3.27% 8.91% respect n = 30, respectively, produc translat bleu score reduct 0.11% 0.75%. hand, case english spanish, valu n = 20 n = 10 provid tupl vocabulari reduct 3.31% 8.89% translat bleu score reduct 0.36% 1.98% respect n = 30, respectively. accord results, similar tupl vocabulari reduct affect english-to-spanish translat af- fect spanish-to-english translations. reason, final adopt n = 20 n = 30 prune paramet valu spanish english english spanish, respectively. import observ deriv tabl 3 higher bleu score valu respect on present tabl 2. because, mention above, result present tabl 3 obtain consid translat implement tupl n-gram model addit featur function describ section 3.2. rel impact describ featur function translat accuraci studi section 5.1.1. 4.2.3 translat model featur function training. pruning, tupl n-gram model train translat direct sri languag model toolkit (stolck 2002). option knesernei smooth (kneser nei 1995) interpol higher lower n-gram trainings. then, tupl n-gram translat model final enhanc includ unigram probabil- iti embedded-word tupl describ section 2.2.2. similarly, word n-gram target languag model train translat direct sri languag model toolkit. again, case tupl n-gram model, knesernei smooth interpol higher lower n-gram used. extend target languag model obtain ad addit inform avail monolingu corpora. however, translat task describ here, target languag model estim inform contain target train data set. smt implementation, trigram model consid tupl translat model target languag model. select base perplex measur (over develop data set) obtain n-gram model comput epp train data differ n-gram sizes. tabl 4 present tabl 4 perplex measur translat target languag model differ n-gram sizes. type model languag bigram trigram 4-gram 5-gram translat es en 201.75 161.26 156.88 157.24 translat en es 223.94 179.12 174.10 174.49 languag spanish 81.98 52.49 48.03 47.54 languag english 78.91 50.59 46.22 45.59 538 marino et al. n-gram-bas machin translat perplex valu obtain translat target languag model differ n-gram sizes. implement trigram models, perform translat system differ n-gram size model evaluated. result pre- sent discuss section 5.1.2. finally, source-to-target target-to-sourc lexicon model comput translat direct accord procedur describ section 3.2.3. consid lexicon model, align set source-to-target direct align set target-to-sourc direct used, accordingly. 4.2.4 optimization. model computed, set optim log-linear coeffici estim translat direct configur optim procedure, describ follows. first, develop data set overlap train set test set required. then, trans- lation qualiti develop set maxim iter vari set coefficients. smt implementation, optim procedur per- form tool develop in-house, base simplex method (press et al. 2002), bleu score (papineni et al. 2002) translat qualiti measurement. describ section, differ configur consid experiments. optimizations, develop data describ tabl 1 used. present table, develop data includ translat refer english spanish, comput bleu score iter optim procedures. decod set optimizations. set following: decod perform monotonically, is, reorder capabl used, decod guid sourc sentenc translated, avail decoder, threshold prune used, valu k = 50 during-decod histogram prune used. 5. translat experi error analysi section present translat experi perform brief error analysi obtain results. order evalu rel contribut differ element overal perform n-gram-bas translat system, differ experiment set considered. experi re- sult describ section 5.1, brief error analysi result present section 5.2. finally, comparison n-gram-bas smt state-of-the-art phrase-bas translat system present section 5.3. 5.1 translat experi result mentioned, experiment set considered. setting, impact translat qualiti differ paramet evaluated, namely, 539 comput linguist volum 32, number 4 featur function, n-gram size, source-nul tupl strategy. evalu experiment set perform respect standard configuration, defin term follow parameters: align set tupl extraction: union tupl vocabulari prune parameter: n = 20 spanish english, n = 30 english spanish n-gram size translat model: 3 n-gram size target languag model: 3 expand translat model embedded-word tuples: ye source-nul tupl handl strategy: attach-to-right featur function considered: target language, word-bonus, source-to-target lexicon, target-to-sourc lexicon experiment set considered, present follow subsections, total seven differ configur evalu translat directions, english spanish spanish english. thus, total 14 differ translat experi performed. cases, corre- spond test set translat correspond estim model set optim coefficients. decod set (which previous describ section 4.2.4) optim translat experiments. translat result evalu term mwer bleu refer avail languag test set. 5.1.1 featur function contributions. experi design evalu rel contribut featur function overal performance. section, differ system evaluated. system are: a. constitut basic n-gram translat system, implement tupl trigram translat model alone, is, addit featur function used. b. target-reinforc system. system, translat model target-languag word-bonu models. c. lexicon-reinforc system. system, translat model source-to-target target-to-sourc lexicon models. d. constitut system, is, translat model addit featur functions. correspond standard configur defin begin section 5.1. tabl 5 summar result evaluation, term bleu mwer, system considered. seen table, translat directions, 540 marino et al. n-gram-bas machin translat tabl 5 evalu result experi featur function contribution. direct lm wb s2t t2 mwer bleu es en 39.71 0.4745 b 0.29 0.31 39.51 0.4856 c 0.77 0.08 35.77 0.5356 d 0.49 0.30 0.94 0.25 34.94 0.5434 en es 44.46 0.4276 b 0.33 0.27 44.67 0.4367 c 0.29 0.15 41.69 0.4482 d 0.66 0.73 0.32 0.47 40.34 0.4688 spanish english english spanish, considered. tabl 5 present optim log-linear coeffici associ featur consid configur (the log-linear weight translat model omit tabl valu fix 1 cases). observ tabl 5, inclus featur function translat definit produc signific improv translat qualiti translat directions. particular, evid featur impact translat qualiti lexicon models. target languag model word bonu contribut improv translat quality, lesser degree. also, evid english-to-spanish direct opposit one, notic present result contribut target-languag word-bonu model relev lexicon mod- el (full system). fact, seen lm valu tabl 5, lexicon model included, target-languag model contribut overal translat significant. compar analysi result translat suggest includ lexicon model tend favor short tupl long ones, target-languag model import provid target context inform lexicon model used. how- ever, experiment research requir fulli understand interest result. import observation, follow compar result translat directions, case spanish-to-english translat consist significantli better english-to-spanish translations. clearli inflect natur spanish vocabulary. example, singl english word gener spanish word el, la, los, las. similar situat occur nouns, adjectives, verb differ form spanish. suggest english-to-spanish translat task difficult spanish-to-english task. 5.1.2 translat languag n-gram size. experi design evalu impact translation- language-model n-gram size overal perform- ance. section, (system d previou experiment) com- pare similar system 4-gram train translat 541 comput linguist volum 32, number 4 model and/or target languag model. specifically, system compar experi are: d, implement tupl trigram translat model word trigram target languag model. correspond standard configur defin begin section 5.1. e, implement tupl trigram translat model word 4-gram target languag model. f, implement tupl 4-gram translat model word 4-gram target languag model. tabl 6 summar result evalu system e, f, d. again, translat direct consid optim coeffici associ featur function present configuration. seen tabl 6, us 4-gram model comput provid clear improv translat quality. evid english- to-spanish direct f happen worst rank one, d obtain best mwer score e obtain best bleu score. hand, spanish-to-english direction, littl improv respect d achiev 4-grams. however, clear perform best e obtain best bleu score f obtain best mwer score. accord results, experiment research requir fulli understand interact n-gram size translat target languag models. notic particular case n-gram smt describ here, interact evid n-gram-bas translat model contain target languag model information. 5.1.3 source-nul tupl strategi comparison. experi design eval- uat differ strategi handl source-nul tuples. section, standard configur (systemd) present begin section 5.1, imple- ment attach-to-right strategi describ section 2.2.2, compar similar (refer g) implement complex strategi handl tupl null sourc sides. specifically, us ibm-1 lexic paramet (brown et al. 1993) comput translat probabl possibl new tuples: result null-aligned-word attach tabl 6 evalu result experi n-gram size incidence. direct lm wb s2t t2 mwer bleu es en d 0.49 0.30 0.94 0.25 34.94 0.5434 e 0.50 0.54 0.66 0.45 34.66 0.5483 f 0.66 0.50 1.01 0.57 34.59 0.5464 en es d 0.66 0.73 0.32 0.47 40.34 0.4688 e 0.57 0.45 0.51 0.26 40.55 0.4714 f 1.24 1.07 0.99 0.57 40.91 0.4688 542 marino et al. n-gram-bas machin translat previou word result attach follow one. then, attach direct select accord tupl highest translat probability. tabl 7 summar result evalu system d g. again, trans- lation direct consid optim coeffici associ featur function present configuration. seen tabl 7, consist better result obtain translat task ibm-1 lexicon probabl handl tupl null sourc side. slight improv achiev cases, especi english-to-spanish translat task, result initi attach-to-right strategi easili improv make us bilingu knowledge. 5.2 error analysi section, present brief descript error analysi perform output provid standard configur de- scribe section 5.1 (system d). specifically, detail review 100 trans- late sentenc correspond sourc sentences, direction, conducted. analysi us allow identifi com- mon error problem relat n-gram base smt translat direction. detail analysi review translat reveal translat problem encount typic relat basic differ type errors: verbal forms: signific number wrong verbal tens auxiliari form detected. problem turn common one, reflect difficulti current statist approach captur linguist phenomena shape head verbs, auxiliari verbs, pronoun verbal form language, especi given inflect natur spanish language. omit translations: larg number translat involv tupl null target side detected. case situat correspond correct translations, time result omitted-word errors. reorder problems: specif situat commonli occur problem relat adjectivenoun subjectverb structures. tabl 7 evalu result experi strategi handl source-nul tuples. direct lm wb s2t t2 mwer bleu es en d 0.49 0.30 0.94 0.25 34.94 0.5434 g 0.49 0.45 0.78 0.39 34.15 0.5451 en es d 0.66 0.73 0.32 0.47 40.34 0.4688 g 0.96 0.93 0.53 0.44 40.12 0.4694 543 comput linguist volum 32, number 4 concord problems: inconsist relat gender number commonli found. tabl 8 present rel number occurr type error identifi translat directions. notic tabl 8 common error translat direct relat verbal forms. however, import mention 29.5% verbal- form error english-to-spanish direct actual correspond verbal omissions. similarly, 12.8% verbal-form error spanish-to-english direct verbal omissions. accord this, error omit translat omit verbal form consid together, evid error involv omiss constitut import group, especi case english-to-spanish translations. interest note spanish-to-english direct exhibit omitted- translat error relat verbal form english-to-spanish direction. tabl 8, seen concord error affect twice asmani english-to-spanish translat spanish-to-english ones. result explain inflect natur spanish. finally, illustr example, spanish-to-english translat output present below. present example, error boldfac correct translat provid brackets: exampl 1 polici european union cuba null [must not] change. exampl 2 achiev purposes, necessari null govern alloc [to allocate], least, 60,000 million null dollar year . . . exampl 3 uk null [already] law [enough laws], want encourag null state . . . 5.3 n-gram-bas smt compar phrase-bas smt n-gram-bas translat describ evalu com- pare phrase-bas translat system context european project tabl 8 percentag occurr type error english-to-spanish spanish-to-english translat studied. type error english-to-spanish spanish-to-english verbal form 31.3% 29.9% omit translat 22.0% 26.1% reorder problem 15.9% 19.7% concord problem 10.8% 4.6% error 20.0% 19.7% 544 marino et al. n-gram-bas machin translat tc-star. detail descript evalu campaign (includ main characterist system) avail consortium web site progress report (nei et al. 2005). tabl 9 present best bleu result epp translat task tc-star evalu campaign, result correspond n-gram- base translat provid brackets. total system evalu evalu campaign. task consist translat directions: english spanish spanish english, differ evalu conditions: final text edition, verbatim, asr output. final text edit condit correspond offici transcript epps, actual written-languag translat condition. hand, condit spoken-languag transla- tion conditions. specifically, verbatim condit correspond liter tran- scription parliamentari speeches, includ hesitations, repeat words, spontan speech effects; asr output condit correspond output automat speech recognit system, addition includ speech- recognit errors. seen tabl 9, perform n-gram-bas translat best system translat direct condit consid tc-star evalu campaign. independ comparison translat propos phrase-bas translat system avail result second share task acl 2005 workshop build parallel texts: data- driven machin translat beyond. share task, entitl ex- ploit parallel text statist machin translation, n-gram-bas translat systemwa evalu differ translat directions: spanish english, french english, german english, finish english (banch et al. 2005). domain task european parliament; however, data set consid evalu differ tc-star evalu campaign. final text edit condit (offici transcripts) consid here. total differ system particip share task. tabl 10 present best bleu result translat direct consid share task. again, result correspond n-gram-bas translat provid brackets. seen tabl 10, perform n-gram-bas translat best system translat direct consid acl 2005 workshop share task. tabl 10 es en translat tabl 9 best bleu result epp translat task tc-star evalu campaign. n-gram base result provid brackets. bleu valu present taken tc-star slt progress report, avail at: direct condit second fourth es en final text edit [53.3] 53.1 47.5 46.1 verbatim 45.9 44.1 [42.1] 38.1 asr output 41.5 39.7 [37.7] 34.7 en es final text edit [46.2] 45.2 38.9 37.6 verbatim 42.5 [38.1] 36.8 33.4 asr output 38.7 34.3 [33.8] 33.0 545 comput linguist volum 32, number 4 tabl 10 best bleu result translat direct consid share task exploit parallel text statist machin translat (acl 2005 workshop build parallel texts: data-driven machin translat beyond). n-gram- base result provid brackets. bleu valu present taken share task web site: direct condit second fourth fr en final text edit 30.27 [30.20] 29.53 28.89 es en final text edit 30.95 [30.07] 29.84 29.08 en final text edit 24.77 [24.26] 23.21 22.91 fi en final text edit 22.01 20.95 [20.31] 18.87 deserv comment. convent phrase-bas share decod marie, ibm features, word bonus, target-languag model n-gram-bas system. specif characterist phrase-bas direct invers phrase condit probabl phrase penalty. addit compar- ison n-gram phrase-bas share common decod train test framework crego et al. (2005c). 6. conclus work conclud result presented, tupl n-gram translat model, addit featur functions, provid state-of-the-art transla- tion consid translat directions. import result qualiti spanish-to-english translat significantli consist better obtain english-to-spanish transla- tions. consequently, signific effort dedic properli exploit morpholog analysi synthesi method improv english-to-spanish trans- lation quality. additionally, commonli occur type translat error identifi review signific number translat sentenc pairs. analysi pro- vide us hint futur research improv smt system. however, evalu discuss requir area order fulli understand common translat failur implement appropri solutions. experi present work perform monoton de- coding, reorder strategi implemented. con- figur prove provid state-of-the-art translat task presented, hold task involv distant languag pair reorder capabl implemented. accordingly, result obtain present work, consid research n-gram smt focu follow issues: reorder strategies, non-monoton decod schemes, propos smt develop tested. mention before, reorder problem specif relat adjectivenoun subjectverb structur occur spanish-to-english 546 marino et al. n-gram-bas machin translat english-to-spanish translations. preliminari result concern us word class determinist reorder pos-tag-bas reorder pattern costa-jussa, fonollosa, mont (2006) crego marino (2006), respectively. effect long-tupl unfold strategi develop avoid occurr long tupl result long align links, happen common situat deal translat distant pair languages. problem close relat reordering, preliminari result present crego, marino, gispert (2005b). definit tupl bilingu pair revis order better handl unalign word sourc target sides. mention above, better strategi deal target word align null required. similarly, better handl null target result fewer omitted-transl errors. extens embedded-word concept gener idea embed n-gram evalu implemented. accordingly, translat probabl estim group word occur embed tuples. guarante decod translat option given word word combin previous seen train data. work requir determin rel impact embed n-gram translat model, appropri strategi handl them. linguist inform cope observ morpholog problem english-to-spanish translat direction, gener problem incorrect verbal form translations. regard, ongo research linguist tupl classif order improv translat results. preliminari result detect classifi verb form present gispert (2005). detail error analysi present section 5.2 requir fulli understand n-gram smt behavior specif caus result type error. us improv translat perform clearli identifi error unseen inform training, model problems, decod errors. acknowledg work partli fund european union integr project tc-star (technolog corpora speech speech translation) (ist-2002- fp6-506738, spanish depart educ scienc (mec), depart universities, research inform societi (generalitat catalunya), universitat politecnica catalunya. refer banchs, rachel e., josep maria crego, adria gispert, patrik lambert, jose bernardo marino. 2005. statist machin translat euparl data bilingu n-grams. acl workshop data-driven machin translat beyond, page 133136, ann arbor, mi. bangalore, sriniva giusepp riccardi. 2000. stochast finite-st model spoken languag machin translation. 547 comput linguist volum 32, number 4 proceed workshop embed machin translat systems, page 5259, seattle, wa. berger, adam, stephen della pietra, vincent della pietra. 1996. maximum entropi approach natur languag processing. comput linguistics, 22(1):3971. brown, peter, john cocke, stephen della pietra, vincent della pietra, frederick jelinek, john lafferty, robert mercer, paul s. roossin. 1990. statist approach machin translation. comput linguistics, 16(2):7985. brown, peter, stephen della pietra, vincent della pietra, robert mercer. 1993. mathemat statist machin translation: paramet estimation. comput linguistics, 19(2):263311. casacuberta, francisco. 2001. finite-st transduc speech input translation. proceed ieee asru, page 375380, madonna di campiglio, italy. casacuberta, francisco enriqu vidal. 2004. machin translat infer stochast finite-st transducers. comput linguistics, 30(2):205225. costa-jussa, marta ruiz, jose adrian rodriguez fonollosa, enric monte. 2006. reorder statist machin translat base align block classification. intern report. mruiz/docs/br06.pdf. crego, josep maria, jose bernardo marino, adria gispert. 2004. finite-state-bas phrase-bas statist machin translation. proceed 8th intern confer spoken languag processing, page 3740, jeju, korea. crego, josep maria, jose bernardo marino, adria gispert. 2005a. ngram-bas statist machin translat decoder. interspeech 2005, page 31853188, lisbon, portugal. crego, josep maria, jose bernardo marino, adria gispert. 2005b. reorder search tupl unfold ngram- base smt. proceed tenth machin translat summit, page 283289, phuket, thailand. crego, josep maria, marta ruiz costa-jussa, jose bernardo marino, jose adrian rodriguez fonollosa. 2005c. ngram- base versu phrase-bas statist machin translation. proceed intern workshop spoken languag translation, page 177184, pittsburgh, pa. crego, josep maria jose bernardo marino. 2006. integr postag-bas sourc reorder smt decod extend search graph. proceed 7th biennial confer associ machin translat americas, boston, ma. gispert, adria jose bernardo marino. 2002. x-gram speech-to- speech translation. proceed 7th intern confer spoken languag processing, page 18851888, denver, co. gispert, adria, jose bernardo marino, josep maria crego. 2004. talp: xgram-bas spoken languag translat system. proceed intern workshop spoken languag translation, page 8590, kyoto, japan. gispert, adria. 2005. phrase linguist classif gener improv statist machin translation. acl05 student workshop, page 6772, ann arbor, mi. hutchins, john. 1986.machin translation: past, present future. elli horwood, chichester, england. kay, martin, jean mark gawron, peter norvig. 1992. verbmobil: translat face-to-fac dialog. csli. kneser, reinhard hermann ney. 1995. improv backing-off m-gram languag modeling. ieee intern confer acoustics, speech signal processing, page 4952, detroit, mi. knight, kevin yaser al-onaizan. 1998. translat finite-st devices. ai lectur note artifici intelligence, volum 1529, springer-verlag, page 421437. koehn, philippe, franz joseph och, daniel marcu. 2003. statist phrase-bas translation. proceed 2003 meet north american chapter acl, page 4854, edmonton, alberta, canada. koehn, philippe. 2002. europarl: multilingu corpu evalu machin translation. avail onlin at: people/koehn/publications/europarl/. marino, jose bernardo, rafael e. banchs, josep maria crego, adria gispert, patrik lambert, jose adrian rodriguez fonollosa, marta ruiz. 2005. bilingu n-gram statist machin translation. proceed tenth machin translat summit, page 275282, phuket, thailand. 548 marino et al. n-gram-bas machin translat ney, hermann, volker steinbiss, richard zens, evgeni matusov, jorg gonzalez, young-suk lee, salim roukos, marcello federico, muntsin kolss, rafael banchs. 2005. slt progress report. tc-star deliver d5, european commun project no. fp6-506738. avail onlin at: tc-star.org/pages/f documents.htm. och, franz joseph hermann ney. 2000. improv statist align models. proceed 38th annual meet acl, page 440447, hong kong, china. och, franz joseph hermann ney. 2002. discrimin train maximum entropi model statist machin translation. proceed 40th annual meet acl, page 295302, philadelphia, pa. och, franz joseph hermann ney. 2003. systemat comparison statist align models. comput linguistics, 29(1):1951. och, franz joseph, daniel gildea, sanjeev khudanpur, anoop sarkar, kenji yamada, alexand fraser, shankar kumar, libin shen, david smith, katharin eng, viren jain, zhen jin, dragomir radev. 2004. smorgasbord featur statist machin translation. proceed human languag technolog confer naacl, page 161168, boston, ma, may. papineni, kishore, salim roukos, todd ward, wei-j zhu. 2002. bleu: method automat evalu machin translation. proceed 40th annual confer acl, page 311318, philadelphia, pa. press, william h., saul teukolsky, william vetterling, brian p. flannery. 2002. numer recip c++: art scientif computing, cambridg univers press. riccardi, giuseppe, roberto pieraccini, enrico bocchieri. 1996. stochast automata languag modeling. speech language, 10(4):265293. shannon, claud e. 1949. commun theori secreci systems. bell technic journal, 28:656715. shannon, claud e. 1951. predict entropi print english. bell technic journal, 30:5064. shannon, claud e. warren weaver. 1949. mathemat theori communication, univers illinoi press, urbana, il. stolcke, andrea 2002. srlim: extens languag model toolkit. proceed intern confer spoken languag processing, page 901904, denver, co. tillmann, christoph fei xia. 2003. phrase-bas unigram model statist machin translation. proceed hlt-naacl - short papers, page 106108, edmonton, alberta, canada. vidal, enrique. 1997. finite-st speech-to- speech translation. proceed 1997 ieee intern confer acoustics, speech signal processing, page 111114, munich, germany. weaver, warren. 1955. translation. william lock a. donald booth, editors,machin translat languages: fourteen essays. john wilei & sons, new york, page 1523. zens, richard, franz joseph och, hermann ney. 2002. phrase-bas statist machin translation. 25th german confer artifici intelligence, page 1832, september. aachen, springer verlag. 549