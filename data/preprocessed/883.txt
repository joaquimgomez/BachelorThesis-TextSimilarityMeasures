natur languag engin 1 (1): 126. print unit kingdom c 1998 cambridg univers press 1 select correct candid normal spanish user gener content m. m e l e r oa1, m. r. c o s t - j u s s aa2 , p. l m b e r ta1, m. q u x la3 a1grup lingustica computacional, universitat pompeu fabra roc boronat, 138, 08018 barcelona, catalunya, spain (work partial barcelona media, spain) a2 institut infocomm research, human languag technolog group 1 fusionopoli way, 21-01 connexi (south tower), 138632 singapor a3 depart spanish portuguese, univers texa austin 150 w 21st street, austin, tx, 78712, unit state america ( receiv xxx; revis xxx ) abstract present research aim build tool normal user-gener content (ugc). argu process type text requir revisit initi step natur languag process (nlp), ugc (micro-blog, blog, and, generally, web 2.0 user gener texts) present number non-standard commun linguist characterist closer oral col- loquial languag edit text. present corpu ugc text spanish differ sources: twitter, consum review blogs, main characteristics. motiv need ugc text normal analyz problem process type text convent languag process pipeline, particularli task lemmat morphosyntact tagging. aim paper seiz power exist spell grammar correct engin endow automat normal capabilities, order pave wai applica- tion standard nlp tool typic ugc text. particularly, propos strategi automat normal ugc ad modul pre-exist spell checker select plau- sibl correct unrank list candid provid spell checker. build selector modul train languag models, contain differ type linguist inform trade gener capabilities. experi model train truecas lowercas word form discrimin select best candidate. experi parametr combin models, optim directli select task linear interpol models. result parametr combina- tion obtain result close best perform model improv results, measur test set. precis selector modul rank number expect correct propos test corpora reach 82.5% twitter text (baselin 57%) 88% non-twitt text (baselin 64%). 2 m. melero 1 introduct web 2.0 channel user exchange, explain write live interests, opinion comment peopl opinions, time casual language. languag present peculiar closer transcript oral languag standard edit text. opinion mine techniques, mention example, import sourc inform market research, social network analysi learn analyt (pang lee, 2008). order data extract inform web 2.0 need understand contents. shorten misspel words, frequent social media inform style, increas ambigu interpret possibl word form, pose challeng achiev certain natur languag process (nlp) analysi task tokenization, part-of-speech (pos) tag name entiti recognition, reflect literatur (foster et al., 2011; munoz-garca navarro, 2012; maynard et al., 2012; aminian et al., 2012). nlp techniques, provid linguist represent unstructur data, typic develop deal standard languag yield expect result user gener content (ugc) text. discuss later section, approach tri tackl problem adapt tool text adapt text exist tools, process gener known text normalization. structur articl follows. start explain motiv review relat work. present find character ugc text spanish, base corpu study. explor problem caus ugc text perform pre-exist nlp tool analysi spanish text, compar result pars version ugc text: as-i manual corrected. finally, present evalu approach text normal us modul automat select correct candidates; modul built pre-exist spell checker. 1.1 motiv pang lee (2008) relev analysi ugc text analysi product servic reput polit trends. process larg amount ugc data basi frequenc (mainly) word correl structur data (e.g., us star-bas recommend scales) successfulli character global opinion reput trends, depend granular task hand fine-grain charac- teriz requir e.g., pang lee (2008), gianfortoni et al. (2011). non-standard characterist ugc text main obstacl challeng respect (ritter et al., 2011; maynard et al., 2012; munoz-garca navarro, 2012). said ugc text, social media sites, resembl oral languag regular edit text, new kind text nlp tool trained. however, studi computer-medi commun field descript linguist suggest social media text languag mode (herring, 2012a). linguist character ugc text research line provid interest insight automat analysi ugc bender et al. (2011), gouw et al. (2011) eisenstein (2013). research opinion mine sentiment analysi attribut inaccuraci nlp-base system lower perform standard nlp tool appli noisy, select correct candid normal spanish ugc 3 ill-formed, languag bermingham smeaton (2010) argu text length nois disadvantag perform sentiment analysi twitter texts. studi investig effect ugc characterist perform standard nlp tools. ugc text characterist affect perform task topic detect (munoz-garca navarro, 2012), constitu pars depend pars (foster, 2010; foster et al., 2011), named-ent recognit (ner) (ritter et al., 2011; munoz-garca navarro, 2012; maynard et al., 2012), token (aminian et al., 2012). differ text cleans normal strategi pursu improv perform standard nlp tool applic social media text. contribut articl i) present character ugc corpu spanish, ii) descript normal strategi that, exploit power pre- exist spell grammar correct tools, allow broad-coverag normal includ normal token non-standard words. respect, paper suppos novelti strategi normal inclus token normal task. 1.2 relat work section, review research differ topics: definit text normal task, differ approach text normal strategi literatur rank correct candid automat correct task, oppos human-machin interact correct task. 1.2.1 text normal task text normal term field refer task consist transform origin piec text differ piec text word convert normal form. definit norm, normal form, depend task perform normalization. thus, sproat et al. (2001), classic paper topic, present work normal text given input text-to-speech synthesi engine, claim similar approach appli speech recognit inform extract tasks. however, norm text-to-speech synthesi necessarili norm inform extract extent misspel tackl sproat et al. (2001) article, speech synthesi requir word form obtain said aloud, inform extract requir word form interpret (lexically) analyzed. pose interest question linguist norm actual defined, topic briefli below.1 recent paper eisenstein (2013) address issu differ wai social media text deviat influenc differ aspects: keyboard used, writer literacy, writer intent pragmatics, medium length, actual social variables. paper interestingli suggest ugc, twitter particular, seen real-tim observ platform languag evolv social commun tool. 1 arguabl abl obtain normal form text-to-speech normal written form, task goal certainli different. 4 m. melero interest issu type text normal task performed. sproat et al. (2001) work differ type text (newspap text, real estat ads, servlist text topic palmtop comput cook recipes), later paper deal sm text instanc choudhuri et al. (2007), kobu et al. (2008), cook stevenson (2009) twitter text instanc clark araki (2011), brodi diakopoulo (2011), foster et al. (2011), han baldwin (2011), hassan menez (2013) eisenstein (2013). also, liu et al. (2012) work sm twitter datasets. 1.2.2 approach text normal main differ wai deal ugc text processing, complemen- tary. focus adapt tool algorithm type text annot ugc corpora train correspond tool scratch (michelson knoblock, 2005; ritter et al., 2011), second focus transform sourc ugc text normal version handl process tool (kobu et al., 2008; agarw et al., 2011; liu et al., 2012). attempt combin method adapt extend train model while, time prepar input text, normal ugc relat phenomena (foster, 2010; foster et al., 2011). kobu et al. (2008) present interest discuss differ metaphor wai look sm language, type text featur common ugc text. view motiv differ approach normal task. approach, input token taken deviat correct word form, normal view spell check task. second metaphor consid sm languag differ language, normal view machin translat task. finally, possibl consid normal speech recognit task peopl consid sm closer oral product regular written texts. fact, sm spell tend closer approxim phonem represent word norm spelling, context typographi orthographi function sound (herring, 2012b). attempt text normal base empir obtain list frequent observ phenomena, foster (2010), kobu et al. (2008) agarw et al. (2011), research appli generalist approach (alonso, 2010). zhu et al. (2007) present approach text normal (of e-mail blog posts) us condit random field algorithm lot featur compar classic normal methods. zhu et al. (2007) approach tackl normal task tag problem, differ normal transform requir perform token depend type (line break, space, punctuation, word special). clark (2003) clark araki (2011) us rule-bas approach henrquez q. hernandez (2009) approach task statist machin translat train origin text semi-automat correct version. recently, hassan menez (2013) shown version markov random walk train normal small manual correct corpu labeling. finally, liu et al. (2012) propos broad-coverag normal algorithm, mean domain independent, includ modul ground visual prime theori favor occurr word closer relat word seen text. combin strategi letter sequenc model certain extent select correct candid normal spanish ugc 5 reson simplif zhu et al. (2007) approach standard spell check tech- niqu gener list altern non-standard tokens, assum normal tokenization. aim present work seiz power exist spell grammar correct engin endow automat normal capabilities, order pave wai applic standard nlp tool typic ugc text. respect, research closer liu et al. (2012) research, aim implement broad coverag normal strategy. 1.2.3 correct candid select n-gram model detection2 correction3 misspel isol word late 1980 (kukich, 1992). church gale (1990) demonstr potenti word bigram improv accuraci isol word correct mai et al. (1991) trigram model obtain 76% accuraci detect 73% accuraci correction. hodg austin (2003) integr ham distanc n-gram algorithm high recal type error phonet spell-check algorithm singl architecture. ahm et al. (2010) propos spell checker work select promis candid rank list deriv n-gram statist lexic resources. approach correct spell includ rule-bas techniqu (mangu brill, 1997), noisi channel model (brill moore, 2000; toutanova moore, 2002) ternari tree search (martin silva, 2004). far know, littl work date subject spanish, except alonso (2010). alonso us normal approach base strategi group word cluster comput levenshtein edit distanc new (unknown) word seri word cluster work classif task out-of-vocabulari words, candid select task. 2 corpus-bas character ugc text spanish refer corpu studi ugc relat phenomena, collect sampl text spanish follow sources: blog (collect googl blog search), hotel reserva- tion (booking.com), consum review differ domain (ciao.es) twitter. follow sections, corpu size, sourc distribut annot rationale. 2.1 corpu size distribut total size corpu 7,583 sentences, 192,417 words. tabl 1 show size corpu term sentenc words, correspond percentag source. ciao site compris text differ domains: car (61%), mobil oper (12%) bank (26%). row show ratio number run word (total number words) vocabulari size (number differ word appear once, i.e. word types). figur indic twitter book text present greater lexic variat 2 detect task find word express appear specif lexicon respond particular morpholog pattern word formation. 3 correct task provid propos given error, possibl rank list. 6 m. melero account topic-focus type text compar ciao. texts. total twitter blog book ciao no. sentenc 7583 20% 21% 2% 57% no. word 192417 14% 23% 1% 62% ratio words/word type 6 3.1 6 3.4 7.6 tabl 1. corpu size sentenc words, ratio word type (the lower ration, higher number word type total number words). 2.2 annot rational normal ill-form text presuppos definit norm. concept norm vari linguist commun other. example, norm reach consensu english-speak world, dictat prescript institut spanish (real academia espanola la lengua, rae) french (academi francaise). addition, particular commun corpor restrict arbitrari norms, case control languag machine-transl manual corpor guidelin publish houses. english speak world nlp, argu norm tag pars wall street journal, facto standard. case norm underli dictionary, follow rae, includ common latin american spell words. instance, dictionari includ futbol (strength o) futbol (strength u). perspect nlp, norm restrict arbitrari decis linguist apparatus. process pipelin abl recogn particular word identifi belong language; fail assign correspond lexic morphosyntact features. suggest introduction, normal text text-to-speech (tts) differ normal text text mining. instance, tt task highwai m40, written tweet captur figur 1, eventu result em cuarenta [em forty], text mine text stop m-40 intermedi state tt task. agre eisenstein (2013) argu [n]ormal imposs chang mean text given social pragmat implic ugc text entails. 2.3 annot procedur refer corpu manual corrected. textual deviat reviewed, correct classifi differ annot (none involv research work). select correct candid normal spanish ugc 7 fig. 1. real twitter text contain highwai m40 m-40. annot annot differ set texts, inter-annot agreement calculated. text randomli assign annotators, annot end annot differ text genr domains. deviat standard languag norms, identified, classifi corrected. instruct perform task steps: step 1 local correct 1. search deviat form 2. mark span deviat form squar bracket 3. write altern normal version text bracket 4. write number token origin involv deviat step 2 classif 5. classifi deviat form accord follow typologies: (a) linguist type (b) transform type annotators, degre theoret appli linguistics, given instruct print examples. weekli meet organ annot share find doubt check progress us. annot process last week annot work part-time. exampl annot format format later convert xml format describ section 2.3.3. 2.3.1 annot linguist type basi exploratori inspect data, classifi norm deviat follow types: capit text capit emphasi emot purposes, proper noun capitalized: y es broma [not kidding] y es broma recorro espana [i spain] recorro espana. accentu graphic accent omitted: en numero rojo en numero rojo [in red]. punctuat punctuat sign omit reduplicated; includ omiss blank spaces: te quiero!!!!!!! te quiero! [i love you!], aver ver [let see]. inform spell systemat shortcut charact substitut intention user: pq porqu [because], t kier muxo te quier mucho [he love much]. spell error spell error includ previou categories, includ conven- tional misspellings, oie oy [listen] targeta tarjeta [cards]; typos, 8 m. melero dicindo diciendo [saying]; intent unintent redupl characters: cooordenada coordenada [coordinates] , alistarmeeee al- istarm [join up] frrrrrro fro [cold]. error (lexical, syntactic): e.g., agreement error miss prepositions: delant mi casa delant mi casa [in house], mucho gent mucha gent [lot people]. arguabl categori divid finer-grain ones. instance, type capit phenomena exemplifi distinct nature: attribut intent commun goal emphas idea, relax standard spell norms. similarly, spell like frrrrrro includ categori inform spelling, instead spell error. however, distinguish redupl letter ow slip keyboard presum like cooordenada intent commun goal. decid annot process simpl possibl stage research brodi diakopoulo (2011), studi exclus devot analysi exploit letter redupl sentiment analysi twitter, suggest semant interpret certain ugc characterist task itself. 2.3.2 annot transform oper annot includ type transform oper respect normal version given deviat involves. transform oper adopt deriv damerau (1964): addit charact word added, dijo que vendra dijo que vendra. omiss charact word omitted, dicindo diciendo delant mi casa delant mi casa. substitut charact word replac others, t k ier muxo te quier mucho, k replac qu x replac ch. transposit charact word place expect position, uatobu autobu duplic charact word repeat times, frrrrrro fro.4 2.3.3 annot format instruct describ section 2.3, annot correct fragment like shown (1) like fragment shown (2). (1) (...) esteticament la mayoria dela gent gusta por su forma (...) (2) (...) esteticament la [1 mayora] [1 la] gusta por su forma (...) manual annot automat extract tabl generated. second step, manual classifi annot categori describ above. result, obtain tabl error-correct pair like on exemplifi tabl 2. 4 admittedli subset deviat account addit transform operations, high frequenc relev ugc text justifi categori own. select correct candid normal spanish ugc 9 deviat correcct ling. type transform. type mayoria mayora acc subst dela dela punct om q que infspl om la om diviertanse diviertans acc subst diviertanse diviertans splerr add (..) tabl 2. tabl deviat categor complet annot step 2 annot process. fig. 2. xml annot sample. initi manual annot map xml annot scheme. scheme scalabl compat text encod initi (tei) conventions. conceiv stand-off annotation: instead mix data metadata, origin text preserv as-i annot form separ layer, link origin text offset indicators. figur 2 show annot sentenc concerteza amooor=), real twitter mes- sage. normal version |con| |certeza| |amor| |=)|, origin tokens, includ space, result normal tokens, includ spaces. word ap- pear capit begin sentenc word amooor reduc amor. instanc annot multipl annot deviat type possible, <dev>-tag assign normal sequenc characters. 2.4 distribut deviat type differ text sourc overall, rate deviat input ugc refer corpu high: fifth word type (20.8%) contain error deviation. rate vari depend type text rang 4.62% edit text, blog posts, 25% twitter inform consum reviews. note percentag calcul word types, word instances. actual rate error word instances, comput total number word corpus, 5.7%. 10 m. melero tabl 3 show percentag word type manual correct respect total number word type corpus, classifi error deviat type. minor exceptions, frequenc distribut deviat type exhibit signific variat differ text sources. rel frequency, type deviat clearli stand rest: spell errors, capit accentuation. spell error class classif includ redupl express emot purposes, instanc ordinari orthograph errors, which, accentu problem handl convent spell checkers. fact partli motiv strategi chosen deal ugc text normalization, explain section 4. splerr cap acc punct infspl total twitter 8.11 7.29 6.25 1.77 1.52 0.68 25.62 blog 2.64 1.38 0.41 0.12 0.01 0.06 4.62 book 3.71 1.71 8.71 0 0.57 1.56 16.26 ciao-bank 4.98 12.34 9.68 0.35 0.14 0.08 27.57 ciao-car 8.95 5.47 7.99 1.86 0.28 0.50 25.05 ciao-mobil 5.70 10.84 9.78 1.47 0.68 0.93 29.4 total (cross-domain) 6.31 6.30 6.08 1.11 0.57 0.43 20.8 tabl 3. percentag deviat (in term word-types) accord linguist type, genres. 2.4.1 characterist spanish ugc english ugc rel littl research character specif ugc. however, sproat et al. (2001) han baldwin (2011) offer interest information. sproat et al. (2001) percentag non-standard word (nsw) newspap text 8.8%, 43.4% real state ads, 27.3% servlist email topic palmtop computers, 22% servlist email cook recipes. sproat et al. (2001) includ nsw categori phenomena abbrevi (adv advertisement, n.y. new york, govt government), textual item includ number (from phone number car models), non-spoken element (certain punctuat token boundaries), spell error funni spell (sic). han baldwin (2011, p. 370371) provid inform oov rate newspap text, sm twitter text. find twitter sm present larger percentag oov word independ size percentag corpu look at, newspap text present zipfian distribut oov word is, text look at, fewer newer unknown word found. interest find oov word sm tend person names. least, han baldwin frequent reason ill-form word miss extran letters, 72.44%, select correct candid normal spanish ugc 11 second frequent reason slang word slang dictionari avail internet. find fulli compar previou references, blog corpu present lowest deviat rate compar newspap text account sproat et al. (2001) look wider varieti non-standard forms. contrast, corpora present high rate deviat line find sproat et al. (2001) han baldwin (2011) formal type texts. 3 process ugc text hypothesi percentag deviat present ugc text impact perform standard nlp tools. similar experiment, foster (2010) detect problem handl long coordin sentenc (mainli presenc errat punctuat usage), domain-specif fix express unknown words. gaug impact deviat linguist process ugc text, process origin version corpu manual correct one, convent linguist process pipelin spanish (rodrguez et al., 2010). pipelin consist general-scope, state-of-the-art linguist tools, specif adapt ugc text, integr uima platform. compar outcom term chang result annotation. accord analysis, differ result process version 30% 100% tokens, vari percentag depend type error, task domain, below. 3.1 impact lexic coverag expected, normal input increas lexic coverag (see gouw et al. (2011) effect normal lexic coverage). tabl 4 show percentag word term individu instanc word type cover system lexic resourc origin manual normal version. valu notabl lower twitter rest sources. increas coverag normal shown brackets. increas turn evid comparison word type comparison word instances, effect: normal deviat form actual decreas number hapax (word occur once). 3.2 impact perform basic nlp process task investig effect normal basic nlp process tasks: (i) lemma- tization, (ii) part-of-speech tag (short-tag syntact category), (iii) assign morphosyntact featur (gender, number, tense...). task root com- plex higher level process tasks, error level like propag affect task constitu analysis, depend relat identification, nerc, nlp task (see instanc grefenstett tapanainen (1994), chung gildea (2009) moham (2011)). 12 m. melero origin normal twitter 81.3 83.7 (+2.4) t 65.6 68.8 (+3.2) blog 95.5 96.3 (+0.8) t 86.6 89.0 (+2.4) book 97.4 98.9 (+1.5) t 92.0 96.2 (+4.2) ciao 95.4 96.8 (+1.4) t 80.4 85.4 (+5.0) tabl 4. percentag word coverag (instances, i, types, t) origin correct versions. lemmat po tag morphosynt. featur blog 94.6 43.8 62.6 booking-ciao 88.6 43.7 65.5 twitter 85.4 49.8 64.5 total corpu 89.6 45.8 64.2 tabl 5. percentag deviat word incorrectli analyzed, domain. tabl 5 show percentag word chang result linguist analysi normal 5 . general, result fairli uniform genres. hand, observ lemmat sensit presenc error. percentag wrong lemma assign erroneous, non-normalized, word form 90% overall, 85% 95% depend corpus. hand, assign syntact categori gener robust deviation, half non-norm word form (around 46%) chang categori assign have correct normalized, proport wrong assign morphosyntact featur littl higher, 64%, genres. tabl 6 present inform broken deviat type, frequent types. capit turn detriment basic tasks, accentu particularli harmful, robust task po tag assign (main grammat category). tabl 6, lemmat like inaccur deviat words. 5 nlp tool analysi state-of-the-art provid reason results, chang result consequ manual normal input safe assum positive, neutral. manual verif random sampl show posit changes. select correct candid normal spanish ugc 13 lemmat po tag morphosynt. featur capit 68.3 29.5 56.3 accentu 97.8 65.2 75.9 spell error 97.9 56.0 71.1 punctuat 99.8 46.1 59.1 tabl 6. percentag deviat word incorrectli analyzed, type error. result consist previou find field, analysi lexic item particularli sensit (e.g., han baldwin, 2011, p. 370371, gouw et al., 2011, p. 28). lemmat error increas variabl concept like affect semant relat tasks. 4 build normal exist spell checker larg presenc deviat form ugc text costli impact perform nlp tool convinc need specif solut address problem process type text. discuss section 1, approach deal issu literature: transform input text (i.e. normal it) adapt tool (e.g. retrain models). second option feasibl statist train tool (which case foster (2010)), option work tool, statist rule-based, cours follow work. differ approach normal present section 1 chosen view normal spell check task, particularli motiv high rate typic orthograph error (includ accentuation) ugc text. purpos built automat normal spanish version cotig, spell grammar checker develop catalan (quixal et al., 2008). kei differ regular spell checker normal interact end- user. lack interact normal task import implication: specif strategi place rank possibl correct candid decis choos best set. rest articl deal develop dedic selector modul rank list correct candid propos spell checker select highest rank one. import aspect need address effect turn regular spell checker normalizer. main concern rate fals positives. over-correct annoi user spell checker, over-normalizing, i.e. introduc unwant chang origin text, invalid normalizer. vocabulari word main sourc fals positives. straightforward wai deal larger dictionari dictionari adapt domain question. moreover, typic ugc phenomena, inform spell emoticon appropri dealt standard spell check procedures, edit distanc algorithms; thus, ad hoc specif strategi approach phenomena required. 14 m. melero 5 select right candid languag model output spell checker consist unord list correct candid obtain applic algorithm gener correct proposals, base simpl editing-dist criteria. instance, given sentenc aunqu mire otro cox la misma categora [even look car type], list gener spell checker word cox (coch [cars] intended) look shown figur 3. <dev begin="318" end="322" original="coxes"> <proposals> <propos id="1" > box </proposal> <propos id="2" > come </proposal> <propos id="3" > cose </proposal> <propos id="4" > coch </proposal> <propos id="5" > coxa </proposal> <propos id="6" > coge </proposal> <propos id="7" > corr </proposal> <propos id="8" > coxi </proposal> <propos id="9" > cole </proposal> <propos id="10"> boch </proposal> <propos id="11"> coce </proposal> </proposals> </devs> fig. 3. output normal xml format contain list correct candidates. select probabl correct set candidates, experi us differ trigram model train in-domain corpu describ section 5.1, model convei differ level information. inspir so-cal factor model emploi statist machin translat (koehn hoang, 2007; bilm kirchhoff, 2003), selector modul enabl integr differ languag model train differ automat gener linguist annot word-level: truecas form model (tc). model train origin unmodifi text, uppercas lowercas instanc form differ words. specif abstract model largest vocabulary. lowercas form model (lc). model train lowercas version origin corpus. uppercas lowercas version form word. lemma model (lemma). model train lemmat version origin corpus, inflect form substitut root lemma. plural singular version noun word; happen variat person, tens number verbal forms. part-of-speech model (pos). model train po tag version corpus. tag parole-styl part-of-speech long tags, word includ syntact categori morphosyntact featur (e.g. aq0cp0, ncfp000, vsic3p0; select correct candid normal spanish ugc 15 detail (villega et al., 1996)). model gener abstract higher level smallest vocabulary. 5.1 build model corpu build model 24 million word corpu collect web compris text domain genr includ refer corpus, namely: banking, cars, mobile, twitter blogs.6 lemma morphosyntact label assign in-hous linguist pipelin (cf. section 3). built 4 trigram model irstlm toolkit (federico et al., 2008) modifi shift-beta smooth method, known improv kneser-nei smoothing. 5.2 queri model run time queri model slide window propos correct 5 words. exampl figur 3, 11 differ 5-word candid string generated, candid correction, surround immedi context. s1 = mire otro box la s2 = mire otro come la s3 = mire otro cose la s4 = mire otro coch la s5 = mire otro coxa la s6 = mire otro coge la s7 = mire otro corr la s8 = mire otro coxi la s9 = mire otro cole la s10 = mire otro boch la s11 = mire otro coce la candid string si, gener 4 parallel strings: stc word truecase: mire otro box la slc word lowercase: mire otro box la slemma lemma only: mirar otro box la spo po only: vmsp3s0 di3mp0 ncmp000 sps00 da3fs0 c(m,s) cost string s (i.e. logarithm probability) accord model m , queri model cost valu strings. example, c(tc, stc) cost truecas string comput tc model. mean candidate, cost values: c(tc, stc), c(lc, slc), c(lemma, slemma) c(pos, spos). 6 larger data set available, recent research shown select fraction (e.g. 10%) data accord close domain effect keep data set. author select pseudo in-domain languag model train data cross- entropi method obtain good result perplex machin translat task (moor lewi (2010); axelrod et al. (2011); rousseau et al. (2011); toral (2013)). focus effort collect in-domain data. 16 m. melero 5.3 combin model aim build differ model evalu discrimin rank differ candidates. experi combin model strategi improv result best perform model isolation. eq. (1) show linear equat parametr combin differ models. c(total, s) = tcc(tc, stc) + lcc(lc, slc)+ lemmac(lemma, slemma) + posc(pos, spos) (1) 5.3.1 linear interpol languag model linear interpol languag model popular model combin tech- niques. given set n-gram languag models, linear interpol consist comput weight averag compon model cost shown eq. 1. interpol weight i, {i = tc,lc,lemma, pos} satisfi = 1 typic tune optim perplex develop set. empir adjust combin weight follow standard procedur linear interpol languag model order build uniqu optim model. procedur us expectation-maxim (em) algorithm mini- mize perplex specif develop set (stolcke, 2002). appli procedure, previous calcul probabl random variable, tc model word model (lc, lemma pos) class. class model c, calculate: pc(n|nk+1...n1) = p (n|cin |cnk+1 ...cwn1) (2) cin differ class word n. equat model variabl class, us em calcul mention interpol weight i, {i = tc,lc,lemma, pos}. develop set extract text refer corpu (describ section 2), detail section 5.3.2. develop set 50k word optim phase. tabl 7 show vocabulari size train develop set models: tc, lc, lemma, pos. number word train set i.e. 24 million word , size respect vocabulari vari considerably, go 525,742 case tc model 243 case po model. appli develop set. languag model weight optim comput compute-best-mix function srilm toolkit (stolcke, 2002). option expand-class normal vocabulari class word (for lc, po lemma languag models). perplex languag model shown tabl 8. po languag model highest perplexity, reason fewer class and, therefore, higher degre ambiguity. contrast, tc model, word class, lowest perplexity. result optim assign sizeabl weight truecas model, small weight select correct candid normal spanish ugc 17 tc lc lemma po train 525742 456219 440818 243 develop 12673 11482 9058 184 tabl 7. vocabulari size (unigram counts) train develop corpus. perplex truecas 94.5662 lowercas 103.364 lemma 293.121 po 504.553 combin 92.9201 tabl 8. perplex develop set languag model lowercas model practic overlook lemma part-of-speech models. final set weight present eq.(3): c(total, s) = 0.961861 c(tc, stc) + 0.0309452 c(lc, slc) + 0.00690778 c(lemma, slemma) + 0.00000003 c(pos, spos) (3) note theoret methodolog optim weight languag model differ word classes. however, practice, task expand class ambiguous, directli affect interpol procedure. example, expand lowercas word class zapatero possibl surfac form zapatero zapatero, easi task. case expand po word class prepositon, 23 possibl word surfac forms. end, weight given languag model gener class (in case pos) low, direct consequ improp expans classes. 5.3.2 optim task combin model optim tune paramet languag model minim error directli select task. optim task possibl gold standard iter measur improvement. refer corpu describ section 2. process origin non-correct section refer corpus, total 4235 deviat annot underli spell checker correctli detect error normal refer set candid propos selector module. therefore, number deviat go optim experi number deviat (correctli detect 18 m. melero spell checker) candid rank selector modul coincid normal refer accord gold standard. evalu results, us manual normal refer corpus. divid parts: 30% develop set (the linear interpolation) optim task 70% evaluation. iter minim error modifi version simultan perturb stochast approxim (spsa) (spall, 1992; lambert banchs, 2006) optim algorithm. spsa algorithm. spsa procedur gener recurs stochast approxim form, shown eq. (4): k+1 = k akgk(k) (4) gk(k) estim gradient g() e/ iter k, ak denot posit number usual decreas k increases. gradient comput one- side approxim which, given e(k), requir evalu e(k + perturbation). simultan perturb approximation, element k randomli perturb 7 approxim gradient vector is: gk(k) = e(k + ckk) e(k) ck 1/k1 1/k2 ... 1/kn (5) eq. 5, k perturb vector dimens n , valu comput randomly. ck denot small posit number decreas k increases. took compon k bernoulli 1 distribut probabl 1/2 1 outcome, 0,1 distribut probabl 1/3 outcome. detail implement algorithm given lambert banch (2006). main chang respect origin algorithm paramet necessarili updat iteration. new set paramet k+1 wors current one, updat probabl depend wors is. algorithm typic converg 50 60 iterations. note that, general, spsa converg local maximum. task optimization. figur 4 exemplifi optim process candid select task goal maxim precis (minim number time correct propos rank list). initi set weights, 0, normal origin develop corpu calcul precis manual correct refer corpus. give e(0). perturb 0 vector c00, normal develop corpu perturb set weight calcul precision, give e(0+c00). updat set weight accord eqs. (4) (5), give 1. evalu e(1) accord result, 1 0 current set weights. perturb current set weight ckk vector, on. 7 compar finite-differ gradient approximation, involv n time function evaluations, simultan approxim caus deviat search path. deviat averag reach solut accord spall (1998), reason gener conditions, gradient approxim achiev level statist accuraci given number iterations. select correct candid normal spanish ugc 19 evalu evalu optim precis normal languag model tc, lc, lemma, po origin develop corpu annot develop corpu evalu fig. 4. languag model weight optim accord select precision. equat result optim assign equal moder weight tc lc, small weight lemma model zero po model, shown eq.(6): c(total, s) = 0.4519 c(tc, stc) + 0.4519 c(lc, slc) + 0.0962 c(lemma, slemma) + 0 c(pos, spos) (6) 5.4 evalu candid select indic previou section, evalu purpos unus portion annot refer corpus, i.e. 70% total. test model individu differ model combin present section 5.3: linear interpol optim task. baselin ran normal selector module, i.e., take item list propos underli spell checker non-exist rank strategi (quixal et al., 2008). moreover, twitter text known present specif featur differ ugc text affect performance, evalu twitter rest corpu sourc separately. repeat experi optim task specif develop test set twitter non-twitter. results, term percentag instanc refer correct rank first, shown tabl 9. model built lowercas version corpu turn discrimin model isolation, precis 86.59%, measur test set (second column table). set, model combin improv precis achiev lc model, perform better rest model isolation. notic po obtain result baseline. model combin techniques, linear interpol optim task, obtain compar result test set, result slightli better (around 0.4 point improvement). column tabl 9 show result develop set corpus, obtain optim set weight describ section 5.3.2. observ case, weight combin obtain optim task techniqu improv result best perform model isolation, i.e. lc, develop set, 20 m. melero model precis dev test lc 88.31 86.59 optim task 89.12 85.93 linear interpol 86.76 85.53 tc 86.76 84.99 lemma 73.63 69.94 baselin 51.04 61.99 po 62.66 52.50 tabl 9. precis valu model, combin baseline. model precis twitter non-twitt lc 82.56 (-4.03) 87.84 (+1,25) optim task 80.12 (-5.81) 87.46 (+1.53) linear interpol 79.81 (-5.72) 86.93 (+1.40) tc 79.51 (-5.48) 86.70 (+1.71) lemma 67.12 (-2.82) 69.97 (+0.03) baselin 56.88 (-5.11) 63.58 (+1.59) po 55.35 (-2.85) 49.97 (+3.03) tabl 10. precis valu model, combin baseline, separ result twitter non-twitt text, test set. test set linear interpolation8 tc model achiev precision. remark baselin (without selector module) obtain lower result develop set (10 point test set), case clearli surpass worst perform model, i.e. pos. tabl 10 show separ result twitter non-twitt text. tabl bracket neg posit differ valu respect valu tabl 9. precis measur correct select drop 4.5 point averag test twitter text. rank model chang separ results. 8 recal linear interpol tune differ develop set, describ section 5.3.1. select correct candid normal spanish ugc 21 5.5 discuss accuracy, precis recal relat work research closer experi present paper han baldwin (2011) liu et al. (2012), work data includ text twitter text, work normal domain-unspecif text liu et al. (2012) approach broad-coverag system. term spell check detect gener propos han baldwin (2011) liu et al. (2012) work system gener themselves, exist resources. particularli liu et al. (2012) present propos gener strategi inspir visual prime word similar measures. favor gener rank spell correct basi frequenc social text econom transform oper fewer charact changed, better. gener list repres particular word text. instance, word like gener set {pleas, pleeas, pleaas, pleeaas, pleeeaas}. han baldwin (2011) us algorithm base morphophonem similar gener correct proposals. approach allow higher accuraci percentag error correct propos gener selected. addit differ propos gener strategies, import difference, includ normal token normal process, oppos mention work do. reason result hardli compar differ experiments. caveat mind, restrict experiment, case spell-check abl correctli detect error propos set correct candid contain refer correction, show higher precis term 1st-rank correct proposals.9 compar 86.59% vs. liu et al. (2012) 84.13% twitter-bas languag model 79.12% web languag model. recal respect 78.38% 77.11%, han baldwin (2011) reach precis recal 75.30%. 6 conclus paper, present analyz spanish corpu ugc includ text differ sources. seen ugc text present particular featur set apart standard text. hand, contain specif phenomena add expressiveness, emoticons, inform spellings, non-standard capit reduplication. hand, rate typic orthograph error higher edit type text. analyz impact norm deviat standard nlp process tools, compar result process result process manual correct version. result, observ ugc text neg impact perform basic nlp tasks: lemmatization, assign main syntact category, assign morphosyntact features. propos address problem normal ugc text linguist processing. this, convent spell-check built modul 9 actual precis recal number underlying, non-adapt spell-check low: 52% 57% respectively. 22 m. melero automat select best correct candidate. select task, want exper- iment us linguist inform level fine-grainedness. therefore, train languag model larg domain-specif corpus, model contain differ degre inform trade gener capabilities. model base lowercas version corpu turn predictive, reason precis valu 86.59% measur test set. figur baselin slightli higher highest accuraci obtain relat work liu et al. (2012) 84.13% rank correct propos posit list. experi method combin models: model optim directli final task, modifi version spsa algorithm, linear combin model optim independ task. method achiev compar results, weight obtain languag model different. interest conclus optim independ task easier wai round. similar conclus obtain differ task (e.g. phrase-bas statist ma- chine translation). result combin model close best perform model, i.e. lc, perform better, test set data. evalu ad- dition experi twitter text show signific drop precision, compar non-twitt text. experi differ languag model us obtain better result lc model instead baselin tc model. 7 acknowledg author like thank anonym review valuabl comment suggestions. author like thank barcelona media innov center (where work conducted) institut infocomm research support permiss publish work. research lead result receiv fund cdti cenit project social media seventh framework program european commiss intern outgo fellowship (imtrap-2011-29951) intra-european fellowship (crosslingmind-2011-300828) mari curi actions. refer agarwal, a., xie, b., vovsha, i., rambow, o., passonneau, r. 2011. sentiment analysi twitter data. proceed workshop languag social media (lsm 2011), page 3038, portland, oregon. associ comput linguistics. ahmed, f., luca, e. w. d., nurnberger, a. 2010. revis n-gram base automat spell correct tool improv retriev effectiveness. research journal scienc engin applic (polibits) issn 1870-9044, 40. alonso, l. 2010. inisght lingustico relativo la normalizacion lexica contenido genera- do por usuarios. subjetividad y proceso cognitivos, 14(2):2031. print issn: 1666-244x, electron issn :1852-7310. aminian, m., avontuur, t., azar, z., balemans, i., elshof, l., newell, r., van noord, n., ntave- los, a., van zaanen, m. 2012. assign part-of-speech dutch tweets. melero, m., editor, workshop nlp u tag #user-generated-cont ?! lrec-conf.org. languag resourc evalu conference. select correct candid normal spanish ugc 23 axelrod, a., he, x., gao, j. 2011. domain adapt pseudo in-domain data selection. proceed 2011 confer empir method natur languag processing, page 355362, edinburgh, scotland, uk. associ comput linguistics. bender, e. m., morgan, j. t., oxley, m., zachry, m., hutchinson, b., marin, a., zhang, b., ostendorf, m. 2011. annot social acts: author claim align move wikipedia talk pages. proceed workshop languag social media (lsm 2011), page 4857, portland, oregon. associ comput linguistics. bermingham, a. smeaton, a. 2010. classifi sentiment microblogs: breviti advantage? proceed 19th acm intern confer inform knowledg management, page 18331836. acm. bilmes, j. a. kirchhoff, k. 2003. factor languag model gener parallel backoff. proceed hlt/naccl, page 46. brill, e. moore, r. c. 2000. improv error model noisi channel spell correction. proc. 38th annual meet. assoc. comp. ling., page 282293, hong kong. brody, s. diakopoulos, n. 2011. cooooooooooooooollllllllllllll!!!!!!!!!!!!!! word length- en detect sentiment microblogs. proceed 2011 confer empir method natur languag processing, page 562570, edinburgh, scotland, uk. associa- tion comput linguistics. choudhury, m., saraf, r., jain, v., mukherjee, a., sarkar, s., basu, a. 2007. investig model structur text language. intern journal document analysi recognition, 10(3):157174. chung, t. gildea, d. 2009. unsupervis token machin translation. confer empir method natur languag process (emnlp-09), singapore. church, k. gale, w. 1990. poor estim context wors none. darpa workshop speech natur language, hidden valley, pa. clark, e. 2003. pre-process noisi text. proc. workshop shallow process larg corpora. clark, e. araki, k. 2011. text normal social media: progress, problem applic pre-process casual english. pacling. cook, p. stevenson, s. 2009. unsupervis model text messag normalization. calc 09: proceed workshop comput approach linguist creativity, page 7178, morristown, nj, usa. associ comput linguistics. damerau, f. j. 1964. techniqu detect correct errrors. commu- nicat acm, 7:171176. eisenstein, j. 2013. bad languag internet. proceed 2013 confer north american chapter associ comput linguistics: human languag technologies, page 359369, atlanta, georgia. associ computa- tional linguistics. federico, m., bertoldi, n., cettolo, m. 2008. irstlm: open sourc toolkit handl larg scale languag models. interspeech, page 16181621, brisbane, australia. foster, j. 2010. cba check spelling: investig parser perform discuss forum posts. human languag technologies: 2010 annual confer north american chapter associ comput linguistics, page 381384, lo an- geles, california. associ comput linguistics. foster, j., cetinoglu, o., wagner, j., le roux, j., hogan, s., nivre, j., hogan, d., van genabith, 24 m. melero j., et al. 2011. # hardtoparse: po tag pars twitterverse. proceed workshop analyz microtext (aaai 2011), page 2025. gianfortoni, p., adamson, d., rose, c. p. 2011. model stylist variat social media stretchi patterns. proceed workshop algorithm resourc model dialect languag varieties, dialect 11, page 4959, stroudsburg, pa, usa. associ comput linguistics. gouws, s., metzler, d., cai, c., hovy, e. 2011. contextu bear linguist variat social media. proceed workshop languag social media (lsm 2011), page 2029, portland, oregon. associ comput linguistics. grefenstette, g. tapanainen, p. 1994. [w]hat word, [w]hat sentence? [p]roblem [t]okenization. proceed 3rd confer comput lexicographi text research, page 7987, budapest, hungary. han, b. baldwin, t. 2011. lexic normalis short text messages: makn sen #twitter. acl, page 368378. hassan, h. menezes, a. 2013. social text normal contextu graph random walks. proceed 51st annual meet associ comput lin- guistic (volum 1: long papers), page 15771586, sofia, bulgaria. associ compu- tation linguistics. henrquez q., c. hernandez, a. 2009. n-gram base statist machin translat approach text normal chat-speak style communications. caw 2.0 workshop. herring, s. 2012a. discours web 2.0: familiar, reconfigured, emergent. tannen, d. tester, a. m., editors, discours 2.0: languag new media, georgetown univers round tabl languag linguist 2011. georgetown university, washington, dc. herring, s. 2012b. grammar electron communication. chapelle, c., editor, encyclopedia appli linguistics. wiley-blackwell, hoboken, nj. hodge, v. j. austin, j. 2003. comparison standard spell check algorithm novel binari neural approach. ieee trans. know. dat. eng., 15(5):10731081. kobus, c., yvon, f., damnati, g. 2008. normal sms: metaphor better one? cole 08. koehn, p. hoang, h. 2007. factor translat models. proceed 2007 joint confer empir method natur languag process comput natur languag learn (emnlp-conll), page 868876. kukich, k. 1992. techniqu automat correct word text. acm comput. surv., 24(4):377439. lambert, p. banchs, r. e. 2006. tune machin translat paramet spsa. proceed intern workshop spoken languag translat (iwslt), page 190196, kyoto, japan. liu, f., weng, f., jiang, x. 2012. broad-coverag normal social media language. acl (1), page 10351044. associ linguistics. mangu, l. brill, e. 1997. automat rule acquisit spell correction. proceed 14th intern confer machin learning, page 734741. morgan kaufmann. martins, b. silva, m. j. 2004. spell correct search engin queries. estal - espana natur languag processing, alicante, spain. maynard, d., bontcheva, k., rout, d. 2012. challeng develop opinion mine tool social media. melero, m., editor, workshop nlp u tag #user-generated-cont ?! lrec-conf.org, istanbul. languag resourc evalu conference. select correct candid normal spanish ugc 25 mays, e., damerau, f. j., mercer, r. l. 1991. context base spell correction. inform process management, 27(5):517 522. michelson, m. knoblock, c. a. 2005. semant annot unstructur ungrammat- ical text. proceed 19th intern joint confer artifici intellig (ijcai), page 10911098. mohamed, e. 2011. effect automat tokenization, vocalization, stemming, po tag arab depend parsing. proceed fifteenth confer com- putat natur languag learning, page 1018, portland, oregon, usa. associ comput linguistics. moore, r. c. lewis, w. 2010. intellig select languag model train data. proceed acl 2010 confer short papers, page 220224, uppsala, sweden. as- sociat comput linguistics. munoz-garca, o. navarro, c. 2012. compar user gener content publish differ social media sources. melero, m., editor, workshop nlp u tag #user-generated-cont ?! lrec-conf.org, istanbul. languag resourc evalu conference. pang, b. lee, l. 2008. opinion mine sentiment analysis. found. trend inf. retr., 2(1-2):1135. quixal, m., badia, t., benavent, f., boullosa, j. r., domingo, j., grau, b., masso, g., valentn, o. 2008. user-centr design error correct tools. chair), n. c. c., choukri, k., maegaard, b., mariani, j., odjik, j., piperidis, s., tapias, d., ed- itors, proceed sixth intern languag resourc evalu (lrec08), marrakech, morocco. european languag resourc associ (elra). conf.org/proceedings/lrec2008/. ritter, a., clark, s., mausam, etzioni, o. 2011. name entiti recognit tweets: experiment study. emnlp, page 15241534. acl. rodrguez, c., banchs, r., codina, j., grivolla, j. 2010. cometa: semant explor custom review extract valuabl inform busi intelligence. technic report, barcelona media innov center. rousseau, a., bougares, f., deleglise, p., schwenk, h., esteve, y. 2011. lium system iwslt 2011 speech translat tasks. intern workshop spoken languag translation, san francisco (usa). spall, j. c. 1992. multivari stochast approxim simultan perturb gradient approximation. ieee trans. automat. control, 37:332341. spall, j. c. 1998. overview simultan perturb method effici optimization. john hopkin apl technic digest, 19(4):482492. sproat, r., black, a. w., chen, s. f., kumar, s., ostendorf, m., richards, c. 2001. nor- maliz non-standard words. speech & language, 15(3):287333. stolcke, a. 2002. srilm-an extens languag model toolkit. proceed intern confer spoken languag processing, page 257286. toral, a. 2013. hybrid select languag model train data linguist inform perplexity. proceed second workshop hybrid approach translation, page 812, sofia, bulgaria. associ comput linguistics. toutanova, k. moore, r. c. 2002. pronunci model improv spell correction. proc. 40th annual meet assoc. comp. ling., page 144151, hong kong. villegas, m., brosa, m. i., bel, n. 1996. el lexico parol del espanol. xiv congreso la sociedad espanola para el procesamiento del lenguaje. 26 m. melero zhu, c., tang, j., li, h., ng, h. t., zhao, t. 2007. unifi tag approach text normalization. proceed 45th annual meet associ comput linguistics, page 688695, prague, czech republic. associ comput linguis- tics.