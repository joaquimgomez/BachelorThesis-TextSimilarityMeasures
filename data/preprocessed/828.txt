survei model base approach 2d 3d visual human pose recoveri sensor 2014, 14, 4189-4210; doi:10.3390/s140304189 open access sensor issn 1424-8220 www.mdpi.com/journal/sensor review survei model base approach 2d 3d visual human pose recoveri xavier perez-sala 1,*, sergio escalera 2, cecilio angulo 3 jordi gonzalez 4 1 fundacio privada sant antoni abat, vilanova la geltru, universitat politecnica catalunya, vilanova la geltru 08800, catalonia, spain 2 depart mathemat (maia), universitat barcelona vision center (cvc), barcelona 08007, catalonia, spain; e-mail: 3 automat control depart (esaii), universitat politecnica catalunya, vilanova la geltru 08800, catalonia, spain; e-mail: 4 depart science, universitat autonoma barcelona vision center (cvc), bellaterra 08193, catalonia, spain; e-mail: * author correspond addressed; e-mail: received: 29 novemb 2013; revis form: 30 januari 2014 / accepted: 9 februari 2014 / published: 3 march 2014 abstract: human pose recoveri studi field vision 40 years. approach reported, signific improv obtain data represent model design. however, problem human pose recoveri uncontrol environ far solved. paper, defin gener taxonomi group model base approach human pose recovery, compos main modules: appearance, viewpoint, spatial relations, tempor consistence, behavior. subsequently, methodolog comparison perform follow propos taxonomy, evalu current soa approach aforement group categories. result comparison, discuss main advantag drawback review literature. keywords: human pose recovery; human bodi modelling; behavior analysis; vision sensor 2014, 14 4190 1. introduct human pose recovery, pose recoveri short, refer process estim underli kinemat structur person sensor input [1]. vision-bas approach provid solution, camera sensor [2]. pose recoveri import issu vision applications, video index [3], surveil [4], automot safeti [5] behavior analysi [6], human interact applic [7,8]. bodi pose estim challeng problem degre freedom estimated. addition, appear limb highli vari chang cloth bodi shape (with extrem usual case self occlusions), chang viewpoint manifest 2d non-rigid deformations. moreover, dynam chang background real-world scene data associ complex differ frames. difficulti address wai depend input data provided. sometimes, 3d inform avail multipl camera instal scene. nowadays, number human pose estim approach depth map publish recent market releas low cost depth camera [9]. cases, problem challeng ambigu relat 2d imag project avoid 3d data combin rgb information. applications, however, camera available. cases, rgb data consid imag available, combin tempor inform input imag provid video sequence. pose recoveri approach recov human bodi pose imag plane. however, recent work step estim human pose 3d [10]. probably, challeng issu 3d pose estim project ambigu 3d pose 2d imag evidences. problem particularli difficult clutter realist scene multipl people, appear partial fulli occlud certain interv time. monocular data inform input address 3d pose recoveri problem, gener solut clutter scenes. exist differ approaches, depend activ peopl video sequenc carri out. however, lack work take account activity, task behavior refin gener approach. bodi pose recoveri approach classified, step, model base model free methods. hand, model free method [11,12] learn map appear bodi pose, lead fast perform accur result certain action (ex. walk poses). however, method limit background subtract pre-process poor gener pose detected. hand, human pose estim approach classifi model base method emploi human knowledg recov bodi pose. search space reduced, example, take account human bodi appear structure, depend viewpoint, human motion relat activ carri out. order updat recent advanc field human pose recovery, provid gener standard taxonomi classifi state-of-the-art (soa) model base approaches. propos taxonomi compos main modules: appearance, viewpoint, spatial relations, tempor consistence, behavior. survei analyz vision approach human pose sensor 2014, 14 4191 recovery, imag evid interpret relat previou knowledg bodi appearance. depend appear detect spatio-tempor post processing, work infer coars refin viewpoint body, pose estim approach restrict possibl viewpoint detect train dataset. bodi pose recoveri task impli locat bodi part image, spatial relat taken account. way, video sequenc available, motion bodi part studi refin bodi pose analyz behavior performed. finally, block behavior refers, hand, method account particular activ inform scene provid feedback previou modules, improv final pose recognition. hand, work implicitli account behavior elect dataset contain certain activities. global taxonomi rest paper illustr figur 1. figur 1. propos taxonomi model-bas human pose recoveri approaches. rest paper organ follows: section 2 review soa methods, categor propos taxonomy. section 3 perform methodolog comparison relev work accord taxonomi discuss advantag drawbacks, main conclus section 4. 2. state art human pose recoveri refer process estim configur bodi part person (3d pose recovery) 2d project imag plane (2d pose recovery). gener terms, human pose recoveri estim skeleton correctli fit imag evidences. process preced detect track phases, typic pedestrian detect applications. initi detect phase usual reduc comput time system, highli reduc possibl pose estimated. inform relat topic refer survei human detect track [5,13,14]. pose estim survei exit literatur [1517], gener studi involv recent work vision-bas human motion analysi [1,18]. provid taxonomy. [18], research divid categories, 2d 3d approaches, [1] defin taxonomi categories: model-free, indirect model use, direct model use. far know, work [16] consid complet survei literature. defin taxonomi model build (a likelihood function) estim (the plausibl pose given likelihood function). subsections, soa relat human pose recoveri review model base work classifi accord main modul propos [17]: appearance, viewpoint, spatial relations, tempor relat behavior. furthermore, subgroup defin taxonomi module. figur 1. sensor 2014, 14 4192 2.1. appear appear defin imag evid relat human bodi possibl poses. evid refer imag featur input data, pixel label obtain certain label procedure. hence, imag evid consid differ levels, pixel region image. descript imag featur human (or bodi part) detect consid imag evidences. appear peopl imag vari differ human poses, light cloth conditions, chang point view, others. main goal recoveri kinemat configur person, research describ section tri gener kind variations. prior knowledg pose appear requir order obtain accur detect track human body. inform codifi sequenti stages: descript imag detect human bodi (or parts), usual appli previou learn process. entir procedur imag descript detect certain region perform differ levels: pixel, local global (shown figur 2ac). respectively, lead imag segment [1921], detect bodi part [2225] bodi locat [26,27]. wide accept describ human bodi ensembl part improv recognit human bodi complex poses, despit increas comput time. contrast, global descriptor successfulli human detect field, allow fast detect certain pose (e.g., pedestrians), serv initi human pose recoveri approaches. sub-taxonomi descript detect stage detail next. figur 2. exampl descriptor appli pixel, local global levels, respectively: (a) graph cut approach bodi hand segment (frame extract [21]); (b) steerabl basi (frame extract [25]); (c) imag person hog descriptor, descriptor weight posit neg classif area (frame extract [26]). 2.1.1. descript inform extract imag descript phase analyz detect stage. typic method appli describ imag cue detail below. silhouett contour silhouett boundari (edg contours) provid power descriptor invari chang color texture. fit human bodi sensor 2014, 14 4193 imag [28] bodi pose inform remain silhouette. however, method suffer bad noisi segment real-world scenes, difficulti recov degre freedom (dof) lack depth information. intensity, color textur hand, gradient imag intens wide appli featur describ appear person. histogram orient gradient (hog) sift descriptor us consid [26]. hand, color textur inform addit cue local descript region [10]. color inform usual codifi mean histogram space color model [29], textur describ discret fourier transform (dft) [30] wavelet gabor filter [31], others. depth recently, depth cue consid human pose recognit depth map avail multi-sensor kinecttm. new depth represent offer near 3d inform cheap sensor synchron rgb data. base representation, new depth multi-mod descriptor proposed, classic method revisit take advantag new visual cues. exampl gabor filter depth map hand descript [32] novel keypoint detector base salienc depth map [33]. approach comput fast discrimin descript detect extrema geodes map comput histogram normal vector distribution. however, requir specif imag cue, depth map available. motion optic flow [34] common featur model path motion classifi human activ [35,36]. additionally, work track visual descriptor codifi motion provid certain visual region addit local cue [37]. sense, follow idea hog, histogram optic flow (hof) construct [35] regions, bodi part movements. logic import notic new descriptor includ logic relat recent proposed. case group-let approach yao fei-fei [38], local featur codifi logic operators, allow intuit discrimin descript imag (or region) context. 2.1.2. detect stage refer specif imag detect output classifi codifi human inform images. synthesi process perform gener area summar below. discrimin classifi common techniqu detect peopl imag consist describ imag region standard descriptor (i.e., hog) train discrimin classifi (e.g., support vector machines) global descriptor human bodi [26] multi-part descript learn part [39]. author extend kind approach includ spatial relat object descriptor second level discrimin classifier, case poselet [27]. sensor 2014, 14 4194 gener classifi case discrimin classifiers, gener approach propos address person detection. however, case gener approach us deal problem person segmentation. instance, approach rother, kolmogorov blake [40] learn color model initi evid person, background objects, optim probabilist function graph cuts. templat example-bas method human pose estim propos compar observ imag databas sampl [10]. point salient point part imag comput pose behavior carri video sequenc [37]. sense, refer reader [41] fair list region detectors. 2.2. viewpoint viewpoint estim us determin rel posit orient object (or human body) camera (i.e., camera pose), significantli reduc ambigu 3d bodi pose [10]. literatur term camera pose usual refer pose, prefer explicitli distinguish camera pose pose refer human bodi posture, review. usually, bodi viewpoint directli estim human track pose recoveri literature, however, indirectli considered. some, possibl viewpoint detect constrained, example, train dataset. wok upper bodi pose estim pedestrian detect literature, view respect studied. example, detector [23] present abl detect peopl arbitrari views, perform evalu walk views. work explicitli restrict approach reduc set views, frontal later viewpoint [42]. case data set compos motion captur taken differ view clear discrimin them, consid viewpoint explicitli implicitli considered. research 3d viewpoint estim divid discret classif continu viewpoint estim (figur 1). 2.2.1. discret discret approach treat problem viewpoint classif category, viewpoint queri imag classifi limit set possibl initi known [43,44] unknown [45] views. works, 3d geometri appear object captur group local featur part learn relations. imag evid directli categor viewpoint. stage work andriluka, roth schiel [10], discret viewpoint estim pedestrian train viewpoint-specif peopl detector (shown figur 3a). stage, classif refin viewpoint continu wai (shown figur 3b), estim rotat angl person vertic axi project 3d exemplar 2d bodi part detections. sensor 2014, 14 4195 figur 3. viewpoint estim examples: (a) (discrete) (b) second (continuous) phase viewpoint estim (frame extract [10]); (c) cluster camera pose space object provid continu viewpoint (frame extract [46]). 2.2.2. continu continu approach viewpoint estim refer estim real valu viewpoint angl exampl object human 3d. continu viewpoint estim wide studi field shape registration, refer find correspond set point recov transform map point set other. monocular non-rigid shape registr [47] seen similar problem bodi pose estimation, point deform shape interpret bodi joint [48]. given static images, simultan continu camera pose shape estim studi rigid surfac [46], deform shape [49]. works, prior knowledg camera provid model possibl camera pose gaussian mixtur model (shown figur 3c). 2.3. spatial model spatial model encod configur human bodi hard (e.g., skeleton, bone lengths) soft wai (e.g., pictori structures, grammars). hand, structur model encod 3d skeleton accur kinemat chains. hand, degen project human bodi imag plane usual model ensembl parts. independ chosen strategy, human pose recoveri refer estim bodi structure, torso upper bodi estimate. tv show scene film leg appear visibl frame, work [50,51] dataset [52] restrict upper bodi estimation. 2.3.1. ensembl part techniqu base ensembl part consist detect like locat differ bodi part correspond consistent, plausibl configur human body. however, composit defin physic bodi constraint possibl locat bodi part image, techniqu deal high variabl bodi pose viewpoints. sensor 2014, 14 4196 pictori structur [53] gener 2d assembl parts, detect specif detector (shown figur 4a,b). pictori structur gener framework object detect wide peopl detect human pose estim [23,54]. tradit structur represent graph [53] (shown figur 4a), recent approach repres underli bodi model tree, infer facil studi [54]. constraint part model follow gaussian distributions, match, example, typic walk movement thigh shank. however, gaussian distribut correspond restrict 2d imag plane: appli parametr space repres position, orient scale [54]. figur 4. exampl bodi model ensembl parts: (a) origin (frame extract [53]) (b) extend (frame extract [23]) pictori structures; (c) human model base grammars: coars filter (left), differ filter higher resolut (middle), model spatial locat part (right) (frame extract [39]); (d) hierarch composit bodi piec (frame extract [24]); (e) spatio-tempor loopi graph (frame extract [55]); (f) differ tree obtain mixtur part (frame extract [56]); structur models: (g) sampl 3d pose estim danc sequenc (frame extract [57]); (h) possibl 3d pose (down) match 2d project (up) match detect bodi part (frame extract [48]). grammar model formal [58] provid flexibl eleg framework detect object [39], appli human detect [39,59,60]. composit rule repres object combin objects. way, human bodi repres composit trunk, limb face; compos eyes, nose mouth. theoret point view, deform rule lead hierarch deformations, allow rel movement part level; however, deform rule [39] treat pictori structur (shown figur 4c). sensor 2014, 14 4197 make grammar attract structur variabl deal occlus [59]. follow composit idea, [24] base poselet [27] repres bodi hierarch combin bodi piec (shown figur 4d). ensembl part perform 3d 3d inform avail multi-camera system [55,61]. extens pictori structur 3d present [61], tempor evolut taken account (shown figur 4e). joint model follow mixtur gaussian distributions, name loose-limb model loos attach limbs. power rel unexplor graphic represent human 2d pose estim and-or graph [62], seen combin stochast context free grammar multi-level markov random fields. moreover, structur allow rapid probabilist infer logic constrain [63]. research graph infer area, optim algorithm avoid local minima. multi-view tree repres altern global optimum dynam program [56], hard pose prior [64] branch bound algorithm [65]. moreover, [56], paramet bodi model appear learn simultan [56] order deal high deform human bodi chang appear (shown figur 4f). 2.3.2. structur model effici tree similar human bodi acycl graphs, structur model repres kinemat chain follow tree configuration. contrarili tree explain above, node repres bodi parts, node structur tree usual repres joints, parameter degre freedom (dof). wai ensembl part frequent consid 2d, accur kinemat constraint structur model appropri 3d representation. however, us 2d structur model reason us motion parallel imag plane (e.g., gait analysi [42]). 2d pose estim [66] degener 2d model learn imag projections. 3d recoveri human pose monocular imag challeng situat human pose estim project ambiguities. inform lost project real world imag plane, 3d pose match 2d imag evid [57]. kinemat constraint pose movement typic emploi solv inher ambigu monocular human pose reconstruction. therefore, differ work focus reconstruct 3d pose given 2d joint project invers kinemat [67,68], subsequ track [69,70]. [69], human bodi model kinemat chain, parameter twist exponenti maps. track perform 2d, manual initialization, project 3d model imag plane orthograph projection. kinemat model [71], ad refin shape garment, provid fulli automat initi tracking. multi-camera requir 3d laser rang model subject tracked. [57], 3d pose estim project 3d model imag plane suitabl view, perspect imag project (shown figur 4g). comput kinemat model base hard constraint sensor 2014, 14 4198 angl limit weak priors, penalti proport self collisions, inspir strong human knowledge. recov number degre freedom (dof) vari greatli differ works, 10 dof upper bodi pose estimation, full-bodi 50 dof. however, number possibl pose huge model dof discret paramet space. reason, kinemat constraint joint angl limit typic appli structur models. solut reli reduc dimension appli unsupervis techniqu princip compon analysi (pca) possibl 3d pose [42,48,66,72]. continu state space cluster [66], pca appli cluster order deal non-linear human bodi perform differ actions. [42], hierarch pca depend human pose, model bodi bodi part separately. hybrid approach exist, exploit benefit structur model ensembl part (shown figur 4h). follow idea shape registr field, structur model [48] learn bodi deform differ human poses, follow pca order reduc dimension model. moreover, search space possibl pose reduc take profit soa bodi detector propos [56]. intention, paramet structur model appear learn simultaneously. activ shape model (asm) [73] activ appear model (aam) [74] label model abl deform shape accord statist paramet learn train set. aam, moreover, abl learn appear surround anatom landmarks, reliabl label train examples. asm aam face detect head pose estim [75], learn local appear deform bodi part bodi pose estim [76]. approach us provid higher degre gener example-bas approaches, compar imag evid databas samples. bodi part detect [10] perform multi-view pictori structures, 3d reconstruct estim project 3d exampl 2d imag evidence. 2.4. tempor model order reduc search space, tempor consist studi video sequenc available. motion bodi part incorpor refin bodi pose analyz behavior performed. 2.4.1. track track appli ensur coher pose time. track appli separ bodi part repres posit bodi taken account. moreover, 2d track appli pixel world positions, i.e., latest consid person move 3d. subdivis track number hypothesis, singl maintain sequenc multipl hypothesi propag time. singl track appli [42], central bodi estim hidden markov model (hmm). final 2d bodi pose recov refin posit sensor 2014, 14 4199 body. 2d, singl hypothesi bodi joint (shown figur 5b) propag [77]. approach perform 2d, loos gener stage work movement parallel imag plane. contrast, 3d track multipl hypothes comput [10], lead accur consist 3d bodi pose estim (shown figur 5a). figur 5. exampl track sequences: (a) 3d track body, multipl hypothesi approach (frame extract [10]); (b) 2d track bodi part (frame extract [77]); (c) left: 3d featur smile mouth; right: comparison shape trajectori space (frame extract [78]). topic shape recovery, probabilist formul present [79] simultan solv camera pose non-rigid shape mesh (i.e., bodi pose topic) batch. possibl posit landmark (i.e., bodi parts) covari propag sequence, optim simultan 3d track points. 2.4.2. motion model human bodi perform huge divers movements, however, specif action defin smaller set movement (e.g., cyclic action walking). way, set motion prior bodi movement singl action performed. however, hard restrict possibl motion recov establish [66,72]. motion model introduc [80], combin bodi model walk run sequences. reduct dimension perform appli pca sequenc joint angl differ examples, obtain accur tracking. work extend [81] golf swing monocular imag semi-automat framework. scale gaussian process latent variabl model (sgplvm) repres differ human motion [82] cyclic (ex. walking) acycl (ex. golf swing) actions, monocular imag sequences, despit impos hard prior pose motion. [83], instance, problem pose estim address tempor domain. possibl human movement learn gaussian process, reduc search space pose recoveri perform activ skiing, golf skating. potenti issu motion prior varieti movement describ highli depend divers movement train data. hand, gener trajectori base discret cosin transform (dct) introduc [84] reconstruct differ movement from, example, face toi (shown figur 5c). case, trajectori model combin spatial sensor 2014, 14 4200 model track objects. applic motion model relat human pose [85], achiev 3d reconstruct move point track human scenes; [86], articul trajectori reconstruct upper bodi models. 2.5. behavior block behavior taxonomi refer method account activ context inform provid feedback previou pose recognit modul [87]. approach previous describ directli includ kind information. however, databas usual organ action (e.g., walking, jogging, box [88]) algorithm us learn pose belong action (e.g., walk [10], golf swing [81]). sense, select specif train dataset direct indirect choic set action abl detect. import point taxonomi literatur behavior, action, activity, gestur sub-gesture, example, broadli detailed. term behavior gener concept includ action gestures. behavior analysi usual soa pose estimation, work account behavior activ estim accur bodi pose, learn differ model depend action perform [72]. differ subspac comput action [66]. however, number action chosen critic parameter, action seen differ viewpoint interpret differ movements. phenomenon occur degener 2d model learn imag projections, instead build 3d view invari model. figur 6. joint human pose behavior estimation: (a) differ walk exampl (curves), learn model (piecewis lines) kei pose (frame extract [6]); (b) graphic model propos object detect (o) human pose estim (h) bodi (pi) detections, imag exampl human plai tenni (frame extract [89]). work literatur step forward jointli recov pose behavior. work yao li [89], author includ context inform human activ interact object (shown figur 6b) improv final pose estim activ recognition. report ambigu class better discriminated. similarly, andriluka sigal extend [90] previou work multi-peopl 3d pose estim model human sensor 2014, 14 4201 interact context. achiev success result competit danc video treat detect subject mutual context subject scene. finally, work singh nevatia [6] take profit joint estim human pose action performed. set kei pose learn action (shown figur 6a) 3d pose accur recov specif model action, show joint estim behavior pose improv results. 3. discuss human pose recoveri challeng problem degre freedom estimated, chang appear viewpoint, huge number pose movement human perform. order review current trend field, relev work compar figur 7. list method compar base perform result exist common benchmark compar 2d 3d pose estim approaches, joint estim human pose behavior. moreover, best current results, works, overcam recent techniques, signific advanc soa. hence, comparison present figur 7 tackl methodologies, accord tho taxonomi propos figur 1. work [10] exampl model excel results. model modul propos taxonomy, outperform soa. approach reli strong bodi detector conjunct power 3d tracking. contrast, [48] 3d pose estim approach imag proposed. report good estim human pose video frame [10] fails. similar bodi detector but, instead model human dynamics, model possibl bodi deformations, penal non-anthropomorph poses. case 2d pose estimation, best result soa achiev [56]. fast approach base strong bodi detector flexibl tree configur proposed, encod pairwis relat consecut bodi parts. follow images, excel result achiev [89] behavior context inform object detection. however, imag descriptor object bodi parts, current soa imag descriptor orient bodi part [56] improv results. global point view, perform model base approach human pose recoveri reli special appear module, i.e., imag descript bodi detectors. however, soa bodi detector report impress results, fals positives. hence, goal spatial model restrict imag evid specif combin compos human body. hand, best perform 2d pose estim model human bodi ensembl parts. hand, work comput 3d pose requir 3d structur model limit physic anthropomorph constraints. point, approach sophist spatial model impos tempor viewpoint constraint reduc search space. order complet survey, discuss refer current trend taxonomi modul detail below. sensor 2014, 14 4202 figur 7. compar model base human pose recoveri approaches. dash viewpoint behavior indic correspond work studi modul describ column. dash tempor model mean video sequenc avail correspond work. sensor 2014, 14 4203 appear wide accept best current result modul achiev bodi detectors. however, consensu best descriptor. tracking-bas approach tend us simpl descriptor base intensity, current work consid hog derivative-bas approach local imag evidences. [56] hog statist considered, flexibl bodi detector built combin hog basi filters, deal high variabl human appearance. viewpoint refer method viewpoint analysi split discret continu techniques. viewpoint commonli estim 3d human pose recoveri approach usual work bodi pose comput 2d. moreover, huge variabl 3d human pose make project 2d imag plane highli nonlinear [48]. simultan 3d human pose recoveri camera pose estim [49] eleg approach reduc nonlinearities. spatial model spatial model review divid ensembl part structur models, depend flexibility. ensembl part approach result us fit 2d imag evidences, occur 2d degen space accur kinemat constraint hard deal huge bodi movements, combin chang viewpoint projection. structur approach deal 3d pose accurately, reduc search space physic constraints. end, current parametr 3d skeleton [48] kei pose [10] similar results. past years, pictori structur predomin soa. however, recent approach base multi-view tree [56] grammar [39] provid interest framework deal occlusions, high variabl human pose larg fals posit provid bodi detectors. tempor model tempor model review split track motion models. video sequenc available, 3d inform track approach improv 2d method nonlinear viewpoint project reduced. hard motion prior help pose estim problem, reduc search space despit limit possibl movement detected. gener motion model help reduc search space bodi configurations. however, test condit (figur 7). appear modul avoid kei point imag previous provid [86]. way, gener model deserv studi applic bodi detector noisi input data. behavior common approach includ human behavior pose estim method constrain dataset certain activities. however, simultan estim behavior human pose, human pose refin activ estim common literature. scene understand recent demonstr power field research provid us feedback problem object recognit human pose recoveri problem [89]. kind infer incorpor higher layer knowledg (i.e., ambient intellig layer) context, scene activ inform provid valuabl feedback modul approach improv final pose estim process. sensor 2014, 14 4204 4. conclus survey, review past current trend field human pose recovery. propos new taxonomi group soa model base method appearance, viewpoint, spatial relations, tempor consistence, behavior modules. moreover, methodolog comparison perform follow propos taxonomy, evalu current soa approach aforement group categories. appear stabl area wide extend us edg base descriptor (e.g., hog) detect bodi parts. contrast, current trend spatial model diverse. differ represent spatial relat bodi part combin high varieti infer methods, draw heterogen soa. tempor model modul clearli orient tracking, predomin motion model approach video sequenc available. indeed, motion model deepli explor field human pose estimation, reduc huge search space approach 3d human pose recovery. viewpoint behavior modul present literature. however, joint viewpoint 3d pose estim hard problem, reduc nonlinear estim problem. way, joint behavior bodi pose analysi common trend improv gener capabl current approaches, includ context complementari discrimin sourc information. words, futur trend human pose recoveri tend combin knowledg global scene object nearbi detect human pose analyz motion. acknowledg work partli support spanish ministri scienc innov (project tin2009-14404-c02, tin2009-14501-c02-02, tin2011-28854-c03-01 tin2012-39051) comissionat universitat recerca del departa dinnovacio, universitat empresa la generalitat catalunya. author contribut author contribut extens work present paper wrote manuscript. xavier perez-sala review state-of-the-art wrote initi version paper. taxonomi conceiv xavier, sergio escalera cecilio angulo supervis project. xavier, jordi gonzalez provid suggest correct prepar submitted, review final version paper. conflict author declar conflict interest. sensor 2014, 14 4205 refer 1. moeslund, t.; hilton, a.; kruger, v. survei advanc vision-bas human motion captur analysis. comput. vis. imag underst. 2006, 104, 90126. 2. marr, d.; vaina, l. represent recognit movement shapes. proc. r. soc. lond. ser. b. biol. sci. 1982, 214, 501524. 3. eichner, m.; marin-jimenez, m.; zisserman, a.; ferrari, v. articul human pose estim search (almost) unconstrain images; technic report no. 272; eth zurich: zurich, switzerland, septemb 2010. 4. gowsikhaa, d.; abirami, s.; baskaran, r. autom human behavior analysi surveil videos: survey. artif. intell. rev. 2012, doi:10.1007/s10462-012-9341-3. 5. dollar, p.; wojek, c.; schiele, b.; perona, p. pedestrian detection: evalu state art. ieee trans. pattern anal. mach. intell. 2011, 34, 743761 . 6. singh, v.; nevatia, r. action recognit clutter dynam scene pose-specif models. proceed 2011 ieee intern confer vision (iccv), barcelona, brazil, 613 novemb 2011; pp. 113120. 7. seemann, e.; nickel, k.; stiefelhagen, r. head pose estim stereo vision human-robot interaction. proceed sixth ieee intern confer automat face gestur recognition, seoul, korea, 1719 2004; pp. 626631. 8. nickel, k.; stiefelhagen, r. visual recognit point gestur human-robot interaction. imag vis. comput. 2007, 25, 18751884. 9. escalera, s. human behavior analysi depth maps. articul motion deform objects; springer: berlin, germany, 2012; pp. 282292. 10. andriluka, m.; roth, s.; schiele, b. monocular 3d pose estim track detection. proceed 2010 ieee confer vision pattern recognit (cvpr), san francisco, ca, usa, 1318 june 2010; pp. 623630. 11. agarwal, a.; triggs, b. recov 3d human pose monocular images. ieee trans. pattern anal. mach. intell. 2006, 28, 4458. 12. rogez, g.; orrite, c.; martnez-del rincon, j. spatio-tempor 2d-model framework human pose recoveri monocular sequences. pattern recognit. 2008, 41, 29262944. 13. enzweiler, m.; gavrila, d. monocular pedestrian detection: survei experiments. ieee trans. pattern anal. mach. intell. 2009, 31, 21792195. 14. geronimo, d.; lopez, a.; sappa, a. vision approach pedestrian detection: visibl spectrum survey. ieee trans. pattern anal. mach. intell. 2007, 4477, 547554. 15. ramanan, d. part-bas model find peopl estim pose. visual analysi humans; springer: berlin, germany, 2011; pp. 199223. 16. poppe, r. vision-bas human motion analysis: overview. comput. vis. imag underst. 2007, 108, 418. 17. perez-sala, x.; escalera, s.; angulo, c. survei spatio-tempor view invari human pose recovery. proceed 15th intern confer catalan associ artifici intellig (ccia2012), catalonia, spain, 2426 octob 2012. sensor 2014, 14 4206 18. gavrila, d. visual analysi human movement: survey. comput. vis. imag underst. 1999, 73, 8298. 19. shotton, j.; fitzgibbon, a.; cook, m.; sharp, t.; finocchio, m. real-tim human pose recognit rart singl depth images. mach. learn. comput. vis. stud. comput. intell. 2011, 411, 119135. 20. hernandez, a.; reyes, m.; escalera, s.; radeva, p. spatio-tempor grabcut human segment face pose recovery. proceed 2010 ieee societi confer vision pattern recognit workshop (cvprw), san francisco, ca, usa, 1318 june 2010; pp. 3340. 21. hernandez-vela, a.; zlateva, n.; marinov, a.; reyes, m.; radeva, p.; dimov, d.; escalera, s. graph cut optim multi-limb human segment depth maps. proceed 2012 ieee confer vision pattern recognit (cvpr), providence, ri, usa, 1621 june 2012. 22. ramanan, d. learn pars imag articul bodies. proceed twentieth annual confer neural inform process systems, vancouver, bc, canada, 47 decemb 2006; volum 19, p. 1129. 23. andriluka, m.; roth, s.; schiele, b. pictori structur revisited: peopl detect articul pose estimation. proceed ieee societi confer vision pattern , miami, fl, usa, 2025 june 2009; pp. 10141021. 24. wang, y.; tran, d.; liao, z. learn hierarch poselet human parsing. proceed 2011 ieee confer vision pattern recognition, providence, ri, usa, 2025 june 2011; pp. 17051712. 25. pirsiavash, h.; ramanan, d. steerabl models. proceed ieee confer vision pattern recognition, providence, ri, usa, 1621 june 2012. 26. dalal, n.; triggs, b. histogram orient gradient human detection. proceed ieee confer vision pattern recognition, san diego, ca, usa, 2026 june 2005; volum 1, pp. 886893. 27. bourdev, l.d.; malik, j. poselets: bodi detector train 3d human pose annotations. proceed ieee 12th intern confer vision, kyoto, japan, 27 september4 october, 2009; pp. 13651372. 28. mittal, a.; zhao, l.; davis, l. human bodi pose estim silhouett shape analysis. proceed ieee confer advanc video signal base surveillance, miami, fl, usa, 2122 juli 2003; pp. 263270. 29. sande, k.; gevers, t.; snoek, c. evalu color descriptor object scene recognition. ieee trans. pattern anal. mach. intell. 2010, 32, 15821596. 30. navarathna, r.; sridharan, s.; lucey, s. fourier activ appear models. proceed ieee intern confer vision, barcelona, spain, 613 novemb 2011; pp. 19191926. 31. daugman, j.; others. uncertainti relat resolut space, spatial frequency, orient optim two-dimension visual cortic filters. j. opt. soc. am. 1985, 2, 11601169. sensor 2014, 14 4207 32. pugeault, n.; bowden, r. spell out: real-tim asl fingerspel recognition. proceed ieee intern confer vision, barcelona, spain, 613 novemb 2011. 33. plagemann, c.; ganapathi, v.; koller, d.; thrun, s. real-tim identif local bodi part depth images. proceed ieee intern confer vision, barcelona, spain, 613 novemb 2011; pp. 31083113. 34. barron, j.; fleet, d.; beauchemin, s. perform optic flow techniques. int. j. comput. vis. 1994, 12, 4377. 35. laptev, i.; marszalek, m.; schmid, c.; rozenfeld, b. learn realist human action movies. proceed ieee societi confer vision pattern recognit (cvpr 2008), anchorage, ak, usa, 2426 june 2008; pp. 18. 36. chakraborty, b.; holte, m.; moeslund, t.; gonzalez, j. select spatio-tempor points. comput. vis. imag underst. 2012, 116, 396410. 37. laptev, i. space-tim points. int. j. comput. vis. 2005, 64, 107123. 38. yao, b.; li, f.-f. grouplet: structur imag represent recogn human object interactions. proceed 23rd ieee confer vision pattern recognition, san francisco, ca, usa, 1318 june 2010. 39. felzenszwalb, p.; girshick, r.; mcallester, d.; ramanan, d. object detect discrimin train part-bas models. ieee trans. pattern anal. mach. intell. 2010, 32, 16271645. 40. rother, c.; kolmogorov, v.; blake, a. grabcut: interact foreground extract iter graph cuts. acm trans. graph. 2004, 23, 309314. 41. mikolajczyk, k.; tuytelaars, t.; schmid, c.; zisserman, a.; matas, j.; schaffalitzky, f.; kadir, t.; gool, l.v. comparison affin region detectors. int. j. comput. vis. 2005, 65, 4372. 42. karaulova, i.; hall, p.; marshall, a. hierarch model dynam track peopl singl video camera. proceed british machin vision confer 2000, bristol, uk, 1114 septemb 2000; volum 1, pp. 352361. 43. savarese, s.; li, f.-f. 3d gener object categorization, local pose estimation. proceed ieee 11th intern confer vision, rio janeiro, brazil, 1420 octob 2007; pp. 18. 44. sun, m.; su, h.; savarese, s.; li, f.-f. multi-view probabilist model 3d object classes. proceed 2009 ieee societi confer vision pattern recognition, miami, fl, usa, 2025 june 2009; pp. 12471254. 45. su, h.; sun, m.; li, f.-f.; savarese, s. learn dens multi-view represent detection, viewpoint classif synthesi object categories. proceed ieee 12th intern confer vision, kyoto, japan, 27 september4 octob 2009; pp. 213220. 46. moreno-noguer, f.; lepetit, v.; fua, p. pose prior simultan solv align correspondence. proceed 10th european confer vision, marseille, france, 1218 octob 2008; pp. 405418. sensor 2014, 14 4208 47. salzmann, m.; moreno-noguer, f.; lepetit, v.; fua, p. closed-form solut non-rigid 3d surfac registration. proceed 10th european confer vision, marseille, france, 1218 octob 2008; pp. 581594. 48. simo-serra, e.; ramisa, a.; alenya, g.; torras, c.; moreno-noguer, f. singl imag 3d human pose estim noisi observations. proceed 2012 ieee confer vision pattern recognition, providence, ri, usa, 1621 june 2012. 49. sanchez-riera, j.; ostlund, j.; fua, p.; moreno-noguer, f. simultan pose, correspond non-rigid shape. proceed 23rd ieee confer vision pattern recognition, san francisco, ca, usa, 1318 june 2010; pp. 11891196. 50. eichner, m.; marin-jimenez, m.; zisserman, a.; ferrari, v. 2d articul human pose estim retriev (almost) unconstrain images. int. j. comput. vis. 2012, 99, 190214. 51. sapp, b.; weiss, d.; taskar, b. pars human motion stretchabl models. proceed 24th ieee confer vision pattern recognition, colorado springs, co, usa, 2025 june 2011; pp. 12811288. 52. ferrari, v.; eichner, m.; marin-jimenez, m.; zisserman, a. buffi stickmen dataset. avail online: (access 23th juli 2012). 53. fischler, m.; elschlager, r. represent match pictori structures. comput. trans. 1973, 100, 6792. 54. felzenszwalb, p.; huttenlocher, d. pictori structur object recognition. int. j. comput. vis. 2005, 61, 5579. 55. sigal, l.; bhatia, s.; roth, s.; black, m.; isard, m. track loose-limb people. proceed 2004 ieee societi confer vision pattern recognition, washington, dc, usa , 27 june2 juli 2004; volum 1, pp. 421428. 56. yang, y.; ramanan, d. articul pose estim flexibl mixtures-of-parts. proceed 24th ieee confer vision pattern recognition, colorado springs, co, usa, 2025 june 2011; pp. 13851392. 57. sminchisescu, c.; triggs, b. kinemat jump process monocular 3d human tracking. proceed 2003 ieee societi confer vision pattern recognition, madison, wi, usa , 1622 june 2003; volum 1, pp. i69. 58. felzenszwalb, p.; mcallester, d. object detect grammars; technic report: scienc tr; univers chicago: chicago, il, usa, 2010. 59. girshick, r.; felzenszwalb, p.; mcallester, d. object detect grammar models. ieee trans. pattern anal. mach. intell. 2011, 33, 6. 60. pedersoli, m.; gonzalez, j.; hu, x.; roca, f. real-tim pedestrian detect base deform templat model. trans. intell. transp. syst. 2013, 15, 355364 . 61. sigal, l.; isard, m.; haussecker, h.; black, m. loose-limb people: estim 3d human pose motion non-parametr belief propagation. int. j. comput. vis. 2012, 98 1548. 62. zhu, l.; chen, y.; lu, y.; lin, c.; yuille, a. max margin and/or graph learn pars human body. proceed 2008 ieee societi confer vision pattern recognition, anchorage, ak, usa, 2426 june 2008; pp. 18. sensor 2014, 14 4209 63. chen, y.; zhu, l.; lin, c.; yuille, a.; zhang, h. rapid infer novel and/or graph object detection, segment parsing. nip 2007, 20, 289296. 64. lan, x.; huttenlocher, d. trees: common-factor model 2d human pose recovery. proceed 10th ieee intern confer vision (iccv 2005), beijing, china, 1720 octob 2005; volum 1, pp. 470477. 65. singh, v.; nevatia, r.; huang, c. effici infer multipl heterogen detector human pose estimation. eccv 2010, 6313, 314327. 66. agarwal, a.; triggs, b. track articul motion piecewis learn dynam models. proceed 8th european confer vision, prague, czech republic, 1114 2004; volum 3, pp. 5465. 67. wei, x.; chai, j. model 3d human pose uncalibr monocular images. proceed ieee 12th intern confer vision, kyoto, japan, 27 september4 octob 2009; pp. 18731880. 68. valmadre, j.; lucey, s. determinist 3d human pose estim rigid structure. proceed 11th european confer vision, heraklion, crete, greece, 511 septemb 2010; pp. 467480. 69. bregler, c.; malik, j.; pullen, k. twist base acquisit track anim human kinematics. int. j. comput. vis. 2004, 56, 179194. 70. howe, n.; leventon, m.; freeman, w. bayesian reconstruct 3d human motion single-camera video; nips: cambridge, ma, usa, 1999; volum 1999, p. 1. 71. gall, j.; stoll, c.; aguiar, e.; theobalt, c.; rosenhahn, b.; seidel, h. motion captur joint skeleton track surfac estimation. proceed 2009 ieee societi confer vision pattern recognit (cvpr 2009), miami, fl, usa, 2025 june 2009; pp. 17461753. 72. rius, i.; gonzalez, j.; varona, j.; roca, f. action-specif motion prior effici bayesian 3d human bodi tracking. pattern recogn. 2009, 42, 29072921. 73. cootes, t.; taylor, c.; cooper, d.; graham, j.; others. activ shape models-their train application. comput. vis. imag underst. 1995, 61, 3859. 74. cootes, t.; edwards, g.; taylor, c. activ appear models. ieee trans. pattern anal. mach. intell. 2001, 23, 681685. 75. murphy-chutorian, e.; trivedi, m. head pose estim vision: survey. ieee trans. pattern anal. mach. intell. 2009, 31, 607626. 76. kim, d.; paik, j. gait recognit activ shape model motion prediction. comput. vis. iet 2010, 4, 2536. 77. urtasun, r.; fleet, d.; fua, p. tempor motion model monocular multiview 3d human bodi tracking. comput. vis. imag underst. 2006, 104, 157177. 78. akhter, i.; sheikh, y.; khan, s.; kanade, t. trajectori space: dual represent nonrigid structur motion. ieee trans. pattern anal. mach. intell. 2011, 33, 14421456. 79. moreno-noguer, f.; porta, j. probabilist simultan pose non-rigid shape recovery. proceed 24th ieee confer vision pattern recognition, colorado springs, co, usa, 2025 june 2011; pp. 12891296. sensor 2014, 14 4210 80. urtasun, r.; fua, p. 3d human bodi track determinist tempor motion models. proceed 8th european confer vision, prague, czech republic, 1114 2004; pp. 92106. 81. urtasun, r.; fleet, d.; fua, p. monocular 3d track golf swing. proceed 2005 ieee societi confer vision pattern recognit (cvpr 2005), san diego, ca, usa , 2026 june 2005; volum 2, pp. 932938. 82. urtasun, r.; fleet, d.; hertzmann, a.; fua, p. prior peopl track small train sets. proceed 10th ieee intern confer vision (iccv 2005), beijing, china, 1720 octob 2005; volum 1, pp. 403410. 83. fossati, a.; salzmann, m.; fua, p. observ subspac 3d human motion recovery. proceed 2009 ieee societi confer vision pattern recognit (cvpr 2009), miami, fl, usa, 2025 june 2009; pp. 11371144. 84. akhter, i.; sheikh, y.; khan, s.; kanade, t. nonrigid structur motion trajectori space. proceed 22nd annual confer neural inform process systems, vancouver, bc, canada, 811 decemb 2008; pp. 4148. 85. park, h.; shiratori, t.; matthews, i.; sheikh, y. 3d reconstruct move point seri 2d projections. proceed 11th european confer vision, heraklion, crete, greece, 511 septemb 2010; pp. 158171. 86. park, h.; sheikh, y. 3d reconstruct smooth articul trajectori monocular imag sequence. proceed ieee intern confer vision, barcelona, spain, 613 novemb 2011; pp. 201208. 87. shapovalova, n.; fernandez, c.; roca, f.; gonzalez, j. semant human behavior imag sequences. analysi human behavior; springer: berlin, germany, 2011; pp. 151182. 88. sigal, l.; black, m. humaneva: synchron video motion captur dataset evalu articul human motion; technic report; brown univertsity: providence, ri, usa, 2006. 89. yao, b.; fei-fei, l. model mutual context object human pose human-object interact activities. proceed 23rd ieee confer vision pattern recognition, san francisco, ca, usa, 1318 june 2010; pp. 1724. 90. andriluka, m.; sigal, l. human context: model human-human interact monocular 3d pose estimation. articul. motion deform. object 2012, 7378, 260272. c 2014 authors; license mdpi, basel, switzerland. articl open access articl distribut term condit creativ common attribut licens (