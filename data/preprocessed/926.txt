fast super-resolut via dens local train invers regressor search eduardo prez-pellitero12 , jordi salvador1 , iban torres-xirau1 , javier ruiz-hidalgo3 , bodo rosenhahn2 1 technicolor r & hannov 2 tnt lab , leibniz universitt hannov 3 imag process group , universitat politcnica de catalunya abstract .
regression-bas super-resolut ( sr ) address up- scale problem learn map function ( i.e .
regressor ) low-resolut high-resolut manifold .
local linear assumpt , complex non-linear map proper model set linear regressor distribut across manifold .
meth- od , test time spent search right regressor within train set .
paper propos novel inverse-search approach regression-bas sr .
instead perform search imag dictionari regressor , search done invers regressor  dictionari imag patch .
approxim framework appli spheric hash imag regres- sor , reduc invers search comput train function .
addit , propos improv train scheme sr linear re- gressor improv perceiv object qualiti .
merg contribut improv speed qualiti compar state- of-the-art .
1 introduct super resolut ( sr ) compris reconstruct techniqu capabl ex- tend resolut discret signal beyond limit correspond captur devic .
sr problem natur ill-pos , definit suit- abl prior critic .
two decad , mani propos .
origin , imag sr method base piecewis linear smooth prior ( i.e .
bilinear bicub interpol , respect ) , result fast interpolation-bas algorithm .
tsai huang [ 1 ] show possibl reconstruct higher-resolut imag regist fuse multipl imag , thus pioneer vast amount approach multi-imag sr , often call reconstruction-bas sr .
idea refin , among other , introduct iter back-project improv registr irani peleg [ 2 ] , although analysi baker kanad [ 3 ] lin shum [ 4 ] show fundament limit type sr , main condit reg- istrat accuraci .
learning-bas sr , also known example-bas , overcam ruben pocul texto escrito mquina ruben pocul texto escrito mquina prez-pellitero , e. , salvador , j. , torres-xirau , i. , ruiz-hidalgo , j. , & rosenhahn , b .
( 2015 ) .
fast super-resolut via dens local train invers regressor search .
d. cremer , i. reid , h. saito , & m.-h. yang ( ed .
) , comput vision -- accv 2014 se - 23 ( vol .
9005 , pp .
346359 ) .
springer intern publish .
final public avail springer via http : //dx.doi.org/10.1007/978-3-319-16811-1_23 ruben pocul texto escrito mquina ruben pocul texto escrito mquina ruben pocul texto escrito mquina ruben pocul texto escrito mquina ruben pocul texto escrito mquina ruben pocul texto escrito mquina ruben pocul texto escrito mquina 2 prez-pellitero et al .
aforement limit avoid necess registra- tion process build prior imag statist .
origin work freeman et al .
[ 5 ] aim learn patch- feature-bas exampl produc effect magnif well beyond practic limit multi-imag sr. 1-nn ( ) previous approach k-ann ( b ) propos approach fig .
1 : overview propos inverse-search sr : ( ) previous approach search 1st nearest dictionari atom imag patch .
( b ) propos approach search k-nearest imag patch dictionari atom .
example-bas sr approach use dictionari usual divid two categori : intern extern dictionary-bas sr .
first exploit strong self-similar prior .
prior learnt direct relationship imag patch across differ scale input imag .
open work subcategori introduc glasner et al .
[ 6 ] , present power- ful framework fuse reconstruction-bas example-bas sr. research categori freedman fattal [ 7 ] introduc mechan high-frequ transfer base exampl small area around patch , thus better local cross-scal self-similar prior spatial neighborhood .
recent work yang et al .
[ 8 ] develop idea local cross-scal self-similar prior arriv in-plac prior , i.e .
best match across scale locat exact posit scale similar enough .
extern dictionary-bas sr method use imag build dic- tionari .
repres wide use approach one base spars decomposit .
main idea behind approach decomposit patch input imag combin spars subset entri compact dictionari .
work yang et al .
[ 9 ] use extern databas compos relat low high-resolut patch joint learn compact dictionari pair .
test , imag patch decompos spars linear combin entri low-resolut ( lr ) dictionari weight use generat high-resolut ( hr ) patch linear combin hr entri .
dictionari train test fast super-resolut via invers regressor search 3 cost due l1 regular term enforc sparsiti .
work zeyd et al .
[ 10 ] extend spars sr propos sever algorithm speed-up also improv perform .
howev , bottleneck sparsiti method still remain spars decomposit .
recent , regression-bas sr receiv great deal attent research communiti .
case , goal learn certain map manifold lr patch hr patch , follow manifold assumpt alreadi use earlier work chang et al .
[ 11 ] .
map manifold assum local linear therefor sever linear regressor use anchor manifold piecewis linear .
although method among fastest state-of-the-art , search proper regressor take signific quota run time within whole sr pipelin .
paper introduc follow contribut : 1 .
propos train scheme notic improv qualiti linear regress sr ( section 3.1 ) keep test complex , i.e .
increas test time .
2 .
formul inverse-search approach everi regressor dictionari k-nearest neighbor ( k-nn ) input imag featur found ( fig .
1 ) .
also , provid suitabl effici spheric hash framework exploit scheme , great improv speed littl qualiti cost .
( section 3.2 ) .
merg two contribut , improv speed qualiti fastest best-perform state-of-the-art method , shown experiment result .
2 regression-bas sr section introduc sr problem example-bas approach tackl , follow review recent state-of-the-art regress work timoft et al .
[ 12 ] close relat work present paper .
contribut paper follow section 3 .
2.1 problem statement super-resolut aim upscal imag unsatisfactori pixel resolut preserv visual sharp , formal x =  ( ) s.t .
x  , ( 1 ) input imag , x output upscal imag ,  (  ) upsam- pling oper calligraph font denot spectrum imag .
literatur transform usual model backward restor origin imag suffer sever degrad [ 9 ] 4 prez-pellitero et al .
=  ( b ( x ) ) , ( 2 ) b (  ) blur filter  (  ) downsampl oper .
problem usual address patch level , denot lower case ( e.g .
, x ) .
example-bas sr famili tackl super-resolut problem find meaning exampl hr counterpart alreadi known , name coupl dictionari dl dh : min  y dl 2 2 +  p , ( 3 )  select weight element dictionari  weight possibl lp-norm regular term .
lp-norm select dictionary- build process depend chosen prior defin sr algorithm .
2.2 anchor neighborhood regress recent work timoft et al .
[ 12 ] especi remark low- complex natur achiev order magnitud speed-up competit qualiti result compar state-of-the-art .
propos relax l1-norm regular common use neighbor embed ( ne ) spars code ( sc ) approach , reformul prob- lem least squar ( ls ) l2-norm regular regress , also known ridg regress .
solv l1-norm constrain minim problem com- putate demand , relax l2-norm , closed-form solut use .
propos minim problem read min  yf nl 2 2 +  2 , ( 4 ) nl lr neighborhood chosen solv problem yf featur extract lr patch .
algebra solut  = ( ntl nl + i ) 1ntl yf .
( 5 ) coeffici  appli correspond hr neighborhood nh reconstruct hr patch , i.e .
x = nh .
also written matrix multipl x = r yf , project matrix ( i.e .
regressor ) calcul r = nh ( n l nl + i ) 1ntl ( 6 ) comput offlin , therefor move minim problem test train time .
propos use spars dictionari ds atom size , train k-svd algorithm [ 13 ] .
regressor rj anchor atom dj dl , neighborhood nl equat ( 6 ) select k-nn subset dl : fast super-resolut via invers regressor search 5 nlj = knn ( dj , dl ) .
( 7 ) sr problem address find nn atom dj everi input patch featur yif appli associ rj .
specif case neighborhood size k = ds , one general regressor obtain whose neighborhood compris atom dictionari consequ requir nn search .
case refer origin paper global regress ( gr ) .
2.3 linear regress framework closest anchor point found , regress usual appli certain input featur aim recov certain compon patch .
model linear regress framework general way x = x+r yf , ( 8 ) x coars first approxim hr patch x .
choic obtain x requir select prior better approxim x .
work yang et al .
[ 8 ] use in-plac prior first-approxim timoft et al .
[ 12 ] use bicub interpol assum smooth prior .
regressor train improv reconstruct whenev coars prior suffici .
intuit , optim perform , select featur rep- resent relat chosen first approxim x .
support , [ 8 ] use input featur subtract low-pass filter in-plac exampl bicub interpol , intuit model error in- place prior low-frequ band ; [ 12 ] use gradient-bas featur , repres high-frequ compon like go well-reconstruct bicub interpol .
3 fast hashing-bas super-resolut section present super-resolut algorithm base inverse- search scheme .
section divid two part repres contribu- tion paper : first discuss optim train stage linear super- resolut regressor introduc hashing-bas regressor select scheme .
3.1 train regression-bas sr object train given regressor r obtain certain map function lr hr patch .
general perspec- tive , lr patch form input manifoldm dimensionm hr patch form target manifold n dimens n. formal , train pair ( yfi , xi ) yf m xi  n , would like infer map  :  rm  n  rn .
6 prez-pellitero et al .
0 200 400 600 800 1000 1200 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 neighborhood size e n e u cl id e n ta n ce train patch spars dictionari ( ) 0 200 400 600 800 1000 1200 1400 1600 1800 29.5 30 30.5 31 31.5 32 32.5 neighborhood size p n r ( b ) propos train timoft train ( b ) fig .
2 : ( ) mean euclidean distanc atom neighborhood differ neighborhood size .
( b ) qualiti improv measur psnr ( db ) reconstruct use anr [ 12 ] togeth propos train .
1024 anchor point use experi .
previous seen , recent regression-bas sr use linear regressor easili comput close form appli matrix multipl .
howev , map  high complex non-linear [ 14 ] .
model non-linear natur map , ensembl regressor { ri } train , repres local linear parametr  , assumpt manifold n similar local geometri .
analyz effect distribut regressor manifold ( i.e .
anchor point ) import proper choos nl equat ( 6 ) , conclud new train approach .
work timoft et al .
[ 12 ] , overcomplet spars represent obtain initi lr train patch use k-svd [ 13 ] .
new re- duce dictionarydl use anchor point manifold datapoint regress train .
gr , uniqu regressor rg train element dictionari , therefor accept higher regress error due singl linear manifold .
fine-tun regress re- construct also propos anchor neighborhood regress ( anr ) , use anchor point { a1 , .
.
.
, ad } dictionari point { d1 , .
.
.
, dds } build one atom neighborhood k-nn within spars dictionari dl .
perform spars decomposit high number patch effici compress data much smaller dictionari , yield atom repre- sentat whole train dataset , i.e .
whole manifold .
reason suitabl use anchor point , also sub-optim neigh- borhood embed .
sub-optim sinc necessari local condit linear assumpt like violat .
due l1-norm recon- struction minim impos spars dictionari , atom dictionari close euclidean space , shown fig .
2 ( ) .
fast super-resolut via invers regressor search 7 1 0 1 1 0 1 ( ) 1 0 1 1 0 1 ( b ) 1 0 1 1 0 1 ( c ) 1 0 1 1 0 1 ( ) fig .
3 : normal degre 3 polynomi manifold illustr propos ap- proach compar one [ 12 ] .
( ) bidimension manifold sampl .
( b ) manifold ( blue ) spars represent obtain k-svd algorithm ( green ) 8 atom .
( c ) linear regressor ( red ) train neighborhood ( k = 1 ) obtain within spars dictionari , [ 12 ] .
( ) linear regressor ( red ) obtain use propos approach : neighborhood obtain within sampl manifold ( k = 10 ) .
observ lead us propos differ approach train lin- ear regressor sr : use spars represent anchor point man- ifold , form neighborhood raw manifold sampl ( e.g .
featur , patch ) .
fig .
2 ( ) show , , find closer nearest neighbor , therefor , fulfil better local condit .
addit , higher number local independ measur avail ( e.g .
mean distanc 1000 neigh- bor raw-patch approach compar 40 atom neighborhood spars approach ) control number k-nn select , i.e .
upper-bound dictionari size .
show low-dimension exampl propos train scheme fig .
3 .
10 2 10 3 10 4 10 5 10 6 0 0.05 0.1 0.15 0.2 0.25 numbercofcqueri r u n n g ct im e sc ( ) parallelc ( gpu ) parallelc ( cpu ) singlecthread fig .
4 : run time measur comput 6-bit hash code ( 6 hyper- sphere ) increas number queri ( logarithm axi without re- rank ) single-thread ( cpu ) parallel ( cpu gpu ) implementa- tion .
fig .
2 ( b ) show comparison anr [ 12 ] train ap- proach term result imag psnr .
use train dataset origin paper , neighbor embed use l2-normal 8 prez-pellitero et al .
raw featur introduc k-svd algorithm .
fix dictio- nari size ( use anchor point scheme ) 1024 .
appli train scheme achiev substanti qualiti improv , qualit quantit .
3.2 invers search via spheric hash aim fine model map lr hr manifold , sever linear regressor train better repres non-linear problem .
although state-of-th art regression-bas sr alreadi push for- ward comput speed regard dictionary-bas sr [ 10 , 9 ] , find right regressor patch still consum execut time .
work [ 12 ] , encod time ( i.e .
time left subtract- ing share process time , includ bicub interpol , patch extract , etc . )
spent task ( i.e .
 96 % time ) .
{ rn } r1 r2 r3 r4 r5 r6 r7 0 1 0 1 1 1 0 0 1 0 1 0 0 1 ... 0 1 0 0 1 1 0 0 1 fig .
5 : spheric hash appli invers search super-resolut problem .
certain hash function optim featur patch statist creat set hyperspher intersect direct label hash code .
train time , regressor fill intersect ( i.e .
bin ) test time hash function appli patch , direct map regressor .
second contribut paper novel search strategi design benefit train outcom present section 3.1 , i.e .
anchor point dictionari neighborhood obtain independ ahead search structur .
order improv search effici , search structur sublinear com- plexiti often built , usual form binari split , e.g .
tree , hash scheme [ 1518 ] .
one might consid determin search partit set anchor point , sinc element retriev .
howev , small cardin set lead imprecis partit due shortag sampl densiti .
propos invers search scheme consist find k-ann ( approxim nearest neighbor ) patch within imag everi anchor point , shown fig .
1 .
, dens sampl ( i.e .
train patch ) dispos , result meaning partit .
fast super-resolut via invers regressor search 9 choos hash techniqu tree-bas method .
hash scheme provid low memori usag ( number split function hashing-bas structur ( log2 ( n ) ) tree-bas structur ( n ) , n repre- sent number cluster ) high paralleliz .
binari hash techniqu aim emb high-dimension point binari code , provid compact represent high-dimension data .
among vast rang applic , use effici similar search , includ approxim nearest neighbor retriev , sinc hash code preserv relat distanc .
recent activ research data-depend hash function oppos hash method [ 17 ] data- independ .
data-depend method intend better fit hash function data distribut [ 19 , 18 ] off-lin train stage .
among data-depend state-of-the-art method , select spheric hash algorithm heo et al .
[ 16 ] , abl defin close region rm one split function .
hash framework use model invers search scheme enabl benefit substanti speed- up reduc nn search appli precomput function , conveni scale parallel implement , shown fig .
4 .
spheric hash differ previous approach set hyperspher defin hash function behalf previous use hyperplan .
given hash function h ( yf ) = ( h1 ( yf ) , .
.
.
, hc ( yf ) ) map point rm base 2 nc , i.e .
{ 0 , 1 } c. everi hash function hk ( yf ) indic whether point yf insid kth hyperspher , model purpos pivot pk  rm distanc threshold ( i.e .
radius hyperspher ) tk  r+ : hk ( yf ) = { 0 ( pk , yf ) > tk 1 ( dk , yf )  tk , ( 9 ) ( pk , yf ) denot distanc metric ( e.g .
euclidean distanc ) two point rm .
advantag use hyperspher instead hyperplan abil defin close tighter sub-spac rm intersect hyperspher .
iter optim train process propos [ 16 ] obtain set { pk , tk } , aim balanc partit train data independ hash function .
perform mention iter hashing-funct optim set input patch featur train imag , h ( yf ) adapt natur imag distribut featur space .
propos spheric hash search scheme becom symmetr see fig .
5 , i.e .
imag anchor point label binari code .
intuit understood creat nn subspac group ( refer bin ) , label regressor appli hash function anchor point .
relat hash code regressor done train time .
invers search approach return k-nn anchor point , thus ensur input imag patch relat regressor ( i.e .
whenev patch within k-nn anchor point ) .
two solut propos : ( ) use general regressor patch k-nn 10 prez-pellitero et al .
anchor point ( b ) use regressor closest label hash code calcu- late spheric ham distanc , defin [ 16 ] dsh ( , b ) =  ( ab )  ( ab ) ,  xor bit oper  bit oper .
note although guarante , rare happen patch within k-nn regressor ( e.g .
select paramet 6 hyperspher never occur ) .
sinc observ signific differ perform , select ( ) lowest complex solut , although test ( b ) due .
similar way , invers search might also assign two regressor singl patch .
common literatur re-rank strategi deal issu [ 20 ] .
tabl 1 : perform 3 4 magnif term averag psnr ( db ) averag execut time ( ) dataset set14 , kodak 2k .
bicub spars [ 10 ] gr [ 12 ] anr [ 12 ] ne+l ne+nnl ne+ll propos mf psnr time psnr time psnr time psnr time psnr time psnr time psnr time psnr time set14 3 27.54 0.002 28.67 2.981 28.31 0.528 28.65 0.771 28.59 2.854 28.44 25.372 28.60 4.356 28.93 0.188 4 26.00 0.003 26.88 1.862 26.60 0.458 26.85 0.584 26.81 1.716 26.72 14.146 26.81 2.623 27.04 0.184 kodak 3 28.43 0.003 29.22 5.126 28.98 0.921 29.21 1.335 29.17 4.829 29.04 44.102 29.17 7.353 29.42 0.314 4 27.23 0.003 27.83 3.194 27.64 0.757 27.80 1.022 27.77 3.003 27.71 24.428 27.77 4.678 27.92 0.309 2k 3 31.73 0.007 32.63 27.622 32.45 4.860 32.68 7.123 32.62 26.194 32.51 242.875 32.65 40.389 32.88 1.652 4 30.28 0.006 30.97 17.225 30.81 3.968 30.99 5.344 30.94 16.363 30.87 136.058 30.96 25.967 31.04 1.578 4 result section show experiment result propos method com- pare perform term qualiti execut time state-of-the- art recent method .
perform extens experi imag resolut rang 2.5kpixel 2mpixel , show perform classic litera- ture test imag addit demonstr algorithm would perform current upscal scenario .
extend benchmark [ 12 ] ad set5 set14 two dataset : 24 imag kodak dataset 2k , imag set 9 sharp imag obtain internet pixel resolut 1920x1080 .
experi run intel xeon w3690 @ 3.47ghz code compar method obtain [ 12 ] use rec- ommend paramet .
method compar spars code sr zeyd et al [ 10 ] , implement ls regress use chang et al .
[ 11 ] ( ne + lle ) , non-neg least squar ( ne+nnl ) method bevilaqcua et al .
[ 21 ] .
propos algorithm written matlab time-consum stage implement opencl without emphasi optim , fast super-resolut via invers regressor search 11 tabl 2 : perform 3 4 magnif term psnr ( db ) execut time ( ) set5 dataset .
set5 bicub spars [ 10 ] gr [ 12 ] anr [ 12 ] ne+l ne+nnl ne+ll propos imag mf psnr time psnr time psnr time psnr time psnr time psnr time psnr time psnr time babi 3 33.9 0.000 35.1 3.490 34.9 0.662 35.1 0.905 35.0 3.179 34.8 29.377 35.1 5.042 35.1 0.214 bird 3 32.6 0.000 34.6 1.087 33.9 0.242 34.6 0.293 34.4 1.011 34.3 9.449 34.6 1.533 34.9 0.070 butterfli 3 24.0 0.000 25.9 0.839 25.0 0.152 25.9 0.201 25.8 0.766 25.6 6.947 25.8 1.200 26.6 0.058 head 3 32.9 0.000 33.6 1.011 33.5 0.218 33.6 0.270 33.5 0.908 33.5 8.411 33.6 1.395 33.7 0.068 woman 3 28.6 0.000 30.4 0.972 29.7 0.187 30.3 0.249 30.2 0.909 29.9 8.437 30.2 1.390 30.06 0.067 averag 3 30.39 0.000 31.90 1.480 31.41 0.292 31.92 0.384 31.78 1.354 31.60 12.524 31.84 2.112 32.22 0.095 babi 4 31.8 0.000 33.1 2.136 32.8 0.525 33.0 0.652 32.9 2.033 32.8 15.535 33.0 3.128 32.9 0.256 bird 4 30.2 0.000 31.7 0.660 31.3 0.184 31.8 0.226 31.6 0.611 31.5 4.995 31.7 0.955 31.7 0.066 butterfli 4 22.1 0.000 23.6 0.536 23.1 0.138 23.5 0.165 23.4 0.456 23.3 3.882 23.4 0.730 23.7 0.052 head 4 31.6 0.000 32.2 0.582 32.1 0.135 32.3 0.212 32.2 0.567 32.1 4.587 32.2 0.882 32.3 0.061 woman 4 26.5 0.000 27.9 0.576 27.4 0.174 27.8 0.191 27.6 0.583 27.6 4.455 27.7 0.894 28.0 0.063 averag 4 28.42 0.000 29.69 0.898 29.34 0.231 29.69 0.289 29.55 0.850 29.47 6,691 29,61 1.318 29.73 0.100 run cpu platform use method .
experi use k-svd spars dictionari 1024 use compar method .
select bicub coars approxim x sinc limit upscal step super-resolut ( e.g .
in-plac exampl meaning small magnif factor ) also featur use zeyd et al .
[ 10 , 12 ] compos 1st 2nd order deriv filter compress pca truncat featur still conserv 99.9 % energi .
also use l2-norm regular linear regressor illustr equat ( 4 ) .
build therefor top regressor scheme propos timoft et al .
[ 12 ] .
use 6-bit spheric hash ( 6 hyperspher ) chosen neighborhood 1300 k-nn .
select number sphere trade-off qualiti speed , sinc decreas number hyperspher collis regressor ( i.e .
one regressor arriv bin ) due re-rank process get closer exact nearest neighbor search .
seen fig .
7 .
tabl 1 tabl 2 show object result perform term psnr ( db ) execut time ( ) .
measur , propos algorithm best perform .
improv psnr notic magnif factor 3 , reach improv 0.3 db compar second best-perform .
term run time , algorithm consist speed-up dataset scale .
compar gr ( fastest compar method ) , speed-up rang 2 3 , addit gap qualiti reconstruct .
speed-up anr rang 3 4 rest method , run time sever order magnitud slower .
note theoret complex gr lower method sinc perform nn search ( i.e .
similar implement , gr slight faster ) .
nevertheless , parallel implement effici one provid author [ 12 ] , most reli optim matlab matrix multipl .
12 prez-pellitero et al .
fig .
6 : visual qualit assess 3 magnif factor imag differ dataset .
left right top bottom : origin , bicub inter- polat , global regressor [ 12 ] , zeyd et al .
[ 10 ] , anr [ 12 ] propos sr .
better view zoom .
fast super-resolut via invers regressor search 13 2 3 4 5 6 7 8 32.82 32.84 32.86 32.88 32.9 32.92 32.94 # sphere p n r ( b ) ( ) 2 3 4 5 6 7 8 1.6 1.65 1.7 1.75 1.8 1.85 1.9 1.95 2 # sphere ti e ( ) ( b ) fig .
7 : effect number sphere select term psnr ( ) time ( b ) .
fig .
6 visual qualit assess perform .
method obtain natur sharp edg , strong reduc ring .
good exampl shown butterfli imag .
5 conclus paper present two main contribut : improv train stage effici inverse-search approach regression-bas , general , dictionary-bas sr. spheric hash techniqu appli order exploit benefit inverse-search scheme .
obtain qualiti improv due optim train stage also substanti speed-up low-complex spheric hash similar algorithm use regressor select .
exhaust test perform compar method four dataset sever pixel resolut , differ upscal factor sever state-of-the-art method .
experiment result show consist improv psnr run time state-of-the-art method includ benchmark , posit first measur .
refer 1 .
tsai , r. , huang , t. : multipl frame imag restor registr .
: proc .
advanc comput vision imag process .
volum 1 .
( 1984 ) 317339 2 .
irani , m. , peleg , s. : improv resolut imag registr .
cvgip : graphic model imag process 53 ( 1991 ) 231239 3 .
baker , s. , kanad , t. : limit super-resolut break .
ieee tran .
pattern analysi machin intellig 24 ( 2002 ) 11671183 14 prez-pellitero et al .
4 .
lin , z. , shum , h.i .
: fundament limit reconstruction-bas superresolut algorithm local translat .
ieee tran .
pattern analysi machin intellig 26 ( 2004 ) 8397 5 .
freeman , w. , jone , t. , pasztor , e. : example-bas super-resolut .
ieee tran .
comput graphic applic 22 ( 2002 ) 5665 6 .
glasner , d. , bagon , s. , irani , m. : super-resolut singl imag .
: proc .
ieee int .
confer comput vision .
( 2009 ) 7 .
freedman , g. , fattal , r. : imag video upscal local self-exampl .
acm tran .
graphic 30 ( 2011 ) 12:112:11 8 .
yang , j. , lin , z. , cohen , s. : fast imag super-resolut base in-plac ex- ampl regress .
: proc .
ieee confer comput vision pattern recognit .
( 2013 ) 9 .
yang , j. , wright , j. , t.s. , h. , , y. : imag super-resolut via spars represen- tation .
ieee tran .
imag process 19 ( 2010 ) 28612873 10 .
zeyd , r. , elad , m. , protter , m. : singl imag scale-up use sparse- represent .
: proc .
int .
confer curv surfac .
( 2012 ) 11 .
chang , h. , yeung , d.y. , xiong , y. : super-resolut neighbor embed .
( 2004 ) 12 .
timoft , r. , smet , v.d. , goool , l.v .
: anchor neighborhood regress fast example-bas super-resolut .
: proc .
ieee int .
confer comput vision .
( 2013 ) 13 .
aharon , m. , elad , m. , bruckstein , a. : k-svd : algorithm design over- complet dictionari spars represent .
ieee tran .
signal process 54 ( 2006 ) 14 .
peyr , g. : manifold model signal imag .
comput vision imag understand 113 ( 2009 ) 249260 15 .
breiman , l. : random forest .
machin learn 45 ( 2001 ) 532 16 .
heo , j.p. , lee , y. , , j. , chang , s.f. , yoon , s.e .
: spheric hash .
: proc .
ieee conf .
comput vision pattern recognit .
( 2012 ) 17 .
indyk , p. , motwani , r. : approxim nearest neighbor : toward remov curs dimension .
: proc .
thirtieth annual acm symposium theori comput .
stoc  98 ( 1998 ) 604613 18 .
wang , j. , kumar , s. , chang , s.f .
: semi-supervis hash scalabl imag retriev .
( 2010 ) 19 .
weiss , y. , torralba , a. , fergus , r. : spectral hash .
( 2008 ) 20 .
, k. , sun , j. : comput nearest-neighbor field via propagation-assist kd- tree .
: proc .
ieee conf .
comput vision pattern recognit .
( 2012 ) 21 .
bevilacqua , m. , roumi , a. , guillemot , c. , alberi-morel , m.l .
: low-complex single-imag super-resolut base nonneg neighbor embed .
: proc .
british machin vision conf .
( 2012 ) 110
