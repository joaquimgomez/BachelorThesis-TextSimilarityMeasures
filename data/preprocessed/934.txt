untitl ieee/acm transact audio , speech , languag process , vol .
25 , .
4 , april 2017 807 deep learn backend singl multisess i-vector speaker recognit omid ghahabi javier hernando abstractth lack label background data make big per- formanc gap cosin probabilist linear discrimi- nant analysi ( plda ) score baselin techniqu i-vector speaker recognit .
although unsupervis clus- tere techniqu estim label , accur predict true label also assum sev- eral sampl speaker background data could true realiti .
paper , author make use deep learn ( dl ) fill perform gap given unla- bele background data .
goal , author propos impostor select algorithm univers model adapt process hybrid system base deep belief network deep neural network discrimin model target speaker .
order insight behavior dl techniqu single- multisess speaker enrol task , ex- periment carri paper scenario .
experi nation institut standard technolog 2014 i-vector challeng show 46 % perform gap , term minimum decis cost function , fill propos dl-base system .
furthermor , score combin propos dl-base system plda estim label cover 79 % gap .
index termsdeep learn , deep neural network , deep belief network , i-vector , speaker recognit .
.
introduct recent compact represent speech utterancesknown i-vector [ 1 ] becom state-of-the-art text-independ speaker recognit .
two com- mon score techniqu decid two i-vector belong speaker name cosin probabilist linear discrimi- nant analysi ( plda ) [ 2 ] , [ 3 ] .
plda score lead superior perform cost need speaker-label back- ground data .
moreov , need sever sampl back- ground speaker spoken differ session condit work effici .
one recent challeng speaker recognit , organ nation institut standard manuscript receiv june 15 , 2016 ; revis octob 27 , 2016 januari 8 , 2017 ; accept januari 16 , 2017 .
date public februari 8 , 2017 ; date current version march 1 , 2017 .
work support part spanish project deepvoic ( tec2015-69266-p ) part european project camomil ( pcin-2013-067 ) .
associ editor coordin review manuscript approv public dr. bin .
author talp research center , depart sig- nal theori communic , universitat politecnica de catalunya barcelonatech , barcelona 08034 , spain ( e-mail : omid.ghahabi @ upc.edu ; javier.hernando @ upc.edu ) .
color version one figur paper avail onlin http : //ieeexplore.ieee.org .
digit object identifi 10.1109/taslp.2017.2661705 technolog ( nist ) , fill perform gap two common score techniqu label background data avail [ 4 ] .
although un- supervis automat label techniqu like propos [ 5 ] , [ 6 ] , appropri estim true label also assum sever sampl speaker background data could true real- iti .
plda estim label perform reason well [ 5 ] , [ 6 ] , result still far plda actual label [ 7 ] .
hand , success use deep learn ( dl ) speech process , specif speech recognit ( e.g. , [ 8 ]  [ 12 ] ) , inspir communiti make use dl techniqu speaker recognit well .
generat ap- proach , like restrict boltzmann machin ( rbm ) deep belief network ( dbn ) , discrimin one , like deep neural network ( dnn ) , use purpos .
possibl use dl techniqu speaker recognit com- bine state-of-the-art i-vector approach .
two kind combin consid .
dl techniqu use i-vector extract process [ 13 ]  [ 17 ] appli i-vector backend [ 18 ]  [ 23 ] .
dnns use i-vector extract algorithm two main goal .
first , univers background model ( ubm ) replac dnn , typic train acoust model speech recognit [ 13 ] , [ 14 ] , [ 16 ] , [ 24 ] , [ 25 ] .
sec- ond , convent spectral featur replac append so-cal dnn bottleneck featur [ 15 ] , [ 16 ] .
signific perform gain report case shown append bottleneck featur spectral one use gaus- sian ubm acoust model lead higher qualiti i-vector [ 15 ] , [ 16 ] .
besid , i-vector comput , dl techniqu use differ purpos .
exampl , differ combina- tion rbms propos [ 18 ] , [ 19 ] classifi i-vector [ 20 ] learn speaker channel factor sub- space plda simul .
rbms [ 26 ] dnns [ 27 ] use increas discrimin power i-vector given speaker-label background data .
[ 21 ]  [ 23 ] dbns integr adapt process provid better initial- izat dnns order discrimin target model .
also attempt extract compact represent speech signal given spectral featur [ 28 ]  [ 30 ] gmm supervector [ 31 ] .
work , author make use deep architectur backend i-vector classif order fill perform 2329-9290  2017 ieee .
translat content mine permit academ research .
person use also permit , republication/redistribut requir ieee permiss .
see http : //www.ieee.org/publ standards/publications/rights/index.html inform .
808 ieee/acm transact audio , speech , languag process , vol .
25 , .
4 , april 2017 gap cosin ( unlabeled-bas ) plda ( labeled- base ) score baselin system given unlabel background data .
[ 21 ] , [ 22 ] , author take advantag unsupervis learn dbns train global model refer univers dbn ( udbn ) dnn supervis learn model target speaker discrimin .
provid balanc train , impostor select algorithm cope train data , udbn-adapt process propos .
compar [ 21 ] , [ 22 ] , deep architectur differ number layer explor singl multi-sess speaker enrol task .
paramet global model normal adapt .
normal scale paramet facilit train net- work specif one hidden layer use .
top layer pre-train propos [ 21 ] use work .
reason emphas top layer connec- tion weight avoid lower hidden layer learn enough input data .
fact import hidden layer use .
addit , new experi base unsupervis label techniqu plda [ 6 ] perform paper potenti baselin system label background data avail .
preliminari experi perform nist sre 2006 [ 32 ] show effect contribut .
take advan- tage conclus obtain preliminari experi , anoth set experi carri newer challeng databas nist 2014 i-vector challeng [ 4 ] .
exper- iment result perform 2014 i-vector challeng show propos dl-base system fill 46 % perform gap cosin oracl plda score system term mindcf similar plda score result obtain unsupervis estim label .
score combin propos dl-base system plda estim label fill 79 % gap .
rest paper organ follow .
section ii give brief background overview i-vector , plda , deep learn techniqu use experi .
section iii present propos dl-base backend i-vector classif .
section iv describ propos impostor select algorithm order balanc train .
section v show cope amount data train tar- get model .
section vi vii discuss experiment result obtain nist sre 2006 nist 2014 i-vector challeng , respect .
section viii conclud paper .
ii .
background a. i-vector plda shown gaussian mixtur model ( gmm ) adapt univers background model ( ubm ) repres featur vector speech signal adequ [ 33 ] .
mean vector adapt gmm stack build supervector , model follow [ 1 ] , = su + tx ( 1 ) su speaker- session-independ mean super- vector typic ubm , total variabl matrix , fig .
1 .
( ) dnn , ( b ) dbn , ( c ) dbn training/dnn pre-train .
x low rank vector latent variabl .
mean posterior distribut x refer i-vector  [ 1 ] .
posterior distribut condit baum-welch statist given speech utter .
matrix train use expectation-maxim ( em ) algorithm given central baum-welch statist background speech ut- teranc .
word , one say i-vector low rank vector , typic 400 600 , repres speech ut- teranc .
detail found [ 1 ] .
two main score techniqu i-vector cosin [ 1 ] , [ 34 ] probabilist linear discrimin analysi ( plda ) [ 2 ] , [ 3 ] .
plda effici techniqu perform score along session variabl compens .
sinc i- vector suffici low dimens , modifi version plda propos [ 3 ] typic use .
assum i-vector decompos ,  = +  +  ( 2 ) global offset , column  eigenvoic ,  latent vector standard normal prior , residu vector  normal distribut zero mean full covari matrix .
model paramet estim larg collect speaker-label background data use em algorithm [ 2 ] .
within class i-vector covari matric , depend model paramet , store use score .
b .
deep learn deep learn ( dl ) refer branch machin learn techniqu attempt learn high level featur data .
sinc 2006 [ 35 ] , [ 36 ] , dl becom new area research mani applic machin learn signal process .
various deep learn architectur use speech process ( e.g. , [ 11 ] , [ 12 ] , [ 37 ]  [ 39 ] ) .
deep neural network ( dnn ) , deep belief network ( dbn ) , restrict boltzmann machin ( rbm ) three main techniqu use work discrimin model target speaker given input i-vector .
dnns feed-forward neural network multipl hid- den layer ( fig .
1 ( ) ) .
train use discrimin back-propag algorithm given class label input vec- tor .
train algorithm tri minim loss function class label output .
classif task , ghahabi hernando : deep learn backend singl multisess i-vector speaker recognit 809 cross-entropi often use loss function soft- max common use activ function output layer [ 40 ] .
typic , paramet dnns initi small random number .
recent , shown effici techniqu paramet initi [ 41 ]  [ 43 ] .
one techniqu consist initi dnn dbn paramet , often refer unsu- pervis pre-train hybrid dbn-dnn [ 9 ] , [ 44 ] .
empir shown pre-train stage set weight network closer optimum solut ran- dom initi [ 41 ]  [ 43 ] .
dbns generat model multipl hidden layer stochast unit visibl layer repres data vector ( fig .
1 ( b ) ) .
top two layer undirect layer top-down direct connect generat data .
effici greedi layer wise algorithm train dbn paramet [ 36 ] .
case , dbn divid two-lay sub-network one treat rbm ( fig .
1 ( c ) ) .
first rbm built visibl unit train , paramet frozen output given rbm input vector .
process repeat top two layer reach .
rbms generat model construct two undirect layer stochast hidden visibl unit .
rbm train base maximum likelihood criterion use stochast gradient descent algorithm [ 9 ] , [ 36 ] .
gradient estim approxim version contrast diverg ( cd ) algorithm call cd-1 [ 35 ] , [ 36 ] .
theoret practic detail found [ 35 ] , [ 36 ] , [ 45 ] .
whole train algorithm given [ 31 ] .
network , possibl updat parame- ter process train exampl , often effici divid whole input data ( batch ) smaller size batch ( minibatch ) updat paramet averag- ing gradient minibatch .
paramet updat procedur repeat whole avail input data process .
iter call epoch .
iii .
propos deep learn backend i-vector success use i-vector speaker recognit dl techniqu speech process applic encourag research communiti combin techniqu speaker recognit .
two kind combin consid .
dl techniqu use i-vector extract process , appli backend .
work , dl technolog use backend two-class hybrid dbn-dnn train target speaker increas discrimin target i-vector/ i-vector speaker ( non-targets/impostor ) ( fig .
2 ) .
pro- pose network initi speaker-specif paramet adapt global model , refer univer- sal deep belief network ( udbn ) .
cross-entropi be- tween class label output minim use back-propag algorithm .
dnns usual need larg number input sampl train effici .
general rule , deeper network requir fig .
2 .
propos deep learn architectur train speaker model .
input data .
speaker recognit , target speaker enrol one sampl ( singl session task ) multipl sampl ( multi-sess task ) .
case , number target sampl limit .
network train limit data high probabl overfit .
hand , number target impostor sampl high unbalanc , i.e. , one target sampl thousand impostor sampl .
learn unbalanc data result bias dnns toward major class .
word , dnns much higher predict accuraci major class .
fig .
3 show block diagram propos approach discrimin model target speaker .
two main contribut propos work tackl problem .
balanc train block attempt decreas number impostor sampl , contrari , increas number target one reason effect way .
in- format impostor sampl target speaker first select propos impostor select algorithm .
afterward , select impostor cluster cluster centroid consid final impostor sampl target speaker model .
impostor centroid target sampl divid equal minibatch provid balanc impostor tar- get data minibatch .
hand , dbn adapt block propos compens lack input data .
dbn train need label data , whole background i-vector use build udbn .
paramet udbn adapt balanc data obtain target speaker .
end , given target/impostor label , adapt dbn balanc data , dnn discrimin train target speaker .
two contribut describ detail follow section .
iv .
balanc train speaker model propos method final dis- crimin , need posit negat data input .
nevertheless , problem amount posit negat data high unbalanc case , lead bias toward major class .
straightfor- ward way deal unbalanc data problem explor [ 46 ]  [ 48 ] [ 49 ] , [ 50 ] .
common use method data sam- pling .
data major class undersampl , contrari , data minor class oversampl .
effect techniqu high depend data structur .
810 ieee/acm transact audio , speech , languag process , vol .
25 , .
4 , april 2017 fig .
3 .
block-diagram train/test phase propos deep learn backend i-vector .
propos approach shown fig .
3 , amount impostor decreas two step , name select clus- tere .
hand , amount target sampl in- creas either replic combin .
, bal- anc target impostor sampl distribut equal among minibatch .
a. impostor select cluster object decreas larg number negat sam- ples reason way .
propos two main step .
first , impostor i-vector inform train dataset select .
inform impostor mean , case , impostor repres given target also statist close target dataset .
real applic , could make sens select impostor global close enrol speaker .
target speaker chang signific , select im- postor could re-select accord new target dataset .
second , number select impostor sampl still high comparison number target one , cluster k-mean algorithm use cosin distanc criterion .
centroid cluster use final negat sampl .
select method inspir data-driven back- ground data select techniqu propos [ 51 ] .
techniqu given avail impostor supervector , sup- port vector machin ( svm ) classifi train target speaker .
number time impostor select support vector , train svm model , call impostor support vector frequenc [ 51 ] .
impostor exampl higher frequenc select refin impostor dataset .
howev , svm train target speaker would com- putate cost .
moreov , final discrimin model dnns , would worth employ techniqu .
instead , propos use cosin similar effici fast criterion compar i-vector .
compar target i-vector impostor i-vector background data set .
n impostor close target i-vector treat like support vector [ 51 ] .
fig .
4 .
step propos impostor select algorithm .
 impostor higher frequenc select inform impostor .
n  select impostor re- fer local global select impostor work .
paramet n  determin experiment .
whole algorithm shown fig .
4 summar follow , 1 ) set impostor frequenc fm = 0 impostor i-vector m , 1  m 2 ) target i-vector i , 1   ) comput cosin ( i , m ) , 1  m b ) select n impostor highest score c ) select impostor fm  fm + 1 3 ) sort impostor descend order base fm 4 ) select first  impostor final one .
cosin ( i , m ) cosin score target i- vector i impostor i-vector m background dataset , number impostor target i- vector , respect .
note , case multi-sess target enrol , averag avail i-vector per target speaker consid algorithm .
final select impostor could local , global , pool .
local pool use , comput cost would higher k-mean cluster run target model independ .
propos similar algorithm [ 23 ] select process depend background data .
ghahabi hernando : deep learn backend singl multisess i-vector speaker recognit 811 fig .
5 .
exampl propos balanc train dnns multi-sess speaker verif task .
minibatch target i-vector differ impostor shown dnns .
random select subset background data use algorithm rather target train databas .
order make process statist reliabl , whole process repeat sever time impostor frequenc accumul iter .
full algorithm found [ 23 ] .
shown algorithm perform sim- ilar first algorithm use train target set select process background databas larg enough [ 23 ] .
b .
target replic combin order balanc posit negat sampl , number target sampl increas mani number impostor cluster centroid obtain section iv-a .
singl session enrol task , i-vector target speaker simpli replic mani number cluster centroid .
replic target i-vector act exact pre-train process dnns due sampl nois creat rbm train [ 45 ] .
moreov , adapt supervis learn stage replic version make target impostor class weight network paramet updat .
multi-sess task , avail i-vector target speaker combin , i.e. , averag everi n i-vector consid new target i-vector .
number posit negat sampl bal- anc , distribut equal among minibatch .
word , minibatch contain number impostor target .
target sampl multi-sess task combin , target sampl differ impostor one shown network minibatch ( fig .
5 ) .
op- timum number impostor cluster minibatch determin experiment section vi vii .
v. univers dbn adapt unlik dnns , need label data train , dbns necessarili need label data input .
henc , use unsupervis train global model refer univers dbn ( udbn ) [ 21 ] .
udbn train feed background i-vector differ speaker .
train procedur carri layer layer use rbms describ section ii-b .
input i-vector real-valu , fig .
6 .
comparison adapt connect weight visibl first hidden unit two differ speaker .
gaussian-bernoulli rbm ( grbm ) [ 9 ] , [ 45 ] use train connect weight visibl first hidden layer unit .
rest connect weight train bernoulli-bernoulli rbms .
shown pre-train techniqu initi dnns better simpli random number [ 41 ]  [ 43 ] .
howev , input sampl avail , pre-train may enough achiev good model .
case , propos [ 21 ] adapt udbn paramet balanc data obtain target speaker .
adapt carri train dbn initi paramet udbn given balanc data target speaker .
adapt dbns use initi final dnn target model .
or- der avoid overfit , iter consid adapt .
suppos udbn learn speaker channel variabl background data .
therefor , udbn provid meaning initi point dbns simpl random initi .
studi [ 42 ] shown pre-train robust respect random initializa- tion seed .
use udbn paramet make target model almost independ random seed .
contrast [ 21 ] , [ 22 ] , work normal udbn paramet adapt .
normal carri simpli scale maximum absolut valu connec- tion weight 0.01 .
way , connect weight dynam rang similar typic use random ini- tialize .
addit , bias term multipli 0.01 closer zero .
bias term usual set zero connect weight random initi .
udbn paramet normal facilit train network specif one hidden layer use .
way , learn rate number epoch tune random initi dnns also use adapt dnns supervis learn stage .
fig .
6 show comparison adapt udbn connect weight , input layer first hidden layer , 812 ieee/acm transact audio , speech , languag process , vol .
25 , .
4 , april 2017 two differ speaker .
seen figur , speaker- specif initi point set adapt process dnn target model .
given target/impostor label , minibatch stochast gradient descent back-propag carri fine-tun .
softmax logist sigmoid activ function top label layer hidden layer , respect .
propos comput output score log pos- terior ratio ( lpr ) form ,  ( target| ) = log p ( target| )  log p ( non-target| ) ( 3 ) p ( target| ) p ( non-target| ) , respect , posterior probabl target non-target class given test i-vector . lpr comput help gaussian true fals score distribut use score fusion .
addit , make fine-tun process effici momentum factor use smooth updat , weight decay regular use penal larg weight .
top layer pre-train propos [ 21 ] use work .
reason give emphasi top layer connect weight avoid lower layer , closer input , learn enough input data .
fact import higher number hidden layer use .
vi .
experi nist sre 2006 nist sre 2006 [ 32 ] use show effect pro- pose contribut shown fig .
3 singl multi- session speaker verif task .
experi , built whole system scratch includ voic activ detect ( vad ) featur i-vector extract .
take advantag conclus section , nist 2014 i- vector challeng databas [ 4 ] use section vii compar perform propos system recent state-of-the-art baselin system .
a. baselin databas whole core test condit sre 2006 use singl session task 8 convers side train condit use multi-sess task .
case , train test signal approxim two-minut total speech durat .
816 target model 51,068 trial singl session 699 target model 31,080 trial multi-sess task .
speech signal two-minut approxim durat nist sre 2004 2005 use background data contain 6,063 speech signal 1,070 distinct speaker .
frequenc filter ( ff ) featur [ 52 ] use exper- iment .
ffs , like mel frequenc cepstral coeffici ( mfcc ) , decorrel version log filter bank energi ( fbe ) [ 52 ] .
shown ff featur achiev perform equal better mfccs [ 52 ] .
featur extract everi 10 ms use 30 ms ham window .
number static ff featur 16 along delta ff delta log energi , 33-dimension featur vector built .
featur ex- traction , speech signal subject energy-bas silenc remov process .
gender-independ ubm repres diagon covari , 512-compon gmm .
i- vector 400-dimension .
i-vector extract process carri use aliz open sourc softwar [ 53 ] .
ubm , matrix , plda paramet train use back- ground data .
plda baselin system gender-independ 250-dimension speaker space .
plda experi , i-vector length normal .
perform evalu use detect error tradeoff ( det ) curv , equal error rate ( eer ) , minimum decis cost function ( mindcf ) de- fine follow [ 32 ] , dcf ( ) = 0.1 pm ( ) + 0.99 pf ( ) ( 4 ) miss rate pm relat number target trial decid incorrect , fals alarm rate pf relat number non-target trial decid incorrect , threshold dcf comput .
b .
singl session experi dnn experi , size hidden layer set 512 .
dnns three hidden layer explor experi .
go three layer amount data increas comput complex without signific gain .
number minibatch number impostor centroid set experiment 3 12 , respect .
minibatch includ four impostor centroid four replic target sampl .
worth note compar speech recognit amount train data typic high , size number minibatch much less appli- cation .
howev , gradient still stabl train work well .
dnn baselin system , train dnn target speaker use whole impostor background data ran- dom initi .
case , whole background i-vector cluster use k-mean algorithm centroid consid impostor sampl .
work , use uniform distribut u ( 0 , 0.01 ) random initi experiment result show achiev slight better per- formanc normal distribut n ( 0 , 0.01 ) use prior work [ 21 ] .
tune paramet network keep fix experi .
dnn-3l stand three hidden layer dnn .
two paramet n  , number local global select impostor propos impostor select method , need determin experiment .
fig .
7 illustr vari- abil eer term two paramet one hidden layer dnns .
similar behavior observ mindcf curv .
dnn exampl shown figur initi ran- dom .
base figur , dnn-1l set n  10 2,000 , respect .
similar curv plot network n set 10  set 300 500 dnn-2l dnn-3l , respect .
experiment result show main improv due adapt process come adapt con- nection weight input layer first hidden layer dnns .
adapt layer ghahabi hernando : deep learn backend singl multisess i-vector speaker recognit 813 fig .
7 .
determin paramet propos impostor select algorithm one hidden layer dnns .
n  , respect , number local global nearest impostor i-vector target i-vector .
tabl effect propos idea fig .
3 perform propos dnn system impostor select adapt eer ( % ) mindcf ( 104 ) # hidden layer # hidden layer 1 2 3 1 2 3   8.55 7.76 7.59 381 353 351   8.06 7.12 7.09 360 327 326   7.43 7.47 7.45 339 343 339   6.81 6.97 6.99 315 317 313 fusion cosin 6.83 6.88 6.64 308 309 299 fusion plda 4.98 5.03 4.76 253 248 230 result obtain core test condit nist sre 2006 .
cosin plda baselin system achiev ( eer=7.18 % , mindcf=324 ) ( eer=4.78 % , mindcf=253 ) , respect .
signific impact perform .
order decreas probabl overfit adapt , separ net- work adapt minibatch paramet obtain network averag .
tabl summar effect propos contribu- tion .
impostor select improv perform great extent network .
tri global , local , pool global local select impostor k-mean cluster best perform obtain use global select impostor .
biggest improv due adapt process observ dnns one hidden layer .
best result obtain use impostor select adapt techniqu show 8-20 % 10-17 % rela- tive improv term eer mindcf , respect , compar baselin dnns .
biggest relat improve- ment achiev dnn-1l .
last two row tabl show fusion dnn system cosin ( eer=7.18 % , mindcf=0.0324 ) plda ( eer=4.78 % , mindcf=0.0253 ) baselin system .
score system first mean varianc normal simpli sum .
fusion cosin baselin dnn system improv result dnn-3l achiev best result correspond 8 % rela- tive improv eer mindcf comparison cosin score baselin system .
nevertheless , dnn-3l tabl ii effect propos idea fig .
3 perform propos dnn system impostor select adapt eer ( % ) mindcf ( 104 ) # hidden layer # hidden layer 1 2 3 1 2 3   4.58 4.58 4.38 208 213 217   4.02 4.07 3.86 183 201 194   4.24 4.30 4.20 202 207 202   3.68 3.83 3.50 170 189 172 fusion cosin 3.61 3.77 3.45 161 169 162 fusion plda 2.46 2.62 2.36 111 121 112 result obtain nist sre 2006 , 8-session enrol task .
cosin plda baselin system achiev ( eer=4.2 % , mindcf=191 ) ( eer=2.27 % , mindcf=105 ) , respect .
score improv plda result specif mindcf 9 % relat improv .
also combin score dnns differ number hidden layer , gain observ .
c. multi-sess experi configur use singl session task also appli multi-sess one .
number minibatch set 3 .
minibatch , 8 target i-vector accompany- ing 8 impostor cluster centroid shown network .
therefor , size minibatch total number impostor cluster 16 24 , respect .
com- binat i-vector target speaker help train network , replic target i-vector everi minibatch shown fig .
5 .
train net- work paramet tune singl session experi .
result summar tabl ii .
around 12 % relat improv achiev dnns employ impostor select techniqu propos work .
pa- ramet obtain singl session task , re-select impostor new multi-sess data set .
adapta- tion process improv perform 8 % .
singl session task , adapt effect one-hidden- layer dnns .
network , paramet first hidden layer adapt improv observ adapt layer .
best result obtain dnn-3l two propos techniqu combin .
show 20 % relat improv eer mindcf comparison baselin three-lay dnns .
propos three-hidden-lay dnns show perform cosin ( eer=4.2 % , mindcf=0.0191 ) plda ( eer=2.27 % , mindcf=0.0105 ) baselin system , 17 % 10 % relat improv term eer mindcf , respect , compar cosin score .
fusion cosin baselin system improv result case , improv observ combin plda score .
814 ieee/acm transact audio , speech , languag process , vol .
25 , .
4 , april 2017 vii .
experi nist 2014 i-vector challeng full databas provid nist 2014 speaker recog- nition i-vector challeng [ 4 ] use experi section .
rather speech signal , i-vector given direct nist challeng train , test , develop speaker recognit system .
enabl system compar- ison readili consist front-end amount type background data [ 4 ] .
challeng , speaker recognit system evalu two phase : speaker label background data known known system .
cosin plda score techniqu use nist baselin system unlabel label background data avail , re- spectiv .
goal evalu see tech- niqu fill perform gap two baselin system label background data avail .
a. baselin databas convent telephon speech record nist sre 2004 2012 use comput i-vector challeng [ 7 ] .
unlik nist sre 2006 experi , durat speech signal i-vector approxim 2 minut , challeng i-vector extract speech utter vari durat mean 39.6 second .
three set 600- dimension i-vector provid : develop , train , test consist 36,572 , 6,530 , 9,634 i-vector , respect .
number target speaker model 1,306 five i-vector avail .
target model score test i-vector , therefor , total number trial 12,582,004 .
trial divid nist two random select subset : progress subset ( 40 % ) , evalu subset ( 60 % ) .
perform evalu use mindcf obtain [ 4 ] , dcf ( ) = pm ( ) + 100 pf ( ) ( 5 ) two main baselin system consid work background i-vector label : cosin plda estim label .
plda actual label also use oracl system comparison .
, i-vector whiten length normal prior evalu averag i-vector per target speaker use singl target model .
cosin baselin system averag i-vector length normal shown plda system re-norm affect perform [ 7 ] .
plda system gender-independ 400- dimension speaker space .
order best plda actual label , background i-vector extract speech signal shorter 30 second discard plda train [ 7 ] .
plda estim label , two stage unsupervis cluster techniqu use estim speaker label background data .
first stage cluster algorithm similar mean shift base algorithm propos [ 54 ] use success challeng [ 6 ] .
second stage , closer cluster obtain first stage combin .
stage , i-vector join base cosin similar consid threshold set 0.29 experi [ 6 ] .
end , cluster contain less 4 50 i-vector select .
[ 6 ] , i-vector less 20 second speech discard plda train case .
possibl train plda estim label repeat two stage unsupervis cluster algorithm plda similar measur , would time consum signific gain observ practic .
experiment result baselin system show compar perform report [ 6 ] [ 5 ] .
b. multi-sess experi architectur sre 2006 multi-sess experi- ment use experi modifi- cation .
size hidden layer set 400 .
minibatch consist 5 impostor centroid 5 target sampl .
to- tal number impostor centroid 15 target model .
sinc dnn-1l dnn-3l work better dnn-2l sre 2006 experi , implement two network nist i-vector challeng .
dnn-1l dnn-3l train learn rate 0.002 0.07 number epoch 30 300 , respect .
momentum weight decay set , respect , 0.9 0.001 dnns .
whole unlabel background i-vector use udbn train .
learn rate number epoch udbn train set 0.02 200 grbm , 0.06 120 rest rbms , respect .
momentum , weight decay , minibatch size set , respect , 0.9 , 0.0002 , 100 rbms .
dnn-3l adapt first two layer .
learn rate number epoch adapt set , respect , 0.001 10 first layer 0.0001 20 second layer .
discuss section iv-a , background data set big enough like challeng , result slight better train data set use select algorithm .
hand , general rule challeng use train data allow impostor select .
therefor , order fair comparison result particip site , use background i-vector impostor select algorithm ( section iv-a ) .
sre 2006 experi , tri global , local , pool global local select impostor k-mean cluster best perform obtain pool .
global impostor select ,  n set 4,500 100 dnn-1l dnn-3l , respect .
al- gorithm iter 20 time .
afterward , global select impostor pool 500 local impostor target speaker k-mean cluster .
tabl iii compar perform propos dnn system baselin system term mindcf eer , fig .
8 9 compar oper point term det curv .
circl figur show oper point correspond mindcf .
worth note nist 2014 i-vector challeng perform system evalu term mindcf .
howev , also includ eer tabl better comparison .
ghahabi hernando : deep learn backend singl multisess i-vector speaker recognit 815 tabl iii comparison perform propos dnn system baselin system nist 2014 i-vector challeng unlabel background data progress set evalu set eer ( % ) mindcf eer ( % ) mindcf [ 1 ] cosin 4.78 0.386 4.46 0.378 [ 2 ] plda ( estim label ) 3.85 0.300 3.46 0.284 [ 3 ] propos dnn-1l 5.13 0.327 4.61 0.320 [ 4 ] propos dnn-3l 4.55 0.305 4.11 0.300 fusion [ 2 ] & [ 4 ] 2.99 0.260 2.70 0.243 label background data [ 5 ] plda ( actual label ) 2.23 0.226 2.01 0.207 fusion [ 2 ] & [ 5 ] 2.04 0.220 1.85 0.204 fusion [ 4 ] & [ 5 ] 2.13 0.221 2.00 0.196 fusion [ 2 ] & [ 4 ] & [ 5 ] 1.88 0.204 1.74 0.190 fig .
8 .
comparison perform propos dnn-3l system baselin system progress set nist 2014 i-vector challeng .
seen tabl , propos dnn-3l perform better dnn-1l , conclud sre 2006 experi .
propos dnn-3l system achiev compar perform plda estim label term mindcf ( 21 % relat improv compar cosin score ) , lower perform term eer .
word , shown fig .
8 9 , propos dnn-3l system perform closer plda actual label cosin lower fals alarm ( fa ) probabl .
higher fa probabl , way around .
propos dnn plda actual label achiev perform fa probabl around 0.01 , lower 0.01 propos dnn system outperform plda actual label .
seen advantag propos system sinc better perform lower fa probabl import higher secur purpos .
fig .
9 .
comparison perform propos dnn-3l system baselin system evalu set nist 2014 i-vector challeng .
interest point combin dnn-3l plda estim label score level improv result great extent oper point .
score fusion carri use bosari toolkit [ 55 ] .
combin weight train progress trial set use evalu set .
result relat improv compar cosin baselin system 36 % term mindcf evalu set .
improv use background label consider compar 45 % relat improv obtain plda actual label .
although use speaker label background data goal work , would interest see propos dl-base backend plda estim label help oracl plda system , use actual label .
seen tabl iii , case dnn-3l plda estim label , combin oracl plda improv result .
improv higher term eer plda estim label higher term mindcf dnn-3l system .
nevertheless , combin three system achiev best perform , correspond 8 % 13 % relat improv term mindcf eer , respect , compar plda actual label .
viii .
conclus hybrid architectur base deep belief network ( dbn ) deep neural network ( dnn ) propos work discrimin model target speaker i-vector speaker verif .
main object fill per- formanc gap cosin oracl plda score system label background data avail .
two main contribut propos make dnns 816 ieee/acm transact audio , speech , languag process , vol .
25 , .
4 , april 2017 effici particular task .
first , inform im- postor i-vector select cluster provid balanc train .
second , dnn initi speaker specif paramet adapt global model , refer univers dbn ( udbn ) .
order insight behavior techniqu singl multi-sess speaker enrol task , ex- periment carri scenario .
experi perform nist sre 2006 , main develop , nist 2014 i-vector challeng , main evalu .
shown propos hybrid system fill approxim 46 % perform gap cosin ora- cle plda score system term mindcf .
although propos system still outperform baselin plda estim label , score fusion high effect cover 79 % gap .
reason propos system still outperform baselin plda system could explicit compens session variabl carri plda .
thus , expect ad explicit session model propos hybrid model could improv perform , beyond scope paper .
refer [ 1 ] n. dehak , p. kenni , r. dehak , p. dumouchel , p. ouellet ,  front-end factor analysi speaker verif ,  ieee tran .
audio , speech , lang .
process. , vol .
19 , .
4 , pp .
788798 , may 2011 .
[ 2 ] s. j. d. princ j. h. elder ,  probabilist linear discrimin analysi infer ident ,  proc .
2007 ieee 11th int .
conf .
comput .
vis. , 2007 , pp .
18 .
[ 3 ] p. kenni ,  bayesian speaker verif heavi tail prior ,  proc .
odyssey , speaker lang .
recognit .
workshop , 2010 .
[ 4 ] nist ,  nist speaker recognit i-vector machin learn chal- leng ,  2014 .
[ onlin ] .
avail : http : //nist.gov/itl/iad/mig/upload/sre- ivectorchallenge_2013-11-18_r0.p df [ 5 ] e. khouri , l. el shafey , m. ferra , s. marcel ,  hierarch speaker cluster method nist i-vector challeng ,  proc .
odyssey , speaker lang .
recognit .
workshop , 2014 , pp .
254259 .
[ 6 ] s. novoselov , t. pekhovski , k. simonchik ,  stc speaker recognit system nist i-vector challeng ,  proc .
odyssey , speaker lang .
recog .
workshop , 2014 , pp .
231240 .
[ 7 ] c. greenberg et al .
 nist 2014 speaker recognit i-vector machin learn challeng ,  proc .
odyssey , speaker lang .
recog .
workshop , 2014 , pp .
224230 .
[ 8 ] a. moham , d. yu , l. deng ,  investig full-sequ train deep belief network speech recognit ,  proc .
interspeech , 2010 , pp .
28462849 .
[ 9 ] g. e. dahl , d. yu , l. deng , a. acero ,  context-depend pre- train deep neural network large-vocabulari speech recognit ,  ieee tran .
audio , speech , lang .
process. , vol .
20 , .
1 , pp .
3042 , jan. 2012 .
[ 10 ] a. moham , g. e. dahl , g. hinton ,  acoust model use deep belief network ,  ieee tran .
audio , speech , lang .
process. , vol .
20 , .
1 , pp .
1422 , jan. 2012 .
[ 11 ] g. hinton et al. ,  deep neural network acoust model speech recognit : share view four research group ,  ieee signal process .
mag. , vol .
29 , .
6 , pp .
8297 , nov. 2012 .
[ 12 ] .
senior , h. sak , i. shafran ,  context depend phone model lstm rnn acoust model ,  proc .
ieee int .
conf .
acoust. , speech , signal process. , 2015 , pp .
45854589 .
[ 13 ] y. lei , n. scheffer , l. ferr , m. mclaren ,  novel scheme speaker recognit use phonetically-awar deep neural network ,  proc .
ieee int .
conf .
acoust. , speech , signal process. , 2014 , pp .
16951699 .
[ 14 ] p. kenni , v. gupta , t. stafylaki , p. ouellet , j. alam ,  deep neural network extract baum-welch statist speaker recognit ,  proc .
odyssey , 2014 , pp .
293298 .
[ 15 ] m. mclaren , y. lei , l. ferr ,  advanc deep neural network approach speaker recognit ,  proc .
ieee int .
conf .
acoust. , speech , signal process. , 2015 , pp .
48144818 .
[ 16 ] f. richardson , d. reynold , n. dehak ,  deep neural network ap- proach speaker languag recognit ,  ieee signal process .
lett. , vol .
22 , .
10 , pp .
16711675 , oct. 2015 .
[ 17 ] y. liu , y. qian , n. chen , t. fu , y. zhang , k. yu ,  deep featur text-depend speaker verif ,  speech commun. , vol .
73 , pp .
113 , oct. 2015 .
[ 18 ] t. stafylaki , p. kenni , m. senoussaoui , p. dumouchel ,  preliminari investig boltzmann machin classifi speaker recognit ,  proc .
odyssey , 2012 , pp .
109116 .
[ 19 ] m. senoussaoui , n. dehak , p. kenni , r. dehak , p. dumouchel ,  first attempt boltzmann machin speaker verif ,  proc .
odyssey , 2012 , pp .
117121 .
[ 20 ] t. stafylaki , p. kenni , m. senoussaoui , p. dumouchel ,  plda us- ing gaussian restrict boltzmann machin applic speaker verif ,  proc .
interspeech , 2012 , pp .
16921695 .
[ 21 ] o. ghahabi j. hernando ,  deep belief network i-vector base speaker recognit ,  proc .
ieee int .
conf .
acoust. , speech , signal process. , may 2014 , pp .
17001704 .
[ 22 ] o. ghahabi j. hernando ,  i-vector model deep belief net- work multi-sess speaker recognit ,  proc .
odyssey , 2014 , pp .
305310 .
[ 23 ] o. ghahabi j. hernando ,  global impostor select dbns multi-sess i-vector speaker recognit ,  advanc speech languag technolog iberian languag ( lectur note artifici intellig ) .
berlin , germani : springer , nov. 2014 .
[ 24 ] w. m. campbel ,  use deep belief network vector-bas speaker recognit ,  proc .
interspeech , 2014 , pp .
676680 .
[ 25 ] d. garcia-romero , xiaohui zhang , a. mccree , d. povey ,  improv- ing speaker recognit perform domain adapt challeng use deep neural network ,  proc .
2014 ieee spoken lang .
technol .
workshop , dec. 2014 , pp .
378383 .
[ 26 ] s. novoselov , t. pekhovski , k. simonchik , a. shulipa ,  rbm-plda subsystem nist i-vector challeng ,  proc .
interspeech , 2014 , pp .
378382 .
[ 27 ] .
z. isik , h. erdogan , r. sarikaya ,  s-vector : discrimin rep- resent deriv i-vector speaker verif ,  proc .
eur .
signal process .
conf. , nice , franc , aug. 2015 , pp .
20972101 .
[ 28 ] v. vasilakaki , s. cumani , p. lafac ,  speaker recognit mean deep belief network ,  proc .
biometr technol .
forens sci. , 2013 .
[ 29 ] e. variani , xin lei , e. mcdermott , i. lopez moreno , j. gonzalez- dominguez ,  deep neural network small footprint text-depend speaker verif ,  proc .
2014 ieee int .
conf .
acoust. , speech signal process. , may 2014 , pp .
40524056 .
[ 30 ] p. safari , o. ghahabi , j. hernando ,  featur speaker vector mean restrict boltzmann machin adapt ,  proc .
odyssey , 2016 , pp .
366371 .
[ 31 ] o. ghahabi j. hernando ,  restrict boltzmann machin supervec- tor speaker recognit ,  proc .
int .
conf .
acoust. , speech , signal process. , 2015 , pp .
48044808 .
[ 32 ] nist ,  nist year 2006 speaker recognit evalu plan ,  2006 .
[ onlin ] .
avail : http : //www.nist.gov/speech/tests/spk/2006/ index.htm [ 33 ] d. a. reynold , t. f. quatieri , r. b. dunn ,  speaker verif use adapt gaussian mixtur model ,  digit .
signal process. , vol .
10 , .
1 , pp .
1941 , jan. 2000 .
[ 34 ] n. dehak , r. dehak , j .
glass , d. reynold , p. kenni ,  cosin simi- lariti score without score normal techniqu ,  proc .
odyssey , speaker lang .
recognit .
workshop , 2010 , pp .
7175 .
[ 35 ] g. e. hinton r. salakhutdinov ,  reduc dimension data neural network ,  scienc , vol .
313 , .
5786 , pp .
504507 , jul .
2006 .
[ 36 ] g. e. hinton , s. osindero , y-w. teh ,  fast learn algorithm deep belief net ,  neural comput. , vol .
18 , .
7 , pp .
15271554 , may 2006 .
[ 37 ] z-h. ling , l. deng , d. yu ,  model spectral envelop use re- strict boltzmann machin deep belief network statist para- metric speech synthesi ,  ieee tran .
audio , speech , lang .
process. , vol .
21 , .
10 , pp .
21292139 , oct. 2013 .
[ 38 ] x-l. zhang j. wu ,  deep belief network base voic activ de- tection ,  ieee tran .
audio , speech , lang .
process. , vol .
21 , .
4 , pp .
697710 , apr .
2013 .
[ 39 ] tara n. sainath et al .
 deep convolut neural network large-scal speech task ,  neural netw. , vol .
64 , pp .
3948 , apr .
2015 .
ghahabi hernando : deep learn backend singl multisess i-vector speaker recognit 817 [ 40 ] z.-h. ling et al .
 deep learn acoust model parametr speech generat : systemat review exist techniqu futur trend ,  ieee signal process .
mag. , vol .
32 , .
3 , pp .
3552 , may 2015 .
[ 41 ] h. larochell , y. bengio , j. louradour , p. lamblin ,  explor strate- gie train deep neural network ,  j. mach .
learn .
res. , vol .
10 , pp .
140 , jun .
2009 .
[ 42 ] e. dumitru , p. manzagol , y. bengio , s. bengio , p. vincent ,  difficulti train deep architectur effect unsuper- vise pre-train ,  proc .
12th int .
conf .
artif .
intel .
statist. , 2009 , pp .
153160 .
[ 43 ] d. erhan , y. bengio , a. courvill , p. manzagol , p. vincent , s. bengio ,  unsupervis pre-train help deep learn ?  j. mach .
learn .
res. , vol .
11 , pp .
625660 , mar .
2010 .
[ 44 ] l. deng d. yu , deep learn : method applic .
delft , netherland : publish , jun .
2014 .
[ 45 ] g. e. hinton ,  practic guid train restrict boltzmann ma- chine ,  neural network : trick trade ( lectur note com- puter scienc , 7700 ) .
berlin , germani : springer , jan. 2012 , pp .
599619 .
[ 46 ] h. e. a. garcia ,  learn imbalanc data ,  ieee tran .
knowl .
data eng. , vol .
21 , .
9 , pp .
12631284 , sep. 2009 .
[ 47 ] n. thai-ngh , z. gantner , l. schmidt-thiem ,  cost-sensit learn- ing method imbalanc data ,  proc .
2010 int .
joint conf .
neural netw. , jul .
2010 , pp .
18 .
[ 48 ] t. m. khoshgoftaar , j .
van huls , a. napolitano ,  supervis neural network model : empir investig learn imbal- anc data label error ,  ieee tran .
neural netw. , vol .
21 , .
5 , pp .
813830 , may 2010 .
[ 49 ] v. lopez , a. fernandez , s. garca , v. palad , f. herrera ,  in- sight classif imbalanc data : empir result cur- rent trend use data intrins characterist ,  inform .
sci. , vol .
250 , pp .
113141 , nov. 2013 .
[ 50 ] s. barua , m. m. islam , x. yao , k. muras ,  mwmote-major weight minor oversampl techniqu imbalanc data set learn- ing ,  ieee tran .
knowl .
data eng. , vol .
26 , .
2 , pp .
405425 , feb. 2014 .
[ 51 ] m. mclaren , r. vogt , b. baker , s. sridharan ,  data-driven back- ground dataset select svm-base speaker verif ,  ieee tran .
audio , speech , lang .
process. , vol .
18 , .
6 , pp .
14961506 , aug. 2010 .
[ 52 ] c. nadeu , d. macho , j. hernando ,  time frequenc filter filter-bank energi robust hmm speech recognit ,  speech commun. , vol .
34 , .
12 , pp .
93114 , apr .
2001 .
[ 53 ] a. larcher et al .
 aliz 3.0 open sourc toolkit state-of-the-art speaker recognit ,  proc .
interspeech , 2013 , pp .
27682771 .
[ 54 ] m. senoussaoui , p. kenni , t. stafylaki , p. dumouchel ,  studi cosin distance-bas mean shift telephon speech diariza- tion ,  ieee/acm tran .
audio , speech , lang .
process. , vol .
22 , .
1 , pp .
217227 , jan. 2014 .
[ 55 ] n. brummer e. villier ,  bosari toolkit user guid : theori , al- gorithm code binari classifi score process ,  2011 .
[ onlin ] .
avail : https : //sites.google.com/site/bosaristoolkit/ omid ghahabi receiv m.sc .
degre elec- trical engin shahid beheshti univers , tehran , iran , 2009 .
current work toward ph.d. degre technic univers cat- alonia ( upc ) , barcelona , spain .
2009 2011 , speech process group , research center intellig signal process , tehran , iran .
2011 2016 , research speech process group , signal theori com- munic depart , upc .
sinc late 2016 , eml european media laboratori gmbh , heidelberg , germani , speech technologist .
research interest includ , limit , speaker recognit diarize , speech signal process , deep learn .
author coauthor sever journal confer paper topic .
member research center languag speech technolog applic , barcelona , spain .
javier hernando receiv m.s .
ph.d. degre telecommun engin technic univers catalonia ( upc ) , barcelona , spain , 1988 1993 , respect .
sinc 1988 , depart signal theori communic , upc , current full professor director research center languag speech .
academ year 20022003 , visit research pana- sonic speech technolog laboratori , santa barbara , ca , usa .
led upc team sever eu- ropean , spanish , catalan project .
research interest includ robust speech analysi , speech recognit , speaker verif local , oral dialogu , multimod interfac .
author coauthor 200 public book chapter , review articl , confer paper topic .
receiv 1993 extraordinari ph.d. award upc .
< < /ascii85encodepag fals /allowtranspar fals /autopositionepsfil true /autorotatepag /none /bind /left /calgrayprofil ( gray gamma 2.2 ) /calrgbprofil ( srgb iec61966-2.1 ) /calcmykprofil ( u. .
web coat \050swop\051 v2 ) /srgbprofil ( srgb iec61966-2.1 ) /cannotembedfontpolici /warn /compatibilitylevel 1.4 /compressobject /off /compresspag true /convertimagestoindex true /passthroughjpegimag true /createjobticket fals /defaultrenderingint /default /detectblend true /detectcurv 0.0000 /colorconversionstrategi /srgb /dothumbnail true /embedallfont true /embedopentyp fals /parseiccprofilesincom true /embedjobopt true /dscreportinglevel 0 /emitdscwarn fals /endpag -1 /imagememori 1048576 /lockdistillerparam true /maxsubsetpct 100 /optim true /opm 0 /parsedsccom fals /parsedsccommentsfordocinfo true /preservecopypag true /preservedicmykvalu true /preserveepsinfo fals /preserveflat true /preservehalftoneinfo true /preserveopicom fals /preserveoverprintset true /startpag 1 /subsetfont fals /transferfunctioninfo /remov /ucrandbginfo /preserv /useprologu fals /colorsettingsfil ( ) /alwaysemb [ true /algerian /arial-black /arial-blackital /arial-bolditalicmt /arial-boldmt /arial-italicmt /arialmt /arialnarrow /arialnarrow-bold /arialnarrow-boldital /arialnarrow-ital /arialunicodem /baskoldfac /batang /bauhaus93 /bellmt /bellmtbold /bellmtital /berlinsansfb-bold /berlinsansfbdemi-bold /berlinsansfb-reg /bernardmt-condens /bodonimtpostercompress /bookantiqua /bookantiqua-bold /bookantiqua-boldital /bookantiqua-ital /bookmanoldstyl /bookmanoldstyle-bold /bookmanoldstyle-boldital /bookmanoldstyle-ital /bookshelfsymbolseven /britannicbold /broadway /brushscriptmt /californianfb-bold /californianfb-ital /californianfb-reg /centaur /centuri /centurygoth /centurygothic-bold /centurygothic-boldital /centurygothic-ital /centuryschoolbook /centuryschoolbook-bold /centuryschoolbook-boldital /centuryschoolbook-ital /chiller-regular /colonnamt /comicsansm /comicsansms-bold /cooperblack /couriernewps-bolditalicmt /couriernewps-boldmt /couriernewps-italicmt /couriernewpsmt /estrangeloedessa /footlightmtlight /freestylescript-regular /garamond /garamond-bold /garamond-ital /georgia /georgia-bold /georgia-boldital /georgia-ital /haettenschweil /harlowsolid /harrington /hightowertext-ital /hightowertext-reg /impact /informalroman-regular /jokerman-regular /juiceitc-regular /kristenitc-regular /kuenstlerscript-black /kuenstlerscript-medium /kuenstlerscript-twobold /kunstlerscript /latinwid /lettergothicmt /lettergothicmt-bold /lettergothicmt-boldobliqu /lettergothicmt-obliqu /lucidabright /lucidabright-demi /lucidabright-demiital /lucidabright-ital /lucidacalligraphy-ital /lucidaconsol /lucidafax /lucidafax-demi /lucidafax-demiital /lucidafax-ital /lucidahandwriting-ital /lucidasansunicod /magneto-bold /maturamtscriptcapit /mediciscriptltstd /microsoftsansserif /mistral /modern-regular /monotypecorsiva /ms-mincho /msreferencesansserif /msreferencespecialti /niagaraengraved-reg /niagarasolid-reg /nuptialscript /oldenglishtextmt /onyx /palatinolinotype-bold /palatinolinotype-boldital /palatinolinotype-ital /palatinolinotype-roman /parchment-regular /playbil /pmingliu /poorrichard-regular /ravi /showcardgothic-reg /simsun /snapitc-regular /stencil /symbolmt /tahoma /tahoma-bold /tempussansitc /timesnewromanmt-extrabold /timesnewromanmtstd /timesnewromanmtstd-bold /timesnewromanmtstd-boldcond /timesnewromanmtstd-boldit /timesnewromanmtstd-cond /timesnewromanmtstd-condit /timesnewromanmtstd-ital /timesnewromanps-bolditalicmt /timesnewromanps-boldmt /timesnewromanps-italicmt /timesnewromanpsmt /times-roman /trebuchet-boldital /trebuchetm /trebuchetms-bold /trebuchetms-ital /verdana /verdana-bold /verdana-boldital /verdana-ital /vinerhanditc /vivaldii /vladimirscript /webd /wingdings2 /wingdings3 /wingdings-regular /zapfchancerystd-demi /zwadobef ] /neveremb [ true ] /antialiascolorimag fals /cropcolorimag true /colorimageminresolut 150 /colorimageminresolutionpolici /ok /downsamplecolorimag true /colorimagedownsampletyp /bicub /colorimageresolut 150 /colorimagedepth -1 /colorimagemindownsampledepth 1 /colorimagedownsamplethreshold 1.50000 /encodecolorimag true /colorimagefilt /dctencod /autofiltercolorimag fals /colorimageautofilterstrategi /jpeg /coloracsimagedict < < /qfactor 0.76 /hsampl [ 2 1 1 2 ] /vsampl [ 2 1 1 2 ] > > /colorimagedict < < /qfactor 0.40 /hsampl [ 1 1 1 1 ] /vsampl [ 1 1 1 1 ] > > /jpeg2000coloracsimagedict < < /tilewidth 256 /tileheight 256 /qualiti 15 > > /jpeg2000colorimagedict < < /tilewidth 256 /tileheight 256 /qualiti 15 > > /antialiasgrayimag fals /cropgrayimag true /grayimageminresolut 150 /grayimageminresolutionpolici /ok /downsamplegrayimag true /grayimagedownsampletyp /bicub /grayimageresolut 300 /grayimagedepth -1 /grayimagemindownsampledepth 2 /grayimagedownsamplethreshold 1.50000 /encodegrayimag true /grayimagefilt /dctencod /autofiltergrayimag fals /grayimageautofilterstrategi /jpeg /grayacsimagedict < < /qfactor 0.76 /hsampl [ 2 1 1 2 ] /vsampl [ 2 1 1 2 ] > > /grayimagedict < < /qfactor 0.40 /hsampl [ 1 1 1 1 ] /vsampl [ 1 1 1 1 ] > > /jpeg2000grayacsimagedict < < /tilewidth 256 /tileheight 256 /qualiti 15 > > /jpeg2000grayimagedict < < /tilewidth 256 /tileheight 256 /qualiti 15 > > /antialiasmonoimag fals /cropmonoimag true /monoimageminresolut 1200 /monoimageminresolutionpolici /ok /downsamplemonoimag true /monoimagedownsampletyp /bicub /monoimageresolut 600 /monoimagedepth -1 /monoimagedownsamplethreshold 1.50000 /encodemonoimag true /monoimagefilt /ccittfaxencod /monoimagedict < < /k -1 > > /allowpsxobject fals /checkcompli [ /none ] /pdfx1acheck fals /pdfx3check fals /pdfxcompliantpdfon fals /pdfxnotrimboxerror true /pdfxtrimboxtomediaboxoffset [ 0.00000 0.00000 0.00000 0.00000 ] /pdfxsetbleedboxtomediabox true /pdfxbleedboxtotrimboxoffset [ 0.00000 0.00000 0.00000 0.00000 ] /pdfxoutputintentprofil ( none ) /pdfxoutputconditionidentifi ( ) /pdfxoutputcondit ( ) /pdfxregistrynam ( ) /pdfxtrap /fals /createjdffil fals /descript < < /chs < feff4f7f75288fd94e9b8bbe5b9a521b5efa7684002000410064006f006200650020005000440046002065876863900275284e8e55464e1a65876863768467e5770b548c62535370300260a853ef4ee54f7f75280020004100630072006f0062006100740020548c002000410064006f00620065002000520065006100640065007200200035002e003000204ee553ca66f49ad87248672c676562535f00521b5efa768400200050004400460020658768633002 > /cht < feff4f7f752890194e9b8a2d7f6e5efa7acb7684002000410064006f006200650020005000440046002065874ef69069752865bc666e901a554652d965874ef6768467e5770b548c52175370300260a853ef4ee54f7f75280020004100630072006f0062006100740020548c002000410064006f00620065002000520065006100640065007200200035002e003000204ee553ca66f49ad87248672c4f86958b555f5df25efa7acb76840020005000440046002065874ef63002 > /dan < feff004200720075006700200069006e0064007300740069006c006c0069006e006700650072006e0065002000740069006c0020006100740020006f007000720065007400740065002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e007400650072002c0020006400650072002000650067006e006500720020007300690067002000740069006c00200064006500740061006c006a006500720065007400200073006b00e60072006d007600690073006e0069006e00670020006f00670020007500640073006b007200690076006e0069006e006700200061006600200066006f0072007200650074006e0069006e006700730064006f006b0075006d0065006e007400650072002e0020004400650020006f007000720065007400740065006400650020005000440046002d0064006f006b0075006d0065006e0074006500720020006b0061006e002000e50062006e00650073002000690020004100630072006f00620061007400200065006c006c006500720020004100630072006f006200610074002000520065006100640065007200200035002e00300020006f00670020006e0079006500720065002 > /deu < feff00560065007200770065006e00640065006e0020005300690065002000640069006500730065002000450069006e007300740065006c006c0075006e00670065006e0020007a0075006d002000450072007300740065006c006c0065006e00200076006f006e002000410064006f006200650020005000440046002d0044006f006b0075006d0065006e00740065006e002c00200075006d002000650069006e00650020007a0075007600650072006c00e40073007300690067006500200041006e007a006500690067006500200075006e00640020004100750073006700610062006500200076006f006e00200047006500730063006800e40066007400730064006f006b0075006d0065006e00740065006e0020007a0075002000650072007a00690065006c0065006e002e00200044006900650020005000440046002d0044006f006b0075006d0065006e007400650020006b00f6006e006e0065006e0020006d006900740020004100630072006f00620061007400200075006e0064002000520065006100640065007200200035002e003000200075006e00640020006800f600680065007200200067006500f600660066006e00650074002000770065007200640065006e002 > /esp < feff005500740069006c0069006300650020006500730074006100200063006f006e0066006900670075007200610063006900f3006e0020007000610072006100200063007200650061007200200064006f00630075006d0065006e0074006f0073002000640065002000410064006f00620065002000500044004600200061006400650063007500610064006f007300200070006100720061002000760069007300750061006c0069007a00610063006900f3006e0020006500200069006d0070007200650073006900f3006e00200064006500200063006f006e006600690061006e007a006100200064006500200064006f00630075006d0065006e0074006f007300200063006f006d00650072006300690061006c00650073002e002000530065002000700075006500640065006e00200061006200720069007200200064006f00630075006d0065006e0074006f00730020005000440046002000630072006500610064006f007300200063006f006e0020004100630072006f006200610074002c002000410064006f00620065002000520065006100640065007200200035002e003000200079002000760065007200730069006f006e0065007300200070006f00730074006500720069006f007200650073002 > /fra < feff005500740069006c006900730065007a00200063006500730020006f007000740069006f006e00730020006100660069006e00200064006500200063007200e900650072002000640065007300200064006f00630075006d0065006e00740073002000410064006f006200650020005000440046002000700072006f00660065007300730069006f006e006e0065006c007300200066006900610062006c0065007300200070006f007500720020006c0061002000760069007300750061006c00690073006100740069006f006e0020006500740020006c00270069006d007000720065007300730069006f006e002e0020004c0065007300200064006f00630075006d0065006e00740073002000500044004600200063007200e900e90073002000700065007500760065006e0074002000ea0074007200650020006f007500760065007200740073002000640061006e00730020004100630072006f006200610074002c002000610069006e00730069002000710075002700410064006f00620065002000520065006100640065007200200035002e0030002000650074002000760065007200730069006f006e007300200075006c007400e90072006900650075007200650073002 > /ita ( utilizzar quest impostazioni per crear documenti adob pdf adatti per visualizzar e stampar documenti aziendali modo affidabil .
documenti pdf creati possono esser aperti con acrobat e adob reader 5.0 e versioni success . )
/jpn < feff30d330b830cd30b9658766f8306e8868793a304a3088307353705237306b90693057305f002000410064006f0062006500200050004400460020658766f8306e4f5c6210306b4f7f75283057307e305930023053306e8a2d5b9a30674f5c62103055308c305f0020005000440046002030d530a130a430eb306f3001004100630072006f0062006100740020304a30883073002000410064006f00620065002000520065006100640065007200200035002e003000204ee5964d3067958b304f30533068304c3067304d307e305930023053306e8a2d5b9a3067306f30d530a930f330c8306e57cb30818fbc307f3092884c3044307e30593002 > /kor < feffc7740020c124c815c7440020c0acc6a9d558c5ec0020be44c988b2c8c2a40020bb38c11cb97c0020c548c815c801c73cb85c0020bcf4ace00020c778c1c4d558b2940020b3700020ac00c7a50020c801d569d55c002000410064006f0062006500200050004400460020bb38c11cb97c0020c791c131d569b2c8b2e4002e0020c774b807ac8c0020c791c131b41c00200050004400460020bb38c11cb2940020004100630072006f0062006100740020bc0f002000410064006f00620065002000520065006100640065007200200035002e00300020c774c0c1c5d0c11c0020c5f40020c2180020c788c2b5b2c8b2e4002 > /nld ( gebruik deze instellingen om adob pdf-documenten te maken waarme zakelijk documenten betrouwbaar kunnen worden weergegeven en afgedrukt .
de gemaakt pdf-documenten kunnen worden geopend met acrobat en adob reader 5.0 en hoger . )
/nor < feff004200720075006b00200064006900730073006500200069006e006e007300740069006c006c0069006e00670065006e0065002000740069006c002000e50020006f0070007000720065007400740065002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e00740065007200200073006f006d002000650072002000650067006e0065007400200066006f00720020007000e5006c006900740065006c006900670020007600690073006e0069006e00670020006f00670020007500740073006b007200690066007400200061007600200066006f0072007200650074006e0069006e006700730064006f006b0075006d0065006e007400650072002e0020005000440046002d0064006f006b0075006d0065006e00740065006e00650020006b0061006e002000e50070006e00650073002000690020004100630072006f00620061007400200065006c006c00650072002000410064006f00620065002000520065006100640065007200200035002e003000200065006c006c00650072002 > /ptb < feff005500740069006c0069007a006500200065007300730061007300200063006f006e00660069006700750072006100e700f50065007300200064006500200066006f0072006d00610020006100200063007200690061007200200064006f00630075006d0065006e0074006f0073002000410064006f00620065002000500044004600200061006400650071007500610064006f00730020007000610072006100200061002000760069007300750061006c0069007a006100e700e3006f002000650020006100200069006d0070007200650073007300e3006f00200063006f006e0066006900e1007600650069007300200064006500200064006f00630075006d0065006e0074006f007300200063006f006d0065007200630069006100690073002e0020004f007300200064006f00630075006d0065006e0074006f00730020005000440046002000630072006900610064006f007300200070006f00640065006d0020007300650072002000610062006500720074006f007300200063006f006d0020006f0020004100630072006f006200610074002000650020006f002000410064006f00620065002000520065006100640065007200200035002e0030002000650020007600650072007300f50065007300200070006f00730074006500720069006f007200650073002 > /suo < feff004b00e40079007400e40020006e00e40069007400e4002000610073006500740075006b007300690061002c0020006b0075006e0020006c0075006f0074002000410064006f0062006500200050004400460020002d0064006f006b0075006d0065006e007400740065006a0061002c0020006a006f0074006b006100200073006f0070006900760061007400200079007200690074007900730061007300690061006b00690072006a006f006a0065006e0020006c0075006f00740065007400740061007600610061006e0020006e00e400790074007400e4006d0069007300650065006e0020006a0061002000740075006c006f007300740061006d0069007300650065006e002e0020004c0075006f0064007500740020005000440046002d0064006f006b0075006d0065006e00740069007400200076006f0069006400610061006e0020006100760061007400610020004100630072006f0062006100740069006c006c00610020006a0061002000410064006f00620065002000520065006100640065007200200035002e0030003a006c006c00610020006a006100200075007500640065006d006d0069006c006c0061002 > /sve < feff0041006e007600e4006e00640020006400650020006800e4007200200069006e0073007400e4006c006c006e0069006e006700610072006e00610020006f006d002000640075002000760069006c006c00200073006b006100700061002000410064006f006200650020005000440046002d0064006f006b0075006d0065006e007400200073006f006d00200070006100730073006100720020006600f60072002000740069006c006c006600f60072006c00690074006c006900670020007600690073006e0069006e00670020006f006300680020007500740073006b007200690066007400650072002000610076002000610066006600e4007200730064006f006b0075006d0065006e0074002e002000200053006b006100700061006400650020005000440046002d0064006f006b0075006d0065006e00740020006b0061006e002000f600700070006e00610073002000690020004100630072006f0062006100740020006f00630068002000410064006f00620065002000520065006100640065007200200035002e00300020006f00630068002000730065006e006100720065002 > /enu ( use set creat pdfs match `` suggest '' set pdf specif 4.0 ) > > > > setdistillerparam < < /hwresolut [ 600 600 ] /pages [ 612.000 792.000 ] > > setpagedevic
