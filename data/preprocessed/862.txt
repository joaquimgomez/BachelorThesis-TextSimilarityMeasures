novemb 21 , 2014 appli artifici intellig ( aai ) journal main appear appli artifici intellig ( aai ) journal vol .
00 , .
00 , month 20xx , 116 random algorithm exact solut transduct support vector machin g. espositoa m. martina universitat politecnica de catalunya , barcelona , spain ; ( v1.0 releas octob 2014 ) random sampl effici method deal constrain optim problem .
comput geometri , method success appli , clarkson  algo- rithm ( clarkson , 1996 ) , solv general class problem call violat space .
machin learn , tsvm learn method use small fraction label data avail , impli solv non convex optim problem .
sever approxim method propos solv , usual find suboptim solut .
howev , global optim solut may obtain use exact techniqu , cost suffer exponenti time complex respect number instanc .
paper , interpret tsvm term violat space given .
henc , random method present extend use exact method reduc time complex exponen- tial w.r.t .
number support vector optim solut instead exponenti w.r.t .
number instanc .
keyword : transduct , semi-supervis learn , support vector machin , violat space , branch bound 1 .
introduct comput geometri , random sampl effici method deal con- strain optim problem .
first one find optim solut subject random subset constraint .
like , expect number constraint violat solut signific smaller overal number remain constraint .
even lucki case , found solut violat remain constraint .
henc , one exploit properti build simpl random algorithm .
clarkson  algorithm ( clarkson , 1996 ) two-stag random sampl techniqu abl solv linear pro- gram problem , also appli general framework violat space .
violat space framework becom well-establish tool field geometr optim , develop subexponenti algorithm start random- ize variant simplex method .
class violat space includ problem comput minimum-volum ball ellipsoid enclos given point set rd , problem find distanc two convex polytop rd mani computa- tional geometri problem ( gartner , j. matousek , p.skovron , 2008 ) .
general violat space problem make applic number non-linear most geometr problem .
clarkson  algorithm stage base random sampl conceptu simpl .
shown particular optim problem correspond author .
email : gesposit @ lsi.upc.edu 1 novemb 21 , 2014 appli artifici intellig ( aai ) journal main regard violat space problem , certain algorithm primit implement , clarkson  algorithm immedi applic .
machin learn , transduct support vector machin ( tsvm ) ( vapnik , 1995 ) extend well know support vector machin handl partial label dataset .
tsvm learn maximum margin hyperplan classifi use label train data present unlabel data insid margin .
unfortun , deal tsvm impli solv non convex optim problem .
wide spectrum approx- imat techniqu appli solv tsvm problem ( chapell , 2008 ) , guarante find optim global solut .
fact , state-of-the-art approxim tsvm method appli differ benchmark problem , far optim solut found ( chapell , 2008 ) .
unfortun exact method appli small dataset due exponenti time complex cost respect number instanc .
( j. , y. , j. , o. , 2008 ) balcazar et alt .
sug- gest hard margin svm belong class violat space , propos random sampl techniqu determin maximum margin separ hyperplan .
note problem solv svm convex solv tsvm non convex problem , differ natur .
paper prove global optim solut tsvm total reli knowledg support vector set , gather size smaller whole set instanc .
moreov , also demonstr tsvm formul violat space problem allow use clarkson  algorithm find optim global solut .
foster tsvm sparsiti properti , introduc random algorithm abl reduc time complex- iti exact method , scale exponenti w.r.t .
number support vector optim solut instead exponenti w.r.t .
number instanc .
use method one may find exact solut independ number instanc problem support vector .
includ problem dimension featur space relat small .
2 .
violat space random algorithm violat space problem introduc abstract framework random al- gorithm abl solv linear program variant simplex algorithm .
com- putat geometri , exampl problem solv use method smallest enclos ball ( seb ) .
goal comput smallest ball enclos set n point dimension space ( fig .
1 ) .
follow introduc main tool abstract framework violat space order show random- ize method devis comput geometri also appli solv tsvm problem .
detail proof report properti found ( gartner et al. , 2008 ) .
definit 1 : abstract lp-type problem consist finit set h , repres constraint problem , weight function w give g  h cost w ( g ) w optimum solut , w linear order ( w ,  ) .
( h , w , w ,  ) satisfi :  monoton : f  g  h w ( f )  w ( g )  local : f  g  h h  h w ( f ) = w ( g ) w ( g ) < w ( g  { h } ) w ( f ) < w ( f  { h } ) g  h basi inclusion-minim subset b  h w ( g ) = w ( b ) .
combinatori dimens  lp-type problem size largest basi .
violat g addit constraint h  h w ( g ) 6= w ( g  h ) .
2 novemb 21 , 2014 appli artifici intellig ( aai ) journal main extrem violat figur 1 .
smallest enclos ball : extrem ( red encircl red ) point essenti solut , violat ( blue ) point lie outsid ball , basi minim set point ball element h extrem g w ( g  { h } ) 6= w ( g ) .
definit h violat g  h extrem g { h } .
set constraint violat g call violat map v ( g ) : = { h  h : w ( g ) < w ( g  { h } ) } .
use violat map possibl phrase term violat test lp-type problem neglect explicit evalu w : definit 2 : violat space pair ( h , v ) h finit set v map .
( h , v ) satisfi :  consist : g  v ( g ) = hold g  h  local : f  g  h g  v ( f ) = v ( g ) = v ( f ) .
given lp-type problem ( h , w , w ,  ) pair ( h , v ) violat space general framework appli random algorithm describ later .
violat space ( h , v ) combinatori dimens  , order setup basi evalu algorithm need defin follow primit oper : primit 1 : ( violat test ) ( h , v ) violat space implicit defin prim- itiv : given g  h h  h\g decid whether h  v ( g ) consid suitabl violat space defin v ( r ) : = { h  g\r | w ( r  { h } ) 6= w ( r ) } set violat r x ( r ) : = { h  r | w ( r\ { h } ) 6= w ( r ) } set extrem r. follow result hold : lemma 2.1 ( sampl lemma ) : set r size r uniform chosen random set ( g r ) r-element subset g ( |g| = n ) , defin two random variabl vr : r 7 |v ( r ) | xr : r 7 |x ( r ) | expect valu vr : = e ( vr ) , xr : = e ( xr ) .
0  r  n vr = xr+1 nrr+1 .
3 novemb 21 , 2014 appli artifici intellig ( aai ) journal main therefor violat space |h| = n combinatori dimens  choos subset r , sampl lemma bound expect number violat trough vr   nr r+1 .
clarkson ( clarkson , 1996 ) envisag smart random algorithm abl solv viola- tor space problem reli expect number violat bound accord sampl lemma .
seb case , w repres radius ball , h set constraint requir point insid ball , violat point outsid ball .
prove seb violat space problem clarkson  algorithm use solv .
algorithm proceed round maintain vote box initi contain one vote slip per point .
round , set r r vote slip drawn random without repetit vote box seb correspond set r comput .
new round number vote slip violat point doubl .
algorithm termin soon violat ( point outsid ball ) .
r  d2 , expect number round ( log n ) reduc problem size n ( log n ) problem size ( d2 ) .
clarkson  algorithm problem find basi solv use trivial algorithm abl find solut subset size . clarkson  basis2 algo- rithm call trivial algorithm subroutin , increas probabl obtain base iter .
consid g multiset  ( h ) ( initi set one ) de- note multipl h. set f  g compound multipl element f  ( f ) : =  hf  ( h ) .
sampl g done envisag contain  ( h ) copi everi element h. round , amount violat thresh- old , basis2 doubl multipl  ( weight ) violat point , increment probabl select base next round .
converg basis2 algorithm reli fact trivial correct .
iter loop success chang weight element .
estim mani unsuccess iter pass two success one , sampl lemma bound use .
henc , shown k  success iter hold 2k  e [  ( b ) ]  n ek/3 everi basi b g |g| = n particular k < 3 log n. summar clarkson  algorithm basis2 comput basi g expect number 6n log n call primit 1 , expect number 6 log n call trivial set size 62 .
3 .
transduct support vector machin tsvm describ train set l label exampl { ( xi , yi ) } xi  rd label yi = { 1 } = 1 , ... , l i.i.d .
accord unknown distribut p ( x , ) togeth u unlabel exampl { xk } k = l + 1 , ... , n n = l + u total number exampl , distribut accord distribut p ( x ) .
consid w vector normal hyperplan constant b , problem formul find vector label yu = { yl+1 , ... , yn } ( yi = { 1 } ) maxim geometr margin separ hyperplan ( w , b ) solv : 4 novemb 21 , 2014 appli artifici intellig ( aai ) journal main ( w , b , yu ) = min ( w , b , yu ) w22 2 + c l i=1  p + c n k=l+1  p k ( 1 ) subj .
yi ( w t ( xi ) + b )  1 i i  0 1   l yk ( w t ( xk ) + b )  1 k k  0 l + 1  k  n p = 1 2 respect linear ( l1 ) loss quadrat ( l2 ) loss .
first term control general capac other , slack variabl i , number misclassifi sampl .
two regular paramet ( c c  ) akin confid known label .
decis function hypothesi space f  f repres f ( xi ) = w t ( xi ) + b yi = sign ( f ( xi ) ) assum exist given hilbert h space map  : rd  h. map send exampl data featur space generat kernel satisfi mercer  condit .
work refer quadrat loss , sinc fix yu , associ hessian matrix posit definit bring object function uniqu strict convex .
moreov , optim problem consid comput stabl l2 loss .
howev , main result still appli l1 loss case .
earli , two main strategi adopt minim ( w , b , yu ) :  local approxim method : start tentat label yu perform local search space label , use effect heurist , maxim ( w , b , yu ) .
method sensibl local minima .
instanc , svm ligth method ( joachim , 1999 ) use local search algorithm find solut may fail deliv solut close global one .
 exact combinatori method : fix unlabel vector yu ( w , b , yu ) con- vert optim ( w , b ) standard svm .
combinatori method find global optim solut search entir space possibl label yu svm maximum margin .
focus exact combinatori optim j ( yu ) = min ( w , b ) ( w , b , yu ) , ob- jectiv becom minim j ( yu ) set binari variabl .
optim non convex belong comput class np-hard .
solv , instanc , use branch bound ( bb ) ( chapell , sindhwani , keerthi , 2006 ) integ program ( ip ) ( bennett demiriz , 1998 ) , comput demand larg number differ possibl label unlabel instanc .
3.1 .
critic analysi tsvm exact global solut examin optim problem show optim solut depend label unlabel data , label support vector optim solut due sparsiti properti svms .
observ 1 : assum set l label r unlabel exampl .
name yr vector label solv tsvm cost j ( yr ) ( i.e .
label instanc r lower cost ) .
consid svmyr induct svm label ( ylyr ) .
5 novemb 21 , 2014 appli artifici intellig ( aai ) journal main therefor , ad unlabel point x set l  r , lie outsid margin svmyr , induc optim label transduct problem l  r  { x } yr { x } = ( yr  { yx } ) ( yx label induc svmyr x ) .
proof .
assum exist differ label yr { x } better yr { x } j ( yr { x } ) < j ( yr { x } ) lead contradict .
consequ yr { x } must optim label .
fact , assumpt j ( yr { x } ) < j ( yr { x } ) due fact ad point x lie outsid margin svm yr chang svm solut follow j ( yr { x } ) = j ( yr ) .
final , stem j ( yr )  j (  r { x } ) ad one point given label increas leav unchang cost .
therefor j ( yr )  j (  r { x } ) < j ( yr { x } ) = j ( yr ) consequ j (  r ) < j ( yr ) contradict , due hypothesi yr repres optim label set r. observ 2 : assum set l label u unlabel exampl .
consid subset r  u given vector label yr solv tsvm set l  r svmyr induct svm label ( yl  yr ) .
assum  point u \ r lie insid margin svmyr .
case , optim label tsvm lu repres ylu = ( yl yu ) , yu vector label induc solut svmyr set u .
proof .
prove appli observ 1 point u \ r. start label vector yr , notic point u \ r lie outsid margin svm yr iter appli observ 1 end global solut l  u .
observ 3 : necessari condit find global optim solut set point l  u use subset l  r r must contain support vector global optim solut l  u proof .
prove appli observ 2 .
note optim solut l  u built l  r. condit point u \ r lie insid margin .
henceforth ,  support vector u \r r. accord observ may come follow conclus : given tsvm , data point may unnecessari build global optim solut .
set support vector complet defin global optim solut ( tsvm sparsiti properti ) .
suggest feasibl obtain tsvm optim global solut set l  r includ whole set support vector .
therefor question becom get right subset point .
claim tsvm solut may obtain work reduc subset exampl l  r comput leverag |r|  |u| .
notic , tsvm may show build violat space solv problem use random algorithm .
worth note method might practic use whenev number support vector solut tsvm problem scale ( log n ) , usual case .
howev , method still appli solut support vector dimens featur space problem relat small .
6 novemb 21 , 2014 appli artifici intellig ( aai ) journal main 4 .
random algorithm tsvm section readi show tsvm problem belong class violat space .
therefor , clarkson  algorithm use find optim global solut .
case , weight function w repres ( w , b , yu ) evalu subset constraint l  r  l  u combinatori dimens depend number support vector .
given subset partial label point , tsvm global optim solut ( basi ) obtain use exact method like ip bb ( trivial algorithm ) .
moreov need defin violat test clarkson  algorithm reli probabl select basi increas weight violat point .
show violat easili detect remain point lie tsvm separ margin .
tsvm may also arous formul term violat space problem .
endow constrain formul tsvm problem violat space definit formal propos : proposit 4.1 : given tsvm constraint hf , wf ( gf ) : 2 hf wf map- ping defin subset gf  hf wf ( gf ) = minhf f ( gf ) = f ( wg , bg , yg ) wf bound linear order  , quadrupl ( hf , wf , wf ,  ) repres associ violat space problem .
order verifi local monoton need prove lemma : lemma 4.2 : given tsvm constraint hf subset gf  hf global optimum f ( gf ) , ad constraint hf  hf gf chang global optimum accord f ( gf )  f ( gf  hf ) proof .
lemma may easili prove contradict .
suppos lemma true f ( gf ) > f ( gf  hf ) .
solut tsvm problem set constraint gf  hf also feasibl solut tsvm problem set constraint gf .
henc hypothesi f ( gf ) > f ( gf hf ) contradict minim tsvm solut f ( gf ) .
howev , need provid primit build violat space , need construct proof lemma follow increment solut tsvm .
therefor consid subset constraint gf  hf , get object f ( gf ) mean find global optim solut tsvm problem use subset label unlabel data lr  lu .
exact method quest global optimum subset constraint gf entail among 2 r possibl configur vector label yr , cast correspond svm minimum object f ( gf ) solv dual problem written w ( s , b ) .
ad anoth constraint gf  hf vector label yr+1 mean among 2r+1 possibl configur , select correspond svm minimum object f ( gf  hf ) solv dual express w (   ,   h , b  ) .
henc , relationship two object valu found consid increment train analysi svm report ( cauvembergh poggio , 2001 ) differ case gather quadrat loss .
svm dual problem might obtain introduc i  r+ lagrangian multi- plier consid optim solut thekkt condit must satisfi .
elimin w , i ( note quadrat loss i 6= 0 i 6= 0 ) one get dual problem w (  , b ) = max ( r+ , br ) s i=1 i  1 2 s , j=1 yiyjij ( k ( xi , xj ) + ij c ) + b s i=1 iyi 7 novemb 21 , 2014 appli artifici intellig ( aai ) journal main ( c = c c accord ) defin  = [ ij ] = [ yiyjk ( xi , xj ) + ij c ] ( ij = 1 = j , 0 otherwis ) , kkt condit support vector ( i 6= 0 ) s i=1 yii = 0 gs = yif ( xi ) + i  1 = 0 defin vector  equival express compact form [ 0  ] [ b  ] = [ 0 1 ] ( 2 ) kkt non support vector ( i = 0 ) express gr = yif ( xi )  1  0 .
final solut dual problem s give maximum valu w ( s ) substitut kkt condit defin s = ( 0 ts ys s ) written w ( s ) = 1 2 ts ss .
increment train ad new point h consist adiabat increment h start h = 0 chang paramet kkt condit point h fulfil .
increment h done ensur kkt condit point maintain .
follow ,  defin differ new alpha valu   old valu  .
kkt condit h updat connect variat support vector s , b ad one h accord :   0 gs gr gh   =   0 yts ys ss yr rs yh hs   [ b s ] +   yh ths thr thh  h support vector gs = 0 [ b s ] =  [ 0 yts ys ss ] 1 [ yh ths ] h = q1s zhh ( 3 ) gather [ gr gh ] = [ yh hs yr rs ] [ b s ] + [ thr thh ] h tackl equat may infer chang due presenc new data function h .
unfortun , generic valu h direct use system obtain new state , due possibl chang composit set support vector non support vector h increas .
handl situat demand book keep possibl adiabat modif .
, procedur consist increment h maximum one follow case aris : problem solv , keep kkt condit point forc 8 novemb 21 , 2014 appli artifici intellig ( aai ) journal main chang set support vectors1 .
particular deal increment h > 0 may bring chang support vector composit depend amount h .
detail possibl situat :  h = 0 gh  0 , new point chosen label yh  chang set support vector keep solut w ( s )  h > 0 gh = 0 ( g valu increment h ) , new point chosen label yh new support vector support vector set chang composit ( migrat ) henc new kkt written as  0 yts yhys ss ths yh sh hh     bs   h   =  01 1   ensu connect old solut across sherman-morison-woodburi formula block matrix invers  0 yts yhys ss ths yh sh hh  1 = [ q1s 0 0 0 ] + q1h [ q1s zh 1 ] [ zthq 1 1 ] qh = [ qs zh 1 ]  0 yts yhys ss ths yh sh hh   [ qs zh 1 ] = hh  zthq 1 zh ( 4 ) qh  0 due semidefinit posit kernel wherefrom express updat valu h =   h = max ( 0 , 1 yhb shs ) hh  zthq 1 zh = 1 yhf ( xh ) qh = h qh [ b    ] = [ b s ] q1s zhh use h = max ( 0 , 1 yhf ( xh ) ) optimum updat w (   ,   h ) = w ( s ) + 1 2 2hqh = w ( s ) + 1 2 2h qh entail w ( s )  w (   ,   h )  h > 0 gh < 0 , new point chosen label yh new support vector support vector set chang composit .
quadrat loss 1note case quadrat loss need divid set point two set : support ( ) other ( ) , case linear loss , point belong three differ set : support ( ) , error ( e ) other ( ) .
9 novemb 21 , 2014 appli artifici intellig ( aai ) journal main mean two possibl : weather one support vector , say k k > 0 gk = 0 , becom non support vector henc   k = 0 g  k  0 viceversa ( k = 0 gk  0   k > 0 g  k = 0 ) .
one case g  h < 0 condit hold .
set support vector chang increment h ( chang increment ) , global optimum increment accord may evalu : w (   ,   h ) = 1 t  +   h  1 2 [     h ] [ ss sh hs hh ] [     h ] w ( s , h ) = 1 ts + h  1 2 [ s h ] [ ss sh hs hh ] [ s h ]   = s + s   h = h + h allow evalu global optimum increment w = w (   ,   h ) w ( s , h ) .
use equat ( 3 ) express chang global optimum function h written : g  h = 1 + b  yh + s j=1 hj  j + hh  h < 0 gh = 1 + byh + s j=1 hjj + hhh < 0 one easili show w = 1 2 qh 2 h  gh h  0 gh negat ( see assumpt case ) qh alway posit .
assum set equat describ evolut i point chang step .
howev , increas h , check kkt condit still verifi .
consequ , condit longer fulfil given point , status chang ( support non support vector vice versa depend case ) therefor equat must modifi accord bookkeep .
final remain see object function still monoton chang equat support vector set .
easi see l2 loss bookkeep chang valu object function .
fact bookkeep necessari one support vector becom non-support vector way round .
case , k point chang status 0 ( point new support vector k increas 0 , leav status support vector , alpha valu decreas 0 ) .
k = 0 ad remov modifi object function .
consequ object function chang bookkeep .
10 novemb 21 , 2014 appli artifici intellig ( aai ) journal main end conclus increment svm optimum grow monoton- ical .
henceforth , use exact method solv tsvm gf mean look global optim solut among 2r svms , correspond possibl label f ( gf ) = min { yr 1 : 2r | w ( s , b ) } gf  hf look global optim solut among 2r+1 svms , correspond possibl label f ( gfhf ) = min { yr+1 1 : 2r+1 | w (   ,   h , b  ) } may realiz label global optimum gf , except new constraint hf , may differ label correspond global optimum gf  hf .
therefor , thank fact svm global optim solut monoton increas move gf gf  hf global optim solut exact method seek minimum among possibl svms follow f ( gf )  f ( gf  hf ) .
last lemma provid monoton increment optim solut tsvm allow infer ( hf , wf , wf ,  ) repres violat space ( lp-type ) problem report proof proposit 4.1 .
proof .
need show monoton local hold :  monoton : given subset constraint ff gf ff  gf  hf alway build gf ff incremen- tal process ad new constraint h  hf\ff .
lemma ( 4.2 ) follow f ( ff )  f ( gf )  local : given subset constraint ff gf ff  gf  hf constraint h  hf .
f ( ff ) = f ( gf ) two set entail global solut .
ad increment constraint h  hf subset gf f ( gf )  f ( gf  { h } ) convey new constraint chang global solut .
consequ ad h  hf ff also chang global solut f ( gf ) = f ( ff )  f ( ff  { h } ) face definit associ violat space problem tsvm , basi repres set support vector global solut , cardin largest one combinatori dimens .
stage shown inde feasibl formul tsvm violat space problem .
addit , adopt clarkson  algorithm may also use violat map violat test .
primit 2 : ( tsvm violat test ) given tsvm global solut f ( gf ) subset constraint gf decis function fgf ( xh ) , constraint h  hf\gf violat solut ( h  vf ( gf ) ) , h = max ( 0 , 1 yhfgf ( xh ) )  0 label obtain yh = sign ( fgf ( xh ) ) .
beforehand shown may associ violat space problem tsvm deal exact method get optim global solut .
remark , clarkson  random method viabl solv tsvm acquir basi use violat test primit 2 .
effici reli sparsiti properti tsvm .
5 .
algorithm implement exact method like integ program ( ip ) ( bennett demiriz , 1998 ) branch bound ( bb ) ( chapell et al. , 2006 ) investig tsvm .
basic 11 novemb 21 , 2014 appli artifici intellig ( aai ) journal main algorithm 1 stsvm ( xl , yl , xu , maxit , r ) requir : r = 2go  |xl xu| repeat choos xr random accord  distribut : xr  ( u r ) base ( objr , yr ,  , w , b ) : = bb ( xl , xr , yl ) // call branch bound yu\r : = sign ( f ( w , b ) ( xu\r ) ) // comput label ... 2 u\r : = max ( 0 , 1 yu\rf ( w , b ) ( xu\r ) ) 2 // ... slack vbase : = { h  u\r : u\r 6= 0 } // check violat  ( vbase )   ( u ) /g0  ( h ) : = 2 ( h ) , h  vbase // updat weight violat end objr : = objr + 1/2  u\r  2 u\r/qu\r // updat best ... basebest : = minobj ( base ( objr , yr ,  , w , b ) , basebest ) // ... known solut maxit vbase =  vbase = return base ( objr , yr ,  , w , b ) // global optimum els return basebest // best solut found end idea ip tsvm add integ decis variabl indic class point work set .
henc solut found use mix integ program code provid comput resourc suitabl size problem .
branch bound anoth method abl solv combinatori optim problem use enum techniqu implicit effici search entir space solut .
clear method , even exact tsvm could use implement trivial algorithm .
practic reason follow focus bb imple- mentat indic bbtsvm one devis chapell tsvm .
solv problem set binari variabl evalu j ( yu ) embodi induct svm .
bbtsvm minim 2u possibl choic yu .
node binari search tree , partial label data set generat corre- spond son cast label unlabel data .
core bbtsvm subroutin akin primit evalu svm data alreadi label proceed search tree .
svm usual solv constrain quadrat program- ming problem dual , also work primal unconstrain .
bbtsvm use method requir iter get approxim solut ( worst case ) complex ( n3 ) .
svm convex quadrat program problem polynomial-tim solvabl , current best method rais ( worst case ) complex ( n3/2d2 ) .
enumer process bbtsvm may reach complex ( 2nn3 ) ( 2nn3/2d2 ) depend svm solver use .
5.1 .
implement random tsvm set matter way , readi encompass detail implement random version exact method solv tsvm refer stsvm .
algorithm ( 1 ) implement stsvm slight revis clarkson  scheme .
general may ignor combinatori dimens correspond violat space .
fact , apart linear case , theoret bound number support vector practic use .
henceforth , start fix given 12 novemb 21 , 2014 appli artifici intellig ( aai ) journal main valu ro .
accord basis2 , stress probabl select given violat round doubl correspond weight whenev slack u\r 6= 0 .
quadrat loss implement exampl , u\r = u\r mean point would chang margin ad basi .
basic implement trivial make use implement exact method work random sampl l  r  l  u .
envisag , practic implement trivial make use bb .
howev , use differ exact algorithm provid implement trivial chang converg stsvm affect perform .
two stop condit foreseen : ( 1 ) vbase = ( violat condit : return global optimum ) ( 2 ) max number iter ( return best known solut ) .
last case best known solut repres minimum fbest = minobjr bb ( lr ) objr = objr +  ( vr ) = objr + 1/2  u\r  2 u\r/qu\r , qu\r correct factor increment updat equat 4 .
criterium take account objr best result bb , also minim violat contribut  ( vr ) .
implement bb abl optim undergo svm either primal dual formul quadrat linear loss .
5.2 .
converg complex stsvm appli sampl lemma , expect valu e [ vbase ] element u ( u = |u| ) violat random set r , ( cast r = 2g0 < rmax 1  g0   ) bound e [ |vbase| ]    ( u )  r r + 1 <   ( u ) 2g0 =  ( u ) 2g0 markov inequ predict pr ( |vbase|   ( u ) g0 )  pr ( |vbase|  2e [ |vbase| ] )  1/2 impli expect number round twice larg number success one .
let sv set support vector tsvm , success iter xi  sv  l  r henc  ( xi ) get doubl .
sinc |sv|   mean xi get doubl least everi  success round k round  ( xi )  2k/ .
hand , everi success round rais total weight ( 1 +  r ) = ( 1 + 1 2go ) give bound 2k/  e [  ( u ) ]  u ( 1 + 1 2g0 ) k  n e k 2g0  n e k 2 .
k success iter lower bound exceed upper k  2log n. final expect number violat test ( n log n ) expect number call bbtsvm g0log n = ( log n ) set r averag size r = 2g0 = (  2 ) ( rmax ) .
time complex stsvm show sparsiti properti allow relat gain respect use bb whole set data ( 2nn3/2d2 ) 13 novemb 21 , 2014 appli artifici intellig ( aai ) journal main 4 3 2 1 0 1 2 3 4 2.5 2 1.5 1 0.5 0 0.5 1 1.5 2 2.5 x 1 x 2 sbbtsvm twomoon complet 0 500 1000 1500 2000 2500 3000 3500 4000 4500 0 100 200 300 400 500 600 sv reduc index v r e u ce f q u e n cy ( ) ( b ) figur 2 .
( ) distribut exact solut two moon data set ( 4.000 unlabel , 2 label triangl cross ) .
( b ) weight distribut whole set point final round .
support vector optim solut encircl .
(  log n 2r ( r+ l ) 3/2d2 ) .
method effect number support vector much lower number instanc .
6 .
experi section briefli describ result obtain use propos random method two well known benchmark problem previous solv use exact method .
stsvm stand well known benchmark problem two moon com- pose 4.000 unlabel exampl ( figur 2 ) .
two moon problem report burdensom solv state-of-the-art transduct method ( chapell , 2008 ) .
tabl 1 show error rate produc method small data set contain 200 unlabel point .
method fall local minima far global one .
howev , problem solv previous appli bb space possibl label instanc ( chapell et al. , 2006 ) .
unfortun , albeit method abl find optim solut , exponenti time complex number unlabel instanc , consequ , abl solv two moon data set hundr unlabel instanc .
method describ paper find optim solut instead scale number instanc , scale number support vector .
case two moon , number support vector scale number point .
henceforth , face 4.000 unlabel exampl stsvm allow us find exact solut within minut .
stsvm also abl find exact solut anoth well known benchmark problem previous solv use exact method : coil20 data set ( describ ( nene , nayar , muras , 1996 ) ) .
contain 1440 imag 20 object photograph differ perspect ( 72 imag per object ) 2 label imag object .
coil20 belong multi-class problem common solv one- vs-all scheme .
scheme , build svm class assign label accord class return maximum output given point , measur confid classif point .
tabl 1 show success state-of-the-art transduct 14 novemb 21 , 2014 appli artifici intellig ( aai ) journal main data set svm s3vm cs3vm cccp s3vmlight da newton stsvm twomoon 50.2 61 37.7 63.1 68.8 22.5 11 0 coil3 66.6 61.6 61 56.6 56.7 61.6 61.5 0 coil20 24.1 25.6 30.7 26.6 25.3 12.3 24.1 1.4 tabl 1 .
error rate dataset supervis svm , state art transduct algorithm ( report ( chapell , 2008 ) ) , stsvm .
algorithm data set describ chapell ( 2008 ) .
bbtsvm abl solv problem , due larg number instanc , albeit manag coil3 pictur sole 3 class hard discrimin .
stsvm find solut 0 error coil3 data set tabl 1 illustr error produc state- of-the-art transduct method ( chapell ( 2008 ) ) .
last two column error rate l2 loss ( use search tree stsvm ) appli label exampl report , well result obtain stsvm one-vs- scheme act label unlabel .
remark , differ baselin result shown chapell ( 2008 ) , come differ loss use svm ( l2 case , l1 other ) .
even though stsvm might use differ loss , stress error reduct ( 10.9 % coil20 , 0 % coil3 ) , absolut valu .
howev , examin 20 tsvms produc one-vs-al scheme ( one class ) , may notic tsvms found 0 violat 100 iter solut 0 violat found , show right balanc posit negat exampl .
side , tsvms return solut 0 violat right rate posit negat exampl .
consid tsvms good predictor class repres keep .
point label posit class remov whole data set , deliv smaller one .
afterward , tri solv smaller data set appli one-vs-al scheme remain class .
problem simplifi , appear new good predictor class procedur repeat whole data set complet solv .
final error follow procedur 20 error 1400 unlabel initi exampl reduc error coil20 1.4 % .
quit remark irreduc error produc class 5 19 , last class method found good predictor .
seem 2 class hold maximum margin hypothesi addit constraint must use correct classifi ; fact modifi ratio amongst label unlabel larg increas former , problem correct solv .
7 .
conclus futur work paper , shown origin interpret tsvm problem term violat space , abl extend use exact method find optim solut scale time complex number support vector instead number point .
suitabl situat method appli dataset entail small amount support vector , independ size data set .
limit approach appear size support vector set higher hundr , common situat real data set .
futur , plan investig implement use spars svms formul , might allow extend applic method larger dataset .
also , preliminari experi larger benchmark dataset ( number support vector rang hundr ) show method , expect , 15 novemb 21 , 2014 appli artifici intellig ( aai ) journal main abl find optim solut reason time .
howev , case kept best solut describ section 5.1 .
case , return solut better return one svm label exampl .
experi encourag us explor error bound propos method tri appli find good approxim optim solut .
final , consid interest possibl interpret weight obtain exampl random method .
sampl high weight usual appear violat could help us identifi point interest final solut even method abl find exact one .
acknowledg work partial support fi-dgr programm agaur eco/1551/2012 .
refer k. bennett a. demiriz .
semi supervis support vector machin .
adv .
neural infor- mation process system , 12:368374 , 1998 .
g. cauvembergh t. poggio .
increment decrement support vector machin learn .
adv .
neural inform .
proces , mit press ( 13 ) :409415 , 2001 .
o. chapell .
optim techniqu semi supervis support vector machin .
journal machin learn research , 9:203233 , 2008 .
o. chapell , v. sindhwani , s. keerthi .
branch bound semi-supervis support vector machin .
adv .
neural inform proc .
system , 2006 .
k. l. clarkson .
las vega algorithm linear integ program dimens small .
journal acm , 42 , 1996 .
b. gartner , l.rust j. matousek , p.skovron .
violat space : structur algorithm .
discret appli mathemat , 156 ( 11 ) , 2008 .
balcazar j. , dai y. , tanaka j. , watanab o. provabl fast train algorithm support vector machin .
theori comput system , 2008 .
t. joachim .
transduct infer text classif use support vector machin .
intern confer machin learn , 1999 .
s. a. nene , s. k. nayar , h. muras .
columbia object imag librari ( coil-20 ) .
technic report , columbia univers , usa , 1996 .
v. vapnik .
natur statist learn theori .
springer , new york , 1995 .
16
